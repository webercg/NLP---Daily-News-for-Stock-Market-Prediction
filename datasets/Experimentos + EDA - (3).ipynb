{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualização de dados\n",
    "import seaborn as sns\n",
    "\n",
    "#Manipulação datas\n",
    "from datetime import datetime\n",
    "\n",
    "# Prototipação\n",
    "import sklearn\n",
    "#from sklearn.utils.testing import ignore_warnings\n",
    "#from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "#Pipeline e pré-process\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Model Tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "#print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Leitura dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de Noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_mes = {'Jan':'01', 'Fev':'02', 'Mar':'03','Abr':'04', 'Mai':'05', 'Jun':'06','Jul':'07', 'Ago':'08', 'Set':'09','Out':'10', 'Nov':'11', 'Dec':'12'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\1548341161.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df_leitura,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in dicionario_mes.keys():\n",
    "    arquivo = dicionario_mes[i] + \"_GoogleNews_Petr_\" + i + \"_21.csv\"\n",
    "    df_leitura = pd.read_csv(arquivo, sep='|')\n",
    "    df = df.append(df_leitura,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>01/01/2021</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Refinaria Abreu e Lima da Petrobras, a RNEST p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>01/01/2021</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Dicas de Tony Robbins para Ficar Rico Invest...</td>\n",
       "      <td>The Capital Advisor</td>\n",
       "      <td>01/01/2021</td>\n",
       "      <td>O QUE LER AGORA... ibovespa-sobe-021-apos-demi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acadêmicos de engenharia Mecânica criam projet...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>01/01/2021</td>\n",
       "      <td>Petrobras cancela a venda da fábrica de fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinacional dinamarquesa European Energy faz...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>01/01/2021</td>\n",
       "      <td>Petrobras encerra sociedade com a Sete Brasil ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A construção naval brasileira tem chances de a...   \n",
       "1  Refinaria Abreu e Lima da Petrobras, a RNEST p...   \n",
       "2  5 Dicas de Tony Robbins para Ficar Rico Invest...   \n",
       "3  Acadêmicos de engenharia Mecânica criam projet...   \n",
       "4  Multinacional dinamarquesa European Energy faz...   \n",
       "\n",
       "                      media        date  \\\n",
       "0  CPG Click Petroleo e Gas  01/01/2021   \n",
       "1  CPG Click Petroleo e Gas  01/01/2021   \n",
       "2       The Capital Advisor  01/01/2021   \n",
       "3  CPG Click Petroleo e Gas  01/01/2021   \n",
       "4  CPG Click Petroleo e Gas  01/01/2021   \n",
       "\n",
       "                                                desc  \n",
       "0  Dentre os principais pontos do plano estratégi...  \n",
       "1  Petrobras informou em fato relevante na última...  \n",
       "2  O QUE LER AGORA... ibovespa-sobe-021-apos-demi...  \n",
       "3  Petrobras cancela a venda da fábrica de fertil...  \n",
       "4  Petrobras encerra sociedade com a Sete Brasil ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/01/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/02/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/03/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/04/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/05/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/06/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/07/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/08/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/09/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '19/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/11/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '13/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '14/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '15/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '16/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '17/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '18/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '20/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '21/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '22/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '23/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '24/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '25/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '26/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '27/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '28/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '29/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '30/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "C:\\Users\\lenon.oliveira\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1047: UserWarning: Parsing '31/12/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title            object\n",
       "media            object\n",
       "date     datetime64[ns]\n",
       "desc             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando coluna data para datetime:\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos pregões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>20.747751</td>\n",
       "      <td>67136300</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Adj Close    Volume      Var%\n",
       "0  2021-01-04  19.274340  74719700  0.020113\n",
       "1  2021-01-05  20.027718  95181100  0.039087\n",
       "2  2021-01-06  20.067719  96562500  0.001997\n",
       "3  2021-01-07  20.667747  56171300  0.029900\n",
       "4  2021-01-08  20.747751  67136300  0.003871"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro = pd.read_csv('Hist_Preço_Petr_2021_.csv', sep='|')\n",
    "df_petro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         datetime64[ns]\n",
       "Adj Close           float64\n",
       "Volume                int64\n",
       "Var%                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando a coluna Date para datetime\n",
    "df_petro['Date'] = pd.to_datetime(df_petro['Date'])\n",
    "df_petro.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 EDA\n",
    "**H1:** Há uma média razoável de noticias diárias   - **VERDADEIRO**  \n",
    "**H2:** Há poucos dias sem noticias na base de dados  - **VERDADEIRO**   \n",
    "**H3:** Há dias em que o pregão da bolsa não funciona (Finais de Semana) **VERDADEIRO**  \n",
    "**H4:**  \n",
    "**H5:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 H1: Há uma média razoável de noticias diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-01-01    10\n",
       "2021-06-08    10\n",
       "2021-08-27    10\n",
       "2021-08-26    10\n",
       "2021-08-25    10\n",
       "              ..\n",
       "2021-08-15     2\n",
       "2021-03-22     2\n",
       "2021-04-04     2\n",
       "2021-02-14     2\n",
       "2021-07-25     1\n",
       "Name: date, Length: 327, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2021-04-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "0   2021-01-01    10\n",
       "1   2021-06-08    10\n",
       "2   2021-08-27    10\n",
       "3   2021-08-26    10\n",
       "4   2021-08-25    10\n",
       "..         ...   ...\n",
       "322 2021-08-15     2\n",
       "323 2021-03-22     2\n",
       "324 2021-04-04     2\n",
       "325 2021-02-14     2\n",
       "326 2021-07-25     1\n",
       "\n",
       "[327 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coletando as datas e as frequencias de noticias:\n",
    "datas = df.date.value_counts()  \n",
    "data_df = datas.reset_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    datetime64[ns]\n",
       "date              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando os tipos dos dados\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-08-25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2021-04-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "0   2021-01-01    10\n",
       "1   2021-06-08    10\n",
       "2   2021-08-27    10\n",
       "3   2021-08-26    10\n",
       "4   2021-08-25    10\n",
       "..         ...   ...\n",
       "322 2021-08-15     2\n",
       "323 2021-03-22     2\n",
       "324 2021-04-04     2\n",
       "325 2021-02-14     2\n",
       "326 2021-07-25     1\n",
       "\n",
       "[327 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alterando para o formato datetime\n",
    "data_df['index'] = pd.to_datetime(data_df['index'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "98  2021-12-27    10\n",
       "97  2021-12-28    10\n",
       "96  2021-12-29    10\n",
       "95  2021-12-30    10\n",
       "216 2021-12-31    10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organizando o dataframe em ordem cronologica\n",
    "data_df.sort_values(by = 'index', ascending = True, inplace = True) \n",
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.253823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.772258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date\n",
       "count  327.000000\n",
       "mean     9.253823\n",
       "std      1.772258\n",
       "min      1.000000\n",
       "25%     10.000000\n",
       "50%     10.000000\n",
       "75%     10.000000\n",
       "max     10.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há uma média de 9.25 (+- 2) noticias por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Datas', ylabel='Num_Noticias'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizando data vs quantidade de notícias\n",
    "data_df.columns = ['Datas', 'Num_Noticias']\n",
    "sns.lineplot(x = 'Datas', y = 'Num_Noticias', data = data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Noticias</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.655172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Num_Noticias\n",
       "Mes              \n",
       "1        9.444444\n",
       "2        8.888889\n",
       "3        8.666667\n",
       "4        9.000000\n",
       "5        9.642857\n",
       "6        9.185185\n",
       "7        8.884615\n",
       "8        9.535714\n",
       "9        9.642857\n",
       "10       9.357143\n",
       "11       9.038462\n",
       "12       9.655172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inserindo coluna de mês\n",
    "data_df['Mes'] = data_df['Datas'].dt.month\n",
    "\n",
    "# Calculando media de noticias por mês\n",
    "df_noticia_mes = data_df.groupby('Mes').agg({'Num_Noticias':np.mean})\n",
    "df_noticia_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x244dafc0c40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x540 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando distribuição da quantidade de noticias ao longo dos meses\n",
    "sns.catplot(x=\"Num_Noticias\", col=\"Mes\", col_wrap=4,\n",
    "                data=data_df,\n",
    "                kind=\"count\", height=2.5, aspect=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x244dbe1b6d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB6YAAAD0CAYAAAA49UgIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApEklEQVR4nO3dfbRkZ10n+u8vaRCEGMIkYLrTbZDhAlF5s40avBqHUUPmOgEHCeBFFoOTuBQGfFsX5S7Ge12zZAbE6AhKBAachRBmIICKBC4y4BgEQsgrAXkRSXN6SCJcAuhFQ577x6mGQ9Mvp0/XruepOp/PWnudql177+e363zr5Zxf7V3VWgsAAAAAAAAATOWE3gUAAAAAAAAAsNo0pgEAAAAAAACYlMY0AAAAAAAAAJPSmAYAAAAAAABgUhrTAAAAAAAAAExKYxoAAAAAAACASWlML1hVtar6Lxuu76iqW6vqjxdcx4Oq6t1V9aWq+sVFjk0/A+XvJ6rqutl0ZVU9dJHj089AGbxglr9rquqqqvq+RY5PH6Pkb8P431VVX66qx/UYn8UaJX9VdW5VfW72/HdNVT13kePTzygZnI197ix/N1bVOxc9Pos3Sv6q6pc2PP/dMHsdvvcia6CPgTJ4clX9UVVdO3sOfOoix6ePgfJ3SlVdPvtb+L1V9e2LHJ/FGShzh/3/c1WdV1UfrqqPVtWzF1kX01uSDL68qm6pqhsWWRPTGz1/VbW7qt5RVTfN3g8+c5F1jWBH7wK2oS8m+faquntr7e+T/FCST3Wo4zNJ/m2Sx3QYm35Gyd9fJ/mB1tpnq+rRSS5N8t0d6mDxRsng25O8qbXWquohSV6b5EEd6mCxRslfqurEJP8hyRU9xqeLYfKX5M9ba/9bp7HpZ4gMVtW9krw4yXmttU9W1X0WXQNdDJG/1trzkzw/SarqR5P8XGvtM4uugy6GyGCSn03ywdbaj1bVaUk+XFWvaq39Q4daWJxR8vcrSa5prT22qh6U5EVJHtWhDqY3SuYO+f/n2d/DL8p6XfuSvK+q3tRa++DCK2QqQ2dw5hVJfifJHyywHhZj9PzdkeQXWmtXV9VJSd5fVW/bTs+Bjpju40+T/IvZ5ScmefWBG6rqHrNP67yvqj5QVRfM5n/b7NOM18w+2fiA4ymgtXZLa+19Sf7xeLbDUhohf1e21j47u/qXSc44nu2xdEbI4Bdaa2129R5J2pGWZ6V0z9/MM5K8Lsktc9gWy2OU/LF9jZDBJyV5fWvtk8n63yXHuT2Wxwj52+hramBbGCGDLclJVVVJ7pn1f1jecZzbZDmMkL+zsv4h7bTWPpTkzKq673Fuk3F1z9wR/v98dpKPttY+PvtgzmuSXHA8YzGkkTOY1tq7sv46zGoaNn+ttf2ttatnlz+f5KYku45nrGWjMd3Ha5I8oaruluQhSd6z4bbnJPmz1tp3JfnBJM+vqnsk+ekkv9Vae1iSvVn/NNnXqKrL6qunJds4/eTUO8RSGS1/T8v6CwXbxxAZrKrHVtWHkvxJkn89zx1kaN3zV1W7kjw2ye/Ne+cYXvf8zXxvrZ9C9E+r6tvmuH+Mb4QM/i9JTqmq/15V7/e3yrYyQv4OrPONSc7L+ofE2D5GyODvJHlwkrUk1yd5ZmvtzjnuI+MaIX/XJvmx2XpnJ/mWOFBglY2QucPZleTmDdf3ZZs1ZbaJkTPI6luK/FXVmUkeflB9K8+pvDtorV03C9wTk7z5oJt/OMm/rK+ec/5uSfYkeXeS51TVGVk/wuAjh9juhdNVzaoYKX9V9YNZb0z7ft9tZJQMttYuT3J5VX1/kl9L8s+PaUdYSoPk75Ik/0dr7ctVdYx7wDIbJH9XJ/mW1toXqur8JG9I4ijsbWKQDO5I8p1ZP3Xo3ZO8u6r+srX2V8e0MyydQfJ3wI8m+Qun8d5eBsngjyS5Jsk/S3L/JG+rqj9vrd1+LPvC8hkkf89L8ltVdU3WPxjxgThif2UNkrnDOdQfws5kt2IGzyArbhnyV1X3zPoHZZ+13d4Lakz386YkL0hybpJ/smF+JflXrbUPH7T8TVX1nqyffuCKqvqp1tqfbVygqi5L8sBDjPXC1prvSmCj7vmr9e/1fWmSR7fW/nbLe8Ky6p7BA1pr76qq+1fVqa2127awLyyf3vnbm+Q1s6b0qUnOr6o7Wmtv2OL+sFy65m/jHzuttTdX1Ys9/207vZ8D9yW5rbX2xSRfrKp3JXloEo3p7aF3/g54QpzGe7vqncGnJnne7GuFPlpVf53kQUneu9UdYqmM8D7wqbP1KslfzyZWV+/nvMPZl2T3hutnZP1MEqyeUTPI9jBs/qrqLllvSr+qtfb6za63KjSm+3l5ks+11q6vqnM3zL8iyTOq6hmttVZVD2+tfaCqvjXJx1trvz27/JAkX/Og8GkhjkHX/FXVniSvT/JkR8dsW70z+E+TfGw2xiOS3DWJD0hsH13z11q734HLVfWKJH+sKb2t9H7+++Ykn56NcXbWv9rH89/20vvvkDcm+Z2q2pH119/vTvKbx7E/LJfe+UtVnZzkB5L878ezIyyt3hn8ZNbPGPHntf7dvg9M8vHj2B+WS+/3gfdK8ndt/Tt9fyrJu7bbEVrbUO/nvMN5X5IHVNX9knwq6x8Ye9Ictst4Rs0g28OQ+Zt9OOxlSW5qrb3weLe3jHzHdCettX2ttd86xE2/luQuSa6rqhtm15PkwiQ31Prpdh6U5Lg+/VNV31xV+5L8fJL/s6r2VdU3Hc82WR6985fkuVn/lNKLa/07GK46zu2xZAbI4L/asL0XJblwdtQC28AA+WMbGyB/j5tt79okv53kCZ7/tpfeGWyt3ZTkLUmuy/oRgi9trd1wPNtkefTO38xjk7x1dtQ+28wAGfy1JOdU1fVJ3p71r3dx1pJtYoD8PTjJjVX1oSSPTvLM49weg+uducP9/7m1dkeSp2e9OXRTkte21m48nrEY06gZnN326qyfuvmBs/lPO56xGM/A+Xtkkicn+Wf11e+oPv94xlo25f9QAAAAAAAAAEzJEdMAAAAAAAAATEpjGgAAAAAAAIBJaUwDAAAAAAAAMCmNaQAAAAAAAAAmtRSN6fPOO68lMZmOZZob+TNtYZorGTRtYZob+TNtYZob+TNtYZorGTRtYZob+TNtYZorGTRtYZob+TNtYZob+TNtYZorGTRtYZob+TNtYTomS9GYvu2223qXwDYmf/Qmg/Qkf/Qkf/Qmg/Qkf/Qmg/Qkf/Qkf/Qmg/Qkf0xtKRrTAAAAAAAAACwvjWkAAAAAAAAAJqUxDQAAAAAAAMCkNKYBAAAAAAAAmJTGNAAAAAAAAACT0pgGAAAAAAAAYFIa0wAAAAAAAABMSmMaAAAAAFbUrt17UlVzmXbt3tN7dwAAWGI7ehcAAAAAAExjbd/NufAlV85lW5ddfM5ctgMAwPbkiGkAAAAAAAAAJqUxDQAAAAAAAMCkJmtMV9XuqnpHVd1UVTdW1TNn83+1qj5VVdfMpvOnqgEAAAAAAACA/qb8juk7kvxCa+3qqjopyfur6m2z236ztfaCCccGAAAAAAAAYBCTNaZba/uT7J9d/nxV3ZRk11TjAQAAAAAAADCmKY+Y/oqqOjPJw5O8J8kjkzy9qn4yyVVZP6r6s4dY56IkFyXJnj17FlEmfIX80ZsM0pP80ZP80ZsM0pP80ZsM0pP80ZP80ZsM0pP8ccBjHv+k7L/161q2SZLTTzslb3jtHx73GJN9x/QBVXXPJK9L8qzW2u1JfjfJ/ZM8LOtHVP/GodZrrV3aWtvbWtt72mmnTV0mfA35ozcZpCf5oyf5ozcZpCf5ozcZpCf5oyf5ozcZpCf544D9t34293vicw85Ha5hfawmbUxX1V2y3pR+VWvt9UnSWvt0a+3LrbU7k/x+krOnrAEAAAAAAACAviZrTFdVJXlZkptaay/cMP/0DYs9NskNU9UAAAAAAAAAQH9Tfsf0I5M8Ocn1VXXNbN6vJHliVT0sSUvyiSQXT1gDAAAAAAAAAJ1N1phurf2PJHWIm9481ZgAAAAAAAAAjGfS75gGAAAAAAAAgClP5Q0AAHBMdu3ek7V9Nx9xmZ1n7M6nbv7kgioCAGBqZ33HQ7O2tv+oy+3ceXo+eP21C6gIAJiCxjQAADCMtX0358KXXHnEZS67+JwFVQMAwCKsre3Peb/+xqMu95ZfvmAB1QAAU3EqbwAAAAAAAAAmpTENAAAAAAAAwKQ0pgEAAAAAAACYlMY0AAAAAAAAAJPSmAYAAAAAAABgUhrTAAAAAAAAAExKYxoAAAAAAACASWlMAwAAAAAAADApjWkAAAAAAAAAJqUxDQAAAAAAAMCkNKYBAAAAAAAAmJTGNEPatXtPquqo067de3qXypLZbLbkDwBgtW31faH3gAAAALA1O3oXAIeytu/mXPiSK4+63GUXn7OAalglm83WZsgfAMDy2ur7Qu8BAQAAYGscMQ0AAAAAAADApDSmAQAAAAAAAJiUxjQAAAAAAAAAk9KYBgAAAAAAAGBSO3oXAAAAAAAAMJo777wza2trSZKdO3fmhBMc6wdwPDyLAgBsE7t270lVzWXatXtP790BAACASa2treWpL74iT33xFV9pUAOwdY6YBgDYJtb23ZwLX3LlXLZ12cXnzGU7AAAAMLK7n3xq7xIAVoYjpgEAAAAAAACYlMY0AAAAAAAAAJOarDFdVbur6h1VdVNV3VhVz5zNv3dVva2qPjL7ecpUNQAAAAAAAADQ35RHTN+R5Bdaaw9O8j1Jfraqzkry7CRvb609IMnbZ9cBAAAAAAAAWFGTNaZba/tba1fPLn8+yU1JdiW5IMkrZ4u9MsljpqoBAAAAAAAAgP4W8h3TVXVmkocneU+S+7bW9ifrzesk9znMOhdV1VVVddWtt966iDLhK+SP3mSQnuSPnuSP3mSQnuRvtezavSdVNfdp1+49k9Usg/Qkf/Qkf/Qmg9vHVt8jeg/Iqtgx9QBVdc8kr0vyrNba7VW1qfVaa5cmuTRJ9u7d26arEL6e/NGbDNKT/NGT/NGbDNKT/K2WtX0358KXXDn37V528Tlz3+YBMkhP8kdP8kdvMrh9bPU9oveArIpJj5iuqrtkvSn9qtba62ezP11Vp89uPz3JLVPWAAAAAAAAAEBfkzWma/3Q6Jcluam19sINN70pyVNml5+S5I1T1QAAAAAAAABAf1OeyvuRSZ6c5PqqumY271eSPC/Ja6vqaUk+meTHJ6wBAAAAAAAAgM4ma0y31v5HksN9ofSjphoXAAAAAAAAgLFM+h3TAMBX7dq9J1U1l2nX7j29dwcAAAAAADZtylN5AwAbrO27ORe+5Mq5bOuyi8+Zy3YAAAAAAGARHDENAAAAAAAAwKQ0pgEAAAAAAACYlMY0AAAAAAAAAJPSmAYAAAAAAABgUhrTAAAAAAAAAExKYxoAAAAAAACASWlMAwAAAAAAADApjWkAAAAAAAAAJqUxDQAAAAAAAMCkNKYBAAAAAAAAmJTGNAAAAAAAAACT0pgGAAAAAAAAYFIa0wAAAAAAAABMSmMaAAAAAAAAgElpTAMAAAAAAAAwKY1pAAAAAAAAACalMQ0AAAAAAADApDSmAQAAAAAAAJiUxjQAAAAAAAAAk9KYBgAAAAAAAGBSGtMAAAAAAAAATEpjGgAAAAAAAIBJbaoxXVWP3My8g25/eVXdUlU3bJj3q1X1qaq6Zjadf+wlAwAAAAAAALBMNnvE9H/a5LyNXpHkvEPM/83W2sNm05s3OT4AAAAAAAAAS2rHkW6squ9Nck6S06rq5zfc9E1JTjzSuq21d1XVmcddIQAAAAAAAABL7WhHTN81yT2z3sA+acN0e5LHbXHMp1fVdbNTfZ+yxW0AAAAAAAAAsCSOeMR0a+2dSd5ZVa9orf3NHMb73SS/lqTNfv5Gkn99qAWr6qIkFyXJnj175jA0bJ780ZsM0pP80ZP80ZsM0pP80ZsM0pP80ZP80ZsM0pP8sUib/Y7pb6iqS6vqrVX1ZwemYx2stfbp1tqXW2t3Jvn9JGcfYdlLW2t7W2t7TzvttGMdCo6L/NGbDNKT/NGT/NGbDNKT/NGbDNKT/NGT/NGbDNKT/LFIRzxieoP/muT3krw0yZe3OlhVnd5a2z+7+tgkN2x1WwAAAAAAAAAsh802pu9orf3usWy4ql6d5Nwkp1bVviT/Lsm5VfWwrJ/K+xNJLj6WbQIAAAAAAACwfDbbmP6jqvqZJJcn+dKBma21zxxuhdbaEw8x+2XHVh4AAAAAAAAAy26zjemnzH7+0oZ5Lcm3zrccAAAAAAAAAFbNphrTrbX7TV0IAAAAAAAAAKtpU43pqvrJQ81vrf3BfMsBAAAAAAAAYNVs9lTe37Xh8t2SPCrJ1Uk0pgEAAAAAAAA4os2eyvsZG69X1clJ/sskFQEAAAAAAACwUk7Y4np/l+QB8ywEAAAAAAAAgNW02e+Y/qMkbXb1xCQPTvLaqYoCAAAAAAAAYHVs9jumX7Dh8h1J/qa1tm+CegAAAAAAAABYMZs6lXdr7Z1JPpTkpCSnJPmHKYsCAAAAAAAAYHVsqjFdVY9P8t4kP57k8UneU1WPm7IwAAAAAAAAAFbDZk/l/Zwk39VauyVJquq0JP9Pkv82VWEAAAAAAAAArIZNHTGd5IQDTemZvz2GdQEAAAAAAADYxjZ7xPRbquqKJK+eXb8wyZunKQkAAAAAAACAVXLExnRV/dMk922t/VJV/ViS70tSSd6d5FULqA8AAAAAAACAJXe003FfkuTzSdJae31r7edbaz+X9aOlL5m2NAAAAAAAAABWwdEa02e21q47eGZr7aokZ05SEQAAAAAAAAAr5WiN6bsd4ba7z7MQAAAAAAAAAFbT0RrT76uqf3PwzKp6WpL3T1MSAAAAAAAAAKtkx1Fuf1aSy6vqJ/LVRvTeJHdN8tgJ6wIAAAAAAABgRRyxMd1a+3SSc6rqB5N8+2z2n7TW/mzyygAAAAAAAABYCUc7YjpJ0lp7R5J3TFwLAAAAAAAAACvoaN8xDQAAAAAAAADHRWMaAAAAAAAAgElpTAMAAAAAAAAwKY1pAAAAAAAAACY1WWO6ql5eVbdU1Q0b5t27qt5WVR+Z/TxlqvEBAAAAAAAAGMOUR0y/Isl5B817dpK3t9YekOTts+sAAAAAAAAArLDJGtOttXcl+cxBsy9I8srZ5VcmecxU4wMAAAAAAAAwhkV/x/R9W2v7k2T28z6HW7CqLqqqq6rqqltvvXVhBUIif/Qng/Qkf/Qkf/Qmg/Qkf/Qmg/Qkf/Qkf/Qmg/QkfyzSohvTm9Zau7S1tre1tve0007rXQ7bjPzRmwzSk/zRk/zRmwzSk/zRmwzSk/zRk/zRmwzSk/yxSItuTH+6qk5PktnPWxY8PgAAAAAAAAALtujG9JuSPGV2+SlJ3rjg8QEAAAAAAABYsMka01X16iTvTvLAqtpXVU9L8rwkP1RVH0nyQ7PrAAAAAAAAAKywHVNtuLX2xMPc9KipxgQAAAAAAABgPIs+lTcAAAAAAAAA24zGNAAAAAAAAACT0pgGAAAAAAAAYFIa0wAAAAAAAABMSmMaAAAAAAAAgElpTAMAAAAAAAAwKY1pAAAAAAAAACalMQ0AAAAAAADApDSmAQAAAAAAAJiUxjQAAAAAAAAAk9KYBgAAAAAAAGBSGtMAAAAAAAAATEpjGgAAAAAAAIBJaUwDAAAAAAAAMCmNaQAAAAAAAAAmpTENAAAAAAAAwKQ0pgEAAAAAAACYlMY0AAAAAAAAAJPSmAYAAAAAAABgUhrTAAAAAAAAAExKYxoAAAAAAACASWlMAwAAAAAAADApjWkAAAAAAAAAJqUxDQAAAAAAAMCkNKYBAAAAAAAAmNSOHoNW1SeSfD7Jl5Pc0Vrb26MOAAAAAAAAAKbXpTE984Ottds6jg8AAAAAAADAAjiVNwAAAAAAAACT6tWYbkneWlXvr6qLDrVAVV1UVVdV1VW33nrrgstju5M/epNBepI/epI/epNBepI/epNBepI/epI/epNBepI/FqlXY/qRrbVHJHl0kp+tqu8/eIHW2qWttb2ttb2nnXba4itkW5M/epNBepI/epI/epNBepI/epNBepI/epI/epNBepI/FqlLY7q1tjb7eUuSy5Oc3aMOAAAAAAAAAKa38MZ0Vd2jqk46cDnJDye5YdF1AAAAAAAAALAYOzqMed8kl1fVgfH/sLX2lg51AAAAAAAAALAAC29Mt9Y+nuShix4XAAAAAAAAgD66fMc0AAAAAAAAANuHxjQAAAAAAAAAk9KYBgAAAAAAAGBSGtMAAAAAAAAATEpjGgAAAAAAAIBJaUwDAAAAAAAAMCmNaQAAAAAAAAAmpTENAAAAAAAAwKR29C4AAAAAAIDlctZ3PDRra/uPutzOnafng9dfu4CKAIDRaUwDAAAAAHBM1tb257xff+NRl3vLL1+wgGoAgGXgVN4AAAAAAAAATEpjGgAAAAAAAIBJaUwDAAAAAAAAMCnfMQ0AAAAAAAzvzjvvzNraWpJk586dOeGEzR17t9X1AJgvjekVtmv3nqztu/mIy5x4l2/Il//xS0fd1s4zdudTN39yXqVte5v53WyW3w09jZrleda12edJNm/U3ACsoq0+5y7T8+s8X1eYr6l+N1PkU44AYDmsra3lqS++Iknyn3/mR3LGGWdMuh7L4Xjey231f3/L9DcT43rM45+U/bd+9pC3nX7aKXnDa/9wruuNQGN6ha3tuzkXvuTKIy5z2cXnHHWZA8sxP5v53WyW3w09jZrledc14j4us1FzA7CKtvqcu0zPr9thH5fVPF/zN5ridzdFrTIGANO4+8mnLnQ9xnc87+W2+r8/7/WYh/23fjb3e+JzD3nbX7/6/577eiNwvgoAAAAAAAAAJqUxDQAAAAAAAMCkNKYBAAAAAAAAmJTGNAAAAAAAAACT2tG7AAAAAAAAoK8777wza2trSZKdO3fmhBM2d1zbVtbbuM6xjgfA8tKYZuF27d6TtX039y5jdZywI1U1l02deJdvyJf/8UvDbWvnGbvzqZs/OZdtMfBjcI5Zhq2Y52Nj1OdTtofNZnkz2drsa/BmxpTlJbPF12Xv2xZjivdzS/W7875xKc0zt6PmdTvsI2M76zsemrW1/UdcZufO0/PB669dUEUsm7W1tTz1xVckSf7zz/xIzjjjjMnWO7DO3U8+NX//uduOaTzGt9XXRH83wurTmGbh1vbdnAtfcuURl7ns4nMWVM0KuPOOo96fm3XZxecMuy3mZzOPwc2a6+9mzlmGYzXvx8ao22L1bTbLm8nWZjOz2fd3m62LAWzxddnvbzHm+Zp1wFL97ub4vvGApdr/JTXs3yFztB32kbGtre3Peb/+xiMu85ZfvmBB1bCs7n7yqQtb7+4nn5pvPOU+WxqPsW31NXGr/wPxugnLw7kxAAAAAAAAAJiUxjQAAAAAAAAAk+rSmK6q86rqw1X10ap6do8aAAAAAAAAAFiMhTemq+rEJC9K8ugkZyV5YlWdteg6AAAAAAAAAFiMHR3GPDvJR1trH0+SqnpNkguSfLBDLQAAAAAAQJK//9xtSZL9+/dvep39+/cf83ob1/n7z922pfWmrvHg9QA4ftVaW+yAVY9Lcl5r7adm15+c5Ltba08/aLmLklw0u/rAJB9eYJmnJhnl1WakWpLlqee21tp5W92o/H2NkeoZqZZkovwlXTO4LPdxLyPVc6RaPAfOx0i1JMtTj/zNz0j1jFRLspqvwclY9/NItSRj1eM1eDFGqmekWpLVfA5clvu4l5Hq8Rw4vZFqSZanHvmbn5HqGamWZDVfg5Ox7ueRaknGqsdr8GKMVM9ItSRzeg7s0Zj+8SQ/clBj+uzW2jMWWsgRVNVVrbW9vetIxqolUc8ijLZPI9UzUi3JePXMw2j7pJ7DG6mWeRppv0aqJVHPIoy2TyPVM1ItyXj1zMtI+zVSLclY9YxUyzyNtl8j1TNSLcl49czDaPuknsMbqZZ5Gmm/RqolUc8ijLZPI9UzUi3JePXMy0j7NVItyVj1jFTLPI22XyPVM1ItyfzqWfh3TCfZl2T3hutnJFnrUAcAAAAAAAAAC9CjMf2+JA+oqvtV1V2TPCHJmzrUAQAAAAAAAMAC7Fj0gK21O6rq6UmuSHJikpe31m5cdB1HcWnvAjYYqZZEPYsw2j6NVM9ItSTj1TMPo+2Teg5vpFrmaaT9GqmWRD2LMNo+jVTPSLUk49UzLyPt10i1JGPVM1It8zTafo1Uz0i1JOPVMw+j7ZN6Dm+kWuZppP0aqZZEPYsw2j6NVM9ItSTj1TMvI+3XSLUkY9UzUi3zNNp+jVTPSLUkc6pn4d8xDQAAAAAAAMD20uNU3gAAAAAAAABsIxrTAAAAAAAAAExqWzamq2p3Vb2jqm6qqhur6pmHWObcqvpcVV0zm547cU2fqKrrZ2NddYjbq6p+u6o+WlXXVdUjJqzlgRv2+5qqur2qnnXQMpPdP1X18qq6papu2DDv3lX1tqr6yOznKYdZ97yq+vDsfnr2vGqaNxk8Yh1d8zfb/kpnUP6OWovnwImNlkH5+7oaVjqDo+VvNt4QGZS/6cnfUWvxGjyx0TIof19Xw0pncLT8zcYbIoPytxijZXCU/M3GksGJjZa/2XhDZFD+pid/R63F3yETGy2D8vd1NSw2g621bTclOT3JI2aXT0ryV0nOOmiZc5P88QJr+kSSU49w+/lJ/jRJJfmeJO9ZUF0nJvmfSb5lUfdPku9P8ogkN2yY9x+TPHt2+dlJ/sNhav1Ykm9Nctck1x78ex1lksFx8zfb/kpnUP7GzuCq529W61AZlL/tlcHR8jcbb7gMyp/8bbh92zwHrnr+ZrUOlUH5214ZHC1/s/GGy6D8bZ8Mjpi/Db9TGVzx/M3GGy6D8id/G27fNs+Bq56/Wa1DZVD++mZwWx4x3Vrb31q7enb580luSrKrb1VHdUGSP2jr/jLJvarq9AWM+6gkH2ut/c0CxkqStNbeleQzB82+IMkrZ5dfmeQxh1j17CQfba19vLX2D0leM1tvODK4aQvPX7L6GZS/Y+I5cAJLmMFtk79k9TO4hPlLvAbLX1/b5jlw1fOXLGUGt03+ktXP4BLmL/EavDL5S5Yyg54DVyiDS5i/xHOg/PW1bZ4DVz1/yVJmcNvkL1l8BrdlY3qjqjozycOTvOcQN39vVV1bVX9aVd82cSktyVur6v1VddEhbt+V5OYN1/dlMQ/cJyR59WFuW+T9c9/W2v5k/UksyX0OsUyv++i4yOARjZK/ZEUzKH9HNUoGVzJ/yTAZlL+jW8kMDpK/ZMwMyt/E5O+oRsngSuYvGSaD8nd0K5nBQfKXjJlB+VuAQTI4Yv4SGZzcIPlLxsyg/E1M/o5qlAyuZP6SYTIof0c3WQZ3zKW8JVVV90zyuiTPaq3dftDNV2f9cPkvVNX5Sd6Q5AETlvPI1tpaVd0nyduq6kOzTyl8pdxDrNMmrCdVddck/zLJLx/i5kXfP5ux8PvoeMng4S1h/pIly6D8HdkSZnCp8pcMlUH5m4+lyuBA+UsGy6D8TU/+jmwJM7hU+UuGyqD8zcdSZXCg/CWDZVD+FmOgDA6Vv0QGF2Gg/CWDZVD+pid/R7aEGVyq/CVDZVD+5mNL99O2PWK6qu6S9QfAq1prrz/49tba7a21L8wuvznJXarq1Knqaa2tzX7ekuTyrB8Cv9G+JLs3XD8jydpU9cw8OsnVrbVPH3zDou+fJJ+u2akSZj9vOcQyPe6jLZPBoxopf8mKZVD+NmWkDK5U/pKxMih/m7JSGRwpf7MxRsug/E1I/jZlpAyuVP6SsTIof5uyUhkcKX+zMUbLoPxNbKQMDpi/RAYnNVL+ZmOMlkH5m5D8bcpIGVyp/CVjZVD+NmWyDG7LxnRVVZKXJbmptfbCwyzzzbPlUlVnZ/2++tuJ6rlHVZ104HKSH05yw0GLvSnJT9a670nyuTY7jH5CT8xhThuwyPtn5k1JnjK7/JQkbzzEMu9L8oCqut/s0yVPmK03HBnclJHyl6xQBuVv00bK4MrkLxkrg/K3aSuTwZHyN9v+iBmUv4nI36aNlMGVyV8yVgblb9NWJoMj5W+2/REzKH8TGimDg+YvkcHJjJS/2fZHzKD8TUT+Nm2kDK5M/pKxMih/mzZdBltr225K8n1ZP5z8uiTXzKbzk/x0kp+eLfP0JDcmuTbJXyY5Z8J6vnU2zrWzMZ8zm7+xnkryoiQfS3J9kr0T30ffmPVgn7xh3kLun6w/+PYn+cesf+LiaUn+SZK3J/nI7Oe9Z8vuTPLmDeuen+SvZvfTc3pnTQaXL3/bIYPyN3YGVz1/o2VQ/rZfBkfK34gZlD/565m/3hlc9fyNlkH5234ZHCl/I2ZQ/rZXBkfLnwxur/yNmEH5k7+e+eudwVXP32gZlL/+GazZigAAAAAAAAAwiW15Km8AAAAAAAAAFkdjGgAAAAAAAIBJaUwDAAAAAAAAMCmNaQAAAAAAAAAmpTENAAAAAAAAwKQ0pgEAAAAAAACYlMb0FlVVq6rf2HD9F6vqVycc71er6u+q6j4b5n3hKOvcq6p+ZsP1nVX1346yzkur6qzjr5ipySA9yR89yR+9ySA9yR89yR+9ySA9yR+9ySA9yR89yd9q0Zjeui8l+bGqOnWBY96W5BeOYfl7JfnKA6G1ttZae9yRVmit/VRr7YNbK48Fk0F6kj96kj96k0F6kj96kj96k0F6kj96k0F6kj96kr8VojG9dXckuTTJzx18Q1W9oqoet+H6F2Y/z62qd1bVa6vqr6rqeVX1E1X13qq6vqruf5QxX57kwqq69yHG/PmqumE2PWs2+3lJ7l9V11TV86vqzKq6Ybb8iVX1gtm411XVM2bz/3tV7Z1d/t2quqqqbqyq/2vDWM+rqg/O1nvBMdxnzJcMymBP8id/Pcmf/PUmgzLYk/zJX0/yJ3+9yaAM9iR/8tebDMpgT/Infz3J3wrlb0fvApbci5JcV1X/8RjWeWiSByf5TJKPJ3lpa+3sqnpmkmckedYR1v1C1h8Mz0zy7w7MrKrvTPLUJN+dpJK8p6remeTZSb69tfaw2XJnbtjWRUnul+ThrbU7DvXgSvKc1tpnqurEJG+vqock2ZfksUke1FprVXWvY9h35k8GZbAn+ZO/nuRP/nqTQRnsSf7kryf5k7/eZFAGe5I/+etNBmWwJ/mTv57kb0Xy54jp49Bauz3JHyT5t8ew2vtaa/tba19K8rEkb53Nvz7JmZtY/7eTPKWqvmnDvO9Lcnlr7YuttS8keX2S//Uo2/nnSX6vtXZHkrTWPnOIZR5fVVcn+UCSb0tyVpLbk/x/SV5aVT+W5O82UTMTkUEZ7En+5K8n+ZO/3mRQBnuSP/nrSf7krzcZlMGe5E/+epNBGexJ/uSvJ/lbnfxpTB+/S5I8Lck9Nsy7I7P7tqoqyV033PalDZfv3HD9zmziCPbW2v+b5A+z4Vz1Wf9UxrGqJO2wN1bdL8kvJnlUa+0hSf4kyd1mD5yzk7wuyWOSvGULYzNfl0QG6eeSyB/9XBL5o69LIoP0c0nkj34uifzR1yWRQfq5JPJHX5dEBunnksgf/VwS+Vt6GtPHafbJhtdm/cFwwCeSfOfs8gVJ7jLnYV+Y5OJ89YHzriSPqapvrKp7ZP3Q/j9P8vkkJx1mG29N8tNVtSNJDnHqgG9K8sUkn6uq+yZ59Gy5eyY5ubX25qyf5uBhc9ontkgGZbAn+ZO/nuRP/nqTQRnsSf7kryf5k7/eZFAGe5I/+etNBmWwJ/mTv57kbzXypzE9H7+R5NQN138/yQ9U1Xuzfp75L85zsNbabUkuT/INs+tXJ3lFkvcmeU/Wz5P/gdba3yb5i1r/AvbnH7SZlyb5ZNbPyX9tkicdNMa1WT9lwI1ZP4/+X8xuOinJH1fVdUnemUN82TxdyCA9yR89yR+9ySA9yR89yR+9ySA9yR+9ySA9yR89yd+Sq9YOe/Q4AAAAAAAAABw3R0wDAAAAAAAAMKmjfrk3i1VVz0ny4wfN/q+ttX/fox62HxmkJ/mjJ/mjNxmkJ/mjJ/mjNxmkJ/mjNxmkJ/mjJ/nrw6m8AQAAAAAAAJiUU3kDAAAAAAAAMCmNaQAAAAAAAAAmpTENAAAAAAAAwKQ0pgEAAAAAAACY1P8Pxixpg9L+mooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1965.6x252 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando distribuição da quantidade de noticias ao longo dos meses\n",
    "g = sns.FacetGrid(data_df, col=\"Mes\", height=3.5, aspect=.65)\n",
    "g.map(sns.histplot, \"Num_Noticias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há poucas ocorrências de baixo numero de noticias por dia, a maior ocorrência da quantidade de noticias por dia é de 10.\n",
    "Dessa forma, a média de noticias por mês varia de 8.6 á 9.65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Há poucos dias sem noticias na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gerando uma lista com todos os dias de 2021:\n",
    "start_date = '01/01/2021'\n",
    "end_date = '31/12/2021'\n",
    "\n",
    "#Transformando para o padrão inglês\n",
    "start_date = datetime.strptime(start_date, '%d/%m/%Y').strftime('%m-%d-%Y')\n",
    "end_date = datetime.strptime(end_date, '%d/%m/%Y').strftime('%m-%d-%Y')\n",
    "\n",
    "#Gerando a lista com todas as datas\n",
    "todas_datas = pd.date_range(start=start_date, end=end_date, freq = '1D')\n",
    "todas_datas = [i.strftime(\"%d/%m/%Y\") for i in todas_datas ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando lista com todas as datas com noticias\n",
    "datas_com_noticias = [i.strftime(\"%d/%m/%Y\") for i in data_df['Datas'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 38 dias sem notícias em 2021!\n"
     ]
    }
   ],
   "source": [
    "#Gerando lista com todas as datas sem noticias em 2021\n",
    "datas_sem_noticias = [i for i in todas_datas if i not in datas_com_noticias]\n",
    "print(\"Há %s dias sem notícias em 2021!\" % len(datas_sem_noticias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em apenas 38 dias de 2021 não houve retorno de noticias diárias da Petrobras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Há dias em que o pregão da bolsa não funciona (Finais de Semana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_com_pregao = [i.strftime(\"%d/%m/%Y\") for i in df_petro['Date'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_sem_pregao = [i for i in todas_datas if i not in datas_com_pregao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 118 dias sem pregão em 2021!\n"
     ]
    }
   ],
   "source": [
    "print(\"Há %s dias sem pregão em 2021!\" % len(datas_sem_pregao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Padronização das palavras contidas nos títulos das noticias para minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Refinaria Abreu e Lima da Petrobras, a RNEST p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Dicas de Tony Robbins para Ficar Rico Invest...</td>\n",
       "      <td>The Capital Advisor</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>O QUE LER AGORA... ibovespa-sobe-021-apos-demi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acadêmicos de engenharia Mecânica criam projet...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras cancela a venda da fábrica de fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinacional dinamarquesa European Energy faz...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras encerra sociedade com a Sete Brasil ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  A construção naval brasileira tem chances de a...   \n",
       "1  Refinaria Abreu e Lima da Petrobras, a RNEST p...   \n",
       "2  5 Dicas de Tony Robbins para Ficar Rico Invest...   \n",
       "3  Acadêmicos de engenharia Mecânica criam projet...   \n",
       "4  Multinacional dinamarquesa European Energy faz...   \n",
       "\n",
       "                      media       date  \\\n",
       "0  CPG Click Petroleo e Gas 2021-01-01   \n",
       "1  CPG Click Petroleo e Gas 2021-01-01   \n",
       "2       The Capital Advisor 2021-01-01   \n",
       "3  CPG Click Petroleo e Gas 2021-01-01   \n",
       "4  CPG Click Petroleo e Gas 2021-01-01   \n",
       "\n",
       "                                                desc  \n",
       "0  Dentre os principais pontos do plano estratégi...  \n",
       "1  Petrobras informou em fato relevante na última...  \n",
       "2  O QUE LER AGORA... ibovespa-sobe-021-apos-demi...  \n",
       "3  Petrobras cancela a venda da fábrica de fertil...  \n",
       "4  Petrobras encerra sociedade com a Sete Brasil ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refinaria abreu e lima da petrobras, a rnest p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 dicas de tony robbins para ficar rico invest...</td>\n",
       "      <td>The Capital Advisor</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>O QUE LER AGORA... ibovespa-sobe-021-apos-demi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acadêmicos de engenharia mecânica criam projet...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras cancela a venda da fábrica de fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multinacional dinamarquesa european energy faz...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras encerra sociedade com a Sete Brasil ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  a construção naval brasileira tem chances de a...   \n",
       "1  refinaria abreu e lima da petrobras, a rnest p...   \n",
       "2  5 dicas de tony robbins para ficar rico invest...   \n",
       "3  acadêmicos de engenharia mecânica criam projet...   \n",
       "4  multinacional dinamarquesa european energy faz...   \n",
       "\n",
       "                      media       date  \\\n",
       "0  CPG Click Petroleo e Gas 2021-01-01   \n",
       "1  CPG Click Petroleo e Gas 2021-01-01   \n",
       "2       The Capital Advisor 2021-01-01   \n",
       "3  CPG Click Petroleo e Gas 2021-01-01   \n",
       "4  CPG Click Petroleo e Gas 2021-01-01   \n",
       "\n",
       "                                                desc  \n",
       "0  Dentre os principais pontos do plano estratégi...  \n",
       "1  Petrobras informou em fato relevante na última...  \n",
       "2  O QUE LER AGORA... ibovespa-sobe-021-apos-demi...  \n",
       "3  Petrobras cancela a venda da fábrica de fertil...  \n",
       "4  Petrobras encerra sociedade com a Sete Brasil ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = df['title'].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Exclusão noticias que não contenham a palavra chave \"Petrobras\" no título\n",
    "Embora tenha-se configurado A biblioteca GoogleNews() para baixar noticias pela palavra chave \"Petrobras\" pode ocorrer casos em que o termo não é citado no título e nem no corpo da noticia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 dicas de tony robbins para ficar rico investindo'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O QUE LER AGORA... ibovespa-sobe-021-apos-demissao-na-petrobras-prio3-.  Notícias. Ibovespa Sobe +0...'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa noticia \"5 dicas de tony robbins para ficar rico investindo\", por exemplo, não possui relação com a petrobras no título e nem no corpo do artigo ao checar direto na fonte em <https://comoinvestir.thecap.com.br/5-dicas-de-tony-robbins-para-ficar-rico-investindo>. A biblioteca GoogleNews() retornou essa noticia, pois, na pagina HTML há noticias recomendadas ao leitor que possuem a palavra chave \"petrobras\".\n",
    "\n",
    "Noticias sem a palavra chave \"petrobras\" no título serão excluidas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refinaria abreu e lima da petrobras, a rnest p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>The Capital Advisor</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>O QUE LER AGORA... ibovespa-sobe-021-apos-demi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras cancela a venda da fábrica de fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras encerra sociedade com a Sete Brasil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>quer trabalhar na petrobras? falta menos de um...</td>\n",
       "      <td>JC Online</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>O processo seletivo público que oferece 757 va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td></td>\n",
       "      <td>CNN Brasil</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Para ele, a solução desta pressão não deve pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td></td>\n",
       "      <td>PetroNotícias</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Isso porque a Petrobrás anunciou que registrou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>unigel assina contratos para suprimento das fá...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>No dia 27 de dezembro a Unigel fechou contrato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td></td>\n",
       "      <td>Correio Braziliense</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Petrobras manterá preços de mercado, garante p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3026 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     a construção naval brasileira tem chances de a...   \n",
       "1     refinaria abreu e lima da petrobras, a rnest p...   \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "3021  quer trabalhar na petrobras? falta menos de um...   \n",
       "3022                                                      \n",
       "3023                                                      \n",
       "3024  unigel assina contratos para suprimento das fá...   \n",
       "3025                                                      \n",
       "\n",
       "                         media       date  \\\n",
       "0     CPG Click Petroleo e Gas 2021-01-01   \n",
       "1     CPG Click Petroleo e Gas 2021-01-01   \n",
       "2          The Capital Advisor 2021-01-01   \n",
       "3     CPG Click Petroleo e Gas 2021-01-01   \n",
       "4     CPG Click Petroleo e Gas 2021-01-01   \n",
       "...                        ...        ...   \n",
       "3021                 JC Online 2021-12-31   \n",
       "3022                CNN Brasil 2021-12-31   \n",
       "3023             PetroNotícias 2021-12-31   \n",
       "3024  CPG Click Petroleo e Gas 2021-12-31   \n",
       "3025       Correio Braziliense 2021-12-31   \n",
       "\n",
       "                                                   desc  \n",
       "0     Dentre os principais pontos do plano estratégi...  \n",
       "1     Petrobras informou em fato relevante na última...  \n",
       "2     O QUE LER AGORA... ibovespa-sobe-021-apos-demi...  \n",
       "3     Petrobras cancela a venda da fábrica de fertil...  \n",
       "4     Petrobras encerra sociedade com a Sete Brasil ...  \n",
       "...                                                 ...  \n",
       "3021  O processo seletivo público que oferece 757 va...  \n",
       "3022  Para ele, a solução desta pressão não deve pas...  \n",
       "3023  Isso porque a Petrobrás anunciou que registrou...  \n",
       "3024  No dia 27 de dezembro a Unigel fechou contrato...  \n",
       "3025  Petrobras manterá preços de mercado, garante p...  \n",
       "\n",
       "[3026 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = df['title'].apply(lambda x: \"\" if \"petrobras\" not in x else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refinaria abreu e lima da petrobras, a rnest p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>petrobras é condenada em arbitragem iniciada p...</td>\n",
       "      <td>Forbes Brasil</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>A Petrobras disse que a sentença determinou qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>petrobras fez provisionamento para indenizar iesa</td>\n",
       "      <td>Valor Econômico</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>Petrobras fez provisionamento para indenizar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>petrobras é condenada, nos eua, a indenizar a ...</td>\n",
       "      <td>Money Times</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>A Petrobras (PETR3; PETR4) foi condenada por u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>aumento do preço do gás encanado: justiça inti...</td>\n",
       "      <td>FDR</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Na última quinta-feira, 30, a Petrobras recebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>presidente da petrobras diz que eleições não v...</td>\n",
       "      <td>Jovem Pan</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Para 2022, Joaquim Silva e Luna entende que a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>petrobras conclui venda de ativos do rn, em me...</td>\n",
       "      <td>Saiba Mais</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Após os trabalhadores aprovarem estado de grev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>quer trabalhar na petrobras? falta menos de um...</td>\n",
       "      <td>JC Online</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>O processo seletivo público que oferece 757 va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>unigel assina contratos para suprimento das fá...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>No dia 27 de dezembro a Unigel fechou contrato...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1532 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     a construção naval brasileira tem chances de a...   \n",
       "1     refinaria abreu e lima da petrobras, a rnest p...   \n",
       "26    petrobras é condenada em arbitragem iniciada p...   \n",
       "27    petrobras fez provisionamento para indenizar iesa   \n",
       "28    petrobras é condenada, nos eua, a indenizar a ...   \n",
       "...                                                 ...   \n",
       "3018  aumento do preço do gás encanado: justiça inti...   \n",
       "3019  presidente da petrobras diz que eleições não v...   \n",
       "3020  petrobras conclui venda de ativos do rn, em me...   \n",
       "3021  quer trabalhar na petrobras? falta menos de um...   \n",
       "3024  unigel assina contratos para suprimento das fá...   \n",
       "\n",
       "                         media       date  \\\n",
       "0     CPG Click Petroleo e Gas 2021-01-01   \n",
       "1     CPG Click Petroleo e Gas 2021-01-01   \n",
       "26               Forbes Brasil 2021-04-01   \n",
       "27             Valor Econômico 2021-04-01   \n",
       "28                 Money Times 2021-04-01   \n",
       "...                        ...        ...   \n",
       "3018                       FDR 2021-12-31   \n",
       "3019                 Jovem Pan 2021-12-31   \n",
       "3020                Saiba Mais 2021-12-31   \n",
       "3021                 JC Online 2021-12-31   \n",
       "3024  CPG Click Petroleo e Gas 2021-12-31   \n",
       "\n",
       "                                                   desc  \n",
       "0     Dentre os principais pontos do plano estratégi...  \n",
       "1     Petrobras informou em fato relevante na última...  \n",
       "26    A Petrobras disse que a sentença determinou qu...  \n",
       "27    Petrobras fez provisionamento para indenizar I...  \n",
       "28    A Petrobras (PETR3; PETR4) foi condenada por u...  \n",
       "...                                                 ...  \n",
       "3018  Na última quinta-feira, 30, a Petrobras recebe...  \n",
       "3019  Para 2022, Joaquim Silva e Luna entende que a ...  \n",
       "3020  Após os trabalhadores aprovarem estado de grev...  \n",
       "3021  O processo seletivo público que oferece 757 va...  \n",
       "3024  No dia 27 de dezembro a Unigel fechou contrato...  \n",
       "\n",
       "[1532 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['title'] != \"\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1494 noticias não relacionadas ao termo \"Petrobras\" em seus títulos foram foram excluidas do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Adição de classe \"Fechamento\" ao dataframe de Ações\n",
    "Classe 1: Fechamento em alta  \n",
    "Classe 0: Fechamento em queda  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>20.747751</td>\n",
       "      <td>67136300</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23.237993</td>\n",
       "      <td>28713600</td>\n",
       "      <td>0.006037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>23.582502</td>\n",
       "      <td>44227900</td>\n",
       "      <td>0.014825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.607111</td>\n",
       "      <td>30688100</td>\n",
       "      <td>0.001044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>23.410248</td>\n",
       "      <td>35508400</td>\n",
       "      <td>-0.008339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>23.336424</td>\n",
       "      <td>43229100</td>\n",
       "      <td>-0.003153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume      Var%\n",
       "0   2021-01-04  19.274340  74719700  0.020113\n",
       "1   2021-01-05  20.027718  95181100  0.039087\n",
       "2   2021-01-06  20.067719  96562500  0.001997\n",
       "3   2021-01-07  20.667747  56171300  0.029900\n",
       "4   2021-01-08  20.747751  67136300  0.003871\n",
       "..         ...        ...       ...       ...\n",
       "242 2021-12-23  23.237993  28713600  0.006037\n",
       "243 2021-12-27  23.582502  44227900  0.014825\n",
       "244 2021-12-28  23.607111  30688100  0.001044\n",
       "245 2021-12-29  23.410248  35508400 -0.008339\n",
       "246 2021-12-30  23.336424  43229100 -0.003153\n",
       "\n",
       "[247 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>20.747751</td>\n",
       "      <td>67136300</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23.237993</td>\n",
       "      <td>28713600</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>23.582502</td>\n",
       "      <td>44227900</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.607111</td>\n",
       "      <td>30688100</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>23.410248</td>\n",
       "      <td>35508400</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>23.336424</td>\n",
       "      <td>43229100</td>\n",
       "      <td>-0.003153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume      Var%  Fechamento\n",
       "0   2021-01-04  19.274340  74719700  0.020113           1\n",
       "1   2021-01-05  20.027718  95181100  0.039087           1\n",
       "2   2021-01-06  20.067719  96562500  0.001997           1\n",
       "3   2021-01-07  20.667747  56171300  0.029900           1\n",
       "4   2021-01-08  20.747751  67136300  0.003871           1\n",
       "..         ...        ...       ...       ...         ...\n",
       "242 2021-12-23  23.237993  28713600  0.006037           1\n",
       "243 2021-12-27  23.582502  44227900  0.014825           1\n",
       "244 2021-12-28  23.607111  30688100  0.001044           1\n",
       "245 2021-12-29  23.410248  35508400 -0.008339           0\n",
       "246 2021-12-30  23.336424  43229100 -0.003153           0\n",
       "\n",
       "[247 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro['Fechamento'] = df_petro['Var%'].apply(lambda x: 0 if x<0 else 1)\n",
    "df_petro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    131\n",
       "0    116\n",
       "Name: Fechamento, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro.Fechamento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x244dc789a60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Fechamento\",\n",
    "                data=df_petro,\n",
    "                kind=\"count\", height=3.5, aspect=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em 2021 houve 131 fechamentos com aumento nos valores de ações da Petrobras e 116 com fechamento em queda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Concatenar noticias diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>20.747751</td>\n",
       "      <td>67136300</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Adj Close    Volume      Var%  Fechamento\n",
       "0 2021-01-04  19.274340  74719700  0.020113           1\n",
       "1 2021-01-05  20.027718  95181100  0.039087           1\n",
       "2 2021-01-06  20.067719  96562500  0.001997           1\n",
       "3 2021-01-07  20.667747  56171300  0.029900           1\n",
       "4 2021-01-08  20.747751  67136300  0.003871           1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a construção naval brasileira tem chances de a...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Dentre os principais pontos do plano estratégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>refinaria abreu e lima da petrobras, a rnest p...</td>\n",
       "      <td>CPG Click Petroleo e Gas</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Petrobras informou em fato relevante na última...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>petrobras é condenada em arbitragem iniciada p...</td>\n",
       "      <td>Forbes Brasil</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>A Petrobras disse que a sentença determinou qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>petrobras fez provisionamento para indenizar iesa</td>\n",
       "      <td>Valor Econômico</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>Petrobras fez provisionamento para indenizar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>petrobras é condenada, nos eua, a indenizar a ...</td>\n",
       "      <td>Money Times</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>A Petrobras (PETR3; PETR4) foi condenada por u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   a construção naval brasileira tem chances de a...   \n",
       "1   refinaria abreu e lima da petrobras, a rnest p...   \n",
       "26  petrobras é condenada em arbitragem iniciada p...   \n",
       "27  petrobras fez provisionamento para indenizar iesa   \n",
       "28  petrobras é condenada, nos eua, a indenizar a ...   \n",
       "\n",
       "                       media       date  \\\n",
       "0   CPG Click Petroleo e Gas 2021-01-01   \n",
       "1   CPG Click Petroleo e Gas 2021-01-01   \n",
       "26             Forbes Brasil 2021-04-01   \n",
       "27           Valor Econômico 2021-04-01   \n",
       "28               Money Times 2021-04-01   \n",
       "\n",
       "                                                 desc  \n",
       "0   Dentre os principais pontos do plano estratégi...  \n",
       "1   Petrobras informou em fato relevante na última...  \n",
       "26  A Petrobras disse que a sentença determinou qu...  \n",
       "27  Petrobras fez provisionamento para indenizar I...  \n",
       "28  A Petrobras (PETR3; PETR4) foi condenada por u...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_datas = []\n",
    "lista_news = []\n",
    "\n",
    "for i in df.date.unique():\n",
    "    news = \"\"\n",
    "    for row in df[(df['date']==i)].iterrows():\n",
    "        news = news + \" \" + row[1][0]\n",
    "    lista_news.append(news)\n",
    "    lista_datas.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>a construção naval brasileira tem chances de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>petrobras reajusta preço da gasolina pela qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>tcu avalia barrar venda de refinaria da petro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>petrobras (petr4) inicia contratação de nona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>valor de venda de refinaria da petrobras é qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>alerj vai à justiça contra a petrobras para b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>distribuidoras de gás de 5 estados entram na ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>petrobras vai recorrer de decisão que suspend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>judicialização coloca mercado de gás em risco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>cvm | petrobras (petr4) informa potencial de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                           Noticias\n",
       "0   2021-01-01   a construção naval brasileira tem chances de ...\n",
       "41  2021-01-03   petrobras reajusta preço da gasolina pela qui...\n",
       "67  2021-01-04   tcu avalia barrar venda de refinaria da petro...\n",
       "87  2021-01-05   petrobras (petr4) inicia contratação de nona ...\n",
       "113 2021-01-06   valor de venda de refinaria da petrobras é qu...\n",
       "..         ...                                                ...\n",
       "294 2021-12-27   alerj vai à justiça contra a petrobras para b...\n",
       "295 2021-12-28   distribuidoras de gás de 5 estados entram na ...\n",
       "296 2021-12-29   petrobras vai recorrer de decisão que suspend...\n",
       "297 2021-12-30   judicialização coloca mercado de gás em risco...\n",
       "298 2021-12-31   cvm | petrobras (petr4) informa potencial de ...\n",
       "\n",
       "[299 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_diaria = pd.DataFrame(list(zip(lista_datas,lista_news)),\n",
    "               columns =['Date', 'Noticias'])\n",
    "df_news_diaria.sort_values(by = 'Date', ascending = True, inplace = True)\n",
    "df_news_diaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 situações checar: \n",
    "\n",
    "\n",
    "1) Dias em que há pregão mas não há noticias, sendo que o dia anterior não tem pregão e tem noticias.  \n",
    "2) Dias que há pregão e há noticias, sendo que no dia anterior não há pregão e há noticias.  \n",
    "\n",
    "**Exemplo 1:** dia 29/11/2021 houve pregão mas não há noticias naquele dia, somente nos dias anteriores que nao houveram pregão e tiveram noticias 27/11/2021 e 28/11/2021.  \n",
    "**Exemplo 2:** dia 18/01/2021 houve pregão e há noticias naquele dia, após concatenar as noticias do dia 18/01/2021 deverá incluir as noticias dos dias 16 e 17/01/2021 que não houve pregão;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/11/2021\n"
     ]
    }
   ],
   "source": [
    "## Itera sobre dias com pregao\n",
    "for i in datas_com_pregao:\n",
    "    \n",
    "    ## Se o dia não tiver noticias retorna a data do dia anterior\n",
    "    if i in datas_sem_noticias:\n",
    "        dia_anterior = str(int(i[:2])-1) + i[2:10]\n",
    "        \n",
    "        # #Se o dia anterior não tiver pregão\n",
    "        if dia_anterior in datas_sem_pregao:\n",
    "                \n",
    "            ## Se o dia anterior tiver noticias:\n",
    "            if dia_anterior in datas_com_noticias:\n",
    "                print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' bolsonaro critica política de preços dos combustíveis da petrobras ibovespa: petrobras (petr4) e vale (vale3) têm maiores altas para itaú bba, pagamento de dividendos da petrobras (petr4) pode ser ainda maior usina termelétrica de camaçari: um dos principais investimentos da petrobras na bahia, foi arrendado ontem (26/11) para a petroquímica proquigel empreiteira de perfuração offshore seadrill conquista contratos de us$ 549 milhões com a petrobras, no campo de búzios'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 27/11/2021\n",
    "noticia_dia_27 = df_news_diaria.iloc[267][1]\n",
    "noticia_dia_27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' por que a privatização da petrobras não é garantia de ... petrobras e mubadala assinam transferência final da rlam nos próximos dias petrobras deve começar a vender fatia na braskem no primeiro trimestre'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 28/11/2021\n",
    "noticia_dia_28 = df_news_diaria.iloc[268][1]\n",
    "noticia_dia_28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 29/11/2021 -- NÂO EXISTE NOTICIA\n",
    "noticia_dia_29 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' mais de 100 vagas de emprego no setor de petróleo e gás! ocyan inicia cadastro de currículo para contratos de manutenção da petrobras'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 16/01/2021\n",
    "noticia_dia_16 = df_news_diaria.iloc[11][1]\n",
    "noticia_dia_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' petrobras quer mudar gestão de plano de saúde'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 17/01/2021\n",
    "noticia_dia_17 = df_news_diaria.iloc[12][1]\n",
    "noticia_dia_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' a petrobras está represando preços de combustíveis? dados indicam que sim, mas analistas não veem motivo para pânico (ainda) petrobras anuncia aumento de mais de 8% na gasolina a partir desta terça-feira litro da gasolina sobe r$ 0,15 nas refinarias da petrobras petrobras avança na venda do maior campo de petróleo em ... ação da petrobras fecha em queda de 0,18% nesta segunda; veja valores petrobras (petr4) aprova abertura de novo plano de ... petrobras recebe em 15 dias propostas para construção de 2 plataformas no rio'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 18/01/2021\n",
    "noticia_dia_18 = df_news_diaria.iloc[13][1]\n",
    "noticia_dia_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Concatenar noticias referentes a datas sem pregões.\n",
    "\n",
    "- O próximo dia útil após o periodo sem pregões deverá consolidar as noticias acumuladas dos dias sem pregões.\n",
    "- O dataset final deverá conter apenas as datas em que ocorreu o pregão\n",
    "\n",
    "Dessa forma, iniciaremos o procedimento, concatenando as noticias de dias que não houveram pregões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\2324495316.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>silva e luna 'militariza' cúpula da petrobra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>mais de 100 vagas de emprego no setor de pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>petrobras encerra 2020 com quadro de funcion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>petrobras mira emissão no mercado internacio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>bolsonaro critica política de preços dos com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>petrobras aumenta exportação de óleo pelo po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>petrobras fecha venda da six por 33 milhões ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>petrobras abre o 1º concurso em 3 anos com s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>petrobras vende carmópolis por us$ 1,1 bilhã...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                           Noticias\n",
       "0  2021-01-11    silva e luna 'militariza' cúpula da petrobra...\n",
       "1  2021-01-18    mais de 100 vagas de emprego no setor de pet...\n",
       "2  2021-01-26    petrobras encerra 2020 com quadro de funcion...\n",
       "3  2021-02-01                                                   \n",
       "4  2021-02-08    petrobras mira emissão no mercado internacio...\n",
       "..        ...                                                ...\n",
       "51 2021-11-29    bolsonaro critica política de preços dos com...\n",
       "52 2021-12-06    petrobras aumenta exportação de óleo pelo po...\n",
       "53 2021-12-13    petrobras fecha venda da six por 33 milhões ...\n",
       "54 2021-12-20    petrobras abre o 1º concurso em 3 anos com s...\n",
       "55 2021-12-27    petrobras vende carmópolis por us$ 1,1 bilhã...\n",
       "\n",
       "[56 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Iterar sobre as datas dos pregões (iniciando pelo segundo dia do pregão de 2021 df_petro.Date.iloc[1:])\n",
    "\n",
    "## Calcular delta (diferença entre dias entre dois registros seguidos de pregões):\n",
    "import datetime\n",
    "\n",
    "df_news_sem_pregao = pd.DataFrame()\n",
    "timedelta_1dia = datetime.timedelta(days=1)\n",
    "\n",
    "lista_datas = []\n",
    "lista_noticias_sem_pregao = []\n",
    "\n",
    "for i, data in enumerate(df_petro.Date.iloc[1:]):\n",
    "    data_anterior = df_petro['Date'].iloc[i]  \n",
    "    delta = data - data_anterior\n",
    "\n",
    "    \n",
    "    # Se houver mais de 1 dia sem pregão:    \n",
    "    if delta > timedelta_1dia:\n",
    "            \n",
    "            \n",
    "        # Filtra as noticias entre as datas sem pregão:\n",
    "        df_aux = df_news_diaria[ (df_news_diaria['Date']> data_anterior) & (df_news_diaria['Date']<= data)  ]\n",
    "        \n",
    "        ## Concatena as noticias das datas sem pregão\n",
    "        news = \"\"\n",
    "        for row in df_aux.iterrows():\n",
    "            news = news + \" \" + row[1][1]\n",
    "\n",
    "\n",
    "        ## Armazena as noticias e data do ultimo pregão valido em listas\n",
    "        lista_noticias_sem_pregao.append(news)\n",
    "        lista_datas.append(data)\n",
    "        \n",
    "        #Cria um dataframe auxiliar com a data do ultimo pregão e as noticias concatenadas dos dias sem pregões:\n",
    "        df_aux2 = pd.DataFrame(list(zip(lista_datas,lista_noticias_sem_pregao)),\n",
    "               columns =['Date', 'Noticias'])\n",
    "    \n",
    "        # Gera o dataframe com as noticias sem pregões + datas do ultimo pregão valido.\n",
    "        df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
    "        \n",
    "        #Resetando as listas para geração de novo DF\n",
    "        lista_noticias_sem_pregao = []\n",
    "        lista_datas = []\n",
    "        \n",
    "df_news_sem_pregao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Note que nos dias 04/06/2021 e 01/02/2021 houveram pregão mas não houveram noticias referente a esses dias nem os dias que os precederam.\n",
    "    \n",
    "    # Situação OK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checagem situação de 29/11/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  bolsonaro critica política de preços dos combustíveis da petrobras ibovespa: petrobras (petr4) e vale (vale3) têm maiores altas para itaú bba, pagamento de dividendos da petrobras (petr4) pode ser ainda maior usina termelétrica de camaçari: um dos principais investimentos da petrobras na bahia, foi arrendado ontem (26/11) para a petroquímica proquigel empreiteira de perfuração offshore seadrill conquista contratos de us$ 549 milhões com a petrobras, no campo de búzios  por que a privatização da petrobras não é garantia de ... petrobras e mubadala assinam transferência final da rlam nos próximos dias petrobras deve começar a vender fatia na braskem no primeiro trimestre '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias_concatenadas = \" \" + noticia_dia_27 + \" \" + noticia_dia_28 + \" \" + noticia_dia_29\n",
    "noticias_concatenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  bolsonaro critica política de preços dos combustíveis da petrobras ibovespa: petrobras (petr4) e vale (vale3) têm maiores altas para itaú bba, pagamento de dividendos da petrobras (petr4) pode ser ainda maior usina termelétrica de camaçari: um dos principais investimentos da petrobras na bahia, foi arrendado ontem (26/11) para a petroquímica proquigel empreiteira de perfuração offshore seadrill conquista contratos de us$ 549 milhões com a petrobras, no campo de búzios  por que a privatização da petrobras não é garantia de ... petrobras e mubadala assinam transferência final da rlam nos próximos dias petrobras deve começar a vender fatia na braskem no primeiro trimestre '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_sem_pregao.iloc[51][1] + \" \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo OK as noticias são iguais! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checagem situação de 18/01/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  mais de 100 vagas de emprego no setor de petróleo e gás! ocyan inicia cadastro de currículo para contratos de manutenção da petrobras  petrobras quer mudar gestão de plano de saúde  a petrobras está represando preços de combustíveis? dados indicam que sim, mas analistas não veem motivo para pânico (ainda) petrobras anuncia aumento de mais de 8% na gasolina a partir desta terça-feira litro da gasolina sobe r$ 0,15 nas refinarias da petrobras petrobras avança na venda do maior campo de petróleo em ... ação da petrobras fecha em queda de 0,18% nesta segunda; veja valores petrobras (petr4) aprova abertura de novo plano de ... petrobras recebe em 15 dias propostas para construção de 2 plataformas no rio'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias_concatenadas = \" \" + noticia_dia_16 + \" \" + noticia_dia_17 + \" \" + noticia_dia_18\n",
    "noticias_concatenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  mais de 100 vagas de emprego no setor de petróleo e gás! ocyan inicia cadastro de currículo para contratos de manutenção da petrobras  petrobras quer mudar gestão de plano de saúde  a petrobras está represando preços de combustíveis? dados indicam que sim, mas analistas não veem motivo para pânico (ainda) petrobras anuncia aumento de mais de 8% na gasolina a partir desta terça-feira litro da gasolina sobe r$ 0,15 nas refinarias da petrobras petrobras avança na venda do maior campo de petróleo em ... ação da petrobras fecha em queda de 0,18% nesta segunda; veja valores petrobras (petr4) aprova abertura de novo plano de ... petrobras recebe em 15 dias propostas para construção de 2 plataformas no rio'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_sem_pregao.iloc[1][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo OK as noticias são iguais! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Atualiza as noticias concatenadas no df_news_diaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\865046954.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_news_diaria_atualizada = df_news_diaria_atualizada.append(df_noticia_dias_sem_pregao, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "df_news_diaria_atualizada = df_news_diaria.copy()\n",
    "\n",
    "# itera sobre os dias com pregão cujo noticias de dias anteriores foram concatenadas:\n",
    "for data in df_news_sem_pregao.Date.unique():\n",
    "    \n",
    "    #Filtra pelo dia com pregão que teve noticias concatenada\n",
    "    df_noticia_dias_sem_pregao = df_news_sem_pregao[(df_news_sem_pregao['Date']==data)]\n",
    "\n",
    "\n",
    "    #Checa se há registro referente a data no df de noticias\n",
    "    df_check_noticias = df_news_diaria_atualizada[(df_news_diaria_atualizada['Date']==data)]\n",
    "    \n",
    "    # Se não houver registros referente á data então o registro deverá ser criado no df de noticias:\n",
    "    # Se houver, então o registro será atualizado no df de noticias\n",
    "    \n",
    "    if len(df_check_noticias) > 0:\n",
    "        \n",
    "        #Substitui os registros\n",
    "        df_news_diaria_atualizada = df_news_diaria_atualizada.replace ((df_news_diaria_atualizada.loc[df_news_diaria_atualizada['Date'].isin(df_noticia_dias_sem_pregao['Date'])])['Noticias'].values, df_noticia_dias_sem_pregao['Noticias'].values)\n",
    "        \n",
    "    else:\n",
    "        #Insere o novo registro\n",
    "        df_news_diaria_atualizada = df_news_diaria_atualizada.append(df_noticia_dias_sem_pregao, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 306)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_news_diaria), len(df_news_diaria_atualizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Mesclando o dataframe noticias finais e ações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>1</td>\n",
       "      <td>tcu avalia barrar venda de refinaria da petro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras (petr4) inicia contratação de nona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "      <td>valor de venda de refinaria da petrobras é qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras confirma venda da fatia na br distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>20.747751</td>\n",
       "      <td>67136300</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>20.574409</td>\n",
       "      <td>48744700</td>\n",
       "      <td>-0.008355</td>\n",
       "      <td>0</td>\n",
       "      <td>silva e luna 'militariza' cúpula da petrobra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>20.421068</td>\n",
       "      <td>65691900</td>\n",
       "      <td>-0.007453</td>\n",
       "      <td>0</td>\n",
       "      <td>árabes assumem nesta quarta primeira refinari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>19.434349</td>\n",
       "      <td>93826600</td>\n",
       "      <td>-0.048319</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras é a segunda maior do mundo em opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>19.634359</td>\n",
       "      <td>50745400</td>\n",
       "      <td>0.010292</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>18.747646</td>\n",
       "      <td>80673300</td>\n",
       "      <td>-0.045161</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Adj Close    Volume      Var%  Fechamento  \\\n",
       "0 2021-01-04  19.274340  74719700  0.020113           1   \n",
       "1 2021-01-05  20.027718  95181100  0.039087           1   \n",
       "2 2021-01-06  20.067719  96562500  0.001997           1   \n",
       "3 2021-01-07  20.667747  56171300  0.029900           1   \n",
       "4 2021-01-08  20.747751  67136300  0.003871           1   \n",
       "5 2021-01-11  20.574409  48744700 -0.008355           0   \n",
       "6 2021-01-12  20.421068  65691900 -0.007453           0   \n",
       "7 2021-01-13  19.434349  93826600 -0.048319           0   \n",
       "8 2021-01-14  19.634359  50745400  0.010292           1   \n",
       "9 2021-01-15  18.747646  80673300 -0.045161           0   \n",
       "\n",
       "                                            Noticias  \n",
       "0   tcu avalia barrar venda de refinaria da petro...  \n",
       "1   petrobras (petr4) inicia contratação de nona ...  \n",
       "2   valor de venda de refinaria da petrobras é qu...  \n",
       "3   petrobras confirma venda da fatia na br distr...  \n",
       "4                                                NaN  \n",
       "5    silva e luna 'militariza' cúpula da petrobra...  \n",
       "6   árabes assumem nesta quarta primeira refinari...  \n",
       "7   petrobras é a segunda maior do mundo em opera...  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(left = df_petro, right = df_news_diaria_atualizada, how = 'left', on = 'Date')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>a construção naval brasileira tem chances de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>petrobras reajusta preço da gasolina pela qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>tcu avalia barrar venda de refinaria da petro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>petrobras (petr4) inicia contratação de nona ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>valor de venda de refinaria da petrobras é qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>petrobras confirma venda da fatia na br distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-09</td>\n",
       "      <td>silva e luna 'militariza' cúpula da petrobras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>bolsonaro sugere usar dividendos da petrobras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>silva e luna 'militariza' cúpula da petrobra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>árabes assumem nesta quarta primeira refinari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>petrobras é a segunda maior do mundo em opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-16</td>\n",
       "      <td>mais de 100 vagas de emprego no setor de petr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                           Noticias\n",
       "0  2021-01-01   a construção naval brasileira tem chances de ...\n",
       "1  2021-01-03   petrobras reajusta preço da gasolina pela qui...\n",
       "2  2021-01-04   tcu avalia barrar venda de refinaria da petro...\n",
       "3  2021-01-05   petrobras (petr4) inicia contratação de nona ...\n",
       "4  2021-01-06   valor de venda de refinaria da petrobras é qu...\n",
       "5  2021-01-07   petrobras confirma venda da fatia na br distr...\n",
       "6  2021-01-09   silva e luna 'militariza' cúpula da petrobras...\n",
       "7  2021-01-10   bolsonaro sugere usar dividendos da petrobras...\n",
       "8  2021-01-11    silva e luna 'militariza' cúpula da petrobra...\n",
       "9  2021-01-12   árabes assumem nesta quarta primeira refinari...\n",
       "10 2021-01-13   petrobras é a segunda maior do mundo em opera...\n",
       "11 2021-01-16   mais de 100 vagas de emprego no setor de petr..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_diaria_atualizada.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4     2021-01-08\n",
       " 8     2021-01-14\n",
       " 9     2021-01-15\n",
       " 13    2021-01-21\n",
       " 16    2021-01-27\n",
       " 22    2021-02-04\n",
       " 40    2021-03-04\n",
       " 41    2021-03-05\n",
       " 43    2021-03-09\n",
       " 51    2021-03-19\n",
       " 63    2021-04-07\n",
       " 68    2021-04-14\n",
       " 72    2021-04-20\n",
       " 83    2021-05-06\n",
       " 87    2021-05-12\n",
       " 117   2021-06-24\n",
       " 122   2021-07-01\n",
       " 134   2021-07-20\n",
       " 136   2021-07-22\n",
       " 140   2021-07-28\n",
       " 142   2021-07-30\n",
       " 146   2021-08-05\n",
       " 147   2021-08-06\n",
       " 152   2021-08-13\n",
       " 170   2021-09-09\n",
       " 171   2021-09-10\n",
       " 208   2021-11-04\n",
       " 220   2021-11-23\n",
       " Name: Date, dtype: datetime64[ns],\n",
       " 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[(df_final['Noticias'].isnull())].Date, len(df_final[(df_final['Noticias'].isnull())].Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No total houveram 28 registros de pregões sem atribuição de noticias.\n",
    "\n",
    "Para esses registros observou-se que:  \n",
    "\n",
    "**1) Não houveram noticias na respectiva data e/ou**  \n",
    "**2) Considerando as datas sem pregões que antecederam a data do pregão também não houveram noticias.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final), len(df_final[(df_final['Noticias'].isnull())].Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Exclusão dias com pregões sem noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 NLP\n",
    "\n",
    "Será realizado o levantamento das palavras mais frequentes em notícias para inputação de polaridade no dicionário SentilexPT caso não existam ainda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 SentilexPT: Inputação de polaridade de novos termos ao dicionário SentilexPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilexpt = open('SentiLex-lem-PT01.txt','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um dicionário com polaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_palavra_polaridade = {}\n",
    "for i in sentilexpt.readlines():\n",
    "    pos_ponto = i.find('.')            # obtem a posiçãodo caracter ponto\n",
    "    palavra = (i[:pos_ponto])          # Pega a palavra\n",
    "    pol_pos = i.find('POL')            # obtem a posição do inicio da string POL\n",
    "    polaridade = (i[pol_pos+4:pol_pos+6]).replace(';','')         # obtem a polaridade da palavra\n",
    "    dic_palavra_polaridade[palavra] = polaridade                  # atualiza o dicionario com a palavra a polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (dic_palavra_polaridade.get('legal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "print (dic_palavra_polaridade.get('chato'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score_sentimento(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    l_sentimento = []                         # cria uma lista vazia\n",
    "    for p in frase.split():\n",
    "        l_sentimento.append(int(dic_palavra_polaridade.get(p, 0)))      # para cada palavra obtem a polaridade\n",
    "    #print (l_sentimento)                                                # imprime a lista de polaridades\n",
    "    score = sum(l_sentimento)                                           # soma todos os valores da lista\n",
    "    #if score > 0:\n",
    "        #return 'Positivo, Score:{}'.format(score)                       # se maior que 0 retorna 'positivo'\n",
    "    #elif score == 0:\n",
    "        #return 'Neutro, Score:{}'.format(score)                         # se igual a 0 retorna 'neutro'\n",
    "    #else:\n",
    "        #return 'Negativo, Score:{}'.format(score)                       # se menor que 0 retorna 'negativo'\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimento(score):\n",
    "    if score > 0:\n",
    "        return 'Positivo'                      # se maior que 0 retorna 'positivo'\n",
    "    elif score == 0:\n",
    "        return 'Neutro'                     # se igual a 0 retorna 'neutro'\n",
    "    else:\n",
    "        return 'Negativo'                     # se menor que 0 retorna 'negativo'\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testescore = Score_sentimento(\"DescaRadO e feIo\")\n",
    "testescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negativo'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimento(testescore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2 = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>1</td>\n",
       "      <td>tcu avalia barrar venda de refinaria da petro...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras (petr4) inicia contratação de nona ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "      <td>valor de venda de refinaria da petrobras é qu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras confirma venda da fatia na br distr...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>20.574409</td>\n",
       "      <td>48744700</td>\n",
       "      <td>-0.008355</td>\n",
       "      <td>0</td>\n",
       "      <td>silva e luna 'militariza' cúpula da petrobra...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23.237993</td>\n",
       "      <td>28713600</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>1</td>\n",
       "      <td>programa da petrobras que reforça capital de ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>23.582502</td>\n",
       "      <td>44227900</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras vende carmópolis por us$ 1,1 bilhã...</td>\n",
       "      <td>3</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.607111</td>\n",
       "      <td>30688100</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>1</td>\n",
       "      <td>distribuidoras de gás de 5 estados entram na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>23.410248</td>\n",
       "      <td>35508400</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras vai recorrer de decisão que suspend...</td>\n",
       "      <td>3</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>23.336424</td>\n",
       "      <td>43229100</td>\n",
       "      <td>-0.003153</td>\n",
       "      <td>0</td>\n",
       "      <td>judicialização coloca mercado de gás em risco...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume      Var%  Fechamento  \\\n",
       "0   2021-01-04  19.274340  74719700  0.020113           1   \n",
       "1   2021-01-05  20.027718  95181100  0.039087           1   \n",
       "2   2021-01-06  20.067719  96562500  0.001997           1   \n",
       "3   2021-01-07  20.667747  56171300  0.029900           1   \n",
       "5   2021-01-11  20.574409  48744700 -0.008355           0   \n",
       "..         ...        ...       ...       ...         ...   \n",
       "242 2021-12-23  23.237993  28713600  0.006037           1   \n",
       "243 2021-12-27  23.582502  44227900  0.014825           1   \n",
       "244 2021-12-28  23.607111  30688100  0.001044           1   \n",
       "245 2021-12-29  23.410248  35508400 -0.008339           0   \n",
       "246 2021-12-30  23.336424  43229100 -0.003153           0   \n",
       "\n",
       "                                              Noticias  score Sentimento  \n",
       "0     tcu avalia barrar venda de refinaria da petro...     -1   Negativo  \n",
       "1     petrobras (petr4) inicia contratação de nona ...      0     Neutro  \n",
       "2     valor de venda de refinaria da petrobras é qu...     -1   Negativo  \n",
       "3     petrobras confirma venda da fatia na br distr...      0     Neutro  \n",
       "5      silva e luna 'militariza' cúpula da petrobra...      0     Neutro  \n",
       "..                                                 ...    ...        ...  \n",
       "242   programa da petrobras que reforça capital de ...     -1   Negativo  \n",
       "243    petrobras vende carmópolis por us$ 1,1 bilhã...      3   Positivo  \n",
       "244   distribuidoras de gás de 5 estados entram na ...      0     Neutro  \n",
       "245   petrobras vai recorrer de decisão que suspend...      3   Positivo  \n",
       "246   judicialização coloca mercado de gás em risco...      0     Neutro  \n",
       "\n",
       "[219 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2['score'] = df_final2['Noticias'].apply(lambda x: Score_sentimento(x))\n",
    "df_final2['Sentimento'] = df_final2['score'].apply(lambda x: sentimento(x))\n",
    "df_final2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1º Alterações Lenon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pegando os dias de maiores volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final21 = df_final2.sort_values(by=['Volume'], ascending=False)\n",
    "df30 = df_final21.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>14.447424</td>\n",
       "      <td>490230400</td>\n",
       "      <td>-0.207098</td>\n",
       "      <td>0</td>\n",
       "      <td>bolsonaro indica joaquim silva e luna para p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>16.040838</td>\n",
       "      <td>293503100</td>\n",
       "      <td>0.110291</td>\n",
       "      <td>1</td>\n",
       "      <td>troca de comando na petrobras: veja perguntas...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>18.220953</td>\n",
       "      <td>215834800</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0</td>\n",
       "      <td>bolsonaro critica petrobras após reajuste de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>16.732317</td>\n",
       "      <td>196519100</td>\n",
       "      <td>0.057952</td>\n",
       "      <td>1</td>\n",
       "      <td>conselheiro renuncia e tumultua sucessão na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>18.124380</td>\n",
       "      <td>196135500</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras diz que busca competitividade com p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>23.098549</td>\n",
       "      <td>33734500</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras (petr3; petr4) conclui renovação de...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>16.387749</td>\n",
       "      <td>33281000</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras pagará dividendos em 29 de abril p...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.607111</td>\n",
       "      <td>30688100</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>1</td>\n",
       "      <td>distribuidoras de gás de 5 estados entram na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23.237993</td>\n",
       "      <td>28713600</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>1</td>\n",
       "      <td>programa da petrobras que reforça capital de ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>19.320694</td>\n",
       "      <td>26770700</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras anuncia redução no preço do diesel...</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close     Volume      Var%  Fechamento  \\\n",
       "32  2021-02-22  14.447424  490230400 -0.207098           0   \n",
       "33  2021-02-23  16.040838  293503100  0.110291           1   \n",
       "31  2021-02-19  18.220953  215834800 -0.066280           0   \n",
       "71  2021-04-19  16.732317  196519100  0.057952           1   \n",
       "89  2021-05-14  18.124380  196135500  0.052421           1   \n",
       "..         ...        ...        ...       ...         ...   \n",
       "241 2021-12-22  23.098549   33734500 -0.001418           0   \n",
       "75  2021-04-26  16.387749   33281000  0.003799           1   \n",
       "244 2021-12-28  23.607111   30688100  0.001044           1   \n",
       "242 2021-12-23  23.237993   28713600  0.006037           1   \n",
       "168 2021-09-06  19.320694   26770700  0.004937           1   \n",
       "\n",
       "                                              Noticias  score Sentimento  \n",
       "32     bolsonaro indica joaquim silva e luna para p...      1   Positivo  \n",
       "33    troca de comando na petrobras: veja perguntas...     -1   Negativo  \n",
       "31    bolsonaro critica petrobras após reajuste de ...      0     Neutro  \n",
       "71     conselheiro renuncia e tumultua sucessão na ...      0     Neutro  \n",
       "89    petrobras diz que busca competitividade com p...      1   Positivo  \n",
       "..                                                 ...    ...        ...  \n",
       "241   petrobras (petr3; petr4) conclui renovação de...      0     Neutro  \n",
       "75     petrobras pagará dividendos em 29 de abril p...      0     Neutro  \n",
       "244   distribuidoras de gás de 5 estados entram na ...      0     Neutro  \n",
       "242   programa da petrobras que reforça capital de ...     -1   Negativo  \n",
       "168    petrobras anuncia redução no preço do diesel...      0     Neutro  \n",
       "\n",
       "[219 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analise dos 30 dias de maior volume \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fechamento</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Adj Close  Volume  Var%  Noticias  score  Sentimento\n",
       "Fechamento                                                            \n",
       "0             17         17      17    17        17     17          17\n",
       "1             13         13      13    13        13     13          13"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df30.groupby(['Fechamento']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentimento</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negativo</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positivo</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Adj Close  Volume  Var%  Fechamento  Noticias  score\n",
       "Sentimento                                                            \n",
       "Negativo       9          9       9     9           9         9      9\n",
       "Neutro        14         14      14    14          14        14     14\n",
       "Positivo       7          7       7     7           7         7      7"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df30.groupby(['Sentimento']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre os 30 dias de maior volume: \n",
    "- 56% sao de quedas e 44% sao de alta\n",
    "- 23% sentimento positivo, 46% neutro e 30% negativo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as palavras mais comuns no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_final21['Noticias']\n",
    "list(a)\n",
    "b = a.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  bolsonaro indica joaquim silva e luna para presidência da petrobras bolsonaro anuncia indicação de general joaquim silva e luna para assumir presidência da petrobras bolsonaro anuncia general como novo presidente da petrobras bolsonaro demite presidente da petrobras e indica general da reserva para o cargo brasileiro precisa entender que petrobras não pode ser a única responsável por preço, diz especialista petrobras não tem um presidente militar desde 1988  general luna deve manter atual política de preços da petrobras após intervir na petrobras, bolsonaro diz que gasolina poderia estar 15% mais barata conselho da petrobras é formado em sua maioria por nomes escolhidos pelo governo petrobras (petr4): analistas demonstram preocupação com mudança no comando sucessão na petrobras: saiba quem são os conselheiros que vão avaliar indicação de silva e luna para a presidência da estatal petrobras (petr4) caindo? não posso ignorar o 'tapa na cara ...  ‘não há mais como defender. rebaixamos para venda’, diz xp sobre petrobras xp rebaixa para venda recomendação para as ações da petrobras após anúncio de troca de comando petrobras pode ser investigada por mudança de comando abrupta princípio de incêndio atinge plataforma p-48 da petrobras em campos com venda de refinarias, pressão para petrobras controlar combustível pode ser menor petrobras: gestora inglesa de us$ 560 bi faz alerta ao conselho e pede independência petrobras: salim mattar aponta truculência e diz que governo ... ‘vamos meter o dedo na energia elétrica’, diz bolsonaro um dia depois de anunciar troca no comando da petrobras petrobras: política de preço da era dilma custou r$ 100 bi, mais que toda lava-jato brasil se prepara para turbulência puxada por petrobras enquanto mercados globais acumulam alta\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras = nltk.word_tokenize(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "frequencia = FreqDist(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma lista com as noticias de todos os dias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df_final2['Noticias']\n",
    "a = list(a)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"\"\n",
    "for i in a:\n",
    "    c += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = c\n",
    "palavras = nltk.word_tokenize(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('petrobras', 1513),\n",
       " ('de', 1104),\n",
       " ('da', 713),\n",
       " ('e', 529),\n",
       " (',', 522),\n",
       " ('em', 338),\n",
       " ('...', 299),\n",
       " ('do', 296),\n",
       " ('para', 289),\n",
       " ('a', 283),\n",
       " ('no', 225),\n",
       " ('na', 224),\n",
       " ('com', 196),\n",
       " ('(', 187),\n",
       " (')', 185),\n",
       " (':', 181),\n",
       " ('que', 178),\n",
       " ('$', 178),\n",
       " ('%', 154),\n",
       " ('por', 146),\n",
       " ('diz', 135),\n",
       " ('o', 127),\n",
       " ('r', 123),\n",
       " ('venda', 119),\n",
       " ('bolsonaro', 112),\n",
       " ('petr4', 108),\n",
       " ('mais', 107),\n",
       " ('gás', 104),\n",
       " (';', 103),\n",
       " ('gasolina', 96),\n",
       " ('preço', 88),\n",
       " ('é', 87),\n",
       " ('não', 82),\n",
       " ('preços', 82),\n",
       " ('ações', 79),\n",
       " ('petróleo', 70),\n",
       " ('após', 68),\n",
       " ('combustíveis', 64),\n",
       " ('diesel', 62),\n",
       " ('refinaria', 58),\n",
       " ('sobre', 57),\n",
       " ('us', 57),\n",
       " ('dos', 54),\n",
       " ('vale', 53),\n",
       " ('vai', 53),\n",
       " ('alta', 51),\n",
       " ('política', 51),\n",
       " ('dividendos', 51),\n",
       " ('à', 51),\n",
       " ('pela', 50),\n",
       " ('anuncia', 50),\n",
       " (\"'\", 49),\n",
       " ('pode', 46),\n",
       " ('presidente', 45),\n",
       " ('novo', 45),\n",
       " ('bi', 44),\n",
       " ('ao', 44),\n",
       " ('os', 44),\n",
       " ('tem', 42),\n",
       " ('bilhões', 41),\n",
       " ('campos', 40),\n",
       " ('se', 39),\n",
       " ('até', 39),\n",
       " ('?', 38),\n",
       " ('milhões', 37),\n",
       " ('reajuste', 35),\n",
       " ('refinarias', 35),\n",
       " ('campo', 33),\n",
       " ('vende', 33),\n",
       " ('aumento', 33),\n",
       " ('governo', 33),\n",
       " ('brasil', 32),\n",
       " ('nas', 32),\n",
       " ('das', 32),\n",
       " ('lucro', 32),\n",
       " ('mercado', 31),\n",
       " ('sobe', 31),\n",
       " ('bacia', 31),\n",
       " ('como', 31),\n",
       " ('privatização', 30)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = FreqDist(frase)\n",
    "fdist = FreqDist(palavras)\n",
    "fdist.most_common(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoçao de stopwords, talvez seja melhor remover depois de fazer a traduçao e remover em ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Removestopwords(instancia):\n",
    "    instancia = instancia.lower()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteres = [\",\",\"...\", \"(\",\" )\" ,\":\", \"$\",  \"%\",  \";\", \"'\", \"(PETR4)\", \"PETR4\", \"petr4\",\"(petr4)\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Removestopwords(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac = \"!@#$;:,%')(?\"\n",
    "for i in range(0,len(carac)):\n",
    "     d =d.replace(carac[i],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac2 = \"...\"\n",
    "for i in range(0,len(carac2)):\n",
    "     d =d.replace(carac2[i],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = d\n",
    "palavras = nltk.word_tokenize(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('petrobras', 1512),\n",
       " ('diz', 135),\n",
       " ('venda', 118),\n",
       " ('r', 116),\n",
       " ('bolsonaro', 112),\n",
       " ('gás', 104),\n",
       " ('petr4', 103),\n",
       " ('gasolina', 96),\n",
       " ('preço', 88),\n",
       " ('preços', 82),\n",
       " ('ações', 79),\n",
       " ('petróleo', 70),\n",
       " ('após', 68),\n",
       " ('combustíveis', 64),\n",
       " ('diesel', 64),\n",
       " ('refinaria', 58),\n",
       " ('sobre', 57),\n",
       " ('us', 55),\n",
       " ('vale', 53),\n",
       " ('vai', 53),\n",
       " ('alta', 51),\n",
       " ('política', 51),\n",
       " ('dividendos', 51),\n",
       " ('anuncia', 50),\n",
       " ('pode', 46),\n",
       " ('presidente', 45),\n",
       " ('novo', 45),\n",
       " ('bi', 44),\n",
       " ('bilhões', 41),\n",
       " ('campos', 40),\n",
       " ('milhões', 37),\n",
       " ('reajuste', 35),\n",
       " ('refinarias', 35),\n",
       " ('campo', 33),\n",
       " ('vende', 33),\n",
       " ('aumento', 33),\n",
       " ('governo', 33),\n",
       " ('brasil', 32),\n",
       " ('lucro', 32),\n",
       " ('mercado', 31),\n",
       " ('sobe', 31),\n",
       " ('bacia', 31),\n",
       " ('privatização', 30),\n",
       " ('contrato', 30),\n",
       " ('ação', 29),\n",
       " ('bahia', 28),\n",
       " ('quer', 28),\n",
       " ('maior', 28),\n",
       " ('plataforma', 28),\n",
       " ('ibovespa', 28),\n",
       " ('contra', 27),\n",
       " ('rio', 27),\n",
       " ('fecha', 27),\n",
       " ('natural', 27),\n",
       " ('cai', 27),\n",
       " ('empresas', 27),\n",
       " ('valor', 26),\n",
       " ('conclui', 26),\n",
       " ('vender', 26),\n",
       " ('produção', 26),\n",
       " ('“', 25),\n",
       " ('veja', 25),\n",
       " ('pré-sal', 25),\n",
       " ('deve', 24),\n",
       " ('anos', 24),\n",
       " ('faz', 24),\n",
       " ('silva', 23),\n",
       " ('luna', 23),\n",
       " ('queda', 23),\n",
       " ('guedes', 23),\n",
       " ('mil', 22),\n",
       " ('empresa', 21),\n",
       " ('cvm', 21),\n",
       " ('assina', 21),\n",
       " ('”', 20),\n",
       " ('compra', 20),\n",
       " ('’', 20),\n",
       " ('aprova', 20),\n",
       " ('combustível', 20),\n",
       " ('nova', 20)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = FreqDist(frase)\n",
    "fdist = FreqDist(palavras)\n",
    "fdist.most_common(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim 1º Alteracoes Lenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Tradução e aplicação textblob e vader sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando função de tradução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==4.0.0-rc1 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (4.0.0rc1)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.5.18.1)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.12.1)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\lenon.oliveira\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O livro está sobre a mesa'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.translate(\"The book is on the table\", dest = 'pt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduzir(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    frase = trans.translate(frase, dest = 'en').text\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the food is very good'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_teste = traduzir(\"A comida está muito boa\")\n",
    "frase_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando calculo de polaridade e subjetividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9099999999999999, 0.7800000000000001)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_blob = TextBlob(frase_teste)\n",
    "polaridade = text_blob.polarity\n",
    "subjetividade = text_blob.subjectivity\n",
    "\n",
    "polaridade, subjetividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polaridade(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    text_blob = TextBlob(frase)\n",
    "    polaridade = text_blob.polarity\n",
    "    return polaridade\n",
    "\n",
    "def subjetividade(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    text_blob = TextBlob(frase)\n",
    "    subjetividade = text_blob.subjectivity\n",
    "    return subjetividade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando calculo de sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_analyze = SentimentIntensityAnalyzer()\n",
    "sentiment= s_analyze.polarity_scores(frase_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4927}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentiment)\n",
    "sentiment.get('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negatividade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('neg')\n",
    "    return sentimento\n",
    "\n",
    "def neutralidade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('neu')\n",
    "    return sentimento\n",
    "\n",
    "def positividade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('pos')\n",
    "    return sentimento\n",
    "\n",
    "def composicao(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('compound')\n",
    "    return sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final3 = df_final.copy()\n",
    "df_final3 = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2º Alteraçoes Lenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.dropna(subset=['Noticias'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3 = df_final3[df_final3['Noticias']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\3030430285.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3.drop(['index'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df_final3.drop(['index'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\4265196471.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['Noticias'][i] = trans.translate(df_final3['Noticias'][i]).text\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(df_final3['Noticias'])):\n",
    "    if len(df_final3['Noticias'][i])>0:\n",
    "        df_final3['Noticias'][i] = trans.translate(df_final3['Noticias'][i]).text\n",
    "        time.sleep(2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim 2º Alteraçoes Lenon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['polaridade'] = df_final3['Noticias'].apply(lambda x: polaridade(x))\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['subjetividade'] = df_final3['Noticias'].apply(lambda x: subjetividade(x))\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['negatividade'] = df_final3['Noticias'].apply(lambda x: negatividade(x))\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['neutralidade'] = df_final3['Noticias'].apply(lambda x: neutralidade(x))\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['positividade'] = df_final3['Noticias'].apply(lambda x: positividade(x))\n",
      "C:\\Users\\lenon.oliveira\\AppData\\Local\\Temp\\ipykernel_19120\\392382725.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final3['composicao'] = df_final3['Noticias'].apply(lambda x: composicao(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>polaridade</th>\n",
       "      <th>subjetividade</th>\n",
       "      <th>negatividade</th>\n",
       "      <th>neutralidade</th>\n",
       "      <th>positividade</th>\n",
       "      <th>composicao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>19.274340</td>\n",
       "      <td>74719700</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>1</td>\n",
       "      <td>TCU Evaluates Barrar Petrobras Refinery Sale t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>20.027718</td>\n",
       "      <td>95181100</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>1</td>\n",
       "      <td>Petrbras (Petr4) Starts Hiring Ninth Unit of C...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>20.067719</td>\n",
       "      <td>96562500</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "      <td>Petrobras Refinery Sale Value is questioned in...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>20.667747</td>\n",
       "      <td>56171300</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>1</td>\n",
       "      <td>Petrobras confirms the sale of the slice on BR...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>20.574409</td>\n",
       "      <td>48744700</td>\n",
       "      <td>-0.008355</td>\n",
       "      <td>0</td>\n",
       "      <td>Silva and Luna 'militariza' Petrobras Summit P...</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.378333</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>23.237993</td>\n",
       "      <td>28713600</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>1</td>\n",
       "      <td>Petrobras program that reinforces supplier wor...</td>\n",
       "      <td>0.367273</td>\n",
       "      <td>0.430909</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.5256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>23.582502</td>\n",
       "      <td>44227900</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>1</td>\n",
       "      <td>Petrobras sells Carmópolis for $ 1.1 billion P...</td>\n",
       "      <td>0.221818</td>\n",
       "      <td>0.499394</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.607111</td>\n",
       "      <td>30688100</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>1</td>\n",
       "      <td>Gas distributors of 5 states go to court again...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>23.410248</td>\n",
       "      <td>35508400</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras will appeal a decision that suspends...</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.395238</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>23.336424</td>\n",
       "      <td>43229100</td>\n",
       "      <td>-0.003153</td>\n",
       "      <td>0</td>\n",
       "      <td>Judicialization puts gas market at risk, says ...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume      Var%  Fechamento  \\\n",
       "0   2021-01-04  19.274340  74719700  0.020113           1   \n",
       "1   2021-01-05  20.027718  95181100  0.039087           1   \n",
       "2   2021-01-06  20.067719  96562500  0.001997           1   \n",
       "3   2021-01-07  20.667747  56171300  0.029900           1   \n",
       "4   2021-01-11  20.574409  48744700 -0.008355           0   \n",
       "..         ...        ...       ...       ...         ...   \n",
       "212 2021-12-23  23.237993  28713600  0.006037           1   \n",
       "213 2021-12-27  23.582502  44227900  0.014825           1   \n",
       "214 2021-12-28  23.607111  30688100  0.001044           1   \n",
       "215 2021-12-29  23.410248  35508400 -0.008339           0   \n",
       "216 2021-12-30  23.336424  43229100 -0.003153           0   \n",
       "\n",
       "                                              Noticias  polaridade  \\\n",
       "0    TCU Evaluates Barrar Petrobras Refinery Sale t...    0.000000   \n",
       "1    Petrbras (Petr4) Starts Hiring Ninth Unit of C...    0.000000   \n",
       "2    Petrobras Refinery Sale Value is questioned in...    0.150000   \n",
       "3    Petrobras confirms the sale of the slice on BR...    0.000000   \n",
       "4    Silva and Luna 'militariza' Petrobras Summit P...    0.085000   \n",
       "..                                                 ...         ...   \n",
       "212  Petrobras program that reinforces supplier wor...    0.367273   \n",
       "213  Petrobras sells Carmópolis for $ 1.1 billion P...    0.221818   \n",
       "214  Gas distributors of 5 states go to court again...    0.466667   \n",
       "215  Petrobras will appeal a decision that suspends...    0.185714   \n",
       "216  Judicialization puts gas market at risk, says ...    0.050000   \n",
       "\n",
       "     subjetividade  negatividade  neutralidade  positividade  composicao  \n",
       "0         0.000000         0.196         0.804         0.000     -0.7783  \n",
       "1         0.000000         0.000         1.000         0.000      0.0000  \n",
       "2         0.350000         0.020         0.917         0.063      0.4404  \n",
       "3         0.000000         0.051         0.924         0.025     -0.3182  \n",
       "4         0.378333         0.041         0.901         0.057      0.1901  \n",
       "..             ...           ...           ...           ...         ...  \n",
       "212       0.430909         0.000         0.938         0.062      0.5256  \n",
       "213       0.499394         0.098         0.804         0.098     -0.2382  \n",
       "214       0.600000         0.000         0.928         0.072      0.7579  \n",
       "215       0.395238         0.016         0.839         0.145      0.9099  \n",
       "216       0.600000         0.046         0.911         0.043     -0.0516  \n",
       "\n",
       "[217 rows x 12 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final3['polaridade'] = df_final3['Noticias'].apply(lambda x: polaridade(x))\n",
    "df_final3['subjetividade'] = df_final3['Noticias'].apply(lambda x: subjetividade(x))\n",
    "df_final3['negatividade'] = df_final3['Noticias'].apply(lambda x: negatividade(x))\n",
    "df_final3['neutralidade'] = df_final3['Noticias'].apply(lambda x: neutralidade(x))\n",
    "df_final3['positividade'] = df_final3['Noticias'].apply(lambda x: positividade(x))\n",
    "df_final3['composicao'] = df_final3['Noticias'].apply(lambda x: composicao(x))\n",
    "df_final3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Tradução e aplicação do modelo pré-treinado de Roberta\n",
    "https://www.kaggle.com/code/robikscube/sentiment-analysis-python-youtube-tutorial/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install –upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"This oatmeal is not good. Its mushy, soft, I don't like it. Quaker Oats is the way to go.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    neg_roberta = scores[0]\n",
    "   # neu_roberta = scores[1]\n",
    "   # pos_roberta = scores[2]\n",
    "    return neg_roberta\n",
    "\n",
    "def neu_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    #neg_roberta = scores[0]\n",
    "    neu_roberta = scores[1]\n",
    "    #pos_roberta = scores[2]\n",
    "    return neu_roberta\n",
    "\n",
    "def pos_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    #neg_roberta = scores[0]\n",
    "    #neu_roberta = scores[1]\n",
    "    pos_roberta = scores[2]\n",
    "    return pos_roberta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final4 = df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final4['Noticias'] = df_final4['Noticias'].apply(lambda x: traduzir(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final4['Noticias'] = df_final3['Noticias']\n",
    "df_final4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final4['neg_rob'] = df_final4['Noticias'].apply(lambda x: neg_rob(x))\n",
    "df_final4['neu_rob'] = df_final4['Noticias'].apply(lambda x: neu_rob(x))\n",
    "df_final4['pos_rob'] = df_final4['Noticias'].apply(lambda x: pos_rob(x))\n",
    "df_final4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Machine Learning: Testes inicias com seleção de features e classificação com algorítmos ingênuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 SentilexPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final2.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias','Sentimento'])\n",
    "y = df_final2['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 65% á 59%\n",
    "- DummyClassifier\n",
    "- QuadraticDiscriminantAnalysis      \n",
    "- GaussianNB  \n",
    "- LinearSVC    \n",
    "- LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Tradução + Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final3.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias'])\n",
    "y = df_final3['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 65% á 64%\n",
    "- DummyClassifier\n",
    "- XGBClassifier                           \n",
    "- LinearSVC                             \n",
    "- LogisticRegression                     \n",
    "- RidgeClassifier                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Modelo pré-treinado de Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final4.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias'])\n",
    "y = df_final4['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 65% á 52%\n",
    "- DummyClassifier                    \n",
    "- Perceptron                                                    \n",
    "- SGDClassifier                                                   \n",
    "- BernoulliNB                                             \n",
    "- NearestCentroid                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Composição SentilextPT + Tradução & Vader Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final5 = df_final3.merge(df_final2, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final5.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y','Sentimento'])\n",
    "y = df_final5['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos ficou em 68%\n",
    "- ExtraTreesClassifier                                         \n",
    "- LinearSVC                                                 \n",
    "- RidgeClassifierCV                                      \n",
    "- LogisticRegression                     \n",
    "- LinearDiscriminantAnalysis                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Composição SentilextPT + Tradução & Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final6 = df_final4.merge(df_final2, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final6.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y','Sentimento'])\n",
    "y = df_final6['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 65% á 58%\n",
    "\n",
    "DummyClassifier                    \n",
    "Perceptron                         \n",
    "LinearSVC                          \n",
    "LogisticRegression                 \n",
    "RidgeClassifier                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Composição Tradução & Vader Sentiment + Tradução & Roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final7 = df_final4.merge(df_final3, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final7.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y'])\n",
    "y = df_final7['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 65% á 61%\n",
    "\n",
    "DummyClassifier                    \n",
    "LinearSVC                                                   \n",
    "LinearDiscriminantAnalysis  \n",
    "RidgeClassifier    \n",
    "LogisticRegression                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Composição SentilexPT + Tradução & Vader Sentiment + Tradução & Roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentilex + Vader\n",
    "df_final8 = df_final3.merge(df_final2, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + Roberta\n",
    "df_final8 = df_final8.merge(df_final4, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final8.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y', 'Noticias', 'Sentimento'])\n",
    "y = df_final8['Fechamento']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 67% á 64%\n",
    "\n",
    "CalibratedClassifierCV                                 \n",
    "LogisticRegression                                                                    \n",
    "RidgeClassifierCV                    \n",
    "DummyClassifier                        \n",
    "LinearSVC                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Composição SentilexPT + Tradução & Vader Sentiment + Tradução & Roberta com Diminuição de dimensionalidade e Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "\n",
    "X = df_final8.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y', 'Noticias', 'Sentimento'])\n",
    "y = df_final8['Fechamento']\n",
    "    \n",
    "## Laço para experimentações com diversos numeros de PCA (de 2 á 9)\n",
    "for i in range(2,len(X.columns),1):\n",
    "    print(\"Testando com PCA = %s!\" % i)\n",
    "    #Holdout\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) ### \n",
    "    \n",
    "    #Aplicando PCA\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.fit_transform(x_test)\n",
    "\n",
    "    # normalizando os dados de treino e teste\n",
    "    scaler_train = StandardScaler()\n",
    "    scaler_test = StandardScaler()\n",
    "\n",
    "    scaler_train.fit(x_train)\n",
    "    scaler_test.fit(x_test)\n",
    "\n",
    "    x_train_normalized = scaler_train.transform(x_train)\n",
    "    x_test_normalized = scaler_test.transform(x_test)\n",
    "\n",
    "    #Testando os modelos\n",
    "    reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = reg.fit(x_train_normalized, x_test_normalized, y_train, y_test)\n",
    "    models['n_PCA'] = i\n",
    "\n",
    "    # Armazenando os 5 melhores modelos (Maiores Acurácia)\n",
    "    df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos ficou em 59%\n",
    "\n",
    "SGDClassifier com 2 features reduzidas  \n",
    "SGDClassifier com 5 features reduzidas\n",
    "CalibratedClassifierCV com 9 features reduzidas  \n",
    "SGDClassifier com 9 features reduzidas  \n",
    "CalibratedClassifierCV com 8 features reduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.9 Composição SentilexPT + Tradução & Vader Sentiment + Tradução & Roberta com Diminuição de dimensionalidade e SEM Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "\n",
    "X = df_final8.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y', 'Noticias', 'Sentimento'])\n",
    "y = df_final8['Fechamento']\n",
    "    \n",
    "## Laço para experimentações com diversos numeros de PCA (de 2 á 9)\n",
    "for i in range(2,len(X.columns),1):\n",
    "    print(\"Testando com PCA = %s!\" % i)\n",
    "    #Holdout\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) ### \n",
    "    \n",
    "    #Aplicando PCA\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.fit_transform(x_test)\n",
    "\n",
    "    #Testando os modelos\n",
    "    reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = reg.fit(x_train, x_test, y_train, y_test)\n",
    "    models['n_PCA'] = i\n",
    "\n",
    "    # Armazenando os 5 melhores modelos (top 5 Maiores Acurácia)\n",
    "    df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 59% a 58%\n",
    "\n",
    "PassiveAggressiveClassifier com 3 features reduzidas  \n",
    "Perceptron com 8 features reduzidas\n",
    "Perceptron com 7 features reduzidas  \n",
    "XGBClassifier com 2 features reduzidas  \n",
    "CalibratedClassifierCV com 9 features reduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Composição SentilextPT + Tradução & Vader Sentiment com Diminuição de dimensionalidade e Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "\n",
    "X = df_final5.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y','Sentimento'])\n",
    "y = df_final5['Fechamento']\n",
    " \n",
    "## Laço para experimentações com diversos numeros de PCA (de 2 á 6)\n",
    "for i in range(2,len(X.columns),1):\n",
    "    print(\"Testando com PCA = %s!\" % i)\n",
    "    #Holdout\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) ### \n",
    "    \n",
    "    #Aplicando PCA\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.fit_transform(x_test)\n",
    "\n",
    "    # normalizando os dados de treino e teste\n",
    "    scaler_train = StandardScaler()\n",
    "    scaler_test = StandardScaler()\n",
    "\n",
    "    scaler_train.fit(x_train)\n",
    "    scaler_test.fit(x_test)\n",
    "\n",
    "    x_train_normalized = scaler_train.transform(x_train)\n",
    "    x_test_normalized = scaler_test.transform(x_test)\n",
    "\n",
    "    #Testando os modelos\n",
    "    reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = reg.fit(x_train_normalized, x_test_normalized, y_train, y_test)\n",
    "    models['n_PCA'] = i\n",
    "\n",
    "    # Armazenando os 5 melhores modelos (Maiores Acurácia)\n",
    "    df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 64% a 59%\n",
    "\n",
    "LabelPropagation com 2 features reduzidas  \n",
    "LabelSpreading com 2 features reduzidas  \n",
    "ExtraTreesClassifier com 4 features reduzidas  \n",
    "RandomForestClassifier com 5 features reduzidas  \n",
    "ExtraTreeClassifier com 5 features reduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.11 Composição SentilextPT + Tradução & Vader Sentiment com Diminuição de dimensionalidade e SEM Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "\n",
    "X = df_final5.drop(columns=['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias_x','Noticias_y','Sentimento'])\n",
    "y = df_final5['Fechamento']\n",
    "    \n",
    "## Laço para experimentações com diversos numeros de PCA (de 2 á 6)\n",
    "for i in range(2,len(X.columns),1):\n",
    "    print(\"Testando com PCA = %s!\" % i)\n",
    "    #Holdout\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) ### \n",
    "    \n",
    "    #Aplicando PCA\n",
    "    pca = PCA(n_components=i)\n",
    "    x_train = pca.fit_transform(x_train)\n",
    "    x_test = pca.fit_transform(x_test)\n",
    "\n",
    "    #Testando os modelos\n",
    "    reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "    models, predictions = reg.fit(x_train, x_test, y_train, y_test)\n",
    "    models['n_PCA'] = i\n",
    "\n",
    "    # Armazenando os 5 melhores modelos (top 5 Maiores Acurácia)\n",
    "    df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia dos top 5 algorítmos variou de 64% a 59%\n",
    "\n",
    "LabelPropagation com 2 features reduzidas  \n",
    "LabelSpreading com 2 features reduzidas  \n",
    "BaggingClassifier com 5 features reduzidas  \n",
    "ExtraTreesClassifier com 3 features reduzidas  \n",
    "RandomForestClassifier com 5 features reduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Feature Engineering - Seleção do conjunto de features de dias anteriores\n",
    "\n",
    "Selecionaremos o conjunto de features composto pelos métodos de NLP \n",
    "- Composição SentilextPT + Tradução & Vader Sentiment sem normalização e sem PCA e;\n",
    "\n",
    "adicionaremos as features de n dias anteriores para avaliar a performance da classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Adição features de dias anteriores ao dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9 = df_final3.merge(df_final2, how = 'left', on = ['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento'])\n",
    "df_final9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['polaridade', 'subjetividade', 'negatividade', 'neutralidade',  'positividade', 'composicao','score']\n",
    "featuresd1 = [i + \"d1\" for i in features]\n",
    "featuresd2 = [i + \"d2\" for i in features]\n",
    "featuresd3 = [i + \"d3\" for i in features]\n",
    "featuresd4 = [i + \"d4\" for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as colunas de features para d-1, d-2, d-3, d-4 e inicializando com valores zeros:\n",
    "for i in features:\n",
    "    df_final9[i+\"d1\"] = 0\n",
    "    df_final9[i+\"d2\"] = 0\n",
    "    df_final9[i+\"d3\"] = 0\n",
    "    df_final9[i+\"d4\"] = 0\n",
    "df_final9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9[['Date','composicao','composicaod4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#atualiza as features de d-1\n",
    "for a,b in itertools.zip_longest(features,featuresd1):\n",
    "    df_final9[b] = df_final9.shift(periods=1)[a]\n",
    "    \n",
    "#atualiza as features de d-2\n",
    "for a,b in itertools.zip_longest(features,featuresd2):\n",
    "    df_final9[b] = df_final9.shift(periods=2)[a]\n",
    "    \n",
    "#atualiza as features de d-3\n",
    "for a,b in itertools.zip_longest(features,featuresd3):\n",
    "    df_final9[b] = df_final9.shift(periods=3)[a]\n",
    "    \n",
    "#atualiza as features de d-4\n",
    "for a,b in itertools.zip_longest(features,featuresd4):\n",
    "    df_final9[b] = df_final9.shift(periods=4)[a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9[['Date','composicao','composicaod4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eliminação dos registros sem as features de dias anteriores (os primeiros 4 dias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9 = df_final9.dropna()\n",
    "df_final9.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final9.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Experimentos \n",
    "iterando sobre d á d-n;  1<=n<=4  \n",
    "c/ s/ PCA   \n",
    "c/ s/ normalização   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um dicionário com o conjunto de features do dia atual ao d-4:\n",
    "feature_dias = {'dia atual': features, 'd-1': features+featuresd1, 'd-2':features+featuresd1+featuresd2, 'd-3':features+featuresd1+featuresd2+featuresd3, 'd-4':features+featuresd1+featuresd2+featuresd3+featuresd4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame()\n",
    "\n",
    "## repetir o experimento 4x para eliminar possibilidade de outliers\n",
    "for rep in range(0,4,1):\n",
    "    \n",
    "    ## iterar sobre o conjunto de features entre a data e o dia -n (para 1<=n<=4)\n",
    "    for k in feature_dias.keys():\n",
    "    \n",
    "        #Lista de features consideradas e definição de X e Y:\n",
    "        lista_features = feature_dias[k]\n",
    "        X = df_final9[lista_features]\n",
    "        y = df_final9['Fechamento']  \n",
    "    \n",
    "        #Holdout em treino e teste\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rep) ###\n",
    "    \n",
    "        ## iterar sobre a quantidade de reduções de dimensionalidade das features (PCA)\n",
    "        for i in range(2,len(X.columns),1):\n",
    "    \n",
    "            #Aplicando PCA\n",
    "            pca = PCA(n_components=i)\n",
    "            x_train_pca = pca.fit_transform(x_train)\n",
    "            x_test_pca = pca.fit_transform(x_test)\n",
    "    \n",
    "            #Aplicando Normalização\n",
    "            scaler_train = StandardScaler()\n",
    "            scaler_test = StandardScaler()\n",
    "\n",
    "            scaler_train.fit(x_train_pca)\n",
    "            scaler_test.fit(x_test_pca)\n",
    "\n",
    "            x_train_pca_normalized = scaler_train.transform(x_train_pca)\n",
    "            x_test_pca_normalized = scaler_test.transform(x_test_pca)\n",
    "\n",
    "\n",
    "            #Testando PCA + normalizado\n",
    "            print(\"Testando para conjunto de features do dia atual à %s com PCA = %s e Normalização - Rep %s!\" % (k,i,rep)) \n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(x_train_pca_normalized, x_test_pca_normalized, y_train, y_test)\n",
    "            models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i\n",
    "            models['Normalizado'] = True\n",
    "            models['repeticao'] = rep\n",
    "            # Armazenando os 5 melhores modelos (top 5 Maiores Acurácia)\n",
    "            df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)\n",
    "    \n",
    "            #Testando PCA\n",
    "            print(\"Testando para conjunto de features do dia atual à %s com PCA = %s! - Rep %s\" % (k,i,rep))\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(x_train_pca, x_test_pca, y_train, y_test)\n",
    "            models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i \n",
    "            models['Normalizado'] = False\n",
    "            models['repeticao'] = rep\n",
    "            # Armazenando os 5 melhores modelos (top 5 Maiores Acurácia)\n",
    "            df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)    \n",
    "\n",
    "    \n",
    "        #Testando sem PCA e sem Normalizacao\n",
    "        print(\"Testando para conjunto de features do dia atual à %s!\" % k)\n",
    "        reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models, predictions = reg.fit(x_train, x_test, y_train, y_test)\n",
    "        models['conjunto_features'] = k\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['Normalizado'] = False\n",
    "        models['repeticao'] = rep\n",
    "        df_models = df_models.append(models.reset_index().sort_values(by='Accuracy', ascending=False).head(5), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolheremos o conjunto de features referente ao dia atual á 3 dias anteriores.\n",
    "\n",
    "Os seguintes modelos serão selecionados para tunagem:\n",
    "\n",
    "- PassiveAggressiveClassifier;  \n",
    "- GaussianNB;  \n",
    "- BernoulliNB;  \n",
    "- QuadraticDiscriminantAnalysis;  \n",
    "- LGBMClassifier;  \n",
    "- RandomForestClassifier;  \n",
    "- NearestCentroid;  \n",
    "- NuSVC;  \n",
    "- XGBClassifier;  \n",
    "- SGDClassifier;  \n",
    "- Perceptron;  \n",
    "- DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Treinamento e tunagem de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 PassiveAggressiveClassifier\n",
    "- Gridsearch (Hiperparametros, PCA)\n",
    "- CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "\n",
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento']  \n",
    "\n",
    "#Holdout fora do loop para não variar conjunto de teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "#Validação cruzada com 10 kfolds\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "#Repete os experimentos 20x\n",
    "for i in range(20):\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        PassiveAggressiveClassifier(random_state=i),\n",
    "        param_grid={\"max_iter\": [25,50,100,200,500,700,1000,1200,1500], \"tol\": [0.01, 0.001, 0.0001], \"C\": [0.01,0.05,0.1,0.5,1.0,1.5]},\n",
    "        scoring=scoring,\n",
    "        refit=\"f1\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "      \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando f1_score\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = roc_auc_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = roc_auc_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_iter'],hyperparams['tol'],hyperparams['C'],acuracy_treino,accuracy_teste,f1_teste,auc_teste]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('^display.',silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_iter', 'tol','C','acuracy_treino','acuracia_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'f1_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "\n",
    "- modelos com max_iter = 25 perfomou melhor (testaremos para valores <=25)\n",
    "- modelos com tol = 0.001 e 0.0001 perfomaram melhor  \n",
    "- modelos com C = 0.05, 0.01 e 0.1 performaram melhor (testaremos para mais valores entre 0.05 e 0.1)\n",
    "\n",
    "Refinando a solução para os hiperparâmetros e aumentando as repetições:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "\n",
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento']  \n",
    "\n",
    "#Holdout fora do loop para não variar conjunto de teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "#Validação cruzada com 10 kfolds\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "#Repete os experimentos 20x\n",
    "for i in range(20):\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        PassiveAggressiveClassifier(random_state=i),\n",
    "        param_grid={\"max_iter\": [6,8,10,12,14,16,18,20], \"tol\": [0.001, 0.0001], \"C\": [0.01,0.03,0.05,0.07,0.09,0.1]},\n",
    "        scoring=scoring,\n",
    "        refit=\"f1\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "      \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando f1_score\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_iter'],hyperparams['tol'],hyperparams['C'],acuracy_treino,accuracy_teste,f1_teste,auc_teste]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_iter', 'tol','C','acuracy_treino','acuracia_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'f1_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados\n",
    "\n",
    "-  Modelos com max_iter = 8,10,14,20 performaram melhor\n",
    "-  Modelos com tol = 0.001 perfomaram melhor\n",
    "\n",
    "Refinando a solução para os hiperparâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "\n",
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento']  \n",
    "\n",
    "#Holdout fora do loop para não variar conjunto de teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "#Validação cruzada com 10 kfolds\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        PassiveAggressiveClassifier(random_state=i),\n",
    "        param_grid={\"max_iter\": [8,10,14,20], \"tol\": [0.001], \"C\": [0.01,0.03,0.05,0.07,0.09,0.1]},\n",
    "        scoring=scoring,\n",
    "        refit=\"f1\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "      \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando f1_score\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_iter'],hyperparams['tol'],hyperparams['C'],acuracy_treino,accuracy_teste,f1_teste,auc_teste]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_iter', 'tol','C','acuracy_treino','acuracia_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'f1_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados\n",
    "\n",
    "- Modelos com max_iter = 14 performaram melhor; \n",
    "- Modelos com tol = 0.001 performaram melhor;  \n",
    "- Modelos com C = 0.03 e 0.09 performaram melhor; \n",
    "\n",
    "Refinando a solução para os hiperparâmetros:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "\n",
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento']  \n",
    "\n",
    "#Holdout fora do loop para não variar conjunto de teste e treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "#Validação cruzada com 10 kfolds\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        PassiveAggressiveClassifier(random_state=i),\n",
    "        param_grid={\"max_iter\": [14], \"tol\": [0.001], \"C\": [0.03,0.09]},\n",
    "        scoring=scoring,\n",
    "        refit=\"f1\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "      \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando f1_score\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_iter'],hyperparams['tol'],hyperparams['C'],acuracy_treino,accuracy_teste,f1_teste,auc_teste]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_iter', 'tol','C','acuracy_treino','acuracia_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'f1_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "max_iter = 14  \n",
    "tol = 0.001  \n",
    "C = 0.03   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1 Avaliação do PassiveAgressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "passagress = PassiveAggressiveClassifier(random_state=1, max_iter = 14, tol = 0.001, C = 0.03)\n",
    "passagress.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = passagress.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"F1_Score: %s\" % (f1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Modelo aprendeu a classificar bem quando há aumento nos valores das ações mas erra bastante quando há queda nos valores embora os dados estejam balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.2 Hyperparâmetros PassiveAggressiveClassifier + balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "\n",
    "## Balanceamento dos dados:\n",
    "nr = NearMiss()\n",
    "X, y = nr.fit_resample(X_todos, y_todos)\n",
    "    \n",
    " #Holdout:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(30):\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        PassiveAggressiveClassifier(random_state=i),\n",
    "        param_grid={\"max_iter\": [25,50,100,200,500,700,1000,1200,1500], \"tol\": [0.01, 0.001, 0.0001], \"C\": [0.01,0.05,0.1,0.5,1.0,1.5]},\n",
    "        scoring=scoring,\n",
    "        refit=\"f1\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_iter'],hyperparams['tol'],hyperparams['C'],acuracy_treino,accuracy_teste,accuracy_todos,rec0_teste,rec0_todos,rec1_teste,rec1_todos,f1_teste,f1_todos,auc_teste,auc_todos]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_iter', 'tol','C','acuracy_treino','acuracia_teste','acuracia_df','rec_0_teste','rec_0_df','rec_1_teste','rec_1_df','f1_teste','f1_df','auc_teste','auc_df'])\n",
    "resultados.sort_values(by = 'f1_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo após balancear os exemplos em 50/50%  os valores de recall não ficaram equilibrados para o maior valor de f1-score.\n",
    "\n",
    "Recall 0: 32.2%; \n",
    "Recall 1: 81.25% \n",
    "\n",
    "materemos o modelo final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passagress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"F1_Score: %s\" % (f1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        GaussianNB(),\n",
    "        param_grid={\"var_smoothing\": [0.0000000000000001,0.000000000000001,0.00000000000001,0.0000000000001,0.000000000001,0.00000000001,0.0000000001,0.000000001,0.00000001,0.0000001,0.000001,0.00001]}, #var_smoothing=1e-09 é o padrão\n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['var_smoothing'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision',10)\n",
    "pd.reset_option('^display.',silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','var_smoothing','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'acuracia_balanceada_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve sempre a ocorrencia do mesmo hiperparâmetro e uma variância enorme nos resultados. Talvez esse não seja o melhor modelo!\n",
    "\n",
    "Hiperparâmetros\n",
    "\n",
    "- var_smoothing = 0.0000000000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 GaussianNB Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22, stratify=y)\n",
    "\n",
    "gaussianb = GaussianNB(var_smoothing=0.0000000000000001)\n",
    "gaussianb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = gaussianb.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo acerta muito as classes 0 e erra as classes 1. É o comportamento inverso ao modelo PassiveAgressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        BernoulliNB(),\n",
    "        param_grid={\"alpha\": [0,1,10,20,30,40,50], \"binarize\": np.linspace(0,1,11)}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['alpha'],hyperparams['binarize'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','alpha','binarize','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros:\n",
    "\n",
    "Alpha = 0 \n",
    "Binarize = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 BernoulliNB - Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "bernoullinb = BernoulliNB(alpha=0,binarize=0.1)\n",
    "bernoullinb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = bernoullinb.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Quando inputamos valores de Binazire tendendo á 1 o algorítmo tende a errar todas as classes 0 e acertar todas as classes 1. Como um dado viciado ou uma moeda de uma cara só."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        param_grid={\"reg_param\": np.linspace(0.1,1,10), \"store_covariance\":[True,False], \"tol\":[1000,100,10,1,0.1,0.01,0.001,0.0001]}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['reg_param'],hyperparams['store_covariance'],hyperparams['tol'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('^display.',silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','reg_param','store_covariance','tol','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- reg_param: entre 0.1 e 0.8 \n",
    "- store_covarianve: true  \n",
    "- tol: >=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "        param_grid={\"reg_param\": [0.1,0.8], \"store_covariance\":[True,False], \"tol\":[10000,1000,100]}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['reg_param'],hyperparams['store_covariance'],hyperparams['tol'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','reg_param','store_covariance','tol','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- reg_param: 0.1\n",
    "- store_covarianve: true  \n",
    "- tol: 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4.1 QuadraticDiscriminantAnalysis Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "quadratic = QuadraticDiscriminantAnalysis(reg_param = 0.1, store_covariance= True, tol = 10000)\n",
    "quadratic.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = quadratic.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        LGBMClassifier(random_state=i),\n",
    "        param_grid={\"max_depth\": [-1,100], \n",
    "                    \"learning_rate\": [0.1,0.2,0.3], \n",
    "                    \"n_estimators\": [100,50,150], \n",
    "                    \"num_leaves\": [31,10,50]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['learning_rate'],hyperparams['n_estimators'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','learning_rate','n_estimators','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: -1 (sem limite)\n",
    "- learning_rate\t: >=0.3\n",
    "- num_estimator <=100\n",
    "- num_leaves ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 30x\n",
    "for i in range(30):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        LGBMClassifier(random_state=i),\n",
    "        param_grid={\"max_depth\": [-1,100], \n",
    "                    \"learning_rate\": [0.3,0.5,0.7], \n",
    "                    \"n_estimators\": [20,30,40,50,60,70,80,90,100], \n",
    "                    \"num_leaves\": [31,10,50]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['learning_rate'],hyperparams['n_estimators'],hyperparams['num_leaves'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('^display.',silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','learning_rate','n_estimators','num_leaves','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: -1 (sem limite)\n",
    "- learning_rate\t: entre 0.7 e 0.5\n",
    "- num_estimator entre 90 e 70\n",
    "- num_leaves próximo a 31 (>10 e <50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "auc_dados = make_scorer(roc_auc_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 20x\n",
    "for i in range(20):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        LGBMClassifier(random_state=i),\n",
    "        param_grid={\"max_depth\": [-1], \n",
    "                    \"learning_rate\": [0.5,0.6,0.7,0.8], \n",
    "                    \"n_estimators\": [70,75,80,85,90], \n",
    "                    \"num_leaves\": [15,20,25,30,31,35,40,45]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['learning_rate'],hyperparams['n_estimators'],hyperparams['num_leaves'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','learning_rate','n_estimators','num_leaves','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: -1 (sem limite)\n",
    "- learning_rate\t: 0,6\n",
    "- num_estimator entre 80 e 85\n",
    "- num_leaves próximo a <=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 20x\n",
    "for i in range(20):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        LGBMClassifier(random_state=i),\n",
    "        param_grid={\"max_depth\": [-1], \n",
    "                    \"learning_rate\": [0.6], \n",
    "                    \"n_estimators\": [76,77,78,79,80,81,82,83,84,85], \n",
    "                    \"num_leaves\": [2,4,6,8,10,11,12,13,14,15]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['learning_rate'],hyperparams['n_estimators'],hyperparams['num_leaves'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','learning_rate','n_estimators','num_leaves','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: -1 (sem limite)\n",
    "- learning_rate\t: 0,6\n",
    "- num_estimator: 78\n",
    "- num_leaves: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5.1 LGBM Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "lgbm = LGBMClassifier(max_depth = -1,learning_rate = 0.6, num_estimator = 78, num_leaves = 4,  random_state=3)\n",
    "lgbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=i) ,\n",
    "        param_grid={\"max_depth\": [10,20,30], \n",
    "                    \"min_samples_leaf\": [1,2,5,10,15], \n",
    "                    \"min_samples_split\": [2,5,10,15],\n",
    "                    \"criterion\": ['gini','entropy','log_loss']}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['min_samples_leaf'],hyperparams['min_samples_split'],hyperparams['criterion'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','min_samples_leaf','min_samples_split','criterion','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: entre 10 e 20\n",
    "- min_samples_leaf\t: entre 2 e 1\n",
    "- min_samples_split: entre 5 e 15 ou >=15\n",
    "- criterion: entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=i) ,\n",
    "        param_grid={\"max_depth\": [10,12,14,16,18,20], \n",
    "                    \"min_samples_leaf\": [1,2], \n",
    "                    \"min_samples_split\": [5,15,20,25,30],\n",
    "                    \"criterion\": ['entropy']}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['min_samples_leaf'],hyperparams['min_samples_split'],hyperparams['criterion'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','min_samples_leaf','min_samples_split','criterion','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth: 10\n",
    "- min_samples_leaf\t: entre 2 e 1\n",
    "- min_samples_split: entre 5 e 15\n",
    "- criterion: entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=i) ,\n",
    "        param_grid={\"max_depth\": [10], \n",
    "                    \"min_samples_leaf\": [1,2], \n",
    "                    \"min_samples_split\": [5,7,9,11,13,15],\n",
    "                    \"criterion\": ['entropy']}, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['max_depth'],hyperparams['min_samples_leaf'],hyperparams['min_samples_split'],hyperparams['criterion'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','max_depth','min_samples_leaf','min_samples_split','criterion','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- max_depth = 10\n",
    "- min_samples_leaf\t= 2 \n",
    "- min_samples_split = 5\n",
    "- criterion = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1, max_depth = 10, min_samples_leaf = 2, \n",
    "                            min_samples_split = 5, criterion = 'entropy')\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.7 NearestCentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.8 NuSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.9 XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.10 SGDClassifier;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.11 Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.12 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.13 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        MLPClassifier(random_state=i) ,\n",
    "        param_grid={\"hidden_layer_sizes\": [10], \n",
    "                    \"max_iter\": [200], \n",
    "                    \"activation\": ['identity','logistic','tanh','relu'],\n",
    "                    \"learning_rate_init\": [0.001],\n",
    "                    \"solver\": ['lbfgs','sgd','adam'],\n",
    "                    \"alpha\": [0.0001]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['hidden_layer_sizes'],hyperparams['max_iter'],hyperparams['activation'],hyperparams['learning_rate_init'],hyperparams['solver'],hyperparams['alpha'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','hidden_layer_sizes','max_iter','activation','learning_rate_init','solver','alpha','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- hidden_layer_sizes = \n",
    "- max_iter =\n",
    "- activation = entre identity e relu\n",
    "- learning_rate_init = \n",
    "- solver = entre adam e sgd\n",
    "- alpha = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        MLPClassifier(random_state=i) ,\n",
    "        param_grid={\"hidden_layer_sizes\": [10,20,30], \n",
    "                    \"max_iter\": [100,200,300], \n",
    "                    \"activation\": ['identity','relu'],\n",
    "                    \"learning_rate_init\": [0.001,0.01,0.0001],\n",
    "                    \"solver\": ['sgd','adam'],\n",
    "                    \"alpha\": [0.0001, 0.001, 0.00001]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['hidden_layer_sizes'],hyperparams['max_iter'],hyperparams['activation'],hyperparams['learning_rate_init'],hyperparams['solver'],hyperparams['alpha'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','hidden_layer_sizes','max_iter','activation','learning_rate_init','solver','alpha','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- hidden_layer_sizes = entre 10 e 20\n",
    "- max_iter = entre 200 e 300\n",
    "- activation = relu\n",
    "- learning_rate_init = 0.01\n",
    "- solver = entre adam e sgd\n",
    "- alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "#Definição dos dados\n",
    "X_todos = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y_todos = df_final9['Fechamento']  \n",
    "\n",
    "    \n",
    "#Repete os experimentos 10x\n",
    "for i in range(10):\n",
    "    \n",
    "    #Holdout:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i, stratify=y)\n",
    "        \n",
    "    #Validação cruzada com 10 kfolds\n",
    "    kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "    \n",
    "    print(\"Fazendo gridsearch - Repeticao %s\" % (i+1))\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        MLPClassifier(random_state=i) ,\n",
    "        param_grid={\"hidden_layer_sizes\": [10,12,14,16,18,20], \n",
    "                    \"max_iter\": [200,220,240,260,280,300], \n",
    "                    \"activation\": ['relu'],\n",
    "                    \"learning_rate_init\": [0.1,0.01],\n",
    "                    \"solver\": ['sgd','adam'],\n",
    "                    \"alpha\": [0.001]   }, \n",
    "        scoring=scoring,\n",
    "        refit=\"bacuracy\",\n",
    "        n_jobs=2,\n",
    "        return_train_score=True,\n",
    "        cv = kfold\n",
    "            )\n",
    "        \n",
    "    #Treinando o modelo com dados de treino c/ 9 folds e utilizando 1 fold para teste\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    #Melhores resultados e hiperparâmetros encontrados\n",
    "    acuracy_treino = gs.best_score_\n",
    "    hyperparams = gs.best_params_\n",
    "    \n",
    "    ##Predizendo as classes nos dados de teste e todos dados, utilizando os melhores parâmetros\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "    #y_test_pred_todos = gs.predict(X_todos)\n",
    "        \n",
    "    #Calculando acurácia \n",
    "    accuracy_teste = accuracy_score(y_test, y_test_pred)\n",
    "    #accuracy_todos = accuracy_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #calculando f1_score da classe 1\n",
    "    f1_teste = f1_score(y_test, y_test_pred)\n",
    "    #f1_todos = f1_score(y_todos, y_test_pred_todos)\n",
    "    \n",
    "    #calculando área sobre a curva ROC_AUC:\n",
    "    auc_teste = roc_auc_score(y_test, y_test_pred)\n",
    "    #auc_todos = roc_auc_score(y_todos, y_test_pred_todos)\n",
    "        \n",
    "    #Calculando Recall clase 1\n",
    "    rec0_teste = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "    rec1_teste = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "    \n",
    "    #rec0_todos = recall_score(y_todos, y_test_pred_todos, pos_label=0)\n",
    "    #rec1_todos = recall_score(y_todos, y_test_pred_todos, pos_label=1)\n",
    "    \n",
    "    #Calculando a acurácia balanceada\n",
    "    accuracy_teste_balanced = balanced_accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Adicionando todos resultados em uma única lista\n",
    "    resultados.append(np.array([i,hyperparams['hidden_layer_sizes'],hyperparams['max_iter'],hyperparams['activation'],hyperparams['learning_rate_init'],hyperparams['solver'],hyperparams['alpha'],acuracy_treino,accuracy_teste,accuracy_teste_balanced,rec0_teste,rec1_teste,f1_teste,auc_teste]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformando os resultados para dataframe e ordenando por recall da classe 0:\n",
    "resultados = pd.DataFrame(np.array(resultados), columns=['repeticao','hidden_layer_sizes','max_iter','activation','learning_rate_init','solver','alpha','acuracy_treino','acuracia_teste','acuracia_balanceada_teste','rec_0_teste','rec_1_teste','f1_teste','auc_teste'])\n",
    "resultados.sort_values(by = 'auc_teste', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparâmetros\n",
    "\n",
    "- hidden_layer_sizes = 20\n",
    "- max_iter = 280\n",
    "- activation = relu\n",
    "- learning_rate_init = 0.01\n",
    "- solver = sgd\n",
    "- alpha = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.13.1 MLP Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final9[features+featuresd1+featuresd2+featuresd3]\n",
    "y = df_final9['Fechamento'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3, stratify=y)\n",
    "\n",
    "mlp = MLPClassifier(random_state=i, hidden_layer_sizes = 20,  max_iter = 280, activation = 'relu', \n",
    "                    learning_rate_init = 0.01, solver = 'sgd', alpha = 0.0001 )\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predizendo y\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report Dados:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados de Producao:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando acurácia \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "#calculando f1_score\n",
    "f1_0 = f1_score(y_test, y_pred,pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred,pos_label=1)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"F1_Score_0: %s\" % (f1_0))\n",
    "print(\"F1_Score_1: %s\" % (f1_1))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
