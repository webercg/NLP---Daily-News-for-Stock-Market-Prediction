{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/webercg/NLP---Daily-News-for-Stock-Market-Prediction/blob/main/Experimentos_%2B_EDA_(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aMeKxD1txAj"
   },
   "source": [
    "# 1.0 Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZuRBXqqwuLZC"
   },
   "outputs": [],
   "source": [
    "#pip install lazypredict\n",
    "#pip install googletrans==4.0.0-rc1\n",
    "#pip install textblob\n",
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PN29buKktxAm"
   },
   "outputs": [],
   "source": [
    "#Manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualização de dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Manipulação datas\n",
    "from datetime import datetime\n",
    "\n",
    "# Prototipação\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "#Pipeline e pré-process\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "#Model Tunning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4mHHQMbtxAo"
   },
   "source": [
    "# 2.0 Leitura dos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO4Xua-RtxAp"
   },
   "source": [
    "## Leitura de Noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-B_PgkNBtxAp"
   },
   "outputs": [],
   "source": [
    "dicionario_mes_2021 = {'Jan':'01', 'Fev':'02', 'Mar':'03','Abr':'04', 'Mai':'05', 'Jun':'06','Jul':'07', 'Ago':'08', 'Set':'09','Out':'10', 'Nov':'11', 'Dec':'12'}\n",
    "dicionario_mes_2020 = {'Jan':'01', 'Fev':'02', 'Mar':'03','Abr':'04', 'Mai':'05', 'Jun':'06','Jul':'07', 'Ago':'08', 'Set':'09','Out':'10', 'Nov':'11', 'Dez':'12'}\n",
    "dicionario_mes_2022 = {'Jan':'01', 'Fev':'02', 'Mar':'03','Abr':'04', 'Mai':'05', 'Jun':'06'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qb9CxoJdtxAp"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in dicionario_mes_2020.keys():\n",
    "    arquivo = \"dataset-2020/\" + dicionario_mes_2020[i] + \"_GoogleNews_Petr_\" + i + \"-2020.csv\"\n",
    "    df_leitura = pd.read_csv(arquivo, sep='|')\n",
    "    df = df.append(df_leitura,ignore_index=True)\n",
    "\n",
    "for i in dicionario_mes_2021.keys():\n",
    "    arquivo = \"dataset-2021/\" + dicionario_mes_2021[i] + \"_GoogleNews_Petr_\" + i + \"_21.csv\"\n",
    "    df_leitura = pd.read_csv(arquivo, sep='|')\n",
    "    df = df.append(df_leitura,ignore_index=True)\n",
    "\n",
    "\n",
    "for i in dicionario_mes_2022.keys():\n",
    "    arquivo = \"dataset-2022/\" + dicionario_mes_2022[i] + \"_GoogleNews_Petr_\" + i + \"_22.csv\"\n",
    "    df_leitura = pd.read_csv(arquivo, sep='|')\n",
    "    df = df.append(df_leitura,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hd8eSD9FtxAq",
    "outputId": "e56316da-fa01-44b8-d2ff-97ead71ec250"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pré-sal: Centro Oeste fica com R$ 1 bilhão dos...</td>\n",
       "      <td>Correio Braziliense</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>O dinheiro que será distribuído veio do leilão...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preço do etanol fecha 2019 em alta de 11,5% na...</td>\n",
       "      <td>Diario de Pernambuco</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>O diesel foi o segundo combustível com maior a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Série \"Cineastas\" e mais dicas para curtir na ...</td>\n",
       "      <td>GZH</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>Cosmatos; e, por fim, às 23h15min, Rambo III (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feriados em 2020: 11 datas serão em dias da se...</td>\n",
       "      <td>Money Times</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>O dia 29 de fevereiro cairá em um sábado. Veja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O incêndio que matou quase todos os macacos em...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>Principais notícias. Como a Petrobras virou te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>Petrobras retoma venda de três refinarias: sai...</td>\n",
       "      <td>Gazeta do Povo</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>Refinarias da Petrobras em Pernambuco, Paraná ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>Governo avalia mecanismo para obrigar Petrobra...</td>\n",
       "      <td>BiodieselBR.com</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>A Petrobras chegou a assinar em 2019 um acordo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>Postos Petrobras e Shell se rendem à recarga d...</td>\n",
       "      <td>Quatro Rodas</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>O eletroposto foi instalado no posto Petrobras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>Ações Petrobras: saiba o preço após fechamento...</td>\n",
       "      <td>UOL Economia</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>As ações da Petrobras fecharam em queda nesta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Alta do preço das commodities favoreceu o lucr...</td>\n",
       "      <td>Mais Retorno</td>\n",
       "      <td>30/06/2022</td>\n",
       "      <td>Dividendos e JCP em junho: Petrobras e Usimina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7983 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title                 media  \\\n",
       "0     Pré-sal: Centro Oeste fica com R$ 1 bilhão dos...   Correio Braziliense   \n",
       "1     Preço do etanol fecha 2019 em alta de 11,5% na...  Diario de Pernambuco   \n",
       "2     Série \"Cineastas\" e mais dicas para curtir na ...                   GZH   \n",
       "3     Feriados em 2020: 11 datas serão em dias da se...           Money Times   \n",
       "4     O incêndio que matou quase todos os macacos em...                   BBC   \n",
       "...                                                 ...                   ...   \n",
       "7978  Petrobras retoma venda de três refinarias: sai...        Gazeta do Povo   \n",
       "7979  Governo avalia mecanismo para obrigar Petrobra...       BiodieselBR.com   \n",
       "7980  Postos Petrobras e Shell se rendem à recarga d...          Quatro Rodas   \n",
       "7981  Ações Petrobras: saiba o preço após fechamento...          UOL Economia   \n",
       "7982  Alta do preço das commodities favoreceu o lucr...          Mais Retorno   \n",
       "\n",
       "            date                                               desc  \n",
       "0     01/01/2020  O dinheiro que será distribuído veio do leilão...  \n",
       "1     01/01/2020  O diesel foi o segundo combustível com maior a...  \n",
       "2     01/01/2020  Cosmatos; e, por fim, às 23h15min, Rambo III (...  \n",
       "3     01/01/2020  O dia 29 de fevereiro cairá em um sábado. Veja...  \n",
       "4     01/01/2020  Principais notícias. Como a Petrobras virou te...  \n",
       "...          ...                                                ...  \n",
       "7978  30/06/2022  Refinarias da Petrobras em Pernambuco, Paraná ...  \n",
       "7979  30/06/2022  A Petrobras chegou a assinar em 2019 um acordo...  \n",
       "7980  30/06/2022  O eletroposto foi instalado no posto Petrobras...  \n",
       "7981  30/06/2022  As ações da Petrobras fecharam em queda nesta ...  \n",
       "7982  30/06/2022  Dividendos e JCP em junho: Petrobras e Usimina...  \n",
       "\n",
       "[7983 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99DfjCBdtxAq",
    "outputId": "b228b5af-afbe-43ef-fd14-8947ac8d8a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            object\n",
       "media            object\n",
       "date     datetime64[ns]\n",
       "desc             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando coluna data para datetime:\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgmSTyGOtxAq"
   },
   "source": [
    "## Leitura dos pregões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nZ9C4JR0txAr",
    "outputId": "40fa09ec-64b3-4e58-e940-b2a1b94822d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>20.33</td>\n",
       "      <td>48215600</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Adj Close    Volume  Var%\n",
       "0    2020-01-02      20.47  37774500  0.02\n",
       "1    2020-01-03      20.30  71595600 -0.01\n",
       "2    2020-01-06      20.54  81844000  0.01\n",
       "3    2020-01-07      20.46  32822000 -0.00\n",
       "4    2020-01-08      20.33  48215600 -0.01\n",
       "..          ...        ...       ...   ...\n",
       "614  2022-06-24      26.29  53413400 -0.01\n",
       "615  2022-06-27      27.98  90417700  0.06\n",
       "616  2022-06-28      28.33  51388000  0.01\n",
       "617  2022-06-29      28.08  52048800 -0.01\n",
       "618  2022-06-30      27.93  49910100 -0.01\n",
       "\n",
       "[619 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro = pd.read_csv('dataset-2021/Hist_Preço_Petr_2021_.csv', sep='|')\n",
    "df_petro_2020 = pd.read_csv('dataset-2020/Hist_Preço_Petr_2020_.csv', sep='|')\n",
    "df_petro_2022 = pd.read_csv('dataset-2022/Hist_Preço_Petr_2022_.csv', sep='|')\n",
    "df_petro = df_petro_2020.append(df_petro,ignore_index=True)\n",
    "df_petro = df_petro.append(df_petro_2022,ignore_index=True)\n",
    "df_petro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XY073J92txAr",
    "outputId": "a2107dbd-347d-48ce-a603-b899cfeeba82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         datetime64[ns]\n",
       "Adj Close           float64\n",
       "Volume                int64\n",
       "Var%                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando a coluna Date para datetime\n",
    "df_petro['Date'] = pd.to_datetime(df_petro['Date'])\n",
    "df_petro.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8nD2odmtxAr"
   },
   "source": [
    "# 3.0 EDA\n",
    "**H1:** Há uma média razoável de noticias diárias   - **VERDADEIRO**  \n",
    "**H2:** Há poucos dias sem noticias na base de dados  - **VERDADEIRO**   \n",
    "**H3:** Há dias em que o pregão da bolsa não funciona (Finais de Semana) **VERDADEIRO**  \n",
    "**H4:**  \n",
    "**H5:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_6mzAJKtxAs"
   },
   "source": [
    "## 3.1 H1: Há uma média razoável de noticias diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7_it2batxAs",
    "outputId": "2a83b32f-4099-48d0-bdf5-e761a71ba2f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022-01-06    10\n",
       "2022-03-06    10\n",
       "2021-09-12    10\n",
       "2021-04-16    10\n",
       "2021-05-05    10\n",
       "              ..\n",
       "2020-12-27     2\n",
       "2022-02-26     2\n",
       "2021-02-14     2\n",
       "2021-07-25     1\n",
       "2022-01-23     1\n",
       "Name: date, Length: 858, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cj5ciqbItxAs",
    "outputId": "32aed6a7-b1d2-4624-c82d-f5e4346c08e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "0   2022-01-06    10\n",
       "1   2022-03-06    10\n",
       "2   2021-09-12    10\n",
       "3   2021-04-16    10\n",
       "4   2021-05-05    10\n",
       "..         ...   ...\n",
       "853 2020-12-27     2\n",
       "854 2022-02-26     2\n",
       "855 2021-02-14     2\n",
       "856 2021-07-25     1\n",
       "857 2022-01-23     1\n",
       "\n",
       "[858 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coletando as datas e as frequencias de noticias:\n",
    "datas = df.date.value_counts()  \n",
    "data_df = datas.reset_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-Y7ggGStxAs",
    "outputId": "3a700118-72ff-4ad9-b438-8b3db46ab027"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    datetime64[ns]\n",
       "date              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizando os tipos dos dados\n",
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "agYKEw3KtxAt",
    "outputId": "22431ff6-a83b-40e8-be7f-72e39f76a0f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2022-02-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "0   2022-01-06    10\n",
       "1   2022-03-06    10\n",
       "2   2021-09-12    10\n",
       "3   2021-04-16    10\n",
       "4   2021-05-05    10\n",
       "..         ...   ...\n",
       "853 2020-12-27     2\n",
       "854 2022-02-26     2\n",
       "855 2021-02-14     2\n",
       "856 2021-07-25     1\n",
       "857 2022-01-23     1\n",
       "\n",
       "[858 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alterando para o formato datetime\n",
    "data_df['index'] = pd.to_datetime(data_df['index'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yPwAQmMdtxAt",
    "outputId": "0d4bc8c2-2d55-4445-b627-2c2e143516d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  date\n",
       "787 2022-12-02     6\n",
       "484 2022-12-03    10\n",
       "237 2022-12-04    10\n",
       "399 2022-12-05    10\n",
       "614 2022-12-06    10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organizando o dataframe em ordem cronologica\n",
    "data_df.sort_values(by = 'index', ascending = True, inplace = True) \n",
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "biwnoCVRtxAt",
    "outputId": "6addc441-9576-47f1-9eb7-259209b59c7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>858.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date\n",
       "count 858.00\n",
       "mean    9.30\n",
       "std     1.71\n",
       "min     1.00\n",
       "25%    10.00\n",
       "50%    10.00\n",
       "75%    10.00\n",
       "max    10.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzeedf5AtxAu"
   },
   "source": [
    "Há uma média de 9.25 (+- 2) noticias por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "9wB_P6UftxAu",
    "outputId": "2fc2e09b-92f0-437a-e045-8310926a7d45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Datas', ylabel='Num_Noticias'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizando data vs quantidade de notícias\n",
    "data_df.columns = ['Datas', 'Num_Noticias']\n",
    "sns.lineplot(x = 'Datas', y = 'Num_Noticias', data = data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "HDk-58udtxAu",
    "outputId": "7e498c71-66b1-4844-cbc2-a19d4405effc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Noticias</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mes</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Num_Noticias\n",
       "Mes              \n",
       "1            9.07\n",
       "2            8.91\n",
       "3            9.01\n",
       "4            9.46\n",
       "5            9.55\n",
       "6            9.47\n",
       "7            9.03\n",
       "8            9.38\n",
       "9            9.56\n",
       "10           9.71\n",
       "11           9.35\n",
       "12           9.20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inserindo coluna de mês\n",
    "data_df['Mes'] = data_df['Datas'].dt.month\n",
    "\n",
    "# Calculando media de noticias por mês\n",
    "df_noticia_mes = data_df.groupby('Mes').agg({'Num_Noticias':np.mean})\n",
    "df_noticia_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datas</th>\n",
       "      <th>Num_Noticias</th>\n",
       "      <th>Mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Datas  Num_Noticias  Mes\n",
       "96  2020-01-01            10    1\n",
       "589 2020-01-02            10    1\n",
       "841 2020-01-03             3    1\n",
       "205 2020-01-04            10    1\n",
       "89  2020-01-05            10    1\n",
       "616 2020-01-06            10    1\n",
       "398 2020-01-07            10    1\n",
       "842 2020-01-08             3    1\n",
       "303 2020-01-09            10    1\n",
       "181 2020-01-10            10    1\n",
       "805 2020-01-11             6    1\n",
       "496 2020-01-12            10    1\n",
       "292 2020-01-13            10    1\n",
       "46  2020-01-14            10    1\n",
       "619 2020-01-15            10    1\n",
       "528 2020-01-16            10    1\n",
       "280 2020-01-17            10    1\n",
       "319 2020-01-18            10    1\n",
       "134 2020-01-19            10    1\n",
       "450 2020-01-20            10    1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "9zU7co7YtxAu",
    "outputId": "6e043d41-69bb-41b0-b65e-2f7f2605b3dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x18847850cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x540 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando distribuição da quantidade de noticias ao longo dos meses\n",
    "sns.catplot(x=\"Num_Noticias\", col=\"Mes\", col_wrap=4,\n",
    "                data=data_df,\n",
    "                kind=\"count\", height=2.5, aspect=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "4B_Q704ztxAv",
    "outputId": "f23c06e8-bd65-4637-f2d5-bfa8469ee993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x18847896f40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1965.6x252 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando distribuição da quantidade de noticias ao longo dos meses\n",
    "g = sns.FacetGrid(data_df, col=\"Mes\", height=3.5, aspect=.65)\n",
    "g.map(sns.histplot, \"Num_Noticias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCOwL4vBtxAv"
   },
   "source": [
    "Há poucas ocorrências de baixo numero de noticias por dia, a maior ocorrência da quantidade de noticias por dia é de 10.\n",
    "Dessa forma, a média de noticias por mês varia de 8 á 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNTI7DuitxAv"
   },
   "source": [
    "## 3.2 Há poucos dias sem noticias na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cswcZKnoxf1S"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AjnpzAz-txAv"
   },
   "outputs": [],
   "source": [
    "## Gerando uma lista com todos os dias:\n",
    "start_date = '01/01/2020'\n",
    "end_date = '31/12/2022'\n",
    "\n",
    "#Transformando para o padrão inglês\n",
    "start_date = datetime.strptime(start_date, '%d/%m/%Y').strftime('%m-%d-%Y')\n",
    "end_date = datetime.strptime(end_date, '%d/%m/%Y').strftime('%m-%d-%Y')\n",
    "\n",
    "#Gerando a lista com todas as datas\n",
    "todas_datas = pd.date_range(start=start_date, end=end_date, freq = '1D')\n",
    "todas_datas = [i.strftime(\"%d/%m/%Y\") for i in todas_datas ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qY2Fsk1ntxAv"
   },
   "outputs": [],
   "source": [
    "#Gerando lista com todas as datas com noticias\n",
    "datas_com_noticias = [i.strftime(\"%d/%m/%Y\") for i in data_df['Datas'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qwe8jKvQtxAv",
    "outputId": "e75200d8-e2f8-4813-8241-33f416f8e457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 238 dias sem notícias no periodo considerado!\n"
     ]
    }
   ],
   "source": [
    "#Gerando lista com todas as datas sem noticias \n",
    "datas_sem_noticias = [i for i in todas_datas if i not in datas_com_noticias]\n",
    "print(\"Há %s dias sem notícias no periodo considerado!\" % len(datas_sem_noticias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14/01/2021',\n",
       " '15/01/2021',\n",
       " '24/01/2021',\n",
       " '27/01/2021',\n",
       " '04/02/2021',\n",
       " '04/03/2021',\n",
       " '05/03/2021',\n",
       " '09/03/2021',\n",
       " '19/03/2021',\n",
       " '02/04/2021',\n",
       " '14/04/2021',\n",
       " '20/04/2021',\n",
       " '24/04/2021',\n",
       " '12/05/2021',\n",
       " '15/05/2021',\n",
       " '23/05/2021',\n",
       " '04/06/2021',\n",
       " '19/06/2021',\n",
       " '27/06/2021',\n",
       " '01/07/2021',\n",
       " '20/07/2021',\n",
       " '22/07/2021',\n",
       " '28/07/2021',\n",
       " '30/07/2021',\n",
       " '06/08/2021',\n",
       " '08/08/2021',\n",
       " '13/08/2021',\n",
       " '09/09/2021',\n",
       " '10/09/2021',\n",
       " '04/10/2021',\n",
       " '16/10/2021',\n",
       " '23/10/2021',\n",
       " '04/11/2021',\n",
       " '21/11/2021',\n",
       " '23/11/2021',\n",
       " '29/11/2021',\n",
       " '04/12/2021',\n",
       " '19/12/2021',\n",
       " '03/01/2022',\n",
       " '07/01/2022',\n",
       " '08/01/2022',\n",
       " '09/01/2022',\n",
       " '10/01/2022',\n",
       " '11/01/2022',\n",
       " '12/01/2022',\n",
       " '18/01/2022',\n",
       " '07/02/2022',\n",
       " '08/02/2022',\n",
       " '09/02/2022',\n",
       " '10/02/2022',\n",
       " '11/02/2022',\n",
       " '12/02/2022',\n",
       " '22/02/2022',\n",
       " '23/02/2022',\n",
       " '27/02/2022',\n",
       " '28/02/2022',\n",
       " '01/03/2022',\n",
       " '07/03/2022',\n",
       " '08/03/2022',\n",
       " '09/03/2022',\n",
       " '10/03/2022',\n",
       " '11/03/2022',\n",
       " '12/03/2022',\n",
       " '22/03/2022',\n",
       " '03/04/2022',\n",
       " '07/04/2022',\n",
       " '08/04/2022',\n",
       " '09/04/2022',\n",
       " '10/04/2022',\n",
       " '11/04/2022',\n",
       " '12/04/2022',\n",
       " '19/04/2022',\n",
       " '07/05/2022',\n",
       " '08/05/2022',\n",
       " '09/05/2022',\n",
       " '10/05/2022',\n",
       " '11/05/2022',\n",
       " '12/05/2022',\n",
       " '28/05/2022',\n",
       " '02/06/2022',\n",
       " '03/06/2022',\n",
       " '07/06/2022',\n",
       " '08/06/2022',\n",
       " '09/06/2022',\n",
       " '10/06/2022',\n",
       " '11/06/2022',\n",
       " '12/06/2022',\n",
       " '07/07/2022',\n",
       " '08/07/2022',\n",
       " '09/07/2022',\n",
       " '10/07/2022',\n",
       " '11/07/2022',\n",
       " '12/07/2022',\n",
       " '13/07/2022',\n",
       " '14/07/2022',\n",
       " '15/07/2022',\n",
       " '16/07/2022',\n",
       " '17/07/2022',\n",
       " '18/07/2022',\n",
       " '19/07/2022',\n",
       " '20/07/2022',\n",
       " '21/07/2022',\n",
       " '22/07/2022',\n",
       " '23/07/2022',\n",
       " '24/07/2022',\n",
       " '25/07/2022',\n",
       " '26/07/2022',\n",
       " '27/07/2022',\n",
       " '28/07/2022',\n",
       " '29/07/2022',\n",
       " '30/07/2022',\n",
       " '31/07/2022',\n",
       " '07/08/2022',\n",
       " '08/08/2022',\n",
       " '09/08/2022',\n",
       " '10/08/2022',\n",
       " '11/08/2022',\n",
       " '12/08/2022',\n",
       " '13/08/2022',\n",
       " '14/08/2022',\n",
       " '15/08/2022',\n",
       " '16/08/2022',\n",
       " '17/08/2022',\n",
       " '18/08/2022',\n",
       " '19/08/2022',\n",
       " '20/08/2022',\n",
       " '21/08/2022',\n",
       " '22/08/2022',\n",
       " '23/08/2022',\n",
       " '24/08/2022',\n",
       " '25/08/2022',\n",
       " '26/08/2022',\n",
       " '27/08/2022',\n",
       " '28/08/2022',\n",
       " '29/08/2022',\n",
       " '30/08/2022',\n",
       " '31/08/2022',\n",
       " '02/09/2022',\n",
       " '07/09/2022',\n",
       " '08/09/2022',\n",
       " '09/09/2022',\n",
       " '10/09/2022',\n",
       " '11/09/2022',\n",
       " '12/09/2022',\n",
       " '13/09/2022',\n",
       " '14/09/2022',\n",
       " '15/09/2022',\n",
       " '16/09/2022',\n",
       " '17/09/2022',\n",
       " '18/09/2022',\n",
       " '19/09/2022',\n",
       " '20/09/2022',\n",
       " '21/09/2022',\n",
       " '22/09/2022',\n",
       " '23/09/2022',\n",
       " '24/09/2022',\n",
       " '25/09/2022',\n",
       " '26/09/2022',\n",
       " '27/09/2022',\n",
       " '28/09/2022',\n",
       " '29/09/2022',\n",
       " '30/09/2022',\n",
       " '01/10/2022',\n",
       " '05/10/2022',\n",
       " '07/10/2022',\n",
       " '08/10/2022',\n",
       " '09/10/2022',\n",
       " '10/10/2022',\n",
       " '11/10/2022',\n",
       " '12/10/2022',\n",
       " '13/10/2022',\n",
       " '14/10/2022',\n",
       " '15/10/2022',\n",
       " '16/10/2022',\n",
       " '17/10/2022',\n",
       " '18/10/2022',\n",
       " '19/10/2022',\n",
       " '20/10/2022',\n",
       " '21/10/2022',\n",
       " '22/10/2022',\n",
       " '23/10/2022',\n",
       " '24/10/2022',\n",
       " '25/10/2022',\n",
       " '26/10/2022',\n",
       " '27/10/2022',\n",
       " '28/10/2022',\n",
       " '29/10/2022',\n",
       " '30/10/2022',\n",
       " '31/10/2022',\n",
       " '07/11/2022',\n",
       " '08/11/2022',\n",
       " '09/11/2022',\n",
       " '10/11/2022',\n",
       " '11/11/2022',\n",
       " '12/11/2022',\n",
       " '13/11/2022',\n",
       " '14/11/2022',\n",
       " '15/11/2022',\n",
       " '16/11/2022',\n",
       " '17/11/2022',\n",
       " '18/11/2022',\n",
       " '19/11/2022',\n",
       " '20/11/2022',\n",
       " '21/11/2022',\n",
       " '22/11/2022',\n",
       " '23/11/2022',\n",
       " '24/11/2022',\n",
       " '25/11/2022',\n",
       " '26/11/2022',\n",
       " '27/11/2022',\n",
       " '28/11/2022',\n",
       " '29/11/2022',\n",
       " '30/11/2022',\n",
       " '07/12/2022',\n",
       " '08/12/2022',\n",
       " '09/12/2022',\n",
       " '10/12/2022',\n",
       " '11/12/2022',\n",
       " '12/12/2022',\n",
       " '13/12/2022',\n",
       " '14/12/2022',\n",
       " '15/12/2022',\n",
       " '16/12/2022',\n",
       " '17/12/2022',\n",
       " '18/12/2022',\n",
       " '19/12/2022',\n",
       " '20/12/2022',\n",
       " '21/12/2022',\n",
       " '22/12/2022',\n",
       " '23/12/2022',\n",
       " '24/12/2022',\n",
       " '25/12/2022',\n",
       " '26/12/2022',\n",
       " '27/12/2022',\n",
       " '28/12/2022',\n",
       " '29/12/2022',\n",
       " '30/12/2022',\n",
       " '31/12/2022']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_sem_noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e66g9uactxAx"
   },
   "source": [
    "Em apenas 38 dias de 2021 não houve retorno de noticias diárias da Petrobras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxLJise6txAx"
   },
   "source": [
    "## 3.3 Há dias em que o pregão da bolsa não funciona (Finais de Semana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y8-xFjKDtxAx"
   },
   "outputs": [],
   "source": [
    "datas_com_pregao = [i.strftime(\"%d/%m/%Y\") for i in df_petro['Date'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vCJ9yTRftxAy"
   },
   "outputs": [],
   "source": [
    "datas_sem_pregao = [i for i in todas_datas if i not in datas_com_pregao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7anpTFEFtxAy",
    "outputId": "a8866333-124d-48ca-bc4b-1b05a532b61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 477 dias sem pregão no periodo considerado!\n"
     ]
    }
   ],
   "source": [
    "print(\"Há %s dias sem pregão no periodo considerado!\" % len(datas_sem_pregao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n33cDcrqtxAy"
   },
   "source": [
    "# 4.0 Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo91sP18txAy"
   },
   "source": [
    "## 4.1 Padronização das palavras contidas nos títulos das noticias para minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SION7mEytxAy",
    "outputId": "fffe76dc-971d-48c1-fb82-717f9d20fc84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pré-sal: Centro Oeste fica com R$ 1 bilhão dos...</td>\n",
       "      <td>Correio Braziliense</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dinheiro que será distribuído veio do leilão...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Preço do etanol fecha 2019 em alta de 11,5% na...</td>\n",
       "      <td>Diario de Pernambuco</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O diesel foi o segundo combustível com maior a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Série \"Cineastas\" e mais dicas para curtir na ...</td>\n",
       "      <td>GZH</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Cosmatos; e, por fim, às 23h15min, Rambo III (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feriados em 2020: 11 datas serão em dias da se...</td>\n",
       "      <td>Money Times</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dia 29 de fevereiro cairá em um sábado. Veja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O incêndio que matou quase todos os macacos em...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Principais notícias. Como a Petrobras virou te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 media  \\\n",
       "0  Pré-sal: Centro Oeste fica com R$ 1 bilhão dos...   Correio Braziliense   \n",
       "1  Preço do etanol fecha 2019 em alta de 11,5% na...  Diario de Pernambuco   \n",
       "2  Série \"Cineastas\" e mais dicas para curtir na ...                   GZH   \n",
       "3  Feriados em 2020: 11 datas serão em dias da se...           Money Times   \n",
       "4  O incêndio que matou quase todos os macacos em...                   BBC   \n",
       "\n",
       "        date                                               desc  \n",
       "0 2020-01-01  O dinheiro que será distribuído veio do leilão...  \n",
       "1 2020-01-01  O diesel foi o segundo combustível com maior a...  \n",
       "2 2020-01-01  Cosmatos; e, por fim, às 23h15min, Rambo III (...  \n",
       "3 2020-01-01  O dia 29 de fevereiro cairá em um sábado. Veja...  \n",
       "4 2020-01-01  Principais notícias. Como a Petrobras virou te...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iboywtVTtxAy",
    "outputId": "9fff0135-e11e-4355-a994-f15a7771df39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pré-sal: centro oeste fica com r$ 1 bilhão dos...</td>\n",
       "      <td>Correio Braziliense</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dinheiro que será distribuído veio do leilão...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preço do etanol fecha 2019 em alta de 11,5% na...</td>\n",
       "      <td>Diario de Pernambuco</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O diesel foi o segundo combustível com maior a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>série \"cineastas\" e mais dicas para curtir na ...</td>\n",
       "      <td>GZH</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Cosmatos; e, por fim, às 23h15min, Rambo III (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feriados em 2020: 11 datas serão em dias da se...</td>\n",
       "      <td>Money Times</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dia 29 de fevereiro cairá em um sábado. Veja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o incêndio que matou quase todos os macacos em...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Principais notícias. Como a Petrobras virou te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 media  \\\n",
       "0  pré-sal: centro oeste fica com r$ 1 bilhão dos...   Correio Braziliense   \n",
       "1  preço do etanol fecha 2019 em alta de 11,5% na...  Diario de Pernambuco   \n",
       "2  série \"cineastas\" e mais dicas para curtir na ...                   GZH   \n",
       "3  feriados em 2020: 11 datas serão em dias da se...           Money Times   \n",
       "4  o incêndio que matou quase todos os macacos em...                   BBC   \n",
       "\n",
       "        date                                               desc  \n",
       "0 2020-01-01  O dinheiro que será distribuído veio do leilão...  \n",
       "1 2020-01-01  O diesel foi o segundo combustível com maior a...  \n",
       "2 2020-01-01  Cosmatos; e, por fim, às 23h15min, Rambo III (...  \n",
       "3 2020-01-01  O dia 29 de fevereiro cairá em um sábado. Veja...  \n",
       "4 2020-01-01  Principais notícias. Como a Petrobras virou te...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = df['title'].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8TNOpytxAz"
   },
   "source": [
    "## 4.2 Exclusão noticias que não contenham a palavra chave \"Petrobras\" no título\n",
    "Embora tenha-se configurado A biblioteca GoogleNews() para baixar noticias pela palavra chave \"Petrobras\" pode ocorrer casos em que o termo não é citado no título e nem no corpo da noticia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "iBHjFwdDtxAz",
    "outputId": "54e1bbf9-895d-4f58-9d2f-65cd5c96d909"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'série \"cineastas\" e mais dicas para curtir na tv nesta quarta-feira'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "KeSk4ba2txAz",
    "outputId": "bbf26d7d-2627-4c03-db4e-16d9ab0c54d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cosmatos; e, por fim, às 23h15min, Rambo III (1988), de Peter MacDonald.  Especial Lenine e Petrobras Sinfônica - TV Brasil, 22h. Concerto especial  com o...'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ZqNjWXYCtxAz",
    "outputId": "7f45af8b-a8b9-4a4b-c861-478af2838dc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Correio Braziliense</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dinheiro que será distribuído veio do leilão...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Diario de Pernambuco</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O diesel foi o segundo combustível com maior a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>GZH</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Cosmatos; e, por fim, às 23h15min, Rambo III (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Money Times</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>O dia 29 de fevereiro cairá em um sábado. Veja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>BBC</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Principais notícias. Como a Petrobras virou te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>petrobras retoma venda de três refinarias: sai...</td>\n",
       "      <td>Gazeta do Povo</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>Refinarias da Petrobras em Pernambuco, Paraná ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>governo avalia mecanismo para obrigar petrobra...</td>\n",
       "      <td>BiodieselBR.com</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>A Petrobras chegou a assinar em 2019 um acordo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>postos petrobras e shell se rendem à recarga d...</td>\n",
       "      <td>Quatro Rodas</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>O eletroposto foi instalado no posto Petrobras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>ações petrobras: saiba o preço após fechamento...</td>\n",
       "      <td>UOL Economia</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>As ações da Petrobras fecharam em queda nesta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td></td>\n",
       "      <td>Mais Retorno</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>Dividendos e JCP em junho: Petrobras e Usimina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7983 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title                 media  \\\n",
       "0                                                         Correio Braziliense   \n",
       "1                                                        Diario de Pernambuco   \n",
       "2                                                                         GZH   \n",
       "3                                                                 Money Times   \n",
       "4                                                                         BBC   \n",
       "...                                                 ...                   ...   \n",
       "7978  petrobras retoma venda de três refinarias: sai...        Gazeta do Povo   \n",
       "7979  governo avalia mecanismo para obrigar petrobra...       BiodieselBR.com   \n",
       "7980  postos petrobras e shell se rendem à recarga d...          Quatro Rodas   \n",
       "7981  ações petrobras: saiba o preço após fechamento...          UOL Economia   \n",
       "7982                                                             Mais Retorno   \n",
       "\n",
       "           date                                               desc  \n",
       "0    2020-01-01  O dinheiro que será distribuído veio do leilão...  \n",
       "1    2020-01-01  O diesel foi o segundo combustível com maior a...  \n",
       "2    2020-01-01  Cosmatos; e, por fim, às 23h15min, Rambo III (...  \n",
       "3    2020-01-01  O dia 29 de fevereiro cairá em um sábado. Veja...  \n",
       "4    2020-01-01  Principais notícias. Como a Petrobras virou te...  \n",
       "...         ...                                                ...  \n",
       "7978 2022-06-30  Refinarias da Petrobras em Pernambuco, Paraná ...  \n",
       "7979 2022-06-30  A Petrobras chegou a assinar em 2019 um acordo...  \n",
       "7980 2022-06-30  O eletroposto foi instalado no posto Petrobras...  \n",
       "7981 2022-06-30  As ações da Petrobras fecharam em queda nesta ...  \n",
       "7982 2022-06-30  Dividendos e JCP em junho: Petrobras e Usimina...  \n",
       "\n",
       "[7983 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'] = df['title'].apply(lambda x: \"\" if \"petrobras\" not in x else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "KgzG8YfUtxAz",
    "outputId": "87834370-7b65-43b1-dca9-93c1a3f804f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>indústria tem maior nível de emprego em 4 anos...</td>\n",
       "      <td>G1</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Indústria tem maior nível de emprego em 4 anos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clarissa lins, do ibp, renuncia como integrant...</td>\n",
       "      <td>Época Negócios</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>A Petrobras informa que a conselheira de admin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>petrobras viverá momento de transformação nos ...</td>\n",
       "      <td>Valor Econômico</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Os anos 2020 prometem ser de profundas transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>governo não descarta intervir na petrobras par...</td>\n",
       "      <td>Blog do Correio Braziliense</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Assessores próximos do presidente Jair Bolsona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>postos aguardam petrobras para reajustar preço...</td>\n",
       "      <td>Metrópoles</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Postos aguardam Petrobras para reajustar preço...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>petrobras pagará r$ 30,9 bi por plataformas</td>\n",
       "      <td>Valor Econômico</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>O resultado da licitação internacional bilioná...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>petrobras retoma venda de três refinarias: sai...</td>\n",
       "      <td>Gazeta do Povo</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>Refinarias da Petrobras em Pernambuco, Paraná ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>governo avalia mecanismo para obrigar petrobra...</td>\n",
       "      <td>BiodieselBR.com</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>A Petrobras chegou a assinar em 2019 um acordo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>postos petrobras e shell se rendem à recarga d...</td>\n",
       "      <td>Quatro Rodas</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>O eletroposto foi instalado no posto Petrobras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>ações petrobras: saiba o preço após fechamento...</td>\n",
       "      <td>UOL Economia</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>As ações da Petrobras fecharam em queda nesta ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "10    indústria tem maior nível de emprego em 4 anos...   \n",
       "11    clarissa lins, do ibp, renuncia como integrant...   \n",
       "12    petrobras viverá momento de transformação nos ...   \n",
       "20    governo não descarta intervir na petrobras par...   \n",
       "21    postos aguardam petrobras para reajustar preço...   \n",
       "...                                                 ...   \n",
       "7977        petrobras pagará r$ 30,9 bi por plataformas   \n",
       "7978  petrobras retoma venda de três refinarias: sai...   \n",
       "7979  governo avalia mecanismo para obrigar petrobra...   \n",
       "7980  postos petrobras e shell se rendem à recarga d...   \n",
       "7981  ações petrobras: saiba o preço após fechamento...   \n",
       "\n",
       "                            media       date  \\\n",
       "10                             G1 2020-02-01   \n",
       "11                 Época Negócios 2020-02-01   \n",
       "12                Valor Econômico 2020-02-01   \n",
       "20    Blog do Correio Braziliense 2020-03-01   \n",
       "21                     Metrópoles 2020-03-01   \n",
       "...                           ...        ...   \n",
       "7977              Valor Econômico 2022-06-30   \n",
       "7978               Gazeta do Povo 2022-06-30   \n",
       "7979              BiodieselBR.com 2022-06-30   \n",
       "7980                 Quatro Rodas 2022-06-30   \n",
       "7981                 UOL Economia 2022-06-30   \n",
       "\n",
       "                                                   desc  \n",
       "10    Indústria tem maior nível de emprego em 4 anos...  \n",
       "11    A Petrobras informa que a conselheira de admin...  \n",
       "12    Os anos 2020 prometem ser de profundas transfo...  \n",
       "20    Assessores próximos do presidente Jair Bolsona...  \n",
       "21    Postos aguardam Petrobras para reajustar preço...  \n",
       "...                                                 ...  \n",
       "7977  O resultado da licitação internacional bilioná...  \n",
       "7978  Refinarias da Petrobras em Pernambuco, Paraná ...  \n",
       "7979  A Petrobras chegou a assinar em 2019 um acordo...  \n",
       "7980  O eletroposto foi instalado no posto Petrobras...  \n",
       "7981  As ações da Petrobras fecharam em queda nesta ...  \n",
       "\n",
       "[3739 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['title'] != \"\")]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersão das fontes de notícias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmed1 = df\n",
    "dfmed1['media'] = dfmed1['media'].str.replace('Click Petróleo e Gás','CPG Click Petroleo e Gas')\n",
    "dfmed = dfmed1.groupby(['media']).count()\n",
    "dfmed.sort_values(by='title', ascending=False, inplace=True)\n",
    "dfmed.reset_index(inplace=True)\n",
    "totnot = dfmed['title'].sum()\n",
    "dfmed['title'] = pd.to_numeric(dfmed['title'])\n",
    "dfmed['perc'] = ((dfmed['title'] / totnot) *100)\n",
    "dfmed['perc'] = dfmed['perc'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='media'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABSwAAAOJCAYAAAAX6myDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAACqDklEQVR4nOzde7xn5dz/8de707iLwu00IkOiIiojp0REMc7cN5K7A3L+5RDlUMIdk0KUKDqIco4wKMm5HGaKJg011UTTQcepaWo6fX5/rLVv37723rP3zN7zXdO8no/Heuz9Xde1rvVZ3z394e261pWqQpIkSZIkSZK6YI1BFyBJkiRJkiRJQwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnrDXoAqSuu9/97lfTpk0bdBmSJEmSJEl3G3PmzLm6qu4/XJuBpbQM06ZNY/bs2YMuQ5IkSZIk6W4jySUjtbkkXJIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hruES8swd+Eipu07a9BlSJIkSZKk1dSCmTMGXcJK5QxLrTRJ3pBkx0HXIUmSJEmSpO4ysBywJAckOXfQdUy2JDOA1wGfS/KQCRpzQZK9J2IsSZIkSZIkdYOB5XJK8v0kPxuhbbMkleS5K7uuvjp+0dbRf3x9Jddxb+BjwCuAtwJfmKChnwgcMUFjSZIkSZIkqQN8h+XyOxr4bpJpVbWgr+11wCXAaSujkCRrV9VtIzQfC7y/79zNk1zSXVTV9cDj24+XAqdM0LhXTcQ4kiRJkiRJ6g5nWC6/WcCVwO69J5OsDbwWOKb5mKOTXJzk5iQXJHlvkhG/9yRrJNkvyT+SLE0yN8mLe9qntbMkX53k9CQ3A28cpc4lVXVF37GoZ7wHJzkhyTVJliT5U5Lte9rfmGR+klvbn2/oq7eS7JnkW0luSnJRkl36+myR5LT2O7g2yXFJNuhpPy7JD5Psk+SKJIuSzGy/iwOS/LM9v0/fuHdZEp5kgySfT3J5kluSzEvyyp72l7Xf59L2+/1Akozy3UmSJEmSJGklM7BcTlV1O/BlYLe+APKFwP1oZjauASwE/hvYDPgAzWzH3RnZXsB7gH2ALYDvAicl2bKv38dplkNvDnxveZ4hyXrAL4FpwEva+32kp/2lwOHAocBjgc8ARyR5Yd9Q+wMn08yi/AZwTJKNeu5xCrAY2AZ4KfBUmkC313bAw4FnAm8C3gv8CJgCbAscAMxM8oQRniVt/2fQfL+bA+8Cbm3bnwB8Czipfc59gfcBbxv9W5IkSZIkSdLK5JLwFXM0TbC4A3Bqe+51wKlV9Y/28/49/Rck2Rp4dXvtcPYGDqmqE4euT7Jde7535uJhVfXtMdS4Z5Ld+s69t6qOAHYGHgQ8paqubtsu7KvlK1V1ePv5/Db42wf4QU+/r1TVVwGS7EcTum4HfLW9x3rAa6vqxrbPnsDPkzyyqua3YywC3lpVdwB/TfJuYGpV7dRz732B7YE5wzznDsBTgMdU1bz23EU97e8CfllVH+oZb5P2WQ4bZjxJkiRJkiQNgDMsV0BVXUAzQ3EPaJZXAzvSE0YmeVOS2UmuSrIYeCew0XDjJVkfeDDw276m39DMGOw1e4xlfgPYsu84oW3bCjinJ6zst9kYazln6Jd25ulVwAN6xjhnKKxsnQHc2TfOeW1YOeRKoH/39Ct7xu23FXB5T1jZb6Rn2bD93u+iXeY+O8nsO5Ys6m+WJEmSJEnSJHGG5Yo7GvhikvsCuwHX0iyPpn1/4qE0MxXPAG6g2SX7pctxn+r7fNMYr1vUM4txovTX0r/hTzG2MLx3nOHGWN5xx6v/eaiqo4CjAKZM3eTf2iVJkiRJkjQ5nGG54r4N3EKzXHsP4PieHbu3BX5fVYdX1VltcLjxSANV1Q3AZcDT+pq2Bc6b8MrhbOBxSe43Qvu8CahlHrBFknv1nHsqzb+9kWZDLo+zgalJNhuljuGe5dK+2Z+SJEmSJEkaIGdYrqCqujnJiTSbwtyHu76b8nyaTXmeB8wHXkWzKcx1owx5MPCRJBfQvKtxF+DpwNbLWeK6SR7Ud+7WqroWOJFm85mT2/dDLqTZXOfGqvp5W8u3ksyheUfnTsBrgJeN4/4nAB8Gjk+yP813dCRw0gTP/PwZ8HvgO0neSfPdPxJYr6q+B3wS+GOSA2ie+4nAu2k2QZIkSZIkSVJHOMNyYnyJJog7o+8dikcC36QJyP5Isxv3J5cx1mdpgsJP0LzD8aXAy6vqz8tZ2+7A5X3H9wGq6iaaAPVSmk10zqUJF6tt/x7wdpr3bp5Hs5nOW6rqB4xRVS2hea/n+sAfaJbLn0n73s+JUlV3As+jeU/lV2lmVH4GWKdtPwv4L+DlNM85sz0OH248SZIkSZIkDUaqfD2fNJopUzepqbseOugyJEmSJEnSamrBzBmDLmHCJZlTVdOHa3OGpSRJkiRJkqTO8B2W0jJsseEGzL4b/j8ZkiRJkiRJXeQMS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjrDwFKSJEmSJElSZxhYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOMLCUJEmSJEmS1BlrDboAqevmLlzEtH1nDboMSZIkSZLu9hbMnDHoEtQBzrCUJEmSJEmS1BkGlkCS3ZIsHunzGK5fkGTvyalu5UhSSV4x6DokSZIkSZK0epvUwDLJA5N8JsmFSZYmWZjkx0me39NnQRuWVZIlSc5NsmffOGsneXeSOUkWJ7khyTlJZiZ56BjqeFmS05Ncn+SmJHOTHJjkASNc8g3gESv29KPWM63nmSvJdUl+leQZ4xjjuCQ/nKwauySNPZL8tv3b35TkvCSfS7LpoOuTJEmSJEnSxJm0wDLJNOAsYEfgfcDjgB2AWcAX+rp/BJja9vkecGSSV7bjrAOcCnwQ+ArwTOCxwFuAdYF3L6OOA4FvAX8CXgBsDuwFPBx483DXVNXNVfXPMT/s8tuJ5rmfASwCfpTk4RN5gyRrT+R4K1uS0PzdPwecQvPvaTNgd+A64MODq06SJEmSJEkTbTJnWB7R/pxeVd+sqr9V1byqOpwmmOx1Y1VdUVXzq+qDwAXAS9q2dwLbAc+qqkOranZV/b2qflNV/69tH1aSbYD3A++pqne111xSVadX1c7AZ0a47t+WhCd5fpLfJ7k5yTVJfpDkHiNcv0s7E/BFo35DcE373OcAb6IJYJ/bjrF5kllJbkzyzyRfS/Kgtu0AYFdgRs8szWf2zNx8dTuj9GbgjUnWSLJfkn+0M13nJnnxaIUl2TDJ19vZn9e1tWzS1+eNSeYnubX9+YZlPC9JXtjOlL0lycXtTNd1Rrnkv4HXAK+sqo9U1Znt3//37b+VV/WM/cQkpya5uv3+f5PkKcPUfH57/6uTnJLEzackSZIkSZI6YlICyyT3pZk9+Lmq+rd3QVbV9csY4hZgaGbgzsBPq+rs4TpWVY0yzmuAm4DDRrh2WXUAkGQn4PvAT4EnANsDv2SY7y/JXu39XlBV3x/L+K2b259rJ5kK/Ao4F9iGZmbqPYGTk6wBHAJ8EziNZobmVOCMnrE+ThMYb04zY3Uv4D3APsAWwHeBk5JsOcLzrgv8nObv8AzgKcDlwGltG0leChwOHEoz4/UzwBFJXjjSAybZETihve4xwB7AK4CPjfK97Az8baTvsu/vfy+a2ZhPp/ne/kQza/U/2/tPp5mp+WHg0cCzgZ+Mcm9JkiRJkiStZJM1s+yRQIB547monem2C02o9vn29KOAX/T1+xowFIxdUlWPGWHITYALq+q28dQxjP2Ab7cz+oac098pyUeBPWlmgw4bsA4nyXo0od0dNEHom4E/V9U+PX3+B7iWZsbqH9rZk0ur6oqePkO/HlZV3+45vzdwSFWd2J7aP8l2wN4033e/V9H8/XYfCgSTvBH4J82y+m+2136lnTELcH6SJ9CEoj8Y4VE/ABxcVce2ny9Msg/w1STvGSF8fhTwt94TSQ4C3jr0uaru2f48va/f24GXA88DvgpsRBNgf7+qbgQuAf48Qq2SJEmSJEkagMlaEp5ld7mLA9sl2DfTzIA7GDhylP7vBLakmcm43gTWMZKtgJ8to89ewNuBbccRVv6qfe4baQLY3apqLs0szu3SbDC0uO3zj/aajccw7uyhX5KsDzwY+G1fn9/QzMAczhNo3vF5Y8/9FwH36bn/ZuMcc2jcD/Q914k0f8MHLfOp/uVgmr//vvT8/ZM8IMmR7ZLvRTTf6wNogkpoZsheAlyc5IQkuya513A3SLJnktlJZt+xZNE4SpMkSZIkSdKKmKwZlhcARRNqfXcM/T8FHA0sAS7vm2l3PnCXnaCHZhUmuWYZ454PPD3JOlV16xhrX16/oVkG/2qaTYTGYmdgLnB9VfU+yxo0mxPtPcw1V45h3JvGeP+RltOvQbOc+lXDtF27nGMOjfthmk2Q+l01wjXD/f2vBq5OckVf3y8DD6QJtBcAS2mC5nXa625MsjXNO1GfQ7MZ1MeSPLGqLuu7x1HAUQBTpm4y2jNJkiRJkiRpAk3KDMuqupZmR+e3Jblnf3uSe/eduqbdcOeyYZYFfw14Tvv+wfEamr33tuEah6ljJGfTvO9wNHNoNsx5V5L9xjjupVV1YV9YCc3u6o+hWe4+v++4se1zK7Dmsm5QVTcAlwFP62vaFjhvhMvOolnWf/Uw9x8KLOeNc8yhcTcdZsz5VXX7CNd8DXhUkpeNMm7v/Q+rqllV9ReaGZZTeztU1e3tpktDO9evR7PMXZIkSZIkSR0wmbsjv5VmyfDsNsA7h2aJ9vY0M9s2GuXaXp8Gnk+z4cuHgV8D19AEai+mee/jsKrq90k+ARyc5CHAd4BLaZY7vw6YTzPjb1kOBH6QZD5NCBqacPLIqlrSc78/JnkucGqSqqr/HeMz9vsc8AbgG+37Gq8CHkGzY/a729ByAfC8JI+m+T5GW7d8MPCRJBfQBKu70GxMs/UI/U+gmd15cpL9gb8DD6X5vr9QVRe0Y34ryRzgVJrZpa8BRgsWPwL8MMklNO/BvJ1mw55tquq9I1zzDZod409ov4ufAFe09ewC3NnT93xglyS/pwkiP0ET7AKQ5AU0S9p/RTNTdHuajXrG9a5VSZIkSZIkTZ7JeoclVXURTSD2U+AgmsDydOBFNBvTjHWcpTS7ZB8I/A9N2PRXmp2mz6ZZ2jva9fvQLG3eGvgRzQzAw2lCuCPGWMOPgJfSbN5yNs3GONtz17BsqO8faMLMvZN8sL99jPcbmhF5J01A9xeaEHNpewB8kSZom00TaPbPduz1WZqA8RM0O4+/FHh5VQ274Uwbwm4HXESzfPuvNMut7wNc1/b5Hs07O99J853uBbylqkbacIeqOgWYQfPd/aE99qX5W4x0TdEss/9/wI40/57OB46nCWp7Q9c9aHZTnwN8HTiGJtgdcj1N+Hla+0x7A6+vql+PdH9JkiRJkiStXBl+Y2ZJQ6ZM3aSm7nrooMuQJEmSJOlub8HMGYMuQStJkjlVNewrICdthqUkSZIkSZIkjddkvsNSulvYYsMNmO3/wyNJkiRJkrRSOMNSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1xlqDLkDqurkLFzFt31mDLkOSJEnjtGDmjEGXIEmSloMzLCVJkiRJkiR1hoGlJEmSJEmSpM4wsNQqL8kDk3w6yQVJbknyzyRnJHl7knu2ffZM8vMk1yepJNMGXLYkSZIkSZKG4TsstUprg8ffAjcA+wHnADcDjwFeD1wDnAisC5wKnAx8ehC1SpIkSZIkadkMLLWq+zxwJzC9qm7qOX8x8MMkAaiqQwGSTF/pFUqSJEmSJGnMXBKuVVaS/wR2BD7XF1b+n6qqlVuVJEmSJEmSVoSBpVZljwQC/K33ZJJLkyxujy8MpjRJkiRJkiQtDwNL3R09HdgS+ANwj+UZoN2kZ3aS2XcsWTSRtUmSJEmSJGkUvsNSq7L5QAGb9p6sqosBkixZ3oGr6ijgKIApUzdxWbkkSZIkSdJK4gxLrbKq6hqanb/fluSeg65HkiRJkiRJK87AUqu6t9D8O56T5NVJNk/yqCSvBh4P3AGQ5EFJtgQe1V63eZItk9x3IFVLkiRJkiRpWC4J1yqtqi5KshXwPuCjwEOB24B5wBHA4W3XNwEf6rl0Vvtzd+C4lVKsJEmSJEmSlsnAUqu8qroC2Ks9RupzAHDASipJkiRJkiRJy8kl4ZIkSZIkSZI6wxmW0jJsseEGzJ45Y9BlSJIkSZIkrRacYSlJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjpjrUEXIHXd3IWLmLbvrEGXIUmSNBALZs4YdAmSJGk14wxLSZIkSZIkSZ1hYLkaSHJAknMHXYckSZIkSZK0LAaWHZbk+0l+NkLbZkkqyXNXdl19dfwiyeGDrKFfkuOS/HDQdUiSJEmSJGn8DCy77Whg+yTThml7HXAJcNrKKCTJ2ivjPpIkSZIkSVq9GVh22yzgSmD33pNtePha4JjmY45OcnGSm5NckOS9SUb82yZZI8l+Sf6RZGmSuUle3NM+rZ29+eokpye5GXjjWApuZ1wekeRjSa5O8s8khwzV056fM8x1ZyT5bM/n3ZOcl+SWJOcneWfvMyV5Y3v+lvY+pyRZK8kBwK7AjPYZKskz22s2TPL1JNe1x6wkm4zluSRJkiRJkrRyGFh2WFXdDnwZ2K0vgHwhcD/gWJq/4ULgv4HNgA8A76cv5OyzF/AeYB9gC+C7wElJtuzr93HgCGBz4HvjKP01wO3AU4G3Ae8AXtm2fRXYOsmmQ52TPAJ4SttGkjcAHwP2b5/p3W2tb2nbpwOfAz4MPBp4NvCTdrhDgG/SzDyd2h5nJFkX+DlwC/CM9n6XA6e1bZIkSZIkSeoAA8vuOxrYCNih59zrgFOr6h9VdVtV7V9Vf6yqBVX1TeALwKtHGXNv4JCqOrGqzq+q/YFft+d7HVZV366qi6vq0nHUfF5b0/ltPT+nCRWpqvOAs2lCzSE7A+dX1R/az/sB7+259w+AmbSBZft93AR8v6ouqao/V9Wnq+r2qloM3Awsraor2uNW4FVAgN2r6pyq+ivNrNF7Ai8Yx7NJkiRJkiRpEhlYdlxVXQD8EtgDIMmDgR1pgkzac29KMjvJVUkWA++kCfX+TZL1gQcDv+1r+g3NTMpes5ez7HP6Pl8GPKDn81dpQsohrwFOaOu7P/BQ4Mgki4cOmsBy47b/T2ne33lxkhOS7JrkXsuo6QnAw4Ebe8ZcBNynZ9z/k2TP9judfceSRWN4ZEmSJEmSJE2EtQZdgMbkaOCLSe4L7AZcC5wMkOSVwKE0syPPAG4A3gq8dDnuU32fb1q+crltmHF7w/GvAZ9I8hRgKbAp7XLwnn5vonmefy+y6sYkWwPbAc8B3gd8LMkTq+qyEWpaA/gTzUzLftcOc4+jgKMApkzdpP97kSRJkiRJ0iQxsFw1fBs4DNiFZqbl8VU1FApuC/y+qg4f6pzk32YMDqmqG5JcBjwN+FlP07bAeRNd+Ag1XJ7kdJqZlUuBM6vqorbtyra+javq+FHGuB04HTg9yYeAf9Is7T4KuBVYs++Ss2iWyV9dVddP8CNJkiRJkiRpghhYrgKq6uYkJwIH0CxhPrqn+XyaTXmeB8ynmUH4DOC6UYY8GPhIkguAOTRB6NOBrSe++hF9FfgkTbh4YF/bh4DDklwP/AhYu61tw6r6eJIX0Czj/hXN7MjtgXsB89rrFwDPS/Jo4Bqapd8n0MxCPTnJ/sDfaZaevxj4Qrv0XpIkSZIkSQPmOyxXHV+iCSvPqKp5PeePpNkV+0Tgj8A0miBwNJ+lCS0/AZxLs3z85VX15wmueTQnAesC9we+0dtQVV+imUn6WuDPNBsC7Qlc3Ha5HngJzU7gf6UJIl9fVb9u279IE17OBq4CnlZVS2iWkF8EfKu97ss03+lo4a4kSZIkSZJWolT5ej5pNFOmblJTdz100GVIkiQNxIKZMwZdgiRJuhtKMqeqpg/X5gxLSZIkSZIkSZ3hOyylZdhiww2Y7cwCSZIkSZKklcIZlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTPWGnQBUtfNXbiIafvOGnQZkiRJK82CmTMGXYIkSVqNOcNSkiRJkiRJUmcYWGpESdZIcmSSa5JUkmcOuiZJkiRJkiTdvRlYrkaSHJfkh+O45PnA7sALganAGWO4x7Q23LwjyUZ9bfdJcnPbPn1cxUuSJEmSJGm1YGCp0TwSuLyqzqiqK6rq1nFcu5Am7Oz1GuCfE1adJEmSJEmS7nYMLFdTQ7Mtk+yVZGGS65Icm2TdoXbg08BG7YzIBe35KUkOTXJlkluS/C7JtsPc4jhgtyTpOfe69nx/LVskOa2dfXltW9sGY6217ZMk701yYTvO3CS79LSfnuTwvvuun2RJkpeN/xuUJEmSJEnSZDCwXL09HXgssAPwSuClwF5t217AR4BLaZaDP7E9/4m27x7AVsBc4CdJpvaN/SPgHsCzAJJsBWwMfLO3U5L1gFOAxcA2bQ1PBY4ZR60A/0sTiL4V2Bz4OHBkkqEtLr8I7JxkSs81r27v+4Phvx5JkiRJkiStbAaWq7cbgDdV1byqOhX4FvBsgKpaBNwI3NEuB7+qDRffDOxTVbOqah7wJuBKmqCw1+3A8TTBJjRh4jeBm/r67QysB7y2quZW1S+BPYGXJXnkWGpt63oX8Pqq+klVXVxVJ9KElEN1nQTcSRN0DtkDOL6qbhvPlyZJkiRJkqTJs9agC9BAnVdVd/R8vgx40ij9NwbWBn47dKKq7khyJs2sxn7HAGcneRBNMDljmD6bAedU1Y09586gCRc3B+aPodbNaWZz/iRJ9fRZG1jQ1rk0yVdoQsqvJ3kMzYzO3YZ70CR70gSnrLn+/YfrIkmSJEmSpElgYLl6659ZWCz/rNv6txNVf0tyFvA14IqqOjPJtOUcc7Rah36+EPh7X7/e674EnNPuXr4HcGY7S/Tfb1x1FHAUwJSpm/zbs0mSJEmSJGlyuCRc43EhcCvwtKETSdYEngKcN8I1RwPP5N/fSTlkHrBFknv1nHsqzb/NYcPEYZwHLAUeVlXz+45LhjpV1V+A3wNvAHYZpSZJkiRJkiQNiDMsNWZVdVOSzwMHJbkauBh4J/BA4IgRLjueZlOb60doPwH4MHB8kv2B+wBHAidV1fwRrumv68YkhwCHtLuS/wq4J/Bk4M52tuSQLwJfoJl5+Y2xjC9JkiRJkqSVx8BS47VP+/NY4N7A2cBOVXX5cJ3b905ePdJgVbUkyY7AocAfgFuAk7nrDuBjsR/N5j97A5+n2aTnTzS7mvf6BvBZ4Ft9782UJEmSJElSB6TK1/Np9ZHkwTTvuXxGVf12Wf2heYfl1F0PndS6JEmSumTBzOH2SpQkSZo4SeZU1fTh2pxhqdVCkrWB/wQ+Bpw91rBSkiRJkiRJK5eBpVYXTwN+DlwA/Pd4Ltxiww2Y7SwDSZIkSZKklcLAUquFqvoFkEHXIUmSJEmSpNGtMegCJEmSJEmSJGmIgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjpjrUEXIHXd3IWLmLbvrEGXIUmSJtmCmTMGXYIkSZJwhqUkSZIkSZKkDjGw1GolSSV5xUifJUmSJEmSNFgGlquJJA9M8pkkFyZZmmRhkh8neX5PnwVtgPf0vmsPSHJuz+fd2n6nDXOfUQPAnmuHjhuT/CHJylqDNRX4wUq6lyRJkiRJksbJwHI1kGQacBawI/A+4HHADsAs4At93W8BDhrDsHcAz0iy43KUtIQmOJwKPAE4AzgpyUNHuiDJOstxn39TVVdU1dKJGEuSJEmSJEkTz8By9XBE+3N6VX2zqv5WVfOq6nCa8LLXUcBWSV62jDFvafselGS8/46qDQ6vqKrzgQ8C6wCPHerQzvY8IMkxSa4HTmjPz0zytyQ3t30+keQePdc9NMnJSa5NsiTJX5O8qqfdJeCSJEmSJEkd5i7hd3NJ7gvsBHywqhb3t1fV9X2n/gEcBnw8yfer6vZRhv8IMB94DfCV5axvLWB3mgD0z33N7wL+F5gOpD13E7AHsBDYnGaG6FJgv7b9COAewPbADcCjl6cuSZIkSZIkDYaB5d3fI2nCvnnjuObjwOvbo3/J+P+pqiuTHAJ8NMk3x7HUer0kQ+Hpf9AEjrtX1WV9/X5ZVZ/ou+dHez4uSPIxYG/+FVg+DPhOVQ2FnxePsaa7SLInsCfAmuvff3mGkCRJkiRJ0nJwSfjdX5bd5a6q6jqa0PJDSdZbRvdP0sxofOs4brEE2LI9tqJZEn5s7wZArdn9FyZ5RZLfJLmiDT0/DWzU0+UzwAeTnJnkf5M8YRx1/Z+qOqqqplfV9DXX3WB5hpAkSZIkSdJyMLC8+7sAKGCzcV53GHAbzbLsEbXLzD8CfCDJvcc4dlXV/PY4p6o+BfySZkOgXjf1fkjyZODrwCnAC/lX2Ll2z8BHAw8HjgUeBZyR5IAx1iVJkiRJkqQBM7C8m6uqa2kCvrcluWd/+0ghY1XdQrPM+j3AstZEHwVcA+y7AqXeAay7jD5PAxZW1Uer6o9VdQHNEvC7qKpL2xmS/w3sT7u0W5IkSZIkSd1nYLl6eCvN0vDZSf4ryaOTbJrkzcA5o1z3FWABzSY3I2o35nk/sNcY60mSB7XHw9v3Re4InLyM684HNkzymiSPaOt/dd/An0myU9u+Jc2GQ+eNsS5JkiRJkiQNmIHlaqCqLgK2Bn4KHEQTUp4OvIhRZh9W1Z3APjTvqFzWPb7Nv+/yPZJ1gcvbYx7wbpqZkAcu4x4/AA4GDqV5hue01/Vag2Y5+3k0z3slsOsY65IkSZIkSdKApaoGXYPUaVOmblJTdz100GVIkqRJtmDmjEGXIEmStNpIMqeqpg/X5gxLSZIkSZIkSZ2x1qALkLpuiw03YLYzLiRJkiRJklYKZ1hKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjrDwFKSJEmSJElSZxhYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOWGvQBUhdN3fhIqbtO2vQZUiSVhMLZs4YdAmSJEnSQDnD8m4myeuSPG/QdUiSJEmSJEnLw8DybiTJTsCbgM8kedgkjF9JXjHR464sSQ5Icu5InyVJkiRJkjR4BpYdkGTrJHck+e0KjLEBcBDwCprQ8qgkmagaW1OBH6zIAEkWtMFntc+8MMkXktxrgmoczSHAM1bCfSRJkiRJkrScfIdlN7weOAL4nySbVdW88Q5QVYuAx7cfLwFOn8D6hu5xxQQN9RHg88CawGbAMUABbx6uc5I1gFTVHSty06paDCxekTEkSZIkSZI0uZxhOWBJ/gPYGTgK+DbwumH6PCnJWUluSXJ2kue3MxSf2dNn8ySzktyY5J9JvpbkQT3txyX5YZK92lmN1yU5Nsm6PX2S5N1JLkiyNMmlST7e036XJeFJZib5W5Kb25mTn0hyjzE89o1VdUVVLayq04BvAlv3jLtbksXtc54L3ApsluSJSU5NcnWSG5L8JslT+r6rNyY5v/2urk5ySpK12jaXgEuSJEmSJHWcgeXgvQK4pKrmAl+hmWW59lBjknsCPwT+CjwBeC9wcO8ASaYCvwLOBbYBdgDuCZzczk4c8nTgsW37K4GXAnv1tH8M2A/4OPAY4L+Af4xS+03AHjSzJN8CvAr4wNgfHZJsBOwI/L6v6R5tLW8ENqeZNXovmu/o6e1z/gn4UZL/bMeaDnwO+DDwaODZwE/GU48kSZIkSZIGyyXhg/c6mhAO4JfAEuDFNLMtAV5Ds3T6dVV1M/CXJAcCJ/SM8Wbgz1W1z9CJJP8DXAtMB/7Qnr4BeFO7tHpekm/RhHofb4PRdwLvqKpj2v7zgTNHKryqPtrzcUGSjwF70wSNozkwyQHtc90D+DXw/r4+awJvq6o5Pefussw9yduBlwPPA74KbEQTon6/qm6kCTn/vIxahpVkT2BPgDXXv//yDCFJkiRJkqTl4AzLAUrySGBb4ESAqiqaILJ3WfimwLltWDmkfzbiE4Dt2mXUi5Ms5l8zIzfu6Xde33sgLwMe0P6+OTAF+Nk46n9Fuyz7ivaen6YJDZflU8CWwONoAtN1gFl9s0Fvp5lB2Xu/ByQ5sl3yvQi4sa1/6J4/pQkpL05yQpJdl3czn6o6qqqmV9X0NdfdYHmGkCRJkiRJ0nJwhuVgvZ5mJuHfezb0DkCSh1bVaMuxe60BzKKZ3djvyp7fb+trK5YztE7yZODrNMuv3wlcD7yIZifuZbmmqua3v1+Q5B00Mzm351+B6dJhNtn5MvDA9n4LgKVt/3UAqurGJFsD2wHPAd4HfCzJE6vqsvE/pSRJkiRJklY2Z1gOSLsRzK40odqWPcfjgXOA3duufwUe227OM2SbvuHOonnn5CVVNb/vuHGMJc2jCQCfPcb+TwMWVtVHq+qPVXUB8LAxXttvKJhcd9RezWzUw6pqVlX9hWaG5dTeDlV1e1WdXlXvo5nBuR7wguWsS5IkSZIkSSuZgeXgzADuB3yxqs7tPWhmLu6eZtrliTSB3hfbncB34F/ve6z25+eADYBvtDuKPyLJDkmOGuuS6DbY/AzN+yx3T7Jxkm2SvHmES84HNkzymvZ+bwZePcZnv1eSByWZmmQbmk2ErgLOWMZ15wO7tN/DE2m+p1uHGpO8oN0FfaskD6PZff1eNGGsJEmSJEmSVgEGloPzOuDnVXXNMG3fAqYBz2mDxBfSzKA8mybcO6DtdwtAu9z5acCdNLti/4UmxFzaHmP1PuAgmk1z5gHfAR4yXMeq+kFby6E0M0KfA+w/xvvsD1xO8w7NH9JslPPcEb6LXnvQ7H4+hyasPIZmafiQ64GXAKfRzEzdG3h9Vf16jHVJkiRJkiRpwNLs86JVSZIXA98FHlBVVw+6nru7KVM3qam7HjroMiRJq4kFM2cMugRJkiRp0iWZU1XTh2tz051VQJJdgYtodv5+LM2sxh8YVkqSJEmSJOnuxsBy1fBAmt24pwJX0OwIvs9AK1qNbLHhBsx2toskSZIkSdJKYWC5CqiqTwCfGHQdkiRJkiRJ0mRz0x1JkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOMLCUJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzlhr0AVIXTd34SKm7Ttr0GVIkibBgpkzBl2CJEmSpD7OsJQkSZIkSZLUGQaWultKsluSxYOuQ5IkSZIkSeNjYDkASX6R5PBhzv9byJbk3kkOSXJRkluT/DPJ15Ns2tfvgCTnjqOGZyapEY5Nlz1C530DeMSgi5AkSZIkSdL4+A7LDktyH+CM9uNewJ+BBwMfAP6Y5FlV9ccVvM1jgGv7zl21gmMOXFXdDNw86DokSZIkSZI0Ps6w7LYDgY2AZ1fVD6rq71X1O+DFwAXAsUmygvf4Z1Vd0XfcMdSYZNckc5MsTXJlki/3tG2U5LtJbmyPk5I8pKf9gCTnJnlVkgvbPt9Lcr+ePmsk2S/JP9p7zE3y4p72ae2sz1cl+WWSm5OcneRxSR6b5IwkNyX5TZKH91x3l9mqSTZOcnKSK9r+ZyV5wQp+d5IkSZIkSZpgBpYdlWQN4FXACVV1WW9bVd0JfJJmduTjJrGGNwJHAse293k+cG5PfScDDwS2b48HA9/rC1GnAa8EXgo8F9iKJogdshfwHmAfYAvgu8BJSbbsK+fDwEHt9dcDXwMOo5ltug1wD+CzozzOPYEfA88BHg98p73P3WH5uyRJkiRJ0t2GS8K76/7AfYB5I7Sf1/58NM1S8eW1oG+S5vVVNTRLcj/g0Kr6VE/7nPbns2lCzI2ragFAkp2B+W3baW2/tYDdqmpR2+coYPee8fYGDqmqE9vP+yfZrj2/S0+/T1XVj9oxPgn8ANivqn7enjsc+Lf3gg6pqj9z1+/pwCQvBF4B/G9//yR7AnsCrLn+/UcaVpIkSZIkSRPMwFLbA9f1fL4DIMkDgA2Bn41w3WbAZUNhJUBVXZTkMmBz/hVYXjIUVrYuAx7Q3mN9mlmZv+0b+zc0szl7ndPz+5Xtz7l959ZLsm5VLekvNsl6wIeAFwBTgbVpZmWe09+3fZajgKMApkzdpIbrI0mSJEmSpIlnYDkYNwAbDHP+3sBQuHcVzdLnzUcYY+j8+StYy8VVdfUKjtGvN+C7bZi2sbyKoD8kvG2YtuHOjTT2IcBONDM3LwCWAMcD64yhFkmSJEmSJK0kvsNyMP4GbD3Mhjlbt21D76n8OrBzkgf3dmrfH/lu4C+s2HLwEVXVP4GFNMu7hzMPeHCSaT11PYJmxuR5I1zTf48baGZcPq2vaduxjjEO2wLHV9V3quoc4FJg4wm+hyRJkiRJklaQMywH4/PA24DDknwRuIVmCfSrgRf19PsA7fsgk+wD/Ilmmfb7gU2AZ1VV70zEewyzWc2SqhptFuYDkvT/O7i2qm6l2Rzn00muBGYB69LsWP5JmiXf5wAnJNmrve4w4Czg9GU8f6+DgY8kuYDm/Zi7AE+nCW8n0vnAS5OcTDMz80M0S8IlSZIkSZLUIQaWA9C+63E7ms1eTqUJzv4K/FdV/bin37VJngx8kGYH7A1ployfDmxTVf0b8mwMnN13bg4wfZRy/jLMuecAp1XV55PcSjOb8yDgWuBHbW2V5MVtXT9vrzsNeHtfiLosnwXuBXyCZsfxvwEvbzfJmUjvAo4Gfk3zzs5DMbCUJEmSJEnqnIwvW5JWP1OmblJTdz100GVIkibBgpkzBl2CJEmStFpKMqeqhp1k5zssJUmSJEmSJHWGS8KlZdhiww2Y7QwcSZIkSZKklcIZlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTPWGnQBUtfNXbiIafvOGnQZkqRxWjBzxqBLkCRJkrQcnGEpSZIkSZIkqTMMLNU5SXZLsnic11SSV0xWTZIkSZIkSVo5DCw1Lkk2THJUkkuT3JpkYZIvJnnIGK9/SZLTklyb5OYk5yf5cpInTnbtkiRJkiRJ6j4DS41ZkocDs4HHArsCjwR2AR4D/DHJtGVcfyDwbWAu8BJgU+CVwHnAwZNVtyRJkiRJklYdBpYaj88BdwI7VNXPqurvVfVzYIf2/OdGujDJk4D3A++qqndW1a+q6pKqOruqDgK2H+3GSd6YZH47q3N+kjcM0+1BSWYlWZLkkiS79I2xRTu78+Z2hudxSTYY53cgSZIkSZKkSWRgqTFJcl9gJ+BzVbWkt639fATwvCT3GWGInYHFbb9/U1U1yr1fChwOHEozu/MzwBFJXtjX9cPA94EtgaOA45NMb8dYDzilrWEb4KXAU4FjRrqvJEmSJEmSVj4DS43VJkCAeSO0n9e2bzJC+6OAi6rq9qETSd6SZHHPsdEI1+4NfKWqDq+q86vqMOAEYJ++fidV1ZFtnwOB04F3tG07A+sBr62quVX1S2BP4GVJHtl/wyR7JpmdZPYdSxaNUJYkSZIkSZImmoGlBukEmtmQu9CEiSP9e9wM+G3fud8Am/edO3OYz0N9NgPOqaobe9rPoFnK3j8OVXVUVU2vqulrruuqcUmSJEmSpJXFwFJjNR8ohgn3Wpu37fNHaD8f2DjJ2kMnqmpRVc0HLl3OmkZcRj6gcSRJkiRJkrSCDCw1JlV1Dc07IN+SZN3etvbzW4EfV9W1IwzxNZpZlG9fjtvPA57Wd25bmmXovZ48zOehJezzgC2S3Kun/ak0/w2MtMxdkiRJkiRJK9lagy5Aq5S30SyjPi3JB4ELgI2BA2neX/m2kS6sqt8l+QRwcJKHAd8G/g48kOZdkgB3jHD5wcC3kswBTqXZ/Oc1wMv6+r0syR+BXwCvAJ4NPKltO4FmU57jk+wP3Ac4kua9lyPNCpUkSZIkSdJK5gxLjVlVXQhMB/4CfAW4CDiRZobiE6vq4mVcvw/w38AWNLt5zwdOAu4JbFdV/xjhuu/RzMx8J82syr2At1TVD/q6HgC8HDgHeDOwe1X9sR1jCbAjsD7wB+Bkmndc7jHW55ckSZIkSdLkS5Wv75NGM2XqJjV110MHXYYkaZwWzJwx6BIkSZIkjSDJnKqaPlybMywlSZIkSZIkdYbvsJSWYYsNN2C2s3QkSZIkSZJWCmdYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOMLCUJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzlhr0AVIXTd34SKm7Ttr0GVIkkawYOaMQZcgSZIkaQI5w1KSJEmSJElSZxhYSpIkSZIkSeoMA0tNqCTHJalhjt8NujZJkiRJkiR1n++w1GQ4DXht37lbB1GIJEmSJEmSVi3OsNRkWFpVV/Qd1yZ5RpLbkjxzqGOSNya5Ickj2s87Jfl1kuuSXJvklCSb9fSf1s7YfFWSXya5OcnZSR6X5LFJzkhyU5LfJHl4b1FJXphkTpJbklyc5MAk66ysL0WSJEmSJEnLZmCplaaqfgkcDHwlyX2SbAp8Cnh7VV3UdlsPOBTYBngmsAj4wTDB4oeBg4CtgOuBrwGHAR9or70H8Nmhzkl2BE4ADgceA+wBvAL42AQ/piRJkiRJklaAS8I1GXZKsrjv3Oeqah/gQ8BzgKOBacAPq+rLQ52q6ju9FyXZHbiBJoT8TU/Tp6rqR22fTwI/AParqp+35w6nCSeHfAA4uKqObT9fmGQf4KtJ3lNV1XffPYE9AdZc//7jfHxJkiRJkiQtLwNLTYZf0YZ9Pa4HqKrbkuwM/AX4J/Cs3k5JNgY+CjwJuD/NLOA1gI36xjun5/cr259z+86tl2TdqloCPAHYpg0ph6wB/AfwIODy3sGr6ijgKIApUze5S5gpSZIkSZKkyWNgqcmwpKrmj9L+ZJqw8N40oeT1PW0/BC4F3ggsBG4HzgP6l4Tf1vN7jXJujZ6fHwa+NUw9V41SqyRJkiRJklYiA0utVO1GOIcDbwV2olmS/bSquj3JfwKbAm/pWdq9NRPz7/QsYNNlBKmSJEmSJEkaMANLTYYpSR7Ud+4O4FrgK8Avq+rIJN+mWcb9IWA/4DrgauANSf4BbEizSc/tE1DTR4AfJrkE+GY75mOBbarqvRMwviRJkiRJkiaAgaUmww70vROSZnn3kcAjgS0AquqaJLsCP0pySlX9JskraXb3PheYD7wb+A4rqKpOSTKDJhjdmyawPB84bkXHliRJkiRJ0sRJ3+bIkvpMmbpJTd310EGXIUkawYKZMwZdgiRJkqRxSjKnqqYP17bGcCclSZIkSZIkaRBcEi4twxYbbsBsZ+9IkiRJkiStFM6wlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjrDwFKSJEmSJElSZxhYSpIkSZIkSeoMA0tJkiRJkiRJnbHWoAuQum7uwkVM23fWoMuQ1HELZs4YdAmSJEmSdLfgDEtJkiRJkiRJnWFgKUmSJEmSJKkzDCw1cEnun+SIJAuSLE1yZZKfJXnOoGuTJEmSJEnSyuU7LNUF3wHWBV4HzAceADwD+M9BFiVJkiRJkqSVzxmWGqgk9waeDuxbVT+rqkuq6o9VdUhVfb3tsyDJ3n3X/SLJ4T2fFyT5YJIjk9yQ5NIk7+m7ZqMk301yY3uclOQhK+ExJUmSJEmSNEYGlhq0xe3xoiT3WMGx3gnMBbYGDgI+keQpAEnWAE4GHghs3x4PBr6XJCt4X0mSJEmSJE0QA0sNVFXdDuwG7AJcn+TMJIckedJyDHdqVR1eVfOr6jCa5eXPbtueDTwO2LmqZlfVbGBnmnDz2f0DJdkzyewks+9Ysmg5SpEkSZIkSdLyMLDUwFXVd2hmO74Q+DHwVOB3Sd4/zqHO6ft8Gc37MAE2Ay6rqgU9972o7bP5MDUdVVXTq2r6mutuMM4yJEmSJEmStLwMLNUJVXVLVf20qj5SVU8FjgYOSLIOcCfQv2x77WGGua1/WMb2b7zGXbAkSZIkSZImhYGluuo8ml3s7wFcBUwdamjfdbnpOMebBzw4ybSecR5BM7PzvBUtVpIkSZIkSRPDwFIDleQ/k5yeZJckj0vy8CT/BbwX+FlV3QCcDrwmyTOTPAY4hibMHI/TaJaMn5BkepLpwAnAWe34kiRJkiRJ6oDxhj7SRFsM/A7YC3gkMAVYCJwI/G/b5+PANJpdvhcDB9LMjByzqqokLwY+C/y8PX0a8Paqckm4JEmSJElSR8SsRhrdlKmb1NRdDx10GZI6bsHMGYMuQZIkSZJWGUnmVNX04dpcEi5JkiRJkiSpM1wSLi3DFhtuwGxnTkmSJEmSJK0UzrCUJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdsdagC5C6bu7CRUzbd9agy5C0AhbMnDHoEiRJkiRJY+QMS0mSJEmSJEmdYWCpTkhyQJJzB12HJEmSJEmSBsvAssOSHJekkhw9TNtBbdsPB1HbWCWZ1tY52nEAcAjwjAGXK0mSJEmSpAHzHZbd9w/gv5P8v6q6CSDJWsD/AH8faGVj8w9gas/nNwN7AE/sObe4qhYDi1dmYZIkSZIkSeoeZ1h23znABcB/95ybAdwC/KK3Y5I1kuyX5B9JliaZm+TFPe1Dsx1fnuSnSZYkOS/Jc/rG2TzJrCQ3Jvlnkq8leVDbtl2S24Y+91xzYJJz+ouvqjuq6oqhA7gRuMu5qlrcvyS8nV36wyT7JLkiyaIkM9tnPKCt64ok+/TVsUGSo9r2G5P8Msn0vvavtO23JLkoyTvG+LeQJEmSJEnSJDOwXDUcTTMrccgewLFA9fXbC3gPsA+wBfBd4KQkW/b1OxD4LPB44I/A15PcEyDJVOBXwLnANsAOwD2Bk5OsUVW/Ai6kmeFJe80a7ed/W7q+grYDHg48E3gT8F7gR8AUYFvgAGBmkie0dQSYBWwIvADYqn2W09vnAvhfmu/mBcCjab7LhRNctyRJkiRJkpaTgeWq4URgepJN2pmNOwHHDdNvb+CQqjqxqs6vqv2BX7fne326qn5QVRcA7wfuC2zZtr0Z+HNV7VNV86rqHJowchtgaKbil4Dde8bbEXgA8NUVfM5+i4C3VtVfq+prwFnA1Kp6X/t8XwAuAbZv+2/fPscrquoPVTW/qvYDLgJe2/Z5GHBW235JVf2iqr7Vf+MkeyaZnWT2HUsWTfBjSZIkSZIkaSQGlquAqrqOZrbkHsCuwC+q6i7vr0yyPvBg4Ld9l/8G2LzvXO/S7cvanw9ofz4B2C7J4qGD5j2UABu3P78MPCLJU9vPewDfq6prxv1wozuvqu7o+XwlzcxP+s711r4ucFVf/Y/tqf3zwCuT/DnJIUmG3einqo6qqulVNX3NdTeYsAeSJEmSJEnS6Nx0Z9VxDE1QuBjYf5zX9i8dv+3/GqqqWUn9f+H1GjTLqvtnZUITDlJVVyX5PrBHkr8BLwJeOM6axuK2vs81wrne2q8Enj7MWDcAVNWPkzwMeB7wbGBWkm9V1e7DXCNJkiRJkqSVzMBy1fEz4FbgfsD3+hur6oYklwFPa/sO2RY4bxz3OYtmg59Lqqo/HOz1ReDbNMutrwBOG8c9JstZwAOBO6vqopE6VdXVwFeAryT5MfC1JG+qqqUrqU5JkiRJkiSNwCXhq4iqKuBxwMNHCdYOBvZO8uokj0ryEZrZhoeM41afAzYAvpHkSUkekWSHdufte/X0+ylwDfAh4LiqunPcDzXxTqNZEn9ykucleXiSpyT5cJKnAyT5SJKXtO8D3Qx4GXCRYaUkSZIkSVI3GFiuQqrqxqq6YZQun6UJLT9B867HlwIvr6o/j+MeQ7M07wR+AvyFJsRc2h5D/Ypmp/K1258D19b0fOB0mhmgfwO+SbMb+NC7OpfS7JL+Z5pw815MznJ2SZIkSZIkLYc0GY80fkk+Dzyyqp4z6Fom05Spm9TUXQ8ddBmSVsCCmTMGXYIkSZIkqUeSOVU1fbg232GpcUuyAc3O4/9D875LSZIkSZIkaUIYWGp5nAxsAxxdVbMGXcxk22LDDZjt7CxJkiRJkqSVwsBS41ZVzxx0DZIkSZIkSbp7ctMdSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM5Ya9AFSF03d+Eipu07a9BlSBrBgpkzBl2CJEmSJGkCOcNSkiRJkiRJUmcYWGrCJZmepJJMG3QtkiRJkiRJWrUYWIokx7UBYyW5LclFSQ5Jsl4HavtikguT3JzkqiQnJ9lsmH47JjkzyZIk1yc5va99oyQ/SHJTkquTfDbJOivvSSRJkiRJkjQWvsNSQ04DXgusDTwd+BKwHvDmQRSTZJ2quhWYDRwP/AO4L3AAcFqSaVV1W9v3JcCxwAeA3WiC+K17xloTmAVcQ/Ns/wl8GQjw9pXyQJIkSZIkSRoTZ1hqyNKquqKq/lFVJwInAC9JMiXJoUmuTHJLkt8l2bb3wiQ7Jflr2/5r4FH9gyd5apJftjMgFyb5fJL1e9p/0Z47JMlVwG8BqurIqvp1VS2oqrOADwIPBh7RXrcm8FngvVV1RFX9rarmVdUJPbd/LvAY4LVVdVZV/RR4L/CG3hokSZIkSZI0eAaWGsnNNLMtPwG8EtgD2AqYC/wkyVSAJA8Fvgf8FNgSOKy95v8k2QI4Ffg+8HjgZW3fY/ruuQvNrMenA//TX1C7RH134O/Agvb0E4CHArcmOSvJFUlOTbJVz6VPAeZV1T96zp0CTGmvlyRJkiRJUkcYWOrfJNkG2Bn4Oc2S8H2qalZVzQPeBFwJvLXt/maaAPH/VdVfq+qbwBf6hnwP8I2q+mRVXVBVv2+ve3mSB/T0u7iq3t2OM6+nnrckWQwsBp4HPLuqlrbNj2h/fgT4GDADuBT4xVCoCjyorbnX1cAdbdtw38GeSWYnmX3HkkWjfV2SJEmSJEmaQAaWGrJTksVJbgHOBH5FM1tybdrl2QBVdUfbvnl7ajPgd1VVPWOd2Tf2E4Bd2vEXt+Hj0Jgb9/SbM0JtJ9DM7nwGcD7wrSTrtm1D/4YPrKpvV9UcYE9gEcPM0hyrqjqqqqZX1fQ1191geYeRJEmSJEnSOLnpjob8iibouw24rKpuS/K4UfrXKG391qDZxOfTw7Qt7Pn9pmFvVLWIJoC8IMnvgOuAlwNfAS5vu53X0//2JBcAG7WnrgCe1jfs/YA12zZJkiRJkiR1hDMsNWRJVc2vqkuGdt8GLgRupSfsaze5eQr/CgjnAU9Kkp6xntw39lnAY9rx+4+bx1ln2mNK+3kOsBR4dE+Na9DM3LykPXUmsFmSh/SM85z2upFmdUqSJEmSJGkADCw1oqq6Cfg8cFCS5yfZrP38QOCIttsXgGnAoUkeneQVNO+57HUQsE2SLyTZKskjk7wgyZGj3b/tt0+SJyTZKMlTgW/RBI0/bGu8oa3hw0l2TPJo4DPAfWhmYEKz4c9fgOPb++8AHAx8sb1ekiRJkiRJHeGScC3LPu3PY4F7A2cDO1XV5QBV9fckLwM+BbyRZsbivsBXhwaoqnOSbAf8L/BLmqXYFwHfXca9lwLPBN7d3vtKmqXrT6mq3qXc76GZCfplYF2aGZ3b99R4R5IZNCHrb2l2QD+hvU6SJEmSJEkdkrvulSKp35Spm9TUXQ8ddBmSRrBg5oxBlyBJkiRJGqckc6pq+nBtLgmXJEmSJEmS1BkuCZeWYYsNN2C2M7gkSZIkSZJWCmdYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOMLCUJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzlhr0AVIXTd34SKm7Ttr0GVIq6UFM2cMugRJkiRJ0krmDEtJkiRJkiRJnWFg2VFJfpHk8EHXsbyS7JZk8Vg/S5IkSZIkSWBgCUCSByb5TJILkyxNsjDJj5M8f4BlvQx434oM0Iae1R53JrkiyYlJpk5QjaP5BvCIFWiXJEmSJEnSami1DyyTTAPOAnakCQgfB+wAzAK+sALjrpUkw5xfZyzXV9W1VXXj8t6/x7HAVOAhNCHo5sAxo12QZO0VvWlV3VxV/1zedkmSJEmSJK2eVvvAEjii/Tm9qr5ZVX+rqnlVdThNeAlAko2SfDfJje1xUpKH9LQfkOTcdqnzhcBSYL12duNb2/43AR9r+78wyZwktyS5OMmBvWFm/5LwJPdJ8uUk1yW5OclpSR4zhudbUlVXVNVlVXUG8CVg655xn9nW+Pwkf0hyK7Bjko2TnNzOyrwpyVlJXtBz3W49szd7j+N62kdc8j1c+xi+kwVJPpjkyCQ3JLk0yXv6xnhjkvPbMa5OckqStXrad09yXtt+fpJ3JvG/A0mSJEmSpI5YrYOaJPcFdgI+V1X/Fq5V1fVtvzWAk4EHAtu3x4OB7/XNonw4sDPwX8DjgVva8x8CfgRsAXwuyY7ACcDhwGOAPYBX0IaZIzgOeBLwYmAbYAnwkyT/MY7nvT/wEuD3wzQfBHwQ2LRtvyfwY+A57bN8BzgpyaZt/2/QzNwcOnYEbgV+OdZ6+mob63fyTmAuTeh6EPCJJE9px5gOfA74MPBo4NnAT3ru8YZ2vP2BzYB3A/sAb1memiVJkiRJkjTx1lp2l7u1RwIB5i2j37NpZltuXFULAJLsDMxv205r+60DvLaqrhy6sM0zv1FVX+o592Xg4Ko6tj11YZJ9gK8meU9VVe/Nk2wCvAh4RlX9qj33WuDvwGtoZk2OZM8ku7XPuS5wLk242O+Aqjq15/NVwJ97Ph+Y5IU0IeL/VtXNwM1tLQ8AjgI+3/NM4/UBxvadnNrOfgU4LMn/o/kbnAlsBNwEfL9dTn9J3zPsB7y3qr7dfr44yUyawPIuGxwl2RPYE2DN9e+/nI8kSZIkSZKk8VqtZ1jShHhjsRlw2VBYCVBVFwGX0bwTcsilvWFlj9l9n58AfCDJ4qEDOBFYD3jQCPe/kyaUG7r/IpqZhpsP07/XN4AtaWZJbksTcv4syT1HqzHJekk+0S6fvq6tcTpNKNjbbx3gJJrQ993LqGU0Y/1Ozum77jLgAe3vP6UJKS9OckKSXZPcq63z/sBDgSP77jET2Li/mKo6qqqmV9X0NdfdYAUeS5IkSZIkSeOxus+wvAAomkDwu8s5Ru9syJtG6NN/fg2aZcvfGqbvVStw/+Esqqr57e/zk7wOuBx4JXD0KDUeQrNcfm+a72kJcDzNLNJeRwL3AZ5fVXeMs/ZeY/1Obutrq/ZaqurGJFsD29EsZX8f8LEkTwSGansTcMYK1ClJkiRJkqRJtFoHllV1bZJTgLcl+Wz/eyyT3Lt9j+U84MFJpvUsCX8EzXssz1uOW58FbNoTJC7LPJpQ7inA0JLw9WneiTneJdhDwd26y+i3LXB8VX2nvd89aGYinj/UIcnewAuAbarqhnHW0W+838mwqup24HTg9CQfAv4JvKCqjkpyGc2y/uNXsFZJkiRJkiRNktU6sGy9FfgtMDvJfjRLjkOzsc77aJZAn9aePyHJXu11h9GEbKcvxz0/AvwwySXAN4HbgcfSBH/v7e9cVRckOZlmOfOewPXAgcANNMumR7NukqEl1Q+keY/jLcCpI18CNMHkS9v73kazcdA9hhqT7ECzgc1rgJt77nFzu1x9vMb1nQyn3cV8Y5pQ91qav+G9+Nc7Sj9E897L62k2QVqbZvOeDavq48tRsyRJkiRJkibY6v4Oy6F3UW5N8/7Dg2iCydNpNrnZs+1TNLtzXwX8vD2uAF7Sv0HOGO95CjCDJlD7Q3vsS/N+yZHs3vb7fvtzXWCndvOb0exOswT88rbu+9Es3/7bMq57F83sxF/T7Bb+u/b3IdvSBH7f7Bn/cuAzyxh3WMv5nfS7nmYX9NOAv9IsZ399Vf26vceXaHYffy3NZjy/pvkbX7w8NUuSJEmSJGniZTnyNmm1MmXqJjV110MHXYa0Wlowc8agS5AkSZIkTYIkc6pq+nBtq/0MS0mSJEmSJEnd4TsspWXYYsMNmO0sL0mSJEmSpJXCGZaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIkqTMMLCVJkiRJkiR1hoGlJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjrDwFKSJEmSJElSZxhYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkz1hp0AVLXzV24iGn7zhp0GdIqa8HMGYMuQZIkSZK0CnGGpSRJkiRJkqTOMLDUKifJcUl+2PP5F0kOH2RNkiRJkiRJmhgGlhqINnSsYY4tB12bJEmSJEmSBsd3WGqQTgNe23fu6kEUIkmSJEmSpG5whqUGaWlVXdF33J5kuyS/T3JLkiuTfDrJOssYa40kH0tydZJ/Jjkkyf/9+06yS5I/Jrmxbf9Wkg0n+fkkSZIkSZI0TgaW6pQ2RPwxcDawFfA64NXAx5dx6WuA24GnAm8D3gG8sqd9HeBDwOOBFwD3A742gaVLkiRJkiRpArgkXIO0U5LFPZ9/DZwFXAa8paruBOYl2Rc4Msl+VbVkhLHOq6r929/PT/IG4Nm0oWRVHdPT96Ikb27HfkhVXdo/WJI9gT0B1lz//ivwiJIkSZIkSRoPZ1hqkH4FbNlzvB7YDPhdG1YO+Q3NDMlHjjLWOX2fLwMeMPQhydZJTk5ySZIbgdlt00bDDVZVR1XV9Kqavua6G4z5gSRJkiRJkrRixjzDMsl9gE2Aewydq6pfTUZRWm0sqar5vSeSjNa/Rmm7bZi+a7Rjrgecwr82+fknzZLwX9MEoZIkSZIkSeqIMQWWSV4P7AU8BPgT8GTgTOBZk1aZVlfzgP9OskbPLMttgVuBC5dzzE1pAsr3V9XFAEletsKVSpIkSZIkacKNdUn4XsATgUuqanuazVCun6yitFo7AngwcESSzZLMAGYCh4/y/spl+TuwFHhbkke0Y350YsqVJEmSJEnSRBprYHlLVd0CkGRKVf0VePTklaXVVVUtBJ5HE4r/CTiGZuOc96/AmFcBuwIvAc6j2S38XStYqiRJkiRJkibBWN9heWmSewPfA36a5DrgkskqSnd/VbXbKG2/Ap401mur6plj6PMN4Bt93UZ9YaYkSZIkSZJWvjEFllX10vbXA5L8HNgA+MmkVSVJkiRJkiRptTRqYJlk/aq6Icl9e07PbX/eE7h20iqTOmKLDTdg9swZgy5DkiRJkiRptbCsGZYnAi8A5gDFXZfQFvCISapLkiRJkiRJ0mpo1MCyql7Q/nz4yilHkiRJkiRJ0upsWUvCtx6tvarOmthyJEmSJEmSJK3OlrUk/JPtz3sA04E/0ywLfxwwG3jK5JUmSZIkSZIkaXWzxmiNVbV9VW0PXA5sXVXTq+oJwFbAwpVRoCRJkiRJkqTVx6iBZY9HV9XQ7uBU1bnAZpNTkiRJkiRJkqTV1bKWhA85J8mXgK+2n18DnDM5JUmSJEmSJElaXY01sNwdeDOwV/v5V8DnJ6UiSZIkSZIkSautMQWWVXVLki8AP6qqv01yTZIkSZIkSZJWU2N6h2WSFwF/An7Sft4yyfcnsS5JkiRJkiRJq6GxbrrzIWAb4HqAqvoT8PDJKUmSJEmSJEnS6mqsgeVtVbWo71xNdDGSJEmSJEmSVm9j3XTnL0l2BtZMsgnw/4AzJq8sSZIkSZIkSaujVC17omSSdYEPAM9tT50CfLSqlk5ibVInTJm6SU3d9dBBlyF13oKZMwZdgiRJkiRpFZFkTlVNH65trEvCN2+PtYB7AC8G/jgx5d19JTk4yVeSrDnoWiRJkiRJkqRVwViXhJ8A7A2cC9w5eeXcfSTZEPg7sE9V+Z0tQ5INgL2AL1bV5YOuR5IkSZIkSYMx1sDyqqr6waRWcjdTVQuBwwZdxyrkWGD+eMLKJMcB96uqF0xaVZIkSZIkSVqpxrok/ENJvpTk1UleNnRMamWrqCTHJalhjt8NurZlSfKLttbX9p3fLcniSbzvu4ClwD7jvHQvYJeJr0iSJEmSJEmDMtYZlrsDmwJr868l4QWcNBlF3Q2cBry279ytgyhkOdwCfDTJN1fWpkpV9anlvG7RRNciSZIkSZKkwRrrDMsnVtX0qtq1qnZvjz0mtbJV29KquqLvuHaosZ3F+LYks5IsSXJJkrvMFEyyRZLTktyc5Np25uYGfX12TTI3ydIkVyb5ck/bu5Kck+SmJAvbGbL3HkPt3wD+A3jraJ2SPDXJL9v6Fyb5fJL1e9rXS3J8ksVtbe9L8sN2GfdQn/sk+XKS69rnPC3JY/ru8+Qkp7fPsaj9/cFt23FJftjTd0qSQ9v73ZLkd0m27WlfO8lnk1zWfmf/SDJzDN+JJEmSJEmSVpKxBpZnJNl8UitZ/XwY+D6wJXAUcHyS6dCEfcApwGJgG+ClwFOBY4YuTvJG4Eiadz8+Dng+zaZIQ+4E3gE8Bti5HWcs79Rc3Nb2gZECziRbAKe29T8eeFn7HMf0dPsk8Iy29me1/Z7eN9RxwJNodp3fBlgC/CTJf7T3eTzwc2A+8DTgyTSB6kgzgz8BvBLYA9gKmNuON7Vt/39tPa8CNmn7/m2EZ9wzyewks+9Y4kROSZIkSZKklSVVtexOyTxgY+BimncNBqiqetzklrfqaWcQ7kKztLrX56pqn7ZPAV+qqjf0XHcacEVV7ZLkDcAhwEOq6sa2/Zk04d0mVTU/yaXAV6tq3zHWtRNwMvAfI+1anuQXNKHnO4DzgJOqat8kuwGHV9U9237HA7dV1et6rt0SOBt4IE3weC3wP1X19bZ9PeBS4OSq2i3JJsD5wDOq6ldtnw1odlZ/d1V9KckJwCOq6ikj1Hsc7aY77fjXAa+vquPb9jXbe3ytqj6Y5LM0Ae4ONZZ/+K0pUzepqbseOtbu0mprwcwZgy5BkiRJkrSKSDKnqqYP1zbWd1juNIH1rA5+BezZd+76vs9nDvN56H/tbwacMxRWts6gmTW5eZIbgA2Bn41UQJJnAe9rx9oAWBNYB3gQcNloxVfV7Uk+AHw5yXCzMp8APDLJK3tv2f7cmCawXBv4Q8+YNyXpnQG6Wfs8Z/b0WZRkLjA0m3cr4Luj1dpj4/aev+0Z744kZ/aMdxzwU+D8JKcCPwJ+PFKAK0mSJEmSpJVvTIFlVV0y2YXczSypqvmTNPYyZwYmeRgwC/gisD9wDbA18DWa0HLZN6n6VpK9gY8Av+5rXgP4EvDpYS5dCDxqLPcY7fYreP2w41XVWUmmATsCzwa+DPw5yXMMLSVJkiRJkrphrO+w1MR78jCf57W/zwO2SHKvnvan0vy95lXVP2mCwWePMPZ0mmDynVV1ZlWdDzx4OWp8L7ArzTLqXmcBj6mq+cMcNwMXArcBTxy6IMm6wGN7xpjXPs9TevqsD2xBsxwdmiXmzxpjrRfS7MT+tJ7x1mzHHxqPqrqxqr5dVW+mmdH6LOCRY7yHJEmSJEmSJtlYl4RrfKYkeVDfuTuq6qqezy9L8kfgF8AraMLHJ7VtJ9BsfHN8kv2B+9BssHNSz8zNA4FPJ7mSZjblusCzq+qTwAU0YeA7kpxEE4a+Y7wPUVW/TPIT4G3AHT1NBwG/S/KFtq4bgU2BF1bVG6tqcZJjgIOSXA1cDnywrWlotuMFSU4GjkyyJ82S+QOBG4AT2/sc3N7nKOBzNO8FfTpwalX9va/Wm5J8vueeFwPvpHmn5hHQ7Jze1vInmkB15/Z+l473u5EkSZIkSdLkcIbl5NiBJhjrPc7u63MA8HLgHODNwO5V9UeAqlpCs2x5fZr3QJ5M867HPYYurqrPA28F3kCzUc5PaGdCVtU5wF7Au2hmF74e2Hs5n2Vf+paRt+NvB0wDfgn8Gfg4cGVPt71plpJ/n2azoHOA2dx1M6Ld2+f7fvtzXWCndpYmVfUnmu9yU+B3wO9pdvi+bYRa96HZRfxYmlDyce14l7ftNwLvae91Fs3O5s9rv29JkiRJkiR1wJh2CdfEancJ/6+q+vaga1lZkkwBLgEObmeBrjLcJVwaG3cJlyRJkiSN1UTsEi6NS5KtaHYC/wNwL5rZj/eimQG5Stliww2YbRAjSZIkSZK0UhhYajK9C3g0cDvNEu3tqsr3RUqSJEmSJGlEBpYDUFUZdA2TrarOptmtXJIkSZIkSRozN92RJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnrDXoAqSum7twEdP2nTXoMqROWjBzxqBLkCRJkiTdzTjDUpIkSZIkSVJnGFhKkiRJkiRJ6gwDSw1MkuOS1DDH79r2BT3nliQ5N8mePdfv1nfdjUn+kGRG331+0dPn1iQXJvl4kikr+5klSZIkSZI0OgNLDdppwNS+4/k97R9pzz0O+B5wZJJX9rQv6bnuCcAZwElJHtp3n2PbPo8E3gu8FThgYh9FkiRJkiRJK8rAUoO2tKqu6Duu7Wm/sT03v6o+CFwAvKSnvXquOx/4ILAO8Ni++yxp+/y9qr4D/BR47iQ+lyRJkiRJkpaDgaVWNbcAaw/XkGQtYPe2z59HGiDJ44GnAbdNRoGSJEmSJElafmsNugCt9nZKsrjv3Oeqap/eE20YuQuwBfD5nqb1eq7/D2ApsHtVXdY35p5JdqMJO9cB7qRZFj6s9l2ZewKsuf79x/VAkiRJkiRJWn4Glhq0X9EGgz2u7/n9wCQHAFOAW4GDgSN72pcAW7a/rwvsAByb5Iaq+lFPv28AHwbWB/YBrmuXhg+rqo4CjgKYMnWTGtcTSZIkSZIkabkZWGrQllTV/FHaPwUcTRNMXl5V/eFh9V1/TpLnAu8DegPLRUP9kuwC/CXJblV13Ao/gSRJkiRJkiaM77BU113Tbrhz2TBh5UjuoJltOayqug34GPDxJCP2kyRJkiRJ0spnYKlBm5LkQX3HeF4amZ7rHt6+e3JH4ORlXHciUMDblrdwSZIkSZIkTTyXhGvQdgAu7zu3EHjIGK9ft+f6pcAlwP7AQaNdVFW3JjkceG+Sz1fVjWMvWZIkSZIkSZMlY19lK62epkzdpKbueuigy5A6acHMGYMuQZIkSZK0Ckoyp6qmD9fmknBJkiRJkiRJneGScGkZtthwA2Y7i0ySJEmSJGmlcIalJEmSJEmSpM4wsJQkSZIkSZLUGQaWkiRJkiRJkjrDwFKSJEmSJElSZxhYSpIkSZIkSeoMA0tJkiRJkiRJnWFgKUmSJEmSJKkzDCwlSZIkSZIkdYaBpSRJkiRJkqTOMLCUJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqjLUGXYDUdXMXLmLavrMGXYY0KRbMnDHoEiRJkiRJugtnWEqSJEmSJEnqDANLSZIkSZIkSZ1hYKnOSPL9JD8boW2zJJXkue3P4Y43tX2f2X6+X98Y6yS5KsniJBusjGeSJEmSJEnS+BhYqkuOBrZPMm2YttcBlwCntZ/fAEztO768jPFfAlwMnAnsvOLlSpIkSZIkaaIZWKpLZgFXArv3nkyyNvBa4JiqurM9fX1VXdF33LyM8V8HfAU4vv1dkiRJkiRJHWNgqc6oqttpZknulqT33+YLgfsBxy7v2EkeBjwT+DpwErBpkscvf7WSJEmSJEmaDAaW6pqjgY2AHXrOvQ44tar+0XPuK+27KHuPLUYZd3fgp1V1VVXdRBNavmGkzkn2TDI7yew7lixagceRJEmSJEnSeBhYqlOq6gLgl8AeAEkeDOxIE2T2eg+wZd/xt+HGbGdr7k6zHHzIV4DXJLnHCHUcVVXTq2r6muu6P48kSZIkSdLKstagC5CGcTTwxST3BXYDrgVO7utzRVXNH+N4z6WZtXlCkhN6zq8JvBw4YdirJEmSJEmStNI5w1Jd9G3gFmAXmpmWx1fVbSsw3utoloBv2Xd8ETffkSRJkiRJ6hRnWKpzqurmJCcCBwD34d+XgwPcO8mD+s4trqrFvSeS3B94EfBfVXVuX9vRwJlJNq6qCyfsASRJkiRJkrTcnGGprvoSTVh5RlXNG6b9i8Dlfce+bdvQv+vbgdcCS4FThhnjD8A/cJalJEmSJElSZzjDUp1UVWcBGaFt2PM9HgTcXFXXA59qj+HGKeBhK1CmJEmSJEmSJpiBpe42kvwHsDHwduC0AZcjSZIkSZKk5WBgqbuTVwKfAc4A3jZRg26x4QbMnjljooaTJEmSJEnSKAwsdbdRVccBxw24DEmSJEmSJK0AN92RJEmSJEmS1BkGlpIkSZIkSZI6w8BSkiRJkiRJUmcYWEqSJEmSJEnqDANLSZIkSZIkSZ1hYClJkiRJkiSpMwwsJUmSJEmSJHWGgaUkSZIkSZKkzjCwlCRJkiRJktQZBpaSJEmSJEmSOsPAUpIkSZIkSVJnGFhKkiRJkiRJ6oy1Bl2A1HVzFy5i2r6zBl2GxIKZMwZdgiRJkiRJk84ZlpIkSZIkSZI6w8ByFZPkuCQ/HHQdq4IkByQ5d9B1SJIkSZIkaewMLFc9ewG79J5I8sAkn05yQZJbkvwzyRlJ3p7kniMNlGS3JDXCcY9Jf5LJdwjwjEEXIUmSJEmSpLHzHZarmKpa1Ps5yTTgt8ANwH7AOcDNwGOA1wPXACeOMuQSYONh7nPLxFQ8OFW1GFg86DokSZIkSZI0ds6wXMUMsyT888CdwPSq+npVnVdVF1fVD6vqJcDXljFkVdUV/UfP/ZLk3e3szaVJLk3y8Z72LZKcluTmJNe29W3QX2+SvZIsTHJdkmOTrNvTZ0qSQ5Nc2c4Q/V2SbXvan9nO+nxekjntvX6d5CFJnpHkz0kWt/f5z57r7rIkPMkTk5ya5OokNyT5TZKnjO8vIEmSJEmSpMlkYLkKa8O5HYHPVdVNw/WpqlrB23yMZubmx2lmbf4X8I/2/usBp9DMYtwGeCnwVOCYvjGeDjwW2AF4Zdtvr572T7Tn9wC2AuYCP0kytW+cDwPvAJ4E3Af4BrA/sCfwzLa+A0Z5lnsBX2nr2Qb4E/Cj3pBTkiRJkiRJg+WS8FXbI4EAf+s9meRS4N7tx69W1ZtGGWO9JP3Lps+pqqe27798J/COqhoKIecDZ7a/7wysB7y2qm5s770n8PMkj6yq+W2/G4A3VdUdwLwk3wKeDXy8DT3fDLy+qma1Y7wJeBbwVuCDPXXtV1W/bvt8ATgMeEJVndWe+zLwipEetKpO7/ue3g68HHge8NW+tj1pglDWXP/+Iw0pSZIkSZKkCWZgeff0dGBN4ChgWZvnLAG27Du3tP25OTAF+NkI125GE27e2HPuDJol6pvThJsA57Vh5ZDLaGZJQvP+zLVp3sMJQFXdkeTMdoxe5/T8fmX7c27fuQeMUCtJHgB8FNgeeCDNd/QfwEb9favqKJrvjylTN1nRWaqSJEmSJEkaIwPLVdt8oIBNe09W1cUASZaMYYzqmQk5kXpDvtuGaRvL6wj6g8Lb+tuqqv/caON+mSaofCewgCaY/RmwzhhqkSRJkiRJ0krgOyxXYVV1DXAq8LZ2+fZEm0cT6j17lPYtktyr59xTaf5dzRvjPS4EbgWeNnQiyZrAU4DzxlvwMmwLHFZVs6rqL8CNQP97MiVJkiRJkjRABparvrfQ/B3nJHl1ks2TPCrJq4HHA3eMfjlJ8qBhjjXbpd6foXnX5O5JNk6yTZI3t9eeQLOk/Ph2t/DtgCOBk8Y6a7PdLOjzwEFJnp9ks/bzA4EjxvldLMv5wC7td/RE4Os0YakkSZIkSZI6wiXhq7iquijJVsD7aN7P+FCapdPzaAK/w5cxxLrA5cOc34Rmyfn7gOtodgp/CM17Io9v770kyY7AocAfgFuAk7nrDuBjsU/781iazYLOBnaqquHqWhF70LyXcg7NezQPANxRR5IkSZIkqUNS5X4i0mimTN2kpu566KDLkFgwc8agS5AkSZIkaUIkmVNV04drc0m4JEmSJEmSpM5wSbi0DFtsuAGzndkmSZIkSZK0UjjDUpIkSZIkSVJnGFhKkiRJkiRJ6gwDS0mSJEmSJEmdYWApSZIkSZIk/f/27jzajqrM+/j3R5hEAVtFDYMEESEoghicQAGRBjsOraKooAgizo0DCu0AUVsMigoytNCi2AIvCDKIODUIogJKQBlkEjFAmGcSAgTi8/5RdfFwuLlDcpNzknw/a9W6p2rv2vupk9wVfXh2bfUNE5aSJEmSJEmS+oYJS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DdMWEqSJEmSJEnqGyYsJUmSJEmSJPUNE5aSJEmSJEmS+sayvQ5A6neX3XQfE/Y5o9dhSEyfOrnXIUiSJEmStNBZYSlJkiRJkiSpb5iw1GItSSXZoddxSJIkSZIkaWyYsFyIkhzdJtQqySNJrktyYJInL+C4U5JcPlZxjqUk722f98xB2hZGcnE8cPoYjylJkiRJkqQeMWG58J1Jk1R7LvB54MPAgfM7WJLlxiiuhWkusGWS7Rb2RFV1a1U9vLDnkSRJkiRJ0qJhwnLhe7hNqt1YVccBxwL/DpBkhSQHJbktyUNJLkiyxcCNSbZqqxL/Lckfk8wBPgDsB7ygo3rzvW3/5yQ5JcnM9jg5yZod462V5LQkdyeZneSqJO8YKvgkuya5oo3vmiSfSDLc35uHgCOBA4bqm+STSS5N8kCSm5J8N8lT27ZVkjyY5A1d9/xrW636zPb8cVWbSTZKcmZ7791tleuqXe1nJbk/yawklyTZepjnkSRJkiRJ0iJiwnLRexAYqJL8GrAjsBvwYuAy4BdJxnfdcwBNdeYGwGnAN4CraSo3xwMntInB04BnAVu3x+rAqUnSjnM4sFLb9gLg48C98wo0yfuB/YF9gYnAp4C9aapEh/MlYF1gpyH6/KON4QXAu4CXAocAVNX9NEu9u+/fCfi/qrp9kHifDPwSmNWO9WbglcD3OrodB9zStm8CTKFJsEqSJEmSJKkPLNvrAJYmSV5Kk5g7q02ufQjYvarOaNs/CLwG+AhNgnLAlKr6Vcc4s4BHq+rWjmvbAi8C1q2q6e21dwHXAtvQLE1fG/hxVV3S3vb3YUL+AvCZqjppoH+SqTQJy0OHurGqbktyIPDlJD8abNl2VR3UcTo9yWeA05LsUlX/AI4Bjk+yclXNTPIkmiTkB+cx7buAJwPvrqqZ7XewB3B2kudV1bXtd3BgVV3V3nPtYAO19+0BMG6V1YZ6VEmSJEmSJI0hKywXvu3bpccPAecD5wIfo6k+XA74/UDHqprb9tmwa4xpI5hnInDzQLKyHe864OaO8Q4GPp/k/CT/leQl8xosyWrAWsARbfyz2kTp1Db2kfgGsCJNAnawOV6T5P+SzEgyEzgZWB54dtvl58BsmiQlwBuBAKfOY76JwKUDycrWeTSVnAPfwTeB7yb5dZLPJdlgsIGq6siqmlRVk8attOpgXSRJkiRJkrQQmLBc+M6lWXq8PrBiVb1lsOXMXarr/IEFjKEAquooYB3g+8DzgfOSTJnHPQN/Nz5IE//A8UKaJdzDT1o1i2Zp+OcG3k05IMnawBnAlcDbgJfQLI2HJmlJVT0C/Ih/LgvfCTilqmaPZP7ucNoxp9AkL0+lWS5+aZLd5n2bJEmSJEmSFiUTlgvf7Kq6tqqubxNwA/4GzAE2H7iQZBzwCuCKYcacA4zrunYlsHqSCR3jPZfmPZaPjVdVM9rqwbfTvJtyj8EmqKrbaKoz123jf9wxTHydjgTuAvbpuj6JJjH5iao6v6quaWPtdgywTZINge3b83m5Etgoycod115J8/f8yo5n+2tVfbuqJgNHAbuP4nkkSZIkSZK0EPkOyx6pqgeS/DfNTtp30rxP8hM0m+YcPszt04G1k2wK3ADMpHlH5aXAsUn2bPsdAlwM/BogycE0y6yvAVahSQAOlRzdDzgkyb3Az2iWsG8KrFFVXx3hcz6a5LPAD7ua/kqTSPx4kpOBl9NswNN9/3lJrqfZLOdO4KwhpjsW+CLwv0n2Bf4FOAI4uaqubd+BeSBwIs13+CxgC+API3kWSZIkSZIkLXxWWPbW3sAJNEu0/0yzac72VXXLMPf9mCaBeBZwB/DOqirgTe352e1xK/DvbRs0f96H0CQp/w+4DdhlXpNU1Xdplmm/G7gE+C1NReZwm/V0j3NSe3/ntUuBPYFPtvHsDuw1jyGOBTYGjm/f8zmveWYD29EkY/9Is2v6+fxzqflcmiTm0TS7rJ/Stn9yNM8jSZIkSZKkhSf/zGVJGswK49er8bsc1OswJKZPndzrECRJkiRJGhNJLqqqSYO1WWEpSZIkSZIkqW/4DktpGButsSrTrGyTJEmSJElaJKywlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvqGCUtJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt8wYSlJkiRJkiSpb5iwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvqGCUtJkiRJkiRJfWPZXgegsZPk6cBZwL5V9ZNex7OkuOym+5iwzxm9DkNLuOlTJ/c6BEmSJEmS+oIJyyXLy4E9q+o3vQ5EkiRJkiRJmh8mLJcgVWUZoCRJkiRJkhZrvsNyASU5OslPO85XSrJ/kmuTPJTkziS/T/LOtr2GOY7uGGu7JGcluT/Jg0kuSbJnkmW6YpjXWB8cIu5zOvrNSXJLkl8k2TlJuvpOT7LXIPe+u6vfe5PM6jjfqu33jEHmvzzJlHnE03kc3/WcO3TFNdDvwSRXJfl0d/xt33clOT/JrCQPJPlDkp3n9f1IkiRJkiSpN0xYjr3vADsCHwc2ALYFjgGe1raP7zjeP8i1PQGSfBj4GXAR8EpgQ+Bw4IvAsYPM+/6uccYDPxgm1u+3/Z4LvBE4HzgCOCXJuGHufQj4cpIVhuk3GgPxdB4fGOaeL7X9JgIHAvsDe3R2SHJAO/ZpwEuAFwMnA0clmTqG8UuSJEmSJGkBuSR87L0R2KuqBqoupwN/GmisqlsHPie5t/tae31N4FvAIVX1mY6mI5LcRpNQPLmqTuxou7d7nBGY3XHPDODCJBcAvwDeQ5Pkm5cTgNcBHwG+Ocp5RxLPSM3suOe7ST4E/CtN4pUkLwU+A3yiqg7quO+AJA8D32q/yz8uYOySJEmSJEkaA1ZYjr1bge2TrLoAY7wNWB74WndDVZ0K/BV41wKMP09V9UvgMuCtw3SdRVPt+bkkT10YsYxGGlvRVFo+0tG0E02shw9y238DDwDvXNjxSZIkSZIkaWRMWI69PYCXAXcmuTjJoUm2HeUYzwfur6qb59F+JbB+17Uftu9n7Dw2GuW8A66gWSY+nCOBu4B9huk3vTs2msRitz0GeYYPDzP2V9rxHgbOBgJ8u6P9+cB1VTWn+8aqehj4G0/8LkmyR5JpSabNnX3fMCFIkiRJkiRprLgkfIxV1blJngu8HNgceA3wqyRHVtVw72N83FCjnPrTNEu5O90wyjEGZCTzV9WjST4H/CDJIUN03Rq4p+vazwbpdwJN1WanO4YJ45vAUcBqwFeAX1XVecPcM6yqOpImIcsK49cb7Z+FJEmSJEmS5pMJy4Wgqh4BftseU5N8nmaDmq9W1fQRDHENsGqSNarqpkHaNwT+0nXt1qq6dkHi7hr/upF0rKoT2x3Ev0TzvIP5e1Xd2XkhyRMqHoH75uMZ7mrvuTbJW4G/JvlDVZ3dtl8DvCrJCm1FZWcMKwDr0lRmSpIkSZIkqQ+4JHzRuKL9+ZQR9j+J5j2Mn+5uSPJm4HkMvlP4AkuyHfDCNoaR+gywC/CChRHTSFXVPcChNBvppL38/4AnAx8a5JYPt23HLZoIJUmSJEmSNBwrLMdYknNokmTTaN7vuCGwP3AVzbsnh1VVNyb5FHBwW4n4A2A2sC3NRjwndO0QDvDUJM/uujarqmYNMdVK7T3LAuOBf6NJPp4GHDOSWNt4f5PkF8BHgbkjvW+IeDrNqaq7RzHG4cDeNBsX/aiqLkjyDZpdwVcATqFZ7v5m4MvAAe4QLkmSJEmS1D+ssBx7vwTe3f68iiaB9lvgX6tqxMm8qjoEeD2wGXABTbLzo8B+DL5D+P8At3Qdw22Gs2vb7zrgdOAVwAeBN48m1tY+NDubL4iBeDqPn4xmgKq6HfghMCXJMu21vYDdaZKUfwYuodkFffeqGu47kiRJkiRJ0iKUKvcTkYaywvj1avwuB/U6DC3hpk+d3OsQJEmSJElaZJJcVFWTBmuzwlKSJEmSJElS3/AdltIwNlpjVaZZ/SZJkiRJkrRIWGEpSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6hglLSZIkSZIkSX3DhKUkSZIkSZKkvmHCUpIkSZIkSVLfMGEpSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6xrK9DkDqd5fddB8T9jmj12FoMTZ96uRehyBJkiRJ0mLDCktJkiRJkiRJfcOEpcZMknOSHDrKeyrJDgs473uTzFqQMSRJkiRJktQfTFguBpKsluTwJNOTPJzktiRnJdl2Ecx9dJtUrCSPJLk9ydlJPpJkua7ubwH+c2HHNIgTgOf2YF5JkiRJkiSNMd9huXj4MbAS8D7gWuCZwJbA0xfR/GcC7wbGAasBrwG+CLw7yTZV9QBAVd29iOJ5nKp6EHhwXu1JlgXmVlUtuqgkSZIkSZI0P6yw7HNJngq8Ctinqs6qquur6sKqOrCqju/ot3ySA5LMSDI7yYVJtuto36qtknxGx7UJ7bVJw4TxcFXdWlU3VdWfq+qbwFbApsBnOsZ73JLwtiL080mOSHJ/G9unBxn/aUlOTPJAkuuS7Nz1HayR5Pgk97THGUnW62h/3JLwJFOSXN5e/xvwMPDkJM9JckqSme1xcpI1h3l2SZIkSZIkLUImLPvfrPZ4Y5IVh+j3fZqqy3cBLwR+AJyeZOOFEVRVXQ78AnjrMF0/AVxGk9w8APhakld09dkXOA3YmGZ59/eSPAcgyUrA2cBDNM/3CuAW4My2bV7Wofku3taOO6ed41nA1u2xOnBqkozgkSVJkiRJkrQImLDsc1X1KPBeYGfg3iTnJzkwycsG+iRZF3gn8PaqOreqrquqQ4GfAR9YiOFdwfDvjvxVVR1aVddW1SE0S9q36erzw6o6pqquBb4APAq8um17BxBg16q6tKquonmmpwCvH2Le5YF3V9XFbXJ1S+BFwLuqalpVTaNJaG46SDwk2SPJtCTT5s6+b5hHlCRJkiRJ0lgxYbkYqKof01QDvgH4OfBK4IIkn227bEqT1LsiyayBA5gMrLsQQwsw3HshL+06v5nmHZyD9mkTtHd09HkJTbXkzI7nug/4F4Z+thlVdVvH+UTg5qqa3jHXdW08G3bfXFVHVtWkqpo0bqVVh5hGkiRJkiRJY8lNdxYTVfUQ8H/t8aUk3wWmJDmQJvFcwGbAI123DmxG84/2Z+fy5+5dvkdrQ+C6Yfp0x1M8MVE+VJ9lgD/TVFp2G2qTnweGiat7PkmSJEmSJPUBE5aLryto/vxWBP5Ek4h8dlWdPY/+d7Q/x3d83mR+J0/yQmB74L/md4wRuphmufudVXXvAoxzJbB6kgkDVZZJnktTuXrFggYpSZIkSZKkseGS8D6X5OlJfp1k5yQvSrJOkrfR7M59VlXdX1XXAMcCRyfZIclzk0xKsleSt7RDXQvcSFOV+fwk/wp8foRhrJDk2UlWT7Jxkk8C5wAXAQeO6QM/0bHAbcBpSbZsn//VSb7RuVP4CJxJs/T82Pa7mdSOfTHw67EPW5IkSZIkSfPDCsv+Nwu4ANgTeB6wAnATcByPr27cFfgc8DVgTZrl0n+k2WGbqnokyTuAw4FLaJZZfxb46QhieC3NztxzgXuBy4EpwJFVNWcBnm1YVTU7yauBqcCJwKo07508G7hnFONUkjcB327vhSaJ+bGqckm4JEmSJElSn4i5GmloK4xfr8bvclCvw9BibPrUyb0OQZIkSZKkvpLkoqqaNFibS8IlSZIkSZIk9Q2XhEvD2GiNVZlmhZwkSZIkSdIiYYWlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DdMWEqSJEmSJEnqGyYsJUmSJEmSJPUNE5aSJEmSJEmS+oYJS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DdMWEqSJEmSJEnqG8v2OgCp3112031M2OeMXoehIUyfOrnXIUiSJEmSpDFihaUkSZIkSZKkvmHCcimWpJLs0Os4FpUkE9pnnjTYuSRJkiRJknrPhOViIMnRbWKt+9ik17GNVpIpXc9wb5Kzk7x8EUx/IzAe+PMimEuSJEmSJEnzwYTl4uNMmmRb53H5/AyUZPkxjGt+XM0/n2Fz4Fbg50lWnNcNYxFzVc2tqlur6tEFHUuSJEmSJEkLhwnLxcfDbbKt83gUIMmrk/whyUNJbkvyrc4EX5Jzkvx3kgOT3AH8vmPcZyc5I8nsJNcn2blz0iRrJDk+yT3tcUaS9Tra10pyWpK72zGuSvKOYZ7l0Y5n+AvwFeCpwDod41aSjyQ5OckDwP5JxiU5KsnfkzyY5K9JPpNkmY77NkpyVpL7k8xKckmSrds2l4BLkiRJkiT1OROWi7kkawA/B/4EvBh4H/BO4KtdXXcGArwKeE/H9S8CPwE2AY4E/rfjHY8rAWcDDwFbAq8AbgHObNsADgdWArYGXgB8HLh3FPGvCLwbuB2Y3tW8H/AzYCPgMJq/rzcBbwcmAp8DPgvs2nHPcW2ML22faUobvyRJkiRJkhYDy/Y6AI3Y9klmdZz/tqpeB3wYuBn4cFX9A7gyyT7AEUm+UFWz2/5/r6pPDTLuyVV1RPv5K2014sdpEpzvoEly7lpVBZDkAzTJxdcDPwLWBn5cVZcMzDOCZ5nY8SwrAfcAO1TVg139Tqiq73Zd27fj8/Qkm9IkaI9qr60NHFhVV7Xn144gnidIsgewB8C4VVabnyEkSZIkSZI0H0xYLj7OpU2gtQaSexOBC9pk5YDfAcsDzwMuba9dNI9xzx/kfHL7+SU0y7RnJunssxKwbvv5YOA7SbYHzgJOqap5zTXgb8C/tZ9XBnYETkuyVVVd3NFvWveNST4I7E6TmHwSsBxwfUeXbwLfTbJLG8+PO5KXI1ZVR9JUnLLC+PVqtPdLkiRJkiRp/rgkfPExu6qu7ThuGsE9nYm2B+ZjzmVodtTepOt4PnAEQFUdRZPU/H57/bwkU4YZd07Hc/ypqvahqRL9RFe/x8WcZEfgIOBoYLs2lsNpkrO08UwBNgROBV4JXJpkt5E8rCRJkiRJknrPhOXi70rg5Z0bzwBbAHNoKhmH8/JBzq9sP19MU6V5Z1ey9NqqunvghqqaUVVHVtXbaZZs78HozaWp3BzKFsAfqurQqrq4qq7ln5Wej6mqv1bVt6tqMs1S8d3nIx5JkiRJkiT1gAnLxd/hwOrA4UkmJpkMTAUO7Xh/5VDekuT9SdZL8p/ANjRVjADHArfRLNfeMsk67Y7k3xjYKTzJwUm2T/LcJJsA2wNXDDPnskme3R7rJfk8TVXkacPcdw2waZLXtfd9gWYzINpYnpTksCRbtTuCv4wmyTlcPJIkSZIkSeoTvsNyMVdVNyV5HfB1muXb99LslP3ZEQ4xBXgr8G3gDpoNdi5sx56d5NU0CdATgVVplm6fTbNRDjRJ70OAtYCZNO+NHGxzn07r0+zkDTCbphL0Q1X1v8PcdwTNMvDjaDYD+jHwDWBgyfdc4F9oloyPB+4CfgrsNcy4kiRJkiRJ6hNpN3+WNA8rjF+vxu9yUK/D0BCmT508fCdJkiRJktQ3klxUVZMGa3NJuCRJkiRJkqS+4ZJwaRgbrbEq06zgkyRJkiRJWiSssJQkSZIkSZLUN0xYSpIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6hglLSZIkSZIkSX3DhKUkSZIkSZKkvmHCUpIkSZIkSVLfMGEpSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6hglLSZIkSZIkSX1j2V4HIPW7y266jwn7nNHrMDSE6VMn9zoESZIkSZI0RqywlCRJkiRJktQ3TFiqbyXZKkklecYQfXZIUosyLkmSJEmSJC08JiwXc0mObpN63ccFQ9xTSXZYlHEOJ8n0JHt1XT4PGA/c1YOQJEmSJEmS1AO+w3LJcCbw7q5rc3oRyFiqqjnArQt7niTLt3NJkiRJkiSpx6ywXDI8XFW3dh13j/TmtuJyjyQnJnkgyXVJdu5oPy/JN7ruWSXJg0ne0p4vn+SAJDOSzE5yYZLtOvovl+TbSW5O8nCSG5NMbdvOAdYGvj5QIdpef8KS8CTvSXJ9O8dPgWcN8jwfSHJtkjntz/cP8rwfSXJykgeA/Uf6XUmSJEmSJGnhMmGpAfsCpwEbAycA30vynLbtGOAdSTr/vrwVeAgY2D77+8CWwLuAFwI/AE5PsnHb/h/Am4F3AOsBOwJXt21vAWYAX6JZAj5+sACTvAw4GjgS2AQ4vb2ns8+bgUOBg9o4DgYOT/KGruH2A34GbAQcNo/vRJIkSZIkSYuYCcslw/ZJZnUdB4xyjB9W1TFVdS3wBeBR4NVt2wnAasDWHf13Ak6sqoeTrAu8E3h7VZ1bVddV1aE0CcEPtP3XBq4BfltVN1TVeVX1fYC2GnQuMHOgQnQeMe4JnFVVX6mqa6rqCOCUrj57tc9yaNvnEOBYYO+ufidU1XfbWP/ePVFbcTotybS5s+8b8ouTJEmSJEnS2DFhuWQ4l6bisPP4epLvdCYxhxnj0oEPVfUocAfwzPb8LuAXNElKkqxOk7w8pr1lUyDAFV3zTQbWbfsc3cZ1TZLDkkzuqtgciYnA+V3Xus8nAr/vuvY7YMOua9OGmqiqjqyqSVU1adxKq44yTEmSJEmSJM0vN91ZMsxuKyMfJ8m+wIEjHOORrvPi8QntY4D/SfJhmmXdNwK/bduWaftvNsg4DwJU1cVJJgDbAdvQLBm/JMm2VfWPEca4IKrr/IFFMKckSZIkSZJGyQrLJVhV3V5V1w4cCzjcT9qfr6eptDyuqgaSgH+iqbB8dud87XFTRzwzq+qkqvoQTfXla4Dntc1zgHHDxHAl8PKua93nVwKbd13bArhimLElSZIkSZLUB6ywXDKskOTZXdfmVtUdYzVBVT2U5MfA52k25nl3R9s1SY4Fjk7yKeBi4GnAVsB1VXVykk8CtwB/pqnCfBdwP81mOwDTgVclOYZm1/M7Bwnj28B5Sf4TOKkd/81dfb4OnJjkIuBXwPY0Cda3LMjzS5IkSZIkadGwwnLJ8FqaZGDn8aeFMM8xNMnKP1VVd8XirjQ7hX8NuAr4Kc2mPde37TOBTwN/pElobgK8rqpmt+37AmsBf6N5f+YTVNUFwPuAD9G8c/MtwJSuPqcCHwM+QVNVuSfw4ao6ffSPK0mSJEmSpEUt/1zVK2kwK4xfr8bvclCvw9AQpk+d3OsQJEmSJEnSKCS5qKomDdZmhaUkSZIkSZKkvuE7LKVhbLTGqkyzgk+SJEmSJGmRsMJSkiRJkiRJUt8wYSlJkiRJkiSpb5iwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvqGCUtJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt8wYSlJkiRJkiSpb5iwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1jWV7HYDU7y676T4m7HNGr8PQEKZPndzrECRJkiRJ0hixwlKSJEmSJElS3zBhKUmSJEmSJKlvmLDUoJJsmmRukt+P4p6Vk3wxyeVJZie5O8lFST6b5BkLM96uOLZKUotyTkmSJEmSJI0NE5aal92Bw4EXJpk4XOck/wKcD7wP+BbwCuDFwGeA9YHdFl6okiRJkiRJWlKYsNQTJHkS8C7gSOAkmiTkcPYHJgAvraqjquqSqrq+qs6qql2Ar3eMv3OSC5PMTHJ7khOTrNHRfk5bIdl9bNW2L5/kgCQz2krOC5Ns17ZNAM5uh7qjve/otm37JL9Nck9b/fnLkSRjJUmSJEmStOiYsNRgdgCur6rLgB8C70my3Lw6J1kGeAdwTFXdPFifqqqO0+WB/YCNgdcDzwD+X0f7W4DxHcd3gNuAq9r27wNb0iRVXwj8ADg9ycbAjcBb234vaO/fsz1/MnAQ8FJgK+C+9r7l5/lNSJIkSZIkaZFattcBqC+9jyZRCfAbYDbwJppqy8GsBjwVuLrzYpLzgBe1p7+tqtcBVNX3Orpdl+RDwJVJ1qyqGVV1d8cYOwLvBbauqluTrAu8E5hQVTe03Q5N8lrgA1X14SQD999eVXcOjFVVP+6Kb1fgfpoE5u+62vYA9gAYt8pq83hsSZIkSZIkjTUrLPU4SZ4HbAEcB49VRh7LyJaFd9sR2AQ4BXhSxxybJjktyfVJZgLT2qbndMUyCfge8L6quqC9vCkQ4IokswYOYDKw7jDPtm6S45L8Lcn9NFWby3TPC1BVR1bVpKqaNG6lVUf/5JIkSZIkSZovVliq2+7AOOCGJAPXApBkraq6cZB77gDuBTbovDjQN8l9wFrt5ycDvwTOBN4N3E6zJPy3NEvFafutDpwGfLOqjusYdhmggM2AR7rieHCYZ/spMAP4AHAT8ChwRee8kiRJkiRJ6i0rLPWYJMsCuwD/SVMZOXBsDFwK7DrYfVX1D+AEYOckaw0zzQY0CcrPVtW5VXUV8MyuOFYETgXOA/btuv9PNAnUZ1fVtV3HTW2fOe3PcR1jPr2de/+qOrOqrgRWxqS9JEmSJElSXzFZo06TaZKJ/1NVd3U2JDke+GCSL3dtoDPgszQb4VyQZD/gQmAWzcY3W9Esvwa4AXgY+GiSw4CJwJe7xjoCWBXYG3hWR6Xn3VV1TZJjgaOTfAq4GHhaO8d1VXUycD1NFebkJKfTVF7eA9wJvD/JjcAaNDuXPzqqb0iSJEmSJEkLlRWW6vQ+4OzuZGXrRGACsO1gN7Yb5byMZgfvTwIXAJcD/wX8hGajHKrqDpoqzn+nWY69X9u/05bA84G/Abd0HK9s23dt5/kazc7hPwVeTZOopK203A/4Ck2i9NC2CnRHmk2ALgcOA75AkzyVJEmSJElSn8jgxXKSBqwwfr0av8tBvQ5DQ5g+dXKvQ5AkSZIkSaOQ5KKqmjRYmxWWkiRJkiRJkvqG77CUhrHRGqsyzQo+SZIkSZKkRcIKS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DdMWEqSJEmSJEnqGyYsJUmSJEmSJPUNE5aSJEmSJEmS+oYJS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DeW7XUAUr+77Kb7mLDPGb0OQx2mT53c6xAkSZIkSdJCYoWlJEmSJEmSpL5hwlKPSbJVkkryjMHORzHO5UmmLJQgJUmSJEmStEQzYdlnkhzdJgkHjjuT/DTJBotg+vOA8cBdi2CuISU5p+t7GDieOoJ7pyS5fBGEKUmSJEmSpDFmwrI/nUmTOBwP/CvwJOCUoW5IstyCTlpVc6rq1qqqBR1rjHyff34PA8d9PY1IkiRJkiRJC5UJy/70cJs4vLWqLga+BWyQ5EkASSa01YbvTPLrJA8CH0jy9CT/L8mMJA8m+UuSXTsHTvLqJBckmZXkviR/TPLCtm3US8CTPDPJae181yfZbZA+qyY5MsntSWYm+U2SSSMYfnbH9zBwVJKpSa5u55ye5GtJVmznei+wH/CCjqrM97Ztz0lyShvDzCQnJ1lzpM8qSZIkSZKkhc9dwvtckpWBHYHLqurBruavAnsB7wMeAVYELgYOAO4HXgsckeSGqjorybLAacBRwE7AcsCmwNwFCPFoYO12rtk0ydUJHfEHOIOmMvL1wN3ALsCvk6xfVbfMx5wPALsBNwEbAt8BHga+AJwAvLCda6u2/31JlqF59geBrdvrhwKnJtmsj6pKJUmSJEmSlmomLPvT9klmtZ+fDNwI/Nsg/Q6pqpO6rn294/ORSV4DvBM4C1gFeCpwelX9re1z1fwGmeT5wOuALarq9+21XYDrOrptDWwCrNaRcP1CkjcA7wa+NsQUewxUR7aOqaoPVtWXO65NT7I/TeL2C1X1YPvdPVpVt3bEui3wImDdqpreXnsXcC2wDc0y/M5n2wPYA2DcKqsN91VIkiRJkiRpjJiw7E/n0ibLgH8BPgz8KsnLqurGjn7TOm9KMg7Yh6Yicw1gBWB54ByAqro7ydHAL5OcRZPEPKmqbpjPOCcC/wD+OHChqq5PcnNHn5cAKwF3NMWWj1kRWHeY8U8Avthxfj9Akh2AjwPPA54CjGuP4WK9eSBZ2cZ6XRvrhnQlLKvqSOBIgBXGr2f1pSRJkiRJ0iLiOyz70+yqurY9LgR2p6mO3KOr3wNd53sBn6KpstyGprLxVJqkJQBVtSvwMpqk6BuBq5Nst4DxDpXQWwa4rY2l89iAZgn3UO7r+B6urarbk7wcOB74JfAG4MXA52mWty+M+CVJkiRJkrQIWWG5eCiaSsaVhum3Bc1y7x/CY++PfD5w7+MGq7oEuAQ4IMnPad4p+cv5iOsqmoTkS4Hz2jmfA6ze0edi4FnAP6rquieMMHqbAzd1LgtPsnZXnzk8seLySmD1JBM6loQ/t431ijGIS5IkSZIkSWPACsv+tEKSZ7fHROAQmqXPpw9z3zXANkm2SLIBzaYy6ww0Jlmn3WH7lUnWTrI1zXsd5ythV1VXA7+g2djnFUk2odmEp3NzoDOB3wOnJXldG8MrknwxyavmY9prgDWS7JTkuUk+RPOOzk7TgbWTbJrkGUlWaOO4FDg2yaR2l/JjaRKqv56POCRJkiRJkrQQmLDsT68FbmmPPwCbAW+rqnOGue+/aN4n+XOaJd8P0CTlBsymqbg8kSbx94O2/YAFiPW9wN9pkn6nA8fRJAwBaHff/re2/X+Aq4EfAesDNzNKVXU6zZL3g2gSkNsC+3Z1+zHwM5p3dN4BvLON403t+dntcSvw7+4QLkmSJEmS1D9irkYa2grj16vxuxzU6zDUYfrUyb0OQZIkSZIkLYAkF1XVpMHarLCUJEmSJEmS1DfcdEcaxkZrrMo0K/okSZIkSZIWCSssJUmSJEmSJPUNE5aSJEmSJEmS+oYJS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS3zBhKUmSJEmSJKlvmLCUJEmSJEmS1DdMWEqSJEmSJEnqGyYsJUmSJEmSJPUNE5aSJEmSJEmS+oYJS0mSJEmSJEl9w4SlJEmSJEmSpL5hwlKSJEmSJElS31i21wFI/e6ym+5jwj5n9DqMJcL0qZN7HYIkSZIkSepzVlhqoUrynCRfSPKUXsciSZIkSZKk/mfCUgtNkuWBE4G7qmrWQhi/kuww1uNKkiRJkiSpd0xYLqGSHN0m9I4apO2Atu2noxhvfpKDBwJnV9Xho7xPkiRJkiRJSynfYblkuxF4e5L/qKoHAJIsC7wHuGGsJ2vHnltVBVBV/zHWc0iSJEmSJGnJZoXlku1S4K/A2zuuTQYeAs7p7Jhk1yRXJHkoyTVJPpFkmbZtetvtxLbScnp7fUqSy5O8N8nfgIeBJ7fvrTwlycz2ODnJmh1zDdy3e5IbkjyY5NQkz+jos0z77ssbkzyc5LIkbxrqYZOskeT4JPe0xxlJ1utoXyvJaUnuTjI7yVVJ3jHqb1WSJEmSJEkLjQnLJd9RwG4d57sB3wdq4EKS9wP7A/sCE4FPAXsDH267bNb+fD8wvuMcYB3gXcDbgI2BOcBpwLOArdtjdeDUJOm4bwKwM/Am4LXAesD3Otr3BD7dxrERcApwcpJNBnvIJCsBZ9MkY7cEXgHcApzZtgEcDqzUxvQC4OPAvYONJ0mSJEmSpN5wSfiS7zjgwLbScCawPfAx4Esdfb4AfKaqTmrP/55kKk3C8tCquqPNNd5bVbd2jb888O6qug0gybbAi4B1q2p6e+1dwLXANsCZ7X1PAt5TVTe0fT4A/DbJelX1V2Av4MCqOq7tv2+SV7fXdx7kOd8BBNh1YEl6O+btwOuBHwFrAz+uqksGnnNeX1qSPYA9AMatstq8ukmSJEmSJGmMmbBcwlXVPUlOoamsvBc4p6puGCh2TLIasBZwRJL/7rh1WZoE4HBmDCQrWxOBmweSlW0M1yW5GdiQfyYsbxpIVrb+APwDmJjkNpqqzN93zfU74N/mEcdLaKo9Zz6+kJOVgHXbzwcD30myPXAWcEpVXTTYYFV1JHAkwArj16vB+kiSJEmSJGnsmbBcOnwP+AEwi2bZd6eB1wJ8EDhvPsZ+YBR9xyLxN68xlgH+TFNp2e1ugKo6KskvaZKerwXOS/LVqpoyBnFJkiRJkiRpDPgOy6XDWTTvlnwGcGpnQ1sdeTPNEu5ru4+Oro8A40Yw15XA6kkmDFxI8lyaiskrOvqtkWStjvOX0vx9vLKq7m9j2rxr7C26xuh0MfA84M5BnuPujuedUVVHVtXbaZK3e4zgmSRJkiRJkrSIWGG5FKiqSvIiIFX18CBd9gMOSXIv8DNgOWBTYI2q+mrbZzqwTZLfAA9X1T3zmO5Mmt3Jj02yZ3vtEJqE4q87+j0I/CDJJ2neZ/kd4Iz2/ZUAXwe+lOSvwEU07618VRvXYI6leb/laUn2BW6gWer+JuA7VfXXJAcDPweuAVaheZ/nvBKgkiRJkiRJ6gETlkuJqpo5RNt3kzxAsyv3V2mSiX8BDu3o9ingm8CNwE00u3wPNlYleRPwbZpdu6FJYn5sYDOc1nTgeOB0msrPXwG7d7R/G1gZ+BrNjuNXA2/t2DCne97Z7aY8U4ETgVVpqjTPBgaSq8vQJE/XotmA6Kz2uSRJkiRJktQn8vgckrTwJZkC7FBVL+x1LCOxwvj1avwuB/U6jCXC9KmTex2CJEmSJEnqA0kuqqpJg7X5DktJkiRJkiRJfcMl4dIwNlpjVaZZGShJkiRJkrRIWGGpRa6qpiwuy8ElSZIkSZK0aJmwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvqGCUtJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt8wYSlJkiRJkiSpb5iwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvrGsr0OQOp3l910HxP2OaPXYSwRpk+d3OsQJEmSJElSn7PCUn0lyXZJ3t/rOCRJkiRJktQbJiyXIEkmJKkkk3ody/xIsjHwPeD8ebQ/o32+rdrzxfp5JUmSJEmS9EQmLEcgybOSHJzkb0keTnJTkp8n+bdexzaUJFu1Cb1nLMQ5pifZawzG+RfgWOAdVXX5CG+7ERgP/HlB55ckSZIkSVJ/8B2Ww0gyAfg9MBP4T+ASmkTvNsB3gOf0LLhFKMlyVfXIQhp7+aq6B3jhaO6rqrnArQsjJkmSJEmSJPWGFZbDO7z9OamqflRVV1fVlVV1KPCigU5JnpPklCQz2+PkJGt2tE9JcnmSd7SVmjOTnNpZ/ZhkoyRnJbk/yawklyTZum17QrXkUEui20Tr2e3pHW2/o9u2FZIclOS2JA8luSDJFh33Dsz1b0n+mGQOsN1IvqzBKi6TnJPk0K4+U5J8L8m9NJWVtHPu0NFvsyQXtTH+CXhZ9zN2P3+SDZL8JMl97Xd4fpKN2rZlknwhyY1tpexlSd40kueSJEmSJEnSomHCcghJngZsDxxWVbO626vq3rbfMsBpwLOArdtjdeDUJOm4ZQKwI/Bm4F+BFwNf6Wg/DrgFeCmwCTAFeGg+w78ReGv7+QU0S6f3bM+/1saxWxvDZcAvkozvGuMA4PPABsAf5jOOefkkcBUwCfhsd2OSpwBnANe1ffYBDhxqwCSrA78DCtgW2BQ4DBjXdtkT+DSwN7ARcApwcpJNFvhpJEmSJEmSNCZcEj605wEBrhym3zY01ZbrVtV0gCTvAq5t285s+y0LvLeq7mv7HAns2jHO2sCBVXVVe37t/AZeVXOT3N2e3l5Vd7ZzPhn4ELB7VZ3RXvsg8BrgIzQJygFTqupX8xvDMH5TVV8bov1dwPLArm2y+PIkXwF+OMQ9HwEeAN5WVXPaa9d0tO9F8/0e157vm+TV7fWdOwdKsgewB8C4VVYb4SNJkiRJkiRpQVlhObQM3wWAicDNA8lKgKq6DrgZ2LCj3/UDycrWzcAzO86/CXw3ya+TfC7JBvMX9pDWBZajeS/nQKxzaXbm3rCr77SFMP9Ix54IXNpV2Tro7uEdXgz8riNZ+Zgkq9BUvf6+q+l3PPG5qaojq2pSVU0at9Kqw0wrSZIkSZKksWLCcmh/pVlePHEBxqiOz92b1hQdfwZVNYUmeXYq8Erg0iS7tc3/aH92JlGXW4C4BlNd5w/Mxxj/4ImJ3sHinJ+xF5bu55YkSZIkSVKPmLAcQlXdDfwS+Gj7TsXHSfLU9uOVwOrtRjcDbc+lqei7YpRz/rWqvl1Vk4GjgN3bpjvan53vmdxkmOEGKg3HdVz7W3t9845YxwGvGG2s83AHHTEmWZHmHZijdSWwUbuEfcDLh7nnT8AWSZbvbqiq+2kqWjfvatqCsXluSZIkSZIkjQETlsP7CE3F4LQkb0uyfrsT9YeAS9s+Z7afj00yqd21+ljgYuDXI5kkyZOSHNbu0D0hyct4fDLtWpqNdKYkeX6Sf+Xx75sczPU01YOTk6yW5ClV9QDw38AB7S7gE9vzZ/HPHdEXxK+BndrneAHwPebvXanHAY8C30vygiTbAp8b5p7DgacAP2p3GH9eknd2bKrzdWCv9trzk3wJeBXDbOYjSZIkSZKkRceE5TDad1FuCvwfza7Zl9Ik5d5IuylLVRXwJprqwrPb41bg39u2kZgL/AtwNHA1zQ7W59Pspk1VPQK8A3gucAnwRQbZXbsr9puA/Wh2Ir8NOLRt2hs4Afg+8GeaDYO2r6pbRhhrp2VoEosDvkrz/ZwG/IrmHZF/Gu2g7bsrXw+sR5P4PbCNe6h7bgJeTbNZz9ntvB/riO/bNEnLrwGX0+zW/taqumS08UmSJEmSJGnhyMjzadLjtUvJZ9Ls5H1Cr+NZWFYYv16N3+WgXoexRJg+dXKvQ5AkSZIkSX0gyUVVNWmwtvlZqiuR5DnAe2kqLH/b22gkSZIkSZK0pDBhqfn1N5r3au5cVTf3OpiFaaM1VmWalYGSJEmSJEmLhAlLzZeqWq7XMUiSJEmSJGnJ46Y7kiRJkiRJkvqGCUtJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt8wYSlJkiRJkiSpb5iwlCRJkiRJktQ3TFhKkiRJkiRJ6hsmLCVJkiRJkiT1DROWkiRJkiRJkvqGCUtJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt9YttcBSP3uspvuY8I+Z/Q6jCXC9KmTex2CJEmSJEnqc1ZYSpIkSZIkSeobJiw7JJmQpJJM6nUsCyLJOUkOHYNxjk7y07GIaZCxL08ypR9ikSRJkiRJUv9YahKWbSJyqOPoRRDDVkl+muTOJA8muSrJIUkmjPFUbwH+s2Pe6Un2GuM5HifJT5LMTbLtQppiT2DnhTS2JEmSJEmS+sRSk7AExncc7x/k2p4Lc/IkHwDOAu4C3gZMBN5H82fw+bGcq6rurqqZYznmUJKMB7YBvgXsvjDmqKr7qurehTE2QJLlF9bYkiRJkiRJGrmlJmFZVbcOHMC93deq6r6O7msn+b8ks5Nc0V01mGTDJGckmZnk9iT/L8mz5zV3kjWBbwOHVdUuVXV2VU2vqt9X1UeAvdp+T2/HmtFWYP4lya5dY52T5DtJDk5yT3t8PckyXX0OHfgMrA18faCadKRzjcJ7gV8AhwBvTPL0rpifmeS0dp7rk+zW1X5ckh93XVsmyY1JPtmeP25JeJJXJ7kgyawk9yX5Y5IXdrS/JcllSR5ux/lcknS0T08yJcn3ktwLHDufzy5JkiRJkqQxtNQkLEfpKzQJxo2BC4HjkzwFHqsmPBe4HHgp8FrgKcBpnUnDLm8DlgemDtbYUTm4InAx8HrgBcDBwBFJtum6ZSeaP7tXAB8A9gA+Po+53wLMAL7EP6tJRzPXkNok4G7AMVV1PfAH4N1d3Y4GnkfzXf078B5gQkf7McDkJKt2XNuyjfX/DTLnssBpwO9o/oxeBhwEzG3bXwKcCJwMbATsQ7NE/qNdQ30SuAqYBHx2hI8sSZIkSZKkhWjZXgfQp75VVacDJPksTYJtE5oE2YeAS6pq74HOSd4D3E2T+PrjIOOtB9xfVTcPNWlV3QR8vePSkUleA7yTZjn5gFuA/6iqAq5K8nya5Ns3Bxnz7iRzgZltdelo5xrOlsDTgDPa8/8FPkGTQKSN7XXAFlX1+/baLsB1HWP8CrgP2AE4qr22E/DrqrplkDlXAZ4KnF5Vf2uvXdXR/kngN1W1X3t+TZL1gL1pqkAH/KaqvjbYQyXZgyYRzLhVVpvHo0uSJEmSJGmsWWE5uEs7Pg8kGZ/Z/nwJ8Op2KfKsJLOAG9u2decxXuZx/fGdknHt0uVLk9zVjv0W4DldXS9ok5UDzgfWSLLKSOYZ5VzD2R34UVXNac9PAtZN8rL2fCLwDzoSuW0l5s0d548CJ9AkKUmyAvBWmsrLJ6iqu2mqNn/ZLs3/ZJLOuCcCv++67Xc88TuaNq+Hqqojq2pSVU0at9Kq8+omSZIkSZKkMWbCcnCPDHzoSAwu0/HzDJqKy85jPeCxdyx2uQZYJcnqw8y7F/ApmsrHbdpxT6VZTj7WFniuJE+lSSzukeTRJI/SVJo+iSduvlMM7RhgyyRrAJPbOE6eV+eq2pVmKfi5wBuBq5NsN4KwO+N4YAT9JUmSJEmStAiZsBy9i2ne+Xh9VV3bdcxrZ+6TgDk071J8gjbxB7AFzTLnH1bVn4G/Ac8f5JaXdW4gA7wcuLmq7p/H/HOAcV3XRjrXUHYC7qB5j+QmHccewI5JnkyzVHsZmvd9AtBWQz4ueVtVfwSupVmSvhNwWlXNGmryqrqkqg6oqq2Ac4Bd2qYrgc27um8BzFiUu6dLkiRJkiRp9ExYjt5hwKrACUleluS5SV6b5MgkKw92Q1XdSPNex48m+UGSrZKsneQVSQ7hn++SvAbYJskWSTYADgXWGWTI1YGDkqyfZAfg08C3hoh5OvCqJGskecYo5xrK+4CTquryzgP4Ac0y8B2r6mqaHcSPaJ93E5rl3A8OMt6xNJWZk5nHcnCAJOskmZrkle33uDXwIuCKtss3aKo1pyR5fpKdaKpJB31fpSRJkiRJkvqHCctRajfO2ZwmIfcL4C80ScyH22Ne9x0ObAusBvwYuJomcQfwXx0//wj8nGap8wM0Sbxux9JUTP4B+B+ajWqGSljuC6xFU0V5xyjnGlSSTYEX01SPPk77Psuf8M9l4e8F/g78GjgdOI4midrtGGB9mg14fjXE9LNpqkFPpEm8/qCN/YB2/otpdmZ/K81u7lPb49CRPp8kSZIkSZJ6I4/fu0X9Lsk5wOVV9dFex7K0WGH8ejV+l4N6HcYSYfrUyb0OQZIkSZIk9YEkF1XVpMHarLCUJEmSJEmS1DeW7XUAUr/baI1VmWZloCRJkiRJ0iJhwnIx0+6ILUmSJEmSJC2RXBIuSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6hglLSZIkSZIkSX3DhKUkSZIkSZKkvmHCUpIkSZIkSVLfMGEpSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeoby/Y6AEmSJEmSJGlp9cgjjzBjxgweeuihXoeyUKy44oqsueaaLLfcciO+x4SlNIzLbrqPCfuc0esw+tL0qZN7HYIkSZIkSYu1GTNmsPLKKzNhwgSS9DqcMVVV3HXXXcyYMYN11llnxPe5JFySJEmSJEnqkYceeoinP/3pS1yyEiAJT3/600ddPWrCUku8JFOSXN7rOCRJkiRJkgazJCYrB8zPs5mwHIEkRyepQY4LxmDsFZN8IcmVSR5KcneSnyZ52VjEvrAk2ar9Dp7R61gGJJnQxjSpq+lAYMtexCRJkiRJkqTR8R2WI3cm8O6ua3MWZMAkywO/AtYFPgP8Dnga8DHgt0neWlWnL8gcI4mhqhboOfpdVc0CZs2rfWn4DiRJkiRJ0uJhrPfRWJj7Tzz66KMsu+zYpxetsBy5h6vq1q7j7oHGtrJvh84bkkxPstcQY34c2AJ4Q1UdW1XXV9Wfqmo34GfAUUlWasd6wrLmJO9NMqvr2huSXNRWa/49yVfaxGhnTFOSfC/JvcCx7fW3JLksycNJbkzyuYyiZrej4nKbJH9IMjvJtCSbtu2rJHkwyRu67vvXJI8keWZ7vkaS45Pc0x5nJFmvo/9aSU5rK1FnJ7kqyTva5r+3Py9sYzlnsO+urZj9aZK9k8wAZoz0OSVJkiRJkpYk06dPZ4MNNmCnnXZi4sSJ7LDDDsyePZuLLrqILbfckpe85CVst9123HLLLQBstdVWfPzjH2fSpEkcfPDBXHjhhbzyla9k44035qUvfSkzZ85c4JissOytnYAzq+riQdq+TlNxuS1w2kgGS7IdTQJyT+Bc4DnAd4AVgM7E6SeB/wImNbflJcCJ7bVjgc2AI4D7gUNG+UxfBfYGbgEOBo5NsmFV3Z/kdJpn7qwa3Qn4v6q6vU3Ong2cR7OEe04b95lJJlbVbOBwYEVg6za+9TvGeinwR2B74BKGroDdEriv7bvkvihCkiRJkiRpGFdffTVHHXUUm2++ObvtthuHHXYYp5xyCqeddhqrrbYaJ5xwAp/73Of43ve+B8CcOXOYNm0ac+bMYYMNNuCEE05gs8024/777+dJT3rSAsdjwnLktu+uZgQOq6q9F2DM5wPnzKPtivbn+vNoH8zngK9X1ffb878l2Rs4Jsmnq6ra67+pqq8N3JTk2Pbafu2la9qqxr0ZfcLyC1V1djvul2iSrmvQVDEeAxyfZOWqmpnkScCbgQ+2976DJnm460CsST4A3A68HvgRsDbw46q6pL1noKoS4I72511VdeswcT4E7FZVDw/WmGQPYA+AcausNqIHlyRJkiRJWhyttdZabL755gDsvPPO7L///lx++eVsu+22AMydO5fx48c/1n/HHXcEmkTn+PHj2WyzzQBYZZVVxiQeE5Yjdy5tAqvDvYtg3tG8W/ElwEvbJOWAZYAnAc+mqXoEmNZ130Sg+wUJvwP2S7JKVd0/ihgu7fh8c/vzmTQJy58Ds2mSlP8LvJEmQXlqR/zrADO7VqOvRPOeT2iqNr+TZHvgLOCUqrpoFPENuHxeyUqAqjoSOBJghfHr1bz6SZIkSZIkLe663wq48sor84IXvIDzzz9/0P5PfvKTF2o8vsNy5GZX1bVdx50d7cUTlxYvN8yY1wAbzqNtw44+AP8YwfjLAF8ENuk4XgSsxz+rDwEeGCauTqNN1j0yyL3LAFTVIzRVkju113eiSTjO7uj3Zx4f/yY0lahHtGMcRZPU/H57/bwkU0YZI4zuO5AkSZIkSVpi3XDDDY8lJ4877jhe/vKXc8cddzx27ZFHHuEvf/nLE+5bf/31ueWWW7jwwgsBmDlzJo8++ugCx2PCcuzcATxWG5vkWZ3n83AssM3AxjRdPkNTofh/HeM/q2sjnE267rkY2GCQxOq1VTXU35Yrgc27rm0BzKiqBX9T6uMdQ/PMG9K8P/KYjraLgecBdw4S/2MbHFXVjKo6sqreDuzLPytfB6pRx41xzJIkSZIkSUus9ddfn8MOO4yJEydyzz338LGPfYyTTjqJvffem4033phNNtmE88477wn3Lb/88pxwwgl87GMfY+ONN2bbbbfloYceWuB4XBI+ciskeXbXtblVNVC5+GvgI0nOA+YC+9O8J3EoBwFvAH6S5DPA74F/Af6DJpm3XVuVCM27Lp8GfDbJ8cBWwA5d430J+GmS62kqGR8FXgi8tKo+M0Qc36DZWXsKcBzNpjufAj47TPyjVlXntfEdB9xJs6x7wLE0m+yclmRf4AZgLeBNwHeq6q9JDqZZWn4NsArN9zTwvs/bgQeB7ZJMBx6qqvvG+hkkSZIkSZIWlulTJy/yOZdddlmOOeaYx13bZJNNOPfcc5/Q95xzznnc+WabbcYFF1wwpvFYYTlyr6V5B2Tn8aeO9k8B19EkFk8CvkuTQJunqppDswv4/wD7AX9tx3wDsElVndPR90rgQzTVhJe29+3fNd4vgck0O2j/sT32oUn8DRXHxcDbgLcClwNT2+PQoe5bAMcCGwPHV9XcjjhmA6+m+R5PBK4CfkCTxL2n7bYMzUZAV9BUn94G7NLe/yhNsnd3murUEe2uLkmSJEmSpP6Rf24crX6Q5BXAL4H/XsAdyDVGVhi/Xo3f5aBeh9GXevFffSRJkiRJWpJceeWVTJw4sddhLFSDPWOSi6pq0mD9rbDsM1V1Pk0154NJntvreCRJkiRJkqRFyXdY9qGqGljOrT6w0RqrMs1KQkmSJEmStJBUFY/fZ3nJMT+ru62wlCRJkiRJknpkxRVX5K677pqvxF6/qyruuusuVlxxxVHdZ4WlJEmSJEmS1CNrrrkmM2bM4I477uh1KAvFiiuuyJprrjmqe0xYSpIkSZIkST2y3HLLsc466/Q6jL7iknBJkiRJkiRJfcOEpSRJkiRJkqS+YcJSkiRJkiRJUt/IkrgDkTSWkswEru51HJIe8wzgzl4HIekx/k5K/cffS6m/+DspDW7tqlptsAY33ZGGd3VVTep1EJIaSab5Oyn1D38npf7j76XUX/ydlEbPJeGSJEmSJEmS+oYJS0mSJEmSJEl9w4SlNLwjex2ApMfxd1LqL/5OSv3H30upv/g7KY2Sm+5IkiRJkiRJ6htWWEqSJEmSJEnqGyYsJUmSJEmSJPUNE5bSEJJ8OMnfkzyU5KIkr+p1TNLSKMl/Jrkwyf1J7khyepIX9jouSY32d7SSHNrrWKSlVZLxSX7Q/jv5UJIrkmzZ67ikpVGScUm+3PH/Jf+e5L+SLNvr2KTFhQlLaR6S7AgcDOwPvBg4D/h5kuf0NDBp6bQVcDjwSuA1wKPAmUme1sugJEGSlwN7AJf2OhZpaZXkqcDvgQCTgYnAx4DbexiWtDTbG/gI8B/ABsCe7fl/9jIoaXHipjvSPCT5A3BpVb2/49pfgZOqyn9opB5K8hTgPuDfq+r0XscjLa2SrApcDOwO7AdcXlUf7W1U0tInyf7AllW1ea9jkQRJfgrcVVW7dFz7AfD0qnp97yKTFh9WWEqDSLI88BLgV11Nv6Kp8JLUWyvT/Bt2T68DkZZyR9L8h7yzex2ItJT7d+APSU5IcnuSPyf5aJL0OjBpKfU7YOskGwAk2ZBmldDPehqVtBjx/QnS4J4BjANu67p+G/DaRR+OpC4HA38Gzu9xHNJSK8n7gecBO/c6Fkk8F/gw8C1gKrAJcEjb5rtlpUXvAJr/wH5Fkrk0uZevVNXhvQ1LWnyYsJQkLVaSfBPYAtiiqub2Oh5paZRkfZp3PG9RVY/0Oh5JLANM63ht0Z+SrEfzzjwTltKityPwHuBdwF9o/iPCwUn+XlVH9TIwaXFhwlIa3J3AXOBZXdefBdy66MORBJDkW8A7gK2r6rpexyMtxV5BsxrhLx0rTscBr07yQeDJVfVwr4KTlkK3AFd0XbuSZqMPSYve14EDq+r49vyyJGvTbLpjwlIaAd9hKQ2iquYAFwHbdjVtS7NbuKRFLMnBwDuB11TVVb2OR1rKnQpsRFMxMnBMA45vP8/pSVTS0uv3wPpd154PXN+DWCTBSjQFMJ3mYg5GGjErLKV5+ybwwyR/pPkfgR8EVge+09OopKVQksOAd9NsKnBPkme3TbOqalbPApOWUlV1L3Bv57UkDwB3V9XlvYhJWsp9CzgvyeeAE4AXA/8BfLanUUlLr9OBfZL8nWZJ+IuBTwL/29OopMVIqqrXMUh9K8mHgc8A44HLgU9U1bm9jUpa+iSZ1z9WX6yqKYsyFkmDS3IOcHlVfbTXsUhLoySTad4tuz5wA827Kw8p/w+ftMglWRn4MvBm4Jk0r204HvhSVT3Uy9ikxYUJS0mSJEmSJEl9w/cnSJIkSZIkSeobJiwlSZIkSZIk9Q0TlpIkSZIkSZL6hglLSZIkSZIkSX3DhKUkSZIkSZKkvmHCUpIkSZIkSVLfMGEpSZIkSZIkqW+YsJQkSZIkSZLUN0xYSpIkSZIkSeob/x9zmXvnEUEXkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfmed.sort_values(by='perc', ascending=False, inplace=True)\n",
    "dfmed.reset_index(inplace=True)\n",
    "dfmed = dfmed.head(30)\n",
    "dfmed.sort_index(ascending=False).plot(kind='barh',x='media', y='perc', figsize=(20,16),fontsize=(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxqHlZeBtxA0"
   },
   "source": [
    "## 4.4 Adição de classe \"Fechamento\" ao dataframe de Ações\n",
    "Classe 1: Fechamento em alta  \n",
    "Classe 0: Fechamento em queda  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1k0J92qetxA0",
    "outputId": "87604c48-7a51-4ca7-a002-dec27bcb94c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>20.33</td>\n",
       "      <td>48215600</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%\n",
       "0   2020-01-02      20.47  37774500  0.02\n",
       "1   2020-01-03      20.30  71595600 -0.01\n",
       "2   2020-01-06      20.54  81844000  0.01\n",
       "3   2020-01-07      20.46  32822000 -0.00\n",
       "4   2020-01-08      20.33  48215600 -0.01\n",
       "..         ...        ...       ...   ...\n",
       "614 2022-06-24      26.29  53413400 -0.01\n",
       "615 2022-06-27      27.98  90417700  0.06\n",
       "616 2022-06-28      28.33  51388000  0.01\n",
       "617 2022-06-29      28.08  52048800 -0.01\n",
       "618 2022-06-30      27.93  49910100 -0.01\n",
       "\n",
       "[619 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3mze-rUAtxA0",
    "outputId": "e34c2970-7881-476b-faa7-d220e1e6da5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>20.33</td>\n",
       "      <td>48215600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento\n",
       "0   2020-01-02      20.47  37774500  0.02           1\n",
       "1   2020-01-03      20.30  71595600 -0.01           0\n",
       "2   2020-01-06      20.54  81844000  0.01           1\n",
       "3   2020-01-07      20.46  32822000 -0.00           0\n",
       "4   2020-01-08      20.33  48215600 -0.01           0\n",
       "..         ...        ...       ...   ...         ...\n",
       "614 2022-06-24      26.29  53413400 -0.01           0\n",
       "615 2022-06-27      27.98  90417700  0.06           1\n",
       "616 2022-06-28      28.33  51388000  0.01           1\n",
       "617 2022-06-29      28.08  52048800 -0.01           0\n",
       "618 2022-06-30      27.93  49910100 -0.01           0\n",
       "\n",
       "[619 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro['Fechamento'] = df_petro['Var%'].apply(lambda x: 0 if x<0 else 1)\n",
    "df_petro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTjSTl_RtxA0",
    "outputId": "a20c44ae-b982-4178-df3b-b4912ca8b5f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    319\n",
       "0    300\n",
       "Name: Fechamento, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro.Fechamento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "9fxjqOPTtxA0",
    "outputId": "e0fdd9c6-db9b-4253-ba3d-3b202f63e122"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x18856774910>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Fechamento\",\n",
    "                data=df_petro,\n",
    "                kind=\"count\", height=3.5, aspect=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njmDPsKctxA1"
   },
   "source": [
    "Há um balanceamento de classes! Não precisaremos investir muito tempo em tecnicas de balanceamento para treinar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYfqD9YWtxA1"
   },
   "source": [
    "## 4.5 Concatenar noticias diárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "OZaN4GlqtxA1",
    "outputId": "907e53ec-1a00-4e1d-ab9f-fb33f05755a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>20.33</td>\n",
       "      <td>48215600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Adj Close    Volume  Var%  Fechamento\n",
       "0 2020-01-02      20.47  37774500  0.02           1\n",
       "1 2020-01-03      20.30  71595600 -0.01           0\n",
       "2 2020-01-06      20.54  81844000  0.01           1\n",
       "3 2020-01-07      20.46  32822000 -0.00           0\n",
       "4 2020-01-08      20.33  48215600 -0.01           0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_petro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KL-87zkntxA1",
    "outputId": "0f579e09-f179-47de-b6e7-ad47a4641861"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>media</th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>indústria tem maior nível de emprego em 4 anos...</td>\n",
       "      <td>G1</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Indústria tem maior nível de emprego em 4 anos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clarissa lins, do ibp, renuncia como integrant...</td>\n",
       "      <td>Época Negócios</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>A Petrobras informa que a conselheira de admin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>petrobras viverá momento de transformação nos ...</td>\n",
       "      <td>Valor Econômico</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Os anos 2020 prometem ser de profundas transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>governo não descarta intervir na petrobras par...</td>\n",
       "      <td>Blog do Correio Braziliense</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Assessores próximos do presidente Jair Bolsona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>postos aguardam petrobras para reajustar preço...</td>\n",
       "      <td>Metrópoles</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Postos aguardam Petrobras para reajustar preço...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "10  indústria tem maior nível de emprego em 4 anos...   \n",
       "11  clarissa lins, do ibp, renuncia como integrant...   \n",
       "12  petrobras viverá momento de transformação nos ...   \n",
       "20  governo não descarta intervir na petrobras par...   \n",
       "21  postos aguardam petrobras para reajustar preço...   \n",
       "\n",
       "                          media       date  \\\n",
       "10                           G1 2020-02-01   \n",
       "11               Época Negócios 2020-02-01   \n",
       "12              Valor Econômico 2020-02-01   \n",
       "20  Blog do Correio Braziliense 2020-03-01   \n",
       "21                   Metrópoles 2020-03-01   \n",
       "\n",
       "                                                 desc  \n",
       "10  Indústria tem maior nível de emprego em 4 anos...  \n",
       "11  A Petrobras informa que a conselheira de admin...  \n",
       "12  Os anos 2020 prometem ser de profundas transfo...  \n",
       "20  Assessores próximos do presidente Jair Bolsona...  \n",
       "21  Postos aguardam Petrobras para reajustar preço...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "zg24IzQOtxA1"
   },
   "outputs": [],
   "source": [
    "lista_datas = []\n",
    "lista_news = []\n",
    "\n",
    "for i in df.date.unique():\n",
    "    news = \"\"\n",
    "    for row in df[(df['date']==i)].iterrows():\n",
    "        news = news + \" \" + row[1][0]\n",
    "    lista_news.append(news)\n",
    "    lista_datas.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "hGMZ3-n7txA1"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "64SmzW8PtxA2",
    "outputId": "edffc889-f18d-4181-e838-35b0762b0f66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>petrobras faz redução em produção de petróleo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>petrobras avança processo de venda de campos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>bolsonaro diz que trabalha com petrobras para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>bolsonaro diz que petrobras tem \"lucro absurd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>comitê da petrobras aprova nome de josé mauro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>guedes diz que encaminhará ‘imediatamente’ es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>petrobras lança campanha publicitária para re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                           Noticias\n",
       "27  2020-01-02   petrobras e vale retiram seus funcionários de...\n",
       "53  2020-01-03   petrobras reduz preços do diesel e da gasolin...\n",
       "81  2020-01-04   petrobras faz redução em produção de petróleo...\n",
       "128 2020-01-06   petrobras avança processo de venda de campos ...\n",
       "148 2020-01-07   o adeus da petrobras ao amazonas petrobras vê...\n",
       "..         ...                                                ...\n",
       "641 2022-12-02   bolsonaro diz que trabalha com petrobras para...\n",
       "661 2022-12-03   bolsonaro diz que petrobras tem \"lucro absurd...\n",
       "691 2022-12-04   comitê da petrobras aprova nome de josé mauro...\n",
       "718 2022-12-05   guedes diz que encaminhará ‘imediatamente’ es...\n",
       "748 2022-12-06   petrobras lança campanha publicitária para re...\n",
       "\n",
       "[767 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_diaria = pd.DataFrame(list(zip(lista_datas,lista_news)),\n",
    "               columns =['Date', 'Noticias'])\n",
    "df_news_diaria.sort_values(by = 'Date', ascending = True, inplace = True)\n",
    "df_news_diaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4rO-YURtxA3"
   },
   "source": [
    "## 4.6 Concatenar noticias referentes a datas sem pregões.\n",
    "\n",
    "- O próximo dia útil após o periodo sem pregões deverá consolidar as noticias acumuladas dos dias sem pregões.\n",
    "- O dataset final deverá conter apenas as datas em que ocorreu o pregão\n",
    "\n",
    "Dessa forma, iniciaremos o procedimento, concatenando as noticias de dias que não houveram pregões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "qvdyLcUztxA4",
    "outputId": "cf964006-313b-41f1-a16c-9fc10abad024"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>quase fechada a venda de refinaria da petrob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>após bb, petrobras também anuncia que aposen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>demissões em empresa da petrobras em araucár...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>indústria tem maior nível de emprego em 4 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>governo indica josé mauro ferreira coelho pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>defasagem de combustíveis se sustenta nas re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>petrobras anuncia reajuste da gasolina e do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>bolsonaro faz novos ataques à petrobras por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                           Noticias\n",
       "0   2020-01-06    petrobras faz redução em produção de petróle...\n",
       "1   2020-01-13    quase fechada a venda de refinaria da petrob...\n",
       "2   2020-01-20    após bb, petrobras também anuncia que aposen...\n",
       "3   2020-01-27    demissões em empresa da petrobras em araucár...\n",
       "4   2020-02-03    indústria tem maior nível de emprego em 4 an...\n",
       "..         ...                                                ...\n",
       "134 2022-06-06    governo indica josé mauro ferreira coelho pa...\n",
       "135 2022-06-13    defasagem de combustíveis se sustenta nas re...\n",
       "136 2022-06-17    petrobras anuncia reajuste da gasolina e do ...\n",
       "137 2022-06-20    bolsonaro faz novos ataques à petrobras por ...\n",
       "138 2022-06-27    caio andrade nega recomendação do governo pa...\n",
       "\n",
       "[139 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Iterar sobre as datas dos pregões (iniciando pelo segundo dia do pregão de 2021 df_petro.Date.iloc[1:])\n",
    "\n",
    "## Calcular delta (diferença entre dias entre dois registros seguidos de pregões):\n",
    "import datetime\n",
    "\n",
    "df_news_sem_pregao = pd.DataFrame()\n",
    "timedelta_1dia = datetime.timedelta(days=1)\n",
    "\n",
    "lista_datas = []\n",
    "lista_noticias_sem_pregao = []\n",
    "\n",
    "for i, data in enumerate(df_petro.Date.iloc[1:]):\n",
    "    data_anterior = df_petro['Date'].iloc[i]  \n",
    "    delta = data - data_anterior\n",
    "\n",
    "    \n",
    "    # Se houver mais de 1 dia sem pregão:    \n",
    "    if delta > timedelta_1dia:\n",
    "            \n",
    "            \n",
    "        # Filtra as noticias entre as datas sem pregão:\n",
    "        df_aux = df_news_diaria[ (df_news_diaria['Date']> data_anterior) & (df_news_diaria['Date']<= data)  ]\n",
    "        \n",
    "        ## Concatena as noticias das datas sem pregão\n",
    "        news = \"\"\n",
    "        for row in df_aux.iterrows():\n",
    "            news = news + \" \" + row[1][1]\n",
    "\n",
    "\n",
    "        ## Armazena as noticias e data do ultimo pregão valido em listas\n",
    "        lista_noticias_sem_pregao.append(news)\n",
    "        lista_datas.append(data)\n",
    "        \n",
    "        #Cria um dataframe auxiliar com a data do ultimo pregão e as noticias concatenadas dos dias sem pregões:\n",
    "        df_aux2 = pd.DataFrame(list(zip(lista_datas,lista_noticias_sem_pregao)),\n",
    "               columns =['Date', 'Noticias'])\n",
    "    \n",
    "        # Gera o dataframe com as noticias sem pregões + datas do ultimo pregão valido.\n",
    "        df_news_sem_pregao = df_news_sem_pregao.append(df_aux2, ignore_index = True)\n",
    "        \n",
    "        #Resetando as listas para geração de novo DF\n",
    "        lista_noticias_sem_pregao = []\n",
    "        lista_datas = []\n",
    "        \n",
    "df_news_sem_pregao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE2jBlEAtxA5"
   },
   "source": [
    "## 4.7 Atualiza as noticias concatenadas no df_news_diaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oo0kFZuJtxA5"
   },
   "outputs": [],
   "source": [
    "df_news_diaria_atualizada = df_news_diaria.copy()\n",
    "\n",
    "# itera sobre os dias com pregão cujo noticias de dias anteriores foram concatenadas:\n",
    "for data in df_news_sem_pregao.Date.unique():\n",
    "    \n",
    "    #Filtra pelo dia com pregão que teve noticias concatenada\n",
    "    df_noticia_dias_sem_pregao = df_news_sem_pregao[(df_news_sem_pregao['Date']==data)]\n",
    "\n",
    "\n",
    "    #Checa se há registro referente a data no df de noticias\n",
    "    df_check_noticias = df_news_diaria_atualizada[(df_news_diaria_atualizada['Date']==data)]\n",
    "    \n",
    "    # Se não houver registros referente á data então o registro deverá ser criado no df de noticias:\n",
    "    # Se houver, então o registro será atualizado no df de noticias\n",
    "    \n",
    "    if len(df_check_noticias) > 0:\n",
    "        \n",
    "        #Substitui os registros\n",
    "        df_news_diaria_atualizada = df_news_diaria_atualizada.replace ((df_news_diaria_atualizada.loc[df_news_diaria_atualizada['Date'].isin(df_noticia_dias_sem_pregao['Date'])])['Noticias'].values, df_noticia_dias_sem_pregao['Noticias'].values)\n",
    "        \n",
    "    else:\n",
    "        #Insere o novo registro\n",
    "        df_news_diaria_atualizada = df_news_diaria_atualizada.append(df_noticia_dias_sem_pregao, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T48ApqLytxA6",
    "outputId": "9e747f6b-952a-41ad-a2dc-4e3bc124aed5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 785)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_news_diaria), len(df_news_diaria_atualizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTaD-Te1txA6"
   },
   "source": [
    "## 4.8 Mesclando o dataframe noticias finais e ações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "cMe4z2J2txA6",
    "outputId": "b98005cc-12f3-4557-f223-e45075f0f000"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>20.33</td>\n",
       "      <td>48215600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>20.18</td>\n",
       "      <td>25397500</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras pode criar subsidiárias para vender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>20.22</td>\n",
       "      <td>30676800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>quase fechada a venda de refinaria da petrob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>20.00</td>\n",
       "      <td>39796500</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>fábrica de fertilizantes da petrobras no para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>19.70</td>\n",
       "      <td>34405700</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras vende ativos na nigéria e encerra a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0 2020-01-02      20.47  37774500  0.02           1   \n",
       "1 2020-01-03      20.30  71595600 -0.01           0   \n",
       "2 2020-01-06      20.54  81844000  0.01           1   \n",
       "3 2020-01-07      20.46  32822000 -0.00           0   \n",
       "4 2020-01-08      20.33  48215600 -0.01           0   \n",
       "5 2020-01-09      20.27  36102700 -0.00           0   \n",
       "6 2020-01-10      20.18  25397500 -0.00           0   \n",
       "7 2020-01-13      20.22  30676800  0.00           1   \n",
       "8 2020-01-14      20.00  39796500 -0.01           0   \n",
       "9 2020-01-15      19.70  34405700 -0.02           0   \n",
       "\n",
       "                                            Noticias  \n",
       "0   petrobras e vale retiram seus funcionários de...  \n",
       "1   petrobras reduz preços do diesel e da gasolin...  \n",
       "2    petrobras faz redução em produção de petróle...  \n",
       "3   o adeus da petrobras ao amazonas petrobras vê...  \n",
       "4                                                NaN  \n",
       "5   refinarias da petrobras apresentam queda na c...  \n",
       "6   petrobras pode criar subsidiárias para vender...  \n",
       "7    quase fechada a venda de refinaria da petrob...  \n",
       "8   fábrica de fertilizantes da petrobras no para...  \n",
       "9   petrobras vende ativos na nigéria e encerra a...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.merge(left = df_petro, right = df_news_diaria_atualizada, how = 'left', on = 'Date')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "s1o_Hwy_txA6",
    "outputId": "01c476c4-81d5-4cd5-fc1d-ecdf23410617"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>petrobras faz redução em produção de petróleo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>petrobras pode criar subsidiárias para vender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>quase fechada a venda de refinaria da petrobr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>petrobras vende áreas de produção e abre espa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>quase fechada a venda de refinaria da petrob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>fábrica de fertilizantes da petrobras no para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>petrobras vende ativos na nigéria e encerra a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                           Noticias\n",
       "0  2020-01-02   petrobras e vale retiram seus funcionários de...\n",
       "1  2020-01-03   petrobras reduz preços do diesel e da gasolin...\n",
       "2  2020-01-04   petrobras faz redução em produção de petróleo...\n",
       "3  2020-01-06    petrobras faz redução em produção de petróle...\n",
       "4  2020-01-07   o adeus da petrobras ao amazonas petrobras vê...\n",
       "5  2020-01-09   refinarias da petrobras apresentam queda na c...\n",
       "6  2020-01-10   petrobras pode criar subsidiárias para vender...\n",
       "7  2020-01-11   quase fechada a venda de refinaria da petrobr...\n",
       "8  2020-01-12   petrobras vende áreas de produção e abre espa...\n",
       "9  2020-01-13    quase fechada a venda de refinaria da petrob...\n",
       "10 2020-01-14   fábrica de fertilizantes da petrobras no para...\n",
       "11 2020-01-15   petrobras vende ativos na nigéria e encerra a..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_diaria_atualizada.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3xFXjI9txA6",
    "outputId": "daa44a3a-821e-47e7-c106-4c5ac2b52124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4     2020-01-08\n",
       " 25    2020-02-06\n",
       " 28    2020-02-11\n",
       " 31    2020-02-14\n",
       " 43    2020-03-05\n",
       "          ...    \n",
       " 600   2022-06-03\n",
       " 602   2022-06-07\n",
       " 603   2022-06-08\n",
       " 604   2022-06-09\n",
       " 605   2022-06-10\n",
       " Name: Date, Length: 76, dtype: datetime64[ns],\n",
       " 76)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[(df_final['Noticias'].isnull())].Date, len(df_final[(df_final['Noticias'].isnull())].Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0ikKNk3txA6"
   },
   "source": [
    "No total houveram 76 registros de pregões sem atribuição de noticias.\n",
    "\n",
    "Para esses registros observou-se que:  \n",
    "\n",
    "**1) Não houveram noticias na respectiva data e/ou**  \n",
    "**2) Considerando as datas sem pregões que antecederam a data do pregão também não houveram noticias.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vj6ccR0otxA7",
    "outputId": "86d8a353-6150-4235-9048-8c37725308e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619, 76)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final), len(df_final[(df_final['Noticias'].isnull())].Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjjQVDPdtxA7"
   },
   "source": [
    "## 4.9 Exclusão dias com pregões sem noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Vt8ot-gRtxA7"
   },
   "outputs": [],
   "source": [
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LjELo_UitxA7",
    "outputId": "6f98d617-31d5-4020-b2c0-04105ffab61e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0   2020-01-02      20.47  37774500  0.02           1   \n",
       "1   2020-01-03      20.30  71595600 -0.01           0   \n",
       "2   2020-01-06      20.54  81844000  0.01           1   \n",
       "3   2020-01-07      20.46  32822000 -0.00           0   \n",
       "5   2020-01-09      20.27  36102700 -0.00           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "614 2022-06-24      26.29  53413400 -0.01           0   \n",
       "615 2022-06-27      27.98  90417700  0.06           1   \n",
       "616 2022-06-28      28.33  51388000  0.01           1   \n",
       "617 2022-06-29      28.08  52048800 -0.01           0   \n",
       "618 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  \n",
       "0     petrobras e vale retiram seus funcionários de...  \n",
       "1     petrobras reduz preços do diesel e da gasolin...  \n",
       "2      petrobras faz redução em produção de petróle...  \n",
       "3     o adeus da petrobras ao amazonas petrobras vê...  \n",
       "5     refinarias da petrobras apresentam queda na c...  \n",
       "..                                                 ...  \n",
       "614   comitê de elegibilidade da petrobras dá aval ...  \n",
       "615    caio andrade nega recomendação do governo pa...  \n",
       "616   petrobras: novo presidente não conseguirá mud...  \n",
       "617   paes de andrade falta à primeira reunião do c...  \n",
       "618   caio paes de andrade: como um dos investidore...  \n",
       "\n",
       "[543 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLQVL39etxA7"
   },
   "source": [
    "# 5.0 Feature Engineering\n",
    "\n",
    "Será realizado o levantamento das palavras mais frequentes em notícias para inputação de polaridade no dicionário SentilexPT caso não existam ainda.\n",
    "\n",
    "### ATENÇÃO: As seções 5, 6 e 7 Foram automatizadas e otimizadas na seção 8. Rodar os códigos das seções 5, 6 e 7 pode demorar um pouco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i3yaRNmtxA8"
   },
   "source": [
    "# 5.1 Sentilex: Função gerar score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezhLs9TptxA8"
   },
   "source": [
    "Criando um dicionário com polaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função para montar dicionarios\n",
    "def montar_dicionario(versao_sentilex):\n",
    "    versao = 'Versoes dicionarios sentilex/SentiLex-lem-PT01 editado v' + versao_sentilex + '.txt'\n",
    "    sentilexpt = open(versao,'r',encoding='utf-8-sig')\n",
    "    dic_palavra_polaridade = {}\n",
    "    \n",
    "    for i in sentilexpt.readlines():\n",
    "        pos_ponto = i.find('.')            # obtem a posiçãodo caracter ponto\n",
    "        palavra = (i[:pos_ponto])          # Pega a palavra\n",
    "        pol_pos = i.find('POL')            # obtem a posição do inicio da string POL\n",
    "        polaridade = (i[pol_pos+4:pol_pos+6]).replace(';','')         # obtem a polaridade da palavra\n",
    "        #polaridade = (i[pol_pos+4:pol_pos+7]).replace(';','')\n",
    "        dic_palavra_polaridade[palavra] = polaridade                  # atualiza o dicionario com a palavra a polaridade\n",
    "    \n",
    "    return dic_palavra_polaridade\n",
    "\n",
    "\n",
    "## Funçao para retornar o score do sentimento lendo o dicionario\n",
    "def Score_sentimento(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    l_sentimento = []                         # cria uma lista vazia\n",
    "    for p in frase.split():\n",
    "        l_sentimento.append(int(dic_palavra_polaridade.get(p, 0)))      # para cada palavra obtem a polaridade\n",
    "        #l_sentimento.append(float(dic_palavra_polaridade.get(p, 0)))      # para cada palavra obtem a polaridade     \n",
    "    #print (l_sentimento)                                                # imprime a lista de polaridades\n",
    "    score = sum(l_sentimento)                                           # soma todos os valores da lista\n",
    "    #if score > 0:\n",
    "        #return 'Positivo, Score:{}'.format(score)                       # se maior que 0 retorna 'positivo'\n",
    "    #elif score == 0:\n",
    "        #return 'Neutro, Score:{}'.format(score)                         # se igual a 0 retorna 'neutro'\n",
    "    #else:\n",
    "        #return 'Negativo, Score:{}'.format(score)                       # se menor que 0 retorna 'negativo'\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iniciando as features com a versão original do sentilex\n",
    "sentilexpt = open('Versoes dicionarios sentilex/SentiLex-lem-PT01.txt','r',encoding='utf-8-sig')\n",
    "\n",
    "dic_palavra_polaridade = {}\n",
    "\n",
    "for i in sentilexpt.readlines():\n",
    "    pos_ponto = i.find('.')            # obtem a posiçãodo caracter ponto\n",
    "    palavra = (i[:pos_ponto])          # Pega a palavra\n",
    "    pol_pos = i.find('POL')            # obtem a posição do inicio da string POL\n",
    "    polaridade = (i[pol_pos+4:pol_pos+6]).replace(';','')         # obtem a polaridade da palavra\n",
    "    #polaridade = (i[pol_pos+4:pol_pos+7]).replace(';','')\n",
    "    dic_palavra_polaridade[palavra] = polaridade                  # atualiza o dicionario com a palavra a polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fv9M4WICtxA8",
    "outputId": "bef80ee4-e766-4549-f3af-9c7a9f67e863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print (dic_palavra_polaridade.get('legal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1bu0NHstxA8",
    "outputId": "dcaad2b7-a107-409d-f9b3-1c3de8b623ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (dic_palavra_polaridade.get('milhão'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0   2020-01-02      20.47  37774500  0.02           1   \n",
       "1   2020-01-03      20.30  71595600 -0.01           0   \n",
       "2   2020-01-06      20.54  81844000  0.01           1   \n",
       "3   2020-01-07      20.46  32822000 -0.00           0   \n",
       "5   2020-01-09      20.27  36102700 -0.00           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "614 2022-06-24      26.29  53413400 -0.01           0   \n",
       "615 2022-06-27      27.98  90417700  0.06           1   \n",
       "616 2022-06-28      28.33  51388000  0.01           1   \n",
       "617 2022-06-29      28.08  52048800 -0.01           0   \n",
       "618 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  score  \n",
       "0     petrobras e vale retiram seus funcionários de...      0  \n",
       "1     petrobras reduz preços do diesel e da gasolin...      0  \n",
       "2      petrobras faz redução em produção de petróle...      0  \n",
       "3     o adeus da petrobras ao amazonas petrobras vê...      0  \n",
       "5     refinarias da petrobras apresentam queda na c...      0  \n",
       "..                                                 ...    ...  \n",
       "614   comitê de elegibilidade da petrobras dá aval ...      0  \n",
       "615    caio andrade nega recomendação do governo pa...     -1  \n",
       "616   petrobras: novo presidente não conseguirá mud...      0  \n",
       "617   paes de andrade falta à primeira reunião do c...      0  \n",
       "618   caio paes de andrade: como um dos investidore...      1  \n",
       "\n",
       "[543 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['score'] = df_final['Noticias'].apply(lambda x: Score_sentimento(x))\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-ZBNEQvtxBA"
   },
   "source": [
    "# 5.2 Tradução noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihm0MrX6txBA"
   },
   "source": [
    "### Função de tradução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "n_JrD_9ztxBA"
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "sgAl7nNctxBA"
   },
   "outputs": [],
   "source": [
    "trans = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "UOkd9ViutxBB",
    "outputId": "c27cf561-3ade-4c87-b3b1-9ef8615360d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O livro está sobre a mesa'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.translate(\"The book is on the table\", dest = 'pt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "5Q3o2yuhtxBB"
   },
   "outputs": [],
   "source": [
    "def traduzir(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    frase = trans.translate(frase, dest = 'en').text\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "D5-586dPtxBB",
    "outputId": "0d231644-1a2e-483f-864d-b0d7caa8ca57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the food is very good'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_teste = traduzir(\"A comida está muito boa\")\n",
    "frase_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Noticia_traduzida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras and vale withdraw their employees fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduces diesel and gasoline prices a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras makes reduction in oil production an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras goodbye to amazons petrobras sees mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras refineries show a drop in global oil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras eligibility committee approves caio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>caio andrade denies government recommendation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras: new president will not be able to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade misses first meeting of petrob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "      <td>1</td>\n",
       "      <td>caio paes de andrade: how one of the pioneer i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0   2020-01-02      20.47  37774500  0.02           1   \n",
       "1   2020-01-03      20.30  71595600 -0.01           0   \n",
       "2   2020-01-06      20.54  81844000  0.01           1   \n",
       "3   2020-01-07      20.46  32822000 -0.00           0   \n",
       "5   2020-01-09      20.27  36102700 -0.00           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "614 2022-06-24      26.29  53413400 -0.01           0   \n",
       "615 2022-06-27      27.98  90417700  0.06           1   \n",
       "616 2022-06-28      28.33  51388000  0.01           1   \n",
       "617 2022-06-29      28.08  52048800 -0.01           0   \n",
       "618 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  score  \\\n",
       "0     petrobras e vale retiram seus funcionários de...      0   \n",
       "1     petrobras reduz preços do diesel e da gasolin...      0   \n",
       "2      petrobras faz redução em produção de petróle...      0   \n",
       "3     o adeus da petrobras ao amazonas petrobras vê...      0   \n",
       "5     refinarias da petrobras apresentam queda na c...      0   \n",
       "..                                                 ...    ...   \n",
       "614   comitê de elegibilidade da petrobras dá aval ...      0   \n",
       "615    caio andrade nega recomendação do governo pa...     -1   \n",
       "616   petrobras: novo presidente não conseguirá mud...      0   \n",
       "617   paes de andrade falta à primeira reunião do c...      0   \n",
       "618   caio paes de andrade: como um dos investidore...      1   \n",
       "\n",
       "                                     Noticia_traduzida  \n",
       "0    petrobras and vale withdraw their employees fr...  \n",
       "1    petrobras reduces diesel and gasoline prices a...  \n",
       "2    petrobras makes reduction in oil production an...  \n",
       "3    petrobras goodbye to amazons petrobras sees mo...  \n",
       "5    Petrobras refineries show a drop in global oil...  \n",
       "..                                                 ...  \n",
       "614  petrobras eligibility committee approves caio ...  \n",
       "615  caio andrade denies government recommendation ...  \n",
       "616  petrobras: new president will not be able to c...  \n",
       "617  paes de andrade misses first meeting of petrob...  \n",
       "618  caio paes de andrade: how one of the pioneer i...  \n",
       "\n",
       "[543 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Noticia_traduzida'] = df_final['Noticias'].apply(lambda x: traduzir(x))\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tradução alternativa\n",
    "#df_final3.reset_index(inplace=True)\n",
    "#df_final3.drop(['index'], axis = 1, inplace = True) \n",
    "\n",
    "#import time\n",
    "#for i in range(0, len(df_final3['Noticias'])):\n",
    "    #if len(df_final3['Noticias'][i])>0:\n",
    "        #df_final3['Noticias'][i] = trans.translate(df_final3['Noticias'][i]).text\n",
    "        #time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyDzxQC_txBB"
   },
   "source": [
    "## 5.3 Vader Sentiment: Função gerar scores Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "nWxkNchHtxBB"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tce6lphBtxBB",
    "outputId": "82c3d5b1-23c7-47c8-b535-c7573bf5a12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9099999999999999, 0.7800000000000001)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_blob = TextBlob(frase_teste)\n",
    "polaridade = text_blob.polarity\n",
    "subjetividade = text_blob.subjectivity\n",
    "\n",
    "polaridade, subjetividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Zn-wpQcqtxBB"
   },
   "outputs": [],
   "source": [
    "def polaridade(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    text_blob = TextBlob(frase)\n",
    "    polaridade = text_blob.polarity\n",
    "    return polaridade\n",
    "\n",
    "def subjetividade(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    text_blob = TextBlob(frase)\n",
    "    subjetividade = text_blob.subjectivity\n",
    "    return subjetividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "nYfnakqpAITT",
    "outputId": "73141681-7cda-4773-acae-29b822377804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polaridade(\"tudo ótimo e perfeito\"), subjetividade(\"tudo ótimo e perfeito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "WPbBBMeZtxBC"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "bXU8Nf1ktxBC"
   },
   "outputs": [],
   "source": [
    "s_analyze = SentimentIntensityAnalyzer()\n",
    "sentiment= s_analyze.polarity_scores(frase_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5t7ivdWgtxBC",
    "outputId": "e4620508-0ad1-4e22-dfd1-03abc916b794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4927}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lvj5-fJ8txBC",
    "outputId": "f94c3ab1-b49d-4a5f-8378-da63cfe07f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentiment)\n",
    "sentiment.get('neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "RQVdEAPetxBD"
   },
   "outputs": [],
   "source": [
    "def negatividade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('neg')\n",
    "    return sentimento\n",
    "\n",
    "def neutralidade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('neu')\n",
    "    return sentimento\n",
    "\n",
    "def positividade(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('pos')\n",
    "    return sentimento\n",
    "\n",
    "def composicao(frase):\n",
    "    frase = frase.lower()                   # coloca toda a frase em minusculo\n",
    "    s_analyze = SentimentIntensityAnalyzer()\n",
    "    sentiment= s_analyze.polarity_scores(frase)                 \n",
    "    sentimento = sentiment.get('compound')\n",
    "    return sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "mvEc40ERAITW",
    "outputId": "3fcd148b-d884-4fea-9bc9-9102958755e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negatividade(\"tudo ótimo e perfeito\"), neutralidade(\"tudo ótimo e perfeito\"), positividade(\"tudo ótimo e perfeito\"), composicao(\"tudo ótimo e perfeito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['polaridade_vad'] = df_final['Noticia_traduzida'].apply(lambda x: polaridade(str(x)))\n",
    "df_final['subjetividade_vad'] = df_final['Noticia_traduzida'].apply(lambda x: subjetividade(str(x)))\n",
    "df_final['negatividade_vad'] = df_final['Noticia_traduzida'].apply(lambda x: negatividade(str(x)))\n",
    "df_final['neutralidade_vad'] = df_final['Noticia_traduzida'].apply(lambda x: neutralidade(str(x)))\n",
    "df_final['positividade_vad'] = df_final['Noticia_traduzida'].apply(lambda x: positividade(str(x)))\n",
    "df_final['composicao_vad'] = df_final['Noticia_traduzida'].apply(lambda x: composicao(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVhYASlKtxBE"
   },
   "source": [
    "# 5.4 roBERTa: Função gerar score roBERTa\n",
    "https://www.kaggle.com/code/robikscube/sentiment-analysis-python-youtube-tutorial/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "pclifcQWtxBE"
   },
   "outputs": [],
   "source": [
    "#pip install –upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "q_2Kp02dtxBE"
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "OT6JnpdGtxBE"
   },
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "cSTZ9XirtxBF"
   },
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Qn5DtpJ5txBF"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "7ZGjAaOQtxBF"
   },
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "i5mrA8KgtxBF"
   },
   "outputs": [],
   "source": [
    "example = \"This oatmeal is not good. Its mushy, soft, I don't like it. Quaker Oats is the way to go.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "2jDr_YC5txBF"
   },
   "outputs": [],
   "source": [
    "def neg_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    neg_roberta = scores[0]\n",
    "   # neu_roberta = scores[1]\n",
    "   # pos_roberta = scores[2]\n",
    "    return neg_roberta\n",
    "\n",
    "def neu_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    #neg_roberta = scores[0]\n",
    "    neu_roberta = scores[1]\n",
    "    #pos_roberta = scores[2]\n",
    "    return neu_roberta\n",
    "\n",
    "def pos_rob(frase):\n",
    "    #trunca a frase para 514 caracteres (máximo suportado pelo modelo de Roberta)\n",
    "    frase = frase[:514]\n",
    "    \n",
    "    encoded_text = tokenizer(frase, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    #neg_roberta = scores[0]\n",
    "    #neu_roberta = scores[1]\n",
    "    pos_roberta = scores[2]\n",
    "    return pos_roberta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "3L7sGROztxBG",
    "outputId": "add70375-05b5-4e85-991b-295855300596"
   },
   "outputs": [],
   "source": [
    "df_final['neg_rob'] = df_final['Noticia_traduzida'].apply(lambda x: neg_rob(str(x)))\n",
    "df_final['neu_rob'] = df_final['Noticia_traduzida'].apply(lambda x: neu_rob(str(x)))\n",
    "df_final['pos_rob'] = df_final['Noticia_traduzida'].apply(lambda x: pos_rob(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 finBERT: Função gerar score finBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Negative', 'score': 0.9966173768043518}]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"there is a shortage of capital, and we need extra financing\"]\n",
    "results = nlp(sentences)\n",
    "print(results)  #LABEL_0: neutral; LABEL_1: positive; LABEL_2: negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Negative', 'score': 0.9918428659439087}]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"cool facinanting loss\"]\n",
    "results = nlp(sentences)\n",
    "print(results)  #LABEL_0: neutral; LABEL_1: positive; LABEL_2: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimento_finbert_pos(string):\n",
    "    results = nlp([string])\n",
    "    dict_results = results[0]\n",
    "    sentimento = dict_results.get('label')\n",
    "    \n",
    "    if sentimento == \"Positive\":\n",
    "        score = dict_results.get('score')\n",
    "    else:\n",
    "        score = 0\n",
    "        \n",
    "    return score\n",
    "\n",
    "def sentimento_finbert_neg(string):\n",
    "    results = nlp([string])\n",
    "    dict_results = results[0]\n",
    "    sentimento = dict_results.get('label')\n",
    "    \n",
    "    if sentimento == \"Negative\":\n",
    "        score = -1*dict_results.get('score')\n",
    "    else:\n",
    "        score = 0\n",
    "        \n",
    "    return score\n",
    "\n",
    "def sentimento_finbert_neu(string):\n",
    "    results = nlp([string])\n",
    "    dict_results = results[0]\n",
    "    sentimento = dict_results.get('label')\n",
    "    \n",
    "    if sentimento == \"Neutral\":\n",
    "        score = dict_results.get('score')\n",
    "    else:\n",
    "        score = 0        \n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9966173768043518"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimento_finbert_neg(\"there is a shortage of capital, and we need extra financing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['pos_finbert'] = df_final['Noticia_traduzida'].apply(lambda x: sentimento_finbert_pos(x))\n",
    "df_final['neg_finbert'] = df_final['Noticia_traduzida'].apply(lambda x: sentimento_finbert_neg(x))\n",
    "df_final['neu_finbert'] = df_final['Noticia_traduzida'].apply(lambda x: sentimento_finbert_neu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Noticia_traduzida</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>negatividade_vad</th>\n",
       "      <th>neutralidade_vad</th>\n",
       "      <th>positividade_vad</th>\n",
       "      <th>composicao_vad</th>\n",
       "      <th>neg_rob</th>\n",
       "      <th>neu_rob</th>\n",
       "      <th>pos_rob</th>\n",
       "      <th>pos_finbert</th>\n",
       "      <th>neg_finbert</th>\n",
       "      <th>neu_finbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras and vale withdraw their employees fr...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduces diesel and gasoline prices a...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras makes reduction in oil production an...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras goodbye to amazons petrobras sees mo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras refineries show a drop in global oil...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras eligibility committee approves caio ...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>caio andrade denies government recommendation ...</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras: new president will not be able to c...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade misses first meeting of petrob...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "      <td>1</td>\n",
       "      <td>caio paes de andrade: how one of the pioneer i...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0   2020-01-02      20.47  37774500  0.02           1   \n",
       "1   2020-01-03      20.30  71595600 -0.01           0   \n",
       "2   2020-01-06      20.54  81844000  0.01           1   \n",
       "3   2020-01-07      20.46  32822000 -0.00           0   \n",
       "5   2020-01-09      20.27  36102700 -0.00           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "614 2022-06-24      26.29  53413400 -0.01           0   \n",
       "615 2022-06-27      27.98  90417700  0.06           1   \n",
       "616 2022-06-28      28.33  51388000  0.01           1   \n",
       "617 2022-06-29      28.08  52048800 -0.01           0   \n",
       "618 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  score  \\\n",
       "0     petrobras e vale retiram seus funcionários de...      0   \n",
       "1     petrobras reduz preços do diesel e da gasolin...      0   \n",
       "2      petrobras faz redução em produção de petróle...      0   \n",
       "3     o adeus da petrobras ao amazonas petrobras vê...      0   \n",
       "5     refinarias da petrobras apresentam queda na c...      0   \n",
       "..                                                 ...    ...   \n",
       "614   comitê de elegibilidade da petrobras dá aval ...      0   \n",
       "615    caio andrade nega recomendação do governo pa...     -1   \n",
       "616   petrobras: novo presidente não conseguirá mud...      0   \n",
       "617   paes de andrade falta à primeira reunião do c...      0   \n",
       "618   caio paes de andrade: como um dos investidore...      1   \n",
       "\n",
       "                                     Noticia_traduzida  polaridade_vad  \\\n",
       "0    petrobras and vale withdraw their employees fr...            0.00   \n",
       "1    petrobras reduces diesel and gasoline prices a...            0.00   \n",
       "2    petrobras makes reduction in oil production an...            0.00   \n",
       "3    petrobras goodbye to amazons petrobras sees mo...            0.50   \n",
       "5    Petrobras refineries show a drop in global oil...            0.00   \n",
       "..                                                 ...             ...   \n",
       "614  petrobras eligibility committee approves caio ...            0.07   \n",
       "615  caio andrade denies government recommendation ...           -0.04   \n",
       "616  petrobras: new president will not be able to c...            0.17   \n",
       "617  paes de andrade misses first meeting of petrob...            0.14   \n",
       "618  caio paes de andrade: how one of the pioneer i...            0.07   \n",
       "\n",
       "     subjetividade_vad  negatividade_vad  neutralidade_vad  positividade_vad  \\\n",
       "0                 0.00              0.09              0.92              0.00   \n",
       "1                 0.00              0.00              1.00              0.00   \n",
       "2                 0.00              0.04              0.93              0.04   \n",
       "3                 0.50              0.03              0.97              0.00   \n",
       "5                 0.12              0.15              0.85              0.00   \n",
       "..                 ...               ...               ...               ...   \n",
       "614               0.36              0.05              0.83              0.12   \n",
       "615               0.32              0.10              0.88              0.03   \n",
       "616               0.41              0.06              0.92              0.02   \n",
       "617               0.39              0.04              0.83              0.13   \n",
       "618               0.25              0.01              0.94              0.04   \n",
       "\n",
       "     composicao_vad  neg_rob  neu_rob  pos_rob  pos_finbert  neg_finbert  \\\n",
       "0             -0.38     0.72     0.27     0.01         0.00        -1.00   \n",
       "1              0.00     0.13     0.78     0.09         1.00         0.00   \n",
       "2              0.00     0.08     0.85     0.07         0.00         0.00   \n",
       "3             -0.03     0.03     0.80     0.17         0.00         0.00   \n",
       "5             -0.27     0.29     0.68     0.03         0.00        -1.00   \n",
       "..              ...      ...      ...      ...          ...          ...   \n",
       "614            0.69     0.24     0.69     0.07         0.00         0.00   \n",
       "615           -0.97     0.61     0.38     0.01         0.00         0.00   \n",
       "616           -0.40     0.31     0.65     0.04         0.00         0.00   \n",
       "617            0.88     0.41     0.57     0.03         0.00         0.00   \n",
       "618            0.48     0.24     0.73     0.03         0.00         0.00   \n",
       "\n",
       "     neu_finbert  \n",
       "0           0.00  \n",
       "1           0.00  \n",
       "2           1.00  \n",
       "3           0.93  \n",
       "5           0.00  \n",
       "..           ...  \n",
       "614         1.00  \n",
       "615         1.00  \n",
       "616         0.99  \n",
       "617         1.00  \n",
       "618         1.00  \n",
       "\n",
       "[543 rows x 20 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.to_csv('Alldata_with_features.csv',index=False)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O75FlnxLAITx"
   },
   "source": [
    "# 6.0 Pré-processamento 2.0 - Adição do conjunto de features de dias anteriores\n",
    "\n",
    "\n",
    "### ATENÇÃO: As seções 5, 6 e 7 Foram automatizadas e otimizadas na seção 8. Rodar os códigos das seções 5, 6 e 7 pode demorar um pouco\n",
    "\n",
    "adicionaremos as features de n dias anteriores para avaliar a performance da classificação\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "FCmdkcaeAITx",
    "outputId": "6b85b3ae-21fc-412e-cef4-0da52c6cde18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias',\n",
       "       'score', 'Noticia_traduzida', 'polaridade_vad', 'subjetividade_vad',\n",
       "       'negatividade_vad', 'neutralidade_vad', 'positividade_vad',\n",
       "       'composicao_vad', 'neg_rob', 'neu_rob', 'pos_rob', 'pos_finbert',\n",
       "       'neg_finbert', 'neu_finbert'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99 = df_final.copy()\n",
    "df_final99.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "oZ1r5DIMAITy"
   },
   "outputs": [],
   "source": [
    "features = ['polaridade_vad', 'subjetividade_vad', 'negatividade_vad', 'neutralidade_vad', 'positividade_vad',\n",
    "       'composicao_vad','score', 'neg_rob','neu_rob','pos_rob','pos_finbert', 'neg_finbert', 'neu_finbert']\n",
    "featuresd1 = [i + \"d1\" for i in features]\n",
    "featuresd2 = [i + \"d2\" for i in features]\n",
    "featuresd3 = [i + \"d3\" for i in features]\n",
    "featuresd4 = [i + \"d4\" for i in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "AR_3LlklAITy",
    "outputId": "ee004028-1eca-4bbd-fba8-5c4eb53b0794"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Noticia_traduzida</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_finbertd3</th>\n",
       "      <th>pos_finbertd4</th>\n",
       "      <th>neg_finbertd1</th>\n",
       "      <th>neg_finbertd2</th>\n",
       "      <th>neg_finbertd3</th>\n",
       "      <th>neg_finbertd4</th>\n",
       "      <th>neu_finbertd1</th>\n",
       "      <th>neu_finbertd2</th>\n",
       "      <th>neu_finbertd3</th>\n",
       "      <th>neu_finbertd4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras and vale withdraw their employees fr...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduces diesel and gasoline prices a...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras makes reduction in oil production an...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras goodbye to amazons petrobras sees mo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras refineries show a drop in global oil...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0 2020-01-02      20.47  37774500  0.02           1   \n",
       "1 2020-01-03      20.30  71595600 -0.01           0   \n",
       "2 2020-01-06      20.54  81844000  0.01           1   \n",
       "3 2020-01-07      20.46  32822000 -0.00           0   \n",
       "5 2020-01-09      20.27  36102700 -0.00           0   \n",
       "\n",
       "                                            Noticias  score  \\\n",
       "0   petrobras e vale retiram seus funcionários de...      0   \n",
       "1   petrobras reduz preços do diesel e da gasolin...      0   \n",
       "2    petrobras faz redução em produção de petróle...      0   \n",
       "3   o adeus da petrobras ao amazonas petrobras vê...      0   \n",
       "5   refinarias da petrobras apresentam queda na c...      0   \n",
       "\n",
       "                                   Noticia_traduzida  polaridade_vad  \\\n",
       "0  petrobras and vale withdraw their employees fr...            0.00   \n",
       "1  petrobras reduces diesel and gasoline prices a...            0.00   \n",
       "2  petrobras makes reduction in oil production an...            0.00   \n",
       "3  petrobras goodbye to amazons petrobras sees mo...            0.50   \n",
       "5  Petrobras refineries show a drop in global oil...            0.00   \n",
       "\n",
       "   subjetividade_vad  ...  pos_finbertd3  pos_finbertd4  neg_finbertd1  \\\n",
       "0               0.00  ...              0              0              0   \n",
       "1               0.00  ...              0              0              0   \n",
       "2               0.00  ...              0              0              0   \n",
       "3               0.50  ...              0              0              0   \n",
       "5               0.12  ...              0              0              0   \n",
       "\n",
       "   neg_finbertd2  neg_finbertd3  neg_finbertd4  neu_finbertd1  neu_finbertd2  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "5              0              0              0              0              0   \n",
       "\n",
       "   neu_finbertd3  neu_finbertd4  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "5              0              0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando as colunas de features para d-1, d-2, d-3, d-4 e inicializando com valores zeros:\n",
    "for i in features:\n",
    "    df_final99[i+\"d1\"] = 0\n",
    "    df_final99[i+\"d2\"] = 0\n",
    "    df_final99[i+\"d3\"] = 0\n",
    "    df_final99[i+\"d4\"] = 0\n",
    "df_final99.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "YuZYCBXrAITy",
    "outputId": "9f957afc-fb49-4c6e-8df8-bf6d5af22347"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>score</th>\n",
       "      <th>scored4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  score  scored4\n",
       "0   2020-01-02      0        0\n",
       "1   2020-01-03      0        0\n",
       "2   2020-01-06      0        0\n",
       "3   2020-01-07      0        0\n",
       "5   2020-01-09      0        0\n",
       "..         ...    ...      ...\n",
       "614 2022-06-24      0        0\n",
       "615 2022-06-27     -1        0\n",
       "616 2022-06-28      0        0\n",
       "617 2022-06-29      0        0\n",
       "618 2022-06-30      1        0\n",
       "\n",
       "[543 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99[['Date','score','scored4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "KScTKSyaAITy"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#atualiza as features de d-1\n",
    "for a,b in itertools.zip_longest(features,featuresd1):\n",
    "    df_final99[b] = df_final99.shift(periods=1)[a]\n",
    "    \n",
    "#atualiza as features de d-2\n",
    "for a,b in itertools.zip_longest(features,featuresd2):\n",
    "    df_final99[b] = df_final99.shift(periods=2)[a]\n",
    "    \n",
    "#atualiza as features de d-3\n",
    "for a,b in itertools.zip_longest(features,featuresd3):\n",
    "    df_final99[b] = df_final99.shift(periods=3)[a]\n",
    "    \n",
    "#atualiza as features de d-4\n",
    "for a,b in itertools.zip_longest(features,featuresd4):\n",
    "    df_final99[b] = df_final99.shift(periods=4)[a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "MSEgSA1EAITz",
    "outputId": "f46743ac-2f66-4c77-bd5c-fd967cdd01b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>score</th>\n",
       "      <th>scored4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  score  scored4\n",
       "0   2020-01-02      0      nan\n",
       "1   2020-01-03      0      nan\n",
       "2   2020-01-06      0      nan\n",
       "3   2020-01-07      0      nan\n",
       "5   2020-01-09      0     0.00\n",
       "..         ...    ...      ...\n",
       "614 2022-06-24      0    -1.00\n",
       "615 2022-06-27     -1     2.00\n",
       "616 2022-06-28      0    -1.00\n",
       "617 2022-06-29      0     0.00\n",
       "618 2022-06-30      1     0.00\n",
       "\n",
       "[543 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99[['Date','score','scored4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "vaXzCaOFAITz",
    "outputId": "5dcffc2d-ed51-4b97-d6ea-12ccb565bc67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Adj Close        0\n",
       "Volume           0\n",
       "Var%             0\n",
       "Fechamento       0\n",
       "                ..\n",
       "neg_finbertd4    4\n",
       "neu_finbertd1    1\n",
       "neu_finbertd2    2\n",
       "neu_finbertd3    3\n",
       "neu_finbertd4    4\n",
       "Length: 72, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "V0pE3_pkAITz",
    "outputId": "d983f169-3cb3-4cb0-f3be-32c400942286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0\n",
       "Adj Close        0\n",
       "Volume           0\n",
       "Var%             0\n",
       "Fechamento       0\n",
       "                ..\n",
       "neg_finbertd4    0\n",
       "neu_finbertd1    0\n",
       "neu_finbertd2    0\n",
       "neu_finbertd3    0\n",
       "neu_finbertd4    0\n",
       "Length: 72, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Eliminação dos registros sem as features de dias anteriores (os primeiros 4 dias)\n",
    "df_final99 = df_final99.dropna()\n",
    "df_final99.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "PkroruFJAIT0",
    "outputId": "af40dad6-b37a-4e87-a041-6c452986b7a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Adj Close', 'Volume', 'Var%', 'Fechamento', 'Noticias',\n",
       "       'score', 'Noticia_traduzida', 'polaridade_vad', 'subjetividade_vad',\n",
       "       'negatividade_vad', 'neutralidade_vad', 'positividade_vad',\n",
       "       'composicao_vad', 'neg_rob', 'neu_rob', 'pos_rob', 'pos_finbert',\n",
       "       'neg_finbert', 'neu_finbert', 'polaridade_vadd1', 'polaridade_vadd2',\n",
       "       'polaridade_vadd3', 'polaridade_vadd4', 'subjetividade_vadd1',\n",
       "       'subjetividade_vadd2', 'subjetividade_vadd3', 'subjetividade_vadd4',\n",
       "       'negatividade_vadd1', 'negatividade_vadd2', 'negatividade_vadd3',\n",
       "       'negatividade_vadd4', 'neutralidade_vadd1', 'neutralidade_vadd2',\n",
       "       'neutralidade_vadd3', 'neutralidade_vadd4', 'positividade_vadd1',\n",
       "       'positividade_vadd2', 'positividade_vadd3', 'positividade_vadd4',\n",
       "       'composicao_vadd1', 'composicao_vadd2', 'composicao_vadd3',\n",
       "       'composicao_vadd4', 'scored1', 'scored2', 'scored3', 'scored4',\n",
       "       'neg_robd1', 'neg_robd2', 'neg_robd3', 'neg_robd4', 'neu_robd1',\n",
       "       'neu_robd2', 'neu_robd3', 'neu_robd4', 'pos_robd1', 'pos_robd2',\n",
       "       'pos_robd3', 'pos_robd4', 'pos_finbertd1', 'pos_finbertd2',\n",
       "       'pos_finbertd3', 'pos_finbertd4', 'neg_finbertd1', 'neg_finbertd2',\n",
       "       'neg_finbertd3', 'neg_finbertd4', 'neu_finbertd1', 'neu_finbertd2',\n",
       "       'neu_finbertd3', 'neu_finbertd4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Noticia_traduzida</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_finbertd3</th>\n",
       "      <th>pos_finbertd4</th>\n",
       "      <th>neg_finbertd1</th>\n",
       "      <th>neg_finbertd2</th>\n",
       "      <th>neg_finbertd3</th>\n",
       "      <th>neg_finbertd4</th>\n",
       "      <th>neu_finbertd1</th>\n",
       "      <th>neu_finbertd2</th>\n",
       "      <th>neu_finbertd3</th>\n",
       "      <th>neu_finbertd4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras refineries show a drop in global oil...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>20.18</td>\n",
       "      <td>25397500</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras pode criar subsidiárias para vender...</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras may create subsidiaries to sell 8 re...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>20.22</td>\n",
       "      <td>30676800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>quase fechada a venda de refinaria da petrob...</td>\n",
       "      <td>1</td>\n",
       "      <td>the sale of petrobras refinery in bahia almost...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>20.00</td>\n",
       "      <td>39796500</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>fábrica de fertilizantes da petrobras no para...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras fertilizer plant in paraná closes do...</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>19.70</td>\n",
       "      <td>34405700</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras vende ativos na nigéria e encerra a...</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras sells assets in nigeria and closes a...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras eligibility committee approves caio ...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>caio andrade denies government recommendation ...</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras: new president will not be able to c...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade misses first meeting of petrob...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "      <td>1</td>\n",
       "      <td>caio paes de andrade: how one of the pioneer i...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "5   2020-01-09      20.27  36102700 -0.00           0   \n",
       "6   2020-01-10      20.18  25397500 -0.00           0   \n",
       "7   2020-01-13      20.22  30676800  0.00           1   \n",
       "8   2020-01-14      20.00  39796500 -0.01           0   \n",
       "9   2020-01-15      19.70  34405700 -0.02           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "614 2022-06-24      26.29  53413400 -0.01           0   \n",
       "615 2022-06-27      27.98  90417700  0.06           1   \n",
       "616 2022-06-28      28.33  51388000  0.01           1   \n",
       "617 2022-06-29      28.08  52048800 -0.01           0   \n",
       "618 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  score  \\\n",
       "5     refinarias da petrobras apresentam queda na c...      0   \n",
       "6     petrobras pode criar subsidiárias para vender...      1   \n",
       "7      quase fechada a venda de refinaria da petrob...      1   \n",
       "8     fábrica de fertilizantes da petrobras no para...      0   \n",
       "9     petrobras vende ativos na nigéria e encerra a...      1   \n",
       "..                                                 ...    ...   \n",
       "614   comitê de elegibilidade da petrobras dá aval ...      0   \n",
       "615    caio andrade nega recomendação do governo pa...     -1   \n",
       "616   petrobras: novo presidente não conseguirá mud...      0   \n",
       "617   paes de andrade falta à primeira reunião do c...      0   \n",
       "618   caio paes de andrade: como um dos investidore...      1   \n",
       "\n",
       "                                     Noticia_traduzida  polaridade_vad  \\\n",
       "5    Petrobras refineries show a drop in global oil...            0.00   \n",
       "6    petrobras may create subsidiaries to sell 8 re...            0.00   \n",
       "7    the sale of petrobras refinery in bahia almost...            0.05   \n",
       "8    petrobras fertilizer plant in paraná closes do...           -0.15   \n",
       "9    petrobras sells assets in nigeria and closes a...           -0.16   \n",
       "..                                                 ...             ...   \n",
       "614  petrobras eligibility committee approves caio ...            0.07   \n",
       "615  caio andrade denies government recommendation ...           -0.04   \n",
       "616  petrobras: new president will not be able to c...            0.17   \n",
       "617  paes de andrade misses first meeting of petrob...            0.14   \n",
       "618  caio paes de andrade: how one of the pioneer i...            0.07   \n",
       "\n",
       "     subjetividade_vad  ...  pos_finbertd3  pos_finbertd4  neg_finbertd1  \\\n",
       "5                 0.12  ...           1.00           0.00           0.00   \n",
       "6                 0.00  ...           0.00           1.00          -1.00   \n",
       "7                 0.25  ...           0.00           0.00           0.00   \n",
       "8                 0.53  ...           0.00           0.00           0.00   \n",
       "9                 0.29  ...           0.00           0.00           0.00   \n",
       "..                 ...  ...            ...            ...            ...   \n",
       "614               0.36  ...           0.00           0.00           0.00   \n",
       "615               0.32  ...           0.00           0.00           0.00   \n",
       "616               0.41  ...           0.00           0.00           0.00   \n",
       "617               0.39  ...           0.00           0.00           0.00   \n",
       "618               0.25  ...           0.00           0.00           0.00   \n",
       "\n",
       "     neg_finbertd2  neg_finbertd3  neg_finbertd4  neu_finbertd1  \\\n",
       "5             0.00           0.00          -1.00           0.93   \n",
       "6             0.00           0.00           0.00           0.00   \n",
       "7            -1.00           0.00           0.00           1.00   \n",
       "8             0.00          -1.00           0.00           0.00   \n",
       "9             0.00           0.00          -1.00           1.00   \n",
       "..             ...            ...            ...            ...   \n",
       "614           0.00           0.00           0.00           1.00   \n",
       "615           0.00           0.00           0.00           1.00   \n",
       "616           0.00           0.00           0.00           1.00   \n",
       "617           0.00           0.00           0.00           0.99   \n",
       "618           0.00           0.00           0.00           1.00   \n",
       "\n",
       "     neu_finbertd2  neu_finbertd3  neu_finbertd4  \n",
       "5             1.00           0.00           0.00  \n",
       "6             0.93           1.00           0.00  \n",
       "7             0.00           0.93           1.00  \n",
       "8             1.00           0.00           0.93  \n",
       "9             0.00           1.00           0.00  \n",
       "..             ...            ...            ...  \n",
       "614           1.00           0.97           0.55  \n",
       "615           1.00           1.00           0.97  \n",
       "616           1.00           1.00           1.00  \n",
       "617           1.00           1.00           1.00  \n",
       "618           0.99           1.00           1.00  \n",
       "\n",
       "[539 rows x 72 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Amostragem\n",
    "\n",
    "### ATENÇÃO: As seções 5, 6 e 7 Foram automatizadas e otimizadas na seção 8. Rodar os códigos das seções 5, 6 e 7 pode demorar um pouco\n",
    "\n",
    "## 7.1 Separação entre Treino+Validação / Teste\n",
    "\n",
    "- Dados de 2020 e 2021: Treino + Validação - Separados para treinar e selecionar melhores hyperparametros do modelo\n",
    "- Dados de 2022: Teste - Servirá como teste final dos algoritmos prevendo um cenário futuro (2022) com dados nunca vistos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022-01-03T00:00:00.000000000', '2022-01-04T00:00:00.000000000',\n",
       "       '2022-01-05T00:00:00.000000000', '2022-01-06T00:00:00.000000000',\n",
       "       '2022-01-10T00:00:00.000000000', '2022-01-13T00:00:00.000000000',\n",
       "       '2022-01-14T00:00:00.000000000', '2022-01-17T00:00:00.000000000',\n",
       "       '2022-01-19T00:00:00.000000000', '2022-01-20T00:00:00.000000000',\n",
       "       '2022-01-21T00:00:00.000000000', '2022-01-24T00:00:00.000000000',\n",
       "       '2022-01-25T00:00:00.000000000', '2022-01-26T00:00:00.000000000',\n",
       "       '2022-01-27T00:00:00.000000000', '2022-01-28T00:00:00.000000000',\n",
       "       '2022-01-31T00:00:00.000000000', '2022-02-01T00:00:00.000000000',\n",
       "       '2022-02-02T00:00:00.000000000', '2022-02-03T00:00:00.000000000',\n",
       "       '2022-02-04T00:00:00.000000000', '2022-02-07T00:00:00.000000000',\n",
       "       '2022-02-14T00:00:00.000000000', '2022-02-15T00:00:00.000000000',\n",
       "       '2022-02-16T00:00:00.000000000', '2022-02-17T00:00:00.000000000',\n",
       "       '2022-02-18T00:00:00.000000000', '2022-02-21T00:00:00.000000000',\n",
       "       '2022-02-24T00:00:00.000000000', '2022-02-25T00:00:00.000000000',\n",
       "       '2022-03-02T00:00:00.000000000', '2022-03-03T00:00:00.000000000',\n",
       "       '2022-03-04T00:00:00.000000000', '2022-03-07T00:00:00.000000000',\n",
       "       '2022-03-14T00:00:00.000000000', '2022-03-15T00:00:00.000000000',\n",
       "       '2022-03-16T00:00:00.000000000', '2022-03-17T00:00:00.000000000',\n",
       "       '2022-03-18T00:00:00.000000000', '2022-03-21T00:00:00.000000000',\n",
       "       '2022-03-23T00:00:00.000000000', '2022-03-24T00:00:00.000000000',\n",
       "       '2022-03-25T00:00:00.000000000', '2022-03-28T00:00:00.000000000',\n",
       "       '2022-03-29T00:00:00.000000000', '2022-03-30T00:00:00.000000000',\n",
       "       '2022-03-31T00:00:00.000000000', '2022-04-01T00:00:00.000000000',\n",
       "       '2022-04-04T00:00:00.000000000', '2022-04-05T00:00:00.000000000',\n",
       "       '2022-04-06T00:00:00.000000000', '2022-04-11T00:00:00.000000000',\n",
       "       '2022-04-13T00:00:00.000000000', '2022-04-14T00:00:00.000000000',\n",
       "       '2022-04-18T00:00:00.000000000', '2022-04-20T00:00:00.000000000',\n",
       "       '2022-04-22T00:00:00.000000000', '2022-04-25T00:00:00.000000000',\n",
       "       '2022-04-26T00:00:00.000000000', '2022-04-27T00:00:00.000000000',\n",
       "       '2022-04-28T00:00:00.000000000', '2022-04-29T00:00:00.000000000',\n",
       "       '2022-05-02T00:00:00.000000000', '2022-05-03T00:00:00.000000000',\n",
       "       '2022-05-04T00:00:00.000000000', '2022-05-05T00:00:00.000000000',\n",
       "       '2022-05-06T00:00:00.000000000', '2022-05-09T00:00:00.000000000',\n",
       "       '2022-05-13T00:00:00.000000000', '2022-05-16T00:00:00.000000000',\n",
       "       '2022-05-17T00:00:00.000000000', '2022-05-18T00:00:00.000000000',\n",
       "       '2022-05-19T00:00:00.000000000', '2022-05-20T00:00:00.000000000',\n",
       "       '2022-05-23T00:00:00.000000000', '2022-05-24T00:00:00.000000000',\n",
       "       '2022-05-25T00:00:00.000000000', '2022-05-26T00:00:00.000000000',\n",
       "       '2022-05-27T00:00:00.000000000', '2022-05-30T00:00:00.000000000',\n",
       "       '2022-05-31T00:00:00.000000000', '2022-06-01T00:00:00.000000000',\n",
       "       '2022-06-06T00:00:00.000000000', '2022-06-13T00:00:00.000000000',\n",
       "       '2022-06-14T00:00:00.000000000', '2022-06-15T00:00:00.000000000',\n",
       "       '2022-06-17T00:00:00.000000000', '2022-06-20T00:00:00.000000000',\n",
       "       '2022-06-21T00:00:00.000000000', '2022-06-22T00:00:00.000000000',\n",
       "       '2022-06-23T00:00:00.000000000', '2022-06-24T00:00:00.000000000',\n",
       "       '2022-06-27T00:00:00.000000000', '2022-06-28T00:00:00.000000000',\n",
       "       '2022-06-29T00:00:00.000000000', '2022-06-30T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "df_treino_valid = df_final99[(df_final99['Date'] <= parser.parse('2021-12-31'))]\n",
    "df_test = df_final99[(df_final99['Date'] > parser.parse('2021-12-31'))]\n",
    "\n",
    "X_test = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_test = df_test['Fechamento']\n",
    "\n",
    "df_test.Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x23c49486eb0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Fechamento\",\n",
    "                data=df_test,\n",
    "                kind=\"count\", height=3.5, aspect=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Separação entre Treino/Validação - Amostragem Sistemática\n",
    "- De forma que ambas amostras representem equitativamente e proporcionalmente todo o espaço temporal (Jan de 2020 á Dez 2021), portanto, realizaremos amostragem sistemática definindo um intervalo dependente da proporção treino/validação desejada.\n",
    "\n",
    "Para proporção de 33% validação e 66% treino o intervalo para amostragem é de 3 ( para representar todo o espaço temporal )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_validacao = np.arange(0,len(df_treino_valid),3)\n",
    "indices_validacao_lista = indices_validacao.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria array com todos os indexes\n",
    "indices_train = np.arange(0,len(df_treino_valid),1)\n",
    "indices_train_lista = indices_train.tolist()\n",
    "\n",
    "# seleciona os indexes que nao estejam na validacao\n",
    "indices_train_lista = [ i for i in indices_train_lista if i not in indices_validacao_lista]\n",
    "\n",
    "#transforma para array\n",
    "indices_train = np.array(indices_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x23c06317d60>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 201.6x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train =  df_treino_valid.iloc[indices_train]\n",
    "X_train = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_train = df_train['Fechamento']\n",
    "\n",
    "df_valid = df_treino_valid.iloc[indices_validacao]\n",
    "X_valid = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_valid = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "sns.catplot(x=\"Fechamento\",\n",
    "                data=df_train,\n",
    "                kind=\"count\", height=3.5, aspect=.8)\n",
    "\n",
    "sns.catplot(x=\"Fechamento\",\n",
    "                data=df_valid,\n",
    "                kind=\"count\", height=3.5, aspect=.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3340857787810384"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_valid)/len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Consolidação dos dados de diversas versões do sentilex (repetição e automação das etapas 5, 6, e 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Função para montar dicionarios\n",
    "def montar_dicionario(versao_sentilex):\n",
    "    versao = 'Versoes dicionarios sentilex/SentiLex-lem-PT01 editado v' + versao_sentilex + '.txt'\n",
    "    sentilexpt = open(versao,'r',encoding='utf-8-sig')\n",
    "    dic_palavra_polaridade = {}\n",
    "    \n",
    "    for i in sentilexpt.readlines():\n",
    "        pos_ponto = i.find('.')            # obtem a posiçãodo caracter ponto\n",
    "        palavra = (i[:pos_ponto])          # Pega a palavra\n",
    "        pol_pos = i.find('POL')            # obtem a posição do inicio da string POL\n",
    "        polaridade = (i[pol_pos+4:pol_pos+6]).replace(';','')         # obtem a polaridade da palavra\n",
    "        #polaridade = (i[pol_pos+4:pol_pos+7]).replace(';','')\n",
    "        dic_palavra_polaridade[palavra] = polaridade                  # atualiza o dicionario com a palavra a polaridade\n",
    "    \n",
    "    return dic_palavra_polaridade\n",
    "\n",
    "\n",
    "## Funçao para retornar o score do sentimento lendo o dicionario\n",
    "def Score_sentimento(frase):\n",
    "    frase = frase.lower()                     # coloca toda a frase em minusculo\n",
    "    l_sentimento = []                         # cria uma lista vazia\n",
    "    for p in frase.split():\n",
    "        l_sentimento.append(int(dic_palavra_polaridade.get(p, 0)))      # para cada palavra obtem a polaridade\n",
    "        #l_sentimento.append(float(dic_palavra_polaridade.get(p, 0)))      # para cada palavra obtem a polaridade     \n",
    "    #print (l_sentimento)                                                # imprime a lista de polaridades\n",
    "    score = sum(l_sentimento)                                           # soma todos os valores da lista\n",
    "    #if score > 0:\n",
    "        #return 'Positivo, Score:{}'.format(score)                       # se maior que 0 retorna 'positivo'\n",
    "    #elif score == 0:\n",
    "        #return 'Neutro, Score:{}'.format(score)                         # se igual a 0 retorna 'neutro'\n",
    "    #else:\n",
    "        #return 'Negativo, Score:{}'.format(score)                       # se menor que 0 retorna 'negativo'\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>Noticias</th>\n",
       "      <th>score</th>\n",
       "      <th>Noticia_traduzida</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>negatividade_vad</th>\n",
       "      <th>neutralidade_vad</th>\n",
       "      <th>positividade_vad</th>\n",
       "      <th>composicao_vad</th>\n",
       "      <th>neg_rob</th>\n",
       "      <th>neu_rob</th>\n",
       "      <th>pos_rob</th>\n",
       "      <th>pos_finbert</th>\n",
       "      <th>neg_finbert</th>\n",
       "      <th>neu_finbert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>20.47</td>\n",
       "      <td>37774500</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras e vale retiram seus funcionários de...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras and vale withdraw their employees fr...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>20.30</td>\n",
       "      <td>71595600</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduz preços do diesel e da gasolin...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras reduces diesel and gasoline prices a...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>20.54</td>\n",
       "      <td>81844000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras faz redução em produção de petróle...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras makes reduction in oil production an...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>20.46</td>\n",
       "      <td>32822000</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>o adeus da petrobras ao amazonas petrobras vê...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras goodbye to amazons petrobras sees mo...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>20.27</td>\n",
       "      <td>36102700</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>refinarias da petrobras apresentam queda na c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Petrobras refineries show a drop in global oil...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>26.29</td>\n",
       "      <td>53413400</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>comitê de elegibilidade da petrobras dá aval ...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras eligibility committee approves caio ...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>27.98</td>\n",
       "      <td>90417700</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>caio andrade nega recomendação do governo pa...</td>\n",
       "      <td>-1</td>\n",
       "      <td>caio andrade denies government recommendation ...</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>28.33</td>\n",
       "      <td>51388000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>petrobras: novo presidente não conseguirá mud...</td>\n",
       "      <td>0</td>\n",
       "      <td>petrobras: new president will not be able to c...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>28.08</td>\n",
       "      <td>52048800</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade falta à primeira reunião do c...</td>\n",
       "      <td>0</td>\n",
       "      <td>paes de andrade misses first meeting of petrob...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>27.93</td>\n",
       "      <td>49910100</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>caio paes de andrade: como um dos investidore...</td>\n",
       "      <td>1</td>\n",
       "      <td>caio paes de andrade: how one of the pioneer i...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Adj Close    Volume  Var%  Fechamento  \\\n",
       "0   2020-01-02      20.47  37774500  0.02           1   \n",
       "1   2020-01-03      20.30  71595600 -0.01           0   \n",
       "2   2020-01-06      20.54  81844000  0.01           1   \n",
       "3   2020-01-07      20.46  32822000 -0.00           0   \n",
       "4   2020-01-09      20.27  36102700 -0.00           0   \n",
       "..         ...        ...       ...   ...         ...   \n",
       "538 2022-06-24      26.29  53413400 -0.01           0   \n",
       "539 2022-06-27      27.98  90417700  0.06           1   \n",
       "540 2022-06-28      28.33  51388000  0.01           1   \n",
       "541 2022-06-29      28.08  52048800 -0.01           0   \n",
       "542 2022-06-30      27.93  49910100 -0.01           0   \n",
       "\n",
       "                                              Noticias  score  \\\n",
       "0     petrobras e vale retiram seus funcionários de...      0   \n",
       "1     petrobras reduz preços do diesel e da gasolin...      0   \n",
       "2      petrobras faz redução em produção de petróle...      0   \n",
       "3     o adeus da petrobras ao amazonas petrobras vê...      0   \n",
       "4     refinarias da petrobras apresentam queda na c...      0   \n",
       "..                                                 ...    ...   \n",
       "538   comitê de elegibilidade da petrobras dá aval ...      0   \n",
       "539    caio andrade nega recomendação do governo pa...     -1   \n",
       "540   petrobras: novo presidente não conseguirá mud...      0   \n",
       "541   paes de andrade falta à primeira reunião do c...      0   \n",
       "542   caio paes de andrade: como um dos investidore...      1   \n",
       "\n",
       "                                     Noticia_traduzida  polaridade_vad  \\\n",
       "0    petrobras and vale withdraw their employees fr...            0.00   \n",
       "1    petrobras reduces diesel and gasoline prices a...            0.00   \n",
       "2    petrobras makes reduction in oil production an...            0.00   \n",
       "3    petrobras goodbye to amazons petrobras sees mo...            0.50   \n",
       "4    Petrobras refineries show a drop in global oil...            0.00   \n",
       "..                                                 ...             ...   \n",
       "538  petrobras eligibility committee approves caio ...            0.07   \n",
       "539  caio andrade denies government recommendation ...           -0.04   \n",
       "540  petrobras: new president will not be able to c...            0.17   \n",
       "541  paes de andrade misses first meeting of petrob...            0.14   \n",
       "542  caio paes de andrade: how one of the pioneer i...            0.07   \n",
       "\n",
       "     subjetividade_vad  negatividade_vad  neutralidade_vad  positividade_vad  \\\n",
       "0                 0.00              0.09              0.92              0.00   \n",
       "1                 0.00              0.00              1.00              0.00   \n",
       "2                 0.00              0.04              0.93              0.04   \n",
       "3                 0.50              0.03              0.97              0.00   \n",
       "4                 0.12              0.15              0.85              0.00   \n",
       "..                 ...               ...               ...               ...   \n",
       "538               0.36              0.05              0.83              0.12   \n",
       "539               0.32              0.10              0.88              0.03   \n",
       "540               0.41              0.06              0.92              0.02   \n",
       "541               0.39              0.04              0.83              0.13   \n",
       "542               0.25              0.01              0.94              0.04   \n",
       "\n",
       "     composicao_vad  neg_rob  neu_rob  pos_rob  pos_finbert  neg_finbert  \\\n",
       "0             -0.38     0.72     0.27     0.01         0.00        -1.00   \n",
       "1              0.00     0.13     0.78     0.09         1.00         0.00   \n",
       "2              0.00     0.08     0.85     0.07         0.00         0.00   \n",
       "3             -0.03     0.03     0.80     0.17         0.00         0.00   \n",
       "4             -0.27     0.29     0.68     0.03         0.00        -1.00   \n",
       "..              ...      ...      ...      ...          ...          ...   \n",
       "538            0.69     0.24     0.69     0.07         0.00         0.00   \n",
       "539           -0.97     0.61     0.38     0.01         0.00         0.00   \n",
       "540           -0.40     0.31     0.65     0.04         0.00         0.00   \n",
       "541            0.88     0.41     0.57     0.03         0.00         0.00   \n",
       "542            0.48     0.24     0.73     0.03         0.00         0.00   \n",
       "\n",
       "     neu_finbert  \n",
       "0           0.00  \n",
       "1           0.00  \n",
       "2           1.00  \n",
       "3           0.93  \n",
       "4           0.00  \n",
       "..           ...  \n",
       "538         1.00  \n",
       "539         1.00  \n",
       "540         0.99  \n",
       "541         1.00  \n",
       "542         1.00  \n",
       "\n",
       "[543 rows x 20 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.read_csv('Alldata_with_features.csv', sep=',')\n",
    "df_final['Date'] = pd.to_datetime(df_final['Date'])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "dict_dados_variacoes_sentilex = {}\n",
    "\n",
    "correlacoes = []\n",
    "\n",
    "for versao in versoes_sentilex:\n",
    "    \n",
    "    #print(versao)\n",
    "    ## Atualizando Score Sentilex (Etapa 5.1)\n",
    "    dic_palavra_polaridade  = montar_dicionario(versao)\n",
    "\n",
    "    ### Copia o df atualiza o score do dicionário recém-lido\n",
    "    df_final99 = df_final.copy()\n",
    "    \n",
    "    df_final99['score'] = df_final99['Noticias'].apply(lambda x: Score_sentimento(str(x)))\n",
    "    \n",
    "    ### Criação de novas features combinadas\n",
    "    #df_final99['pos_combinada'] = (df_final99['positividade_vad'] * df_final99['pos_rob'] * df_final99['pos_finbert'])**1/2\n",
    "    #df_final99['neg_combinada'] = (df_final99['negatividade_vad'] * df_final99['neg_rob'] * df_final99['neg_finbert'])**1/2\n",
    "    #df_final99['neu_combinada'] = (df_final99['neutralidade_vad'] * df_final99['neu_rob'] * df_final99['neu_finbert'])**1/2\n",
    "    \n",
    "    \n",
    "    #pesos_aleatorios = np.random.random(3).tolist()\n",
    "    #pesos_aleatorios\n",
    "    \n",
    "    #df_final99['pos_teste'] = 3* df_final99['positividade_vad'] + 2* df_final99['pos_rob'] + 1*df_final99['pos_finbert']\n",
    "    #df_final99['neg_teste'] = 2* df_final99['negatividade_vad'] + 3* df_final99['neg_rob'] + 1*df_final99['neg_finbert']\n",
    "    #df_final99['neu_teste'] = 1* df_final99['neutralidade_vad'] + 3* df_final99['neu_rob'] + 2* df_final99['neu_finbert']\n",
    "        \n",
    "    #corr_pos = df_final99.corr().iloc[20, 3]\n",
    "    #corr_neg = df_final99.corr().iloc[21, 3]\n",
    "    #corr_neu = df_final99.corr().iloc[22, 3]\n",
    "    \n",
    "    #correlacoes.append(np.array([corr_pos,corr_neg,corr_neu,pesos_aleatorios[0],pesos_aleatorios[1],pesos_aleatorios[2]]))\n",
    "    \n",
    "    #df_final99['pos_teste'] = 3* df_final99['positividade_vad'] + 2* df_final99['pos_rob'] + 1*df_final99['pos_finbert']\n",
    "    #df_final99['neg_teste'] = 2* df_final99['negatividade_vad'] + 3* df_final99['neg_rob'] + 1*df_final99['neg_finbert']\n",
    "    #df_final99['neu_teste'] = 1* df_final99['neutralidade_vad'] + 3* df_final99['neu_rob'] + 2* df_final99['neu_finbert']\n",
    "    \n",
    "    \n",
    "    features = ['polaridade_vad', 'subjetividade_vad', 'negatividade_vad', 'neutralidade_vad', 'positividade_vad',\n",
    "    'composicao_vad','score', 'neg_rob','neu_rob','pos_rob','pos_finbert', 'neg_finbert', 'neu_finbert']\n",
    "    \n",
    "    #features = ['polaridade_vad', 'subjetividade_vad', 'negatividade_vad', 'neutralidade_vad', 'positividade_vad', 'composicao_vad','score', 'neg_rob','neu_rob','pos_rob','pos_finbert', 'neg_finbert', 'neu_finbert','pos_combinada','neg_combinada','neu_combinada']\n",
    "    \n",
    "    featuresd1 = [i + \"d1\" for i in features]\n",
    "    featuresd2 = [i + \"d2\" for i in features]\n",
    "    featuresd3 = [i + \"d3\" for i in features]\n",
    "    featuresd4 = [i + \"d4\" for i in features]\n",
    "\n",
    "\n",
    "    #Criando as colunas de features para d-1, d-2, d-3, d-4 e inicializando com valores zeros:\n",
    "    for i in features:\n",
    "        df_final99[i+\"d1\"] = 0\n",
    "        df_final99[i+\"d2\"] = 0\n",
    "        df_final99[i+\"d3\"] = 0\n",
    "        df_final99[i+\"d4\"] = 0\n",
    "\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    #atualiza as features de d-1\n",
    "    for a,b in itertools.zip_longest(features,featuresd1):\n",
    "        df_final99[b] = df_final99.shift(periods=1)[a]\n",
    "\n",
    "    #atualiza as features de d-2\n",
    "    for a,b in itertools.zip_longest(features,featuresd2):\n",
    "        df_final99[b] = df_final99.shift(periods=2)[a]\n",
    "\n",
    "    #atualiza as features de d-3\n",
    "    for a,b in itertools.zip_longest(features,featuresd3):\n",
    "        df_final99[b] = df_final99.shift(periods=3)[a]\n",
    "\n",
    "    #atualiza as features de d-4\n",
    "    for a,b in itertools.zip_longest(features,featuresd4):\n",
    "        df_final99[b] = df_final99.shift(periods=4)[a]\n",
    "\n",
    "\n",
    "    df_final99 = df_final99.dropna()\n",
    "\n",
    "\n",
    "    ## Aplicando mesma reamostragem\n",
    "\n",
    "    from dateutil import parser\n",
    "    df_treino_valid = df_final99[(df_final99['Date'] <= parser.parse('2021-12-31'))]\n",
    "    df_test = df_final99[(df_final99['Date'] > parser.parse('2021-12-31'))]\n",
    "    #df_test.Date.unique()\n",
    "\n",
    "    indices_validacao = np.arange(0,len(df_treino_valid),3)\n",
    "    indices_validacao_lista = indices_validacao.tolist()\n",
    "\n",
    "    #cria array com todos os indexes\n",
    "    indices_train = np.arange(0,len(df_treino_valid),1)\n",
    "    indices_train_lista = indices_train.tolist()\n",
    "\n",
    "    # seleciona os indexes que nao estejam na validacao para compor o treino\n",
    "    indices_train_lista = [ i for i in indices_train_lista if i not in indices_validacao_lista]\n",
    "    \n",
    "    #transforma para array\n",
    "    indices_train = np.array(indices_train_lista)\n",
    "\n",
    "    # Redefinindo os datasets\n",
    "    df_train =  df_treino_valid.iloc[indices_train]                 \n",
    "                   \n",
    "    df_valid = df_treino_valid.iloc[indices_validacao]\n",
    "                      \n",
    "    \n",
    "    dict_dados_variacoes_sentilex[versao] = [df_train,df_valid,df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Etapa adicional: Feature Engineering (gerando featurs a partir da combinação linear de todas as features)\n",
    "\n",
    "- Método: Combinação linear aleatoria entre 3 features avaliando a correlação da combinação Vs correlação das variáveis únicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>score</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>negatividade_vad</th>\n",
       "      <th>neutralidade_vad</th>\n",
       "      <th>positividade_vad</th>\n",
       "      <th>...</th>\n",
       "      <th>neu_finbertd1</th>\n",
       "      <th>neu_finbertd2</th>\n",
       "      <th>neu_finbertd3</th>\n",
       "      <th>neu_finbertd4</th>\n",
       "      <th>comp1</th>\n",
       "      <th>comp2</th>\n",
       "      <th>comp3</th>\n",
       "      <th>comp4</th>\n",
       "      <th>comp5</th>\n",
       "      <th>comp6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fechamento</th>\n",
       "      <td>0.047850</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030747</td>\n",
       "      <td>-0.017941</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>-0.092427</td>\n",
       "      <td>0.041607</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069374</td>\n",
       "      <td>0.088502</td>\n",
       "      <td>-0.036006</td>\n",
       "      <td>0.037677</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.009281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var%</th>\n",
       "      <td>0.033939</td>\n",
       "      <td>-0.109499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>-0.074497</td>\n",
       "      <td>-0.054027</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>-0.082030</td>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>0.101303</td>\n",
       "      <td>-0.047854</td>\n",
       "      <td>-0.013726</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>-0.007576</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.023101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_robd4</th>\n",
       "      <td>-0.011097</td>\n",
       "      <td>-0.053229</td>\n",
       "      <td>0.041370</td>\n",
       "      <td>0.130432</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.076603</td>\n",
       "      <td>-0.073941</td>\n",
       "      <td>-0.005832</td>\n",
       "      <td>0.073018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008935</td>\n",
       "      <td>0.019234</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>0.337176</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.031389</td>\n",
       "      <td>0.060561</td>\n",
       "      <td>0.038218</td>\n",
       "      <td>0.055628</td>\n",
       "      <td>0.028335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_finbertd2</th>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.132745</td>\n",
       "      <td>0.102643</td>\n",
       "      <td>-0.034427</td>\n",
       "      <td>-0.077227</td>\n",
       "      <td>0.029947</td>\n",
       "      <td>-0.015075</td>\n",
       "      <td>0.040299</td>\n",
       "      <td>-0.035912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.660453</td>\n",
       "      <td>0.031825</td>\n",
       "      <td>-0.060754</td>\n",
       "      <td>-0.014272</td>\n",
       "      <td>-0.022017</td>\n",
       "      <td>-0.061211</td>\n",
       "      <td>-0.038871</td>\n",
       "      <td>-0.052653</td>\n",
       "      <td>-0.023846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_finbertd2</th>\n",
       "      <td>0.071998</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.101303</td>\n",
       "      <td>0.088502</td>\n",
       "      <td>-0.026562</td>\n",
       "      <td>-0.040469</td>\n",
       "      <td>0.039032</td>\n",
       "      <td>-0.024178</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>-0.002075</td>\n",
       "      <td>-0.003647</td>\n",
       "      <td>-0.003723</td>\n",
       "      <td>-0.024306</td>\n",
       "      <td>-0.017968</td>\n",
       "      <td>-0.018715</td>\n",
       "      <td>-0.008749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Adj Close    Volume      Var%  Fechamento     score  \\\n",
       "Fechamento      0.047850 -0.008048  0.617627    1.000000 -0.030747   \n",
       "Var%            0.033939 -0.109499  1.000000    0.617627 -0.074497   \n",
       "neu_robd4      -0.011097 -0.053229  0.041370    0.130432  0.036869   \n",
       "neg_finbertd2   0.054598  0.000976  0.132745    0.102643 -0.034427   \n",
       "neu_finbertd2   0.071998 -0.074277  0.101303    0.088502 -0.026562   \n",
       "\n",
       "               polaridade_vad  subjetividade_vad  negatividade_vad  \\\n",
       "Fechamento          -0.017941           0.040600         -0.092427   \n",
       "Var%                -0.054027           0.012711         -0.082030   \n",
       "neu_robd4            0.060605           0.076603         -0.073941   \n",
       "neg_finbertd2       -0.077227           0.029947         -0.015075   \n",
       "neu_finbertd2       -0.040469           0.039032         -0.024178   \n",
       "\n",
       "               neutralidade_vad  positividade_vad  ...  neu_finbertd1  \\\n",
       "Fechamento             0.041607          0.031688  ...       0.069374   \n",
       "Var%                   0.038650          0.025910  ...      -0.003385   \n",
       "neu_robd4             -0.005832          0.073018  ...      -0.008935   \n",
       "neg_finbertd2          0.040299         -0.035912  ...       0.079468   \n",
       "neu_finbertd2         -0.000466          0.022137  ...       0.061769   \n",
       "\n",
       "               neu_finbertd2  neu_finbertd3  neu_finbertd4     comp1  \\\n",
       "Fechamento          0.088502      -0.036006       0.037677  0.011842   \n",
       "Var%                0.101303      -0.047854      -0.013726  0.030702   \n",
       "neu_robd4           0.019234       0.036225       0.337176  0.021040   \n",
       "neg_finbertd2       0.660453       0.031825      -0.060754 -0.014272   \n",
       "neu_finbertd2       1.000000       0.051695      -0.002075 -0.003647   \n",
       "\n",
       "                  comp2     comp3     comp4     comp5     comp6  \n",
       "Fechamento     0.013758  0.001498  0.003597  0.005725  0.009281  \n",
       "Var%           0.029692 -0.007576  0.008149  0.003430  0.023101  \n",
       "neu_robd4      0.031389  0.060561  0.038218  0.055628  0.028335  \n",
       "neg_finbertd2 -0.022017 -0.061211 -0.038871 -0.052653 -0.023846  \n",
       "neu_finbertd2 -0.003723 -0.024306 -0.017968 -0.018715 -0.008749  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final99.corr().sort_values(by = 'Fechamento', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n",
      "6726\n",
      "6727\n",
      "6728\n",
      "6729\n",
      "6730\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6734\n",
      "6735\n",
      "6736\n",
      "6737\n",
      "6738\n",
      "6739\n",
      "6740\n",
      "6741\n",
      "6742\n",
      "6743\n",
      "6744\n",
      "6745\n",
      "6746\n",
      "6747\n",
      "6748\n",
      "6749\n",
      "6750\n",
      "6751\n",
      "6752\n",
      "6753\n",
      "6754\n",
      "6755\n",
      "6756\n",
      "6757\n",
      "6758\n",
      "6759\n",
      "6760\n",
      "6761\n",
      "6762\n",
      "6763\n",
      "6764\n",
      "6765\n",
      "6766\n",
      "6767\n",
      "6768\n",
      "6769\n",
      "6770\n",
      "6771\n",
      "6772\n",
      "6773\n",
      "6774\n",
      "6775\n",
      "6776\n",
      "6777\n",
      "6778\n",
      "6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6780\n",
      "6781\n",
      "6782\n",
      "6783\n",
      "6784\n",
      "6785\n",
      "6786\n",
      "6787\n",
      "6788\n",
      "6789\n",
      "6790\n",
      "6791\n",
      "6792\n",
      "6793\n",
      "6794\n",
      "6795\n",
      "6796\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6800\n",
      "6801\n",
      "6802\n",
      "6803\n",
      "6804\n",
      "6805\n",
      "6806\n",
      "6807\n",
      "6808\n",
      "6809\n",
      "6810\n",
      "6811\n",
      "6812\n",
      "6813\n",
      "6814\n",
      "6815\n",
      "6816\n",
      "6817\n",
      "6818\n",
      "6819\n",
      "6820\n",
      "6821\n",
      "6822\n",
      "6823\n",
      "6824\n",
      "6825\n",
      "6826\n",
      "6827\n",
      "6828\n",
      "6829\n",
      "6830\n",
      "6831\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6835\n",
      "6836\n",
      "6837\n",
      "6838\n",
      "6839\n",
      "6840\n",
      "6841\n",
      "6842\n",
      "6843\n",
      "6844\n",
      "6845\n",
      "6846\n",
      "6847\n",
      "6848\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6852\n",
      "6853\n",
      "6854\n",
      "6855\n",
      "6856\n",
      "6857\n",
      "6858\n",
      "6859\n",
      "6860\n",
      "6861\n",
      "6862\n",
      "6863\n",
      "6864\n",
      "6865\n",
      "6866\n",
      "6867\n",
      "6868\n",
      "6869\n",
      "6870\n",
      "6871\n",
      "6872\n",
      "6873\n",
      "6874\n",
      "6875\n",
      "6876\n",
      "6877\n",
      "6878\n",
      "6879\n",
      "6880\n",
      "6881\n",
      "6882\n",
      "6883\n",
      "6884\n",
      "6885\n",
      "6886\n",
      "6887\n",
      "6888\n",
      "6889\n",
      "6890\n",
      "6891\n",
      "6892\n",
      "6893\n",
      "6894\n",
      "6895\n",
      "6896\n",
      "6897\n",
      "6898\n",
      "6899\n",
      "6900\n",
      "6901\n",
      "6902\n",
      "6903\n",
      "6904\n",
      "6905\n",
      "6906\n",
      "6907\n",
      "6908\n",
      "6909\n",
      "6910\n",
      "6911\n",
      "6912\n",
      "6913\n",
      "6914\n",
      "6915\n",
      "6916\n",
      "6917\n",
      "6918\n",
      "6919\n",
      "6920\n",
      "6921\n",
      "6922\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6931\n",
      "6932\n",
      "6933\n",
      "6934\n",
      "6935\n",
      "6936\n",
      "6937\n",
      "6938\n",
      "6939\n",
      "6940\n",
      "6941\n",
      "6942\n",
      "6943\n",
      "6944\n",
      "6945\n",
      "6946\n",
      "6947\n",
      "6948\n",
      "6949\n",
      "6950\n",
      "6951\n",
      "6952\n",
      "6953\n",
      "6954\n",
      "6955\n",
      "6956\n",
      "6957\n",
      "6958\n",
      "6959\n",
      "6960\n",
      "6961\n",
      "6962\n",
      "6963\n",
      "6964\n",
      "6965\n",
      "6966\n",
      "6967\n",
      "6968\n",
      "6969\n",
      "6970\n",
      "6971\n",
      "6972\n",
      "6973\n",
      "6974\n",
      "6975\n",
      "6976\n",
      "6977\n",
      "6978\n",
      "6979\n",
      "6980\n",
      "6981\n",
      "6982\n",
      "6983\n",
      "6984\n",
      "6985\n",
      "6986\n",
      "6987\n",
      "6988\n",
      "6989\n",
      "6990\n",
      "6991\n",
      "6992\n",
      "6993\n",
      "6994\n",
      "6995\n",
      "6996\n",
      "6997\n",
      "6998\n",
      "6999\n",
      "7000\n",
      "7001\n",
      "7002\n",
      "7003\n",
      "7004\n",
      "7005\n",
      "7006\n",
      "7007\n",
      "7008\n",
      "7009\n",
      "7010\n",
      "7011\n",
      "7012\n",
      "7013\n",
      "7014\n",
      "7015\n",
      "7016\n",
      "7017\n",
      "7018\n",
      "7019\n",
      "7020\n",
      "7021\n",
      "7022\n",
      "7023\n",
      "7024\n",
      "7025\n",
      "7026\n",
      "7027\n",
      "7028\n",
      "7029\n",
      "7030\n",
      "7031\n",
      "7032\n",
      "7033\n",
      "7034\n",
      "7035\n",
      "7036\n",
      "7037\n",
      "7038\n",
      "7039\n",
      "7040\n",
      "7041\n",
      "7042\n",
      "7043\n",
      "7044\n",
      "7045\n",
      "7046\n",
      "7047\n",
      "7048\n",
      "7049\n",
      "7050\n",
      "7051\n",
      "7052\n",
      "7053\n",
      "7054\n",
      "7055\n",
      "7056\n",
      "7057\n",
      "7058\n",
      "7059\n",
      "7060\n",
      "7061\n",
      "7062\n",
      "7063\n",
      "7064\n",
      "7065\n",
      "7066\n",
      "7067\n",
      "7068\n",
      "7069\n",
      "7070\n",
      "7071\n",
      "7072\n",
      "7073\n",
      "7074\n",
      "7075\n",
      "7076\n",
      "7077\n",
      "7078\n",
      "7079\n",
      "7080\n",
      "7081\n",
      "7082\n",
      "7083\n",
      "7084\n",
      "7085\n",
      "7086\n",
      "7087\n",
      "7088\n",
      "7089\n",
      "7090\n",
      "7091\n",
      "7092\n",
      "7093\n",
      "7094\n",
      "7095\n",
      "7096\n",
      "7097\n",
      "7098\n",
      "7099\n",
      "7100\n",
      "7101\n",
      "7102\n",
      "7103\n",
      "7104\n",
      "7105\n",
      "7106\n",
      "7107\n",
      "7108\n",
      "7109\n",
      "7110\n",
      "7111\n",
      "7112\n",
      "7113\n",
      "7114\n",
      "7115\n",
      "7116\n",
      "7117\n",
      "7118\n",
      "7119\n",
      "7120\n",
      "7121\n",
      "7122\n",
      "7123\n",
      "7124\n",
      "7125\n",
      "7126\n",
      "7127\n",
      "7128\n",
      "7129\n",
      "7130\n",
      "7131\n",
      "7132\n",
      "7133\n",
      "7134\n",
      "7135\n",
      "7136\n",
      "7137\n",
      "7138\n",
      "7139\n",
      "7140\n",
      "7141\n",
      "7142\n",
      "7143\n",
      "7144\n",
      "7145\n",
      "7146\n",
      "7147\n",
      "7148\n",
      "7149\n",
      "7150\n",
      "7151\n",
      "7152\n",
      "7153\n",
      "7154\n",
      "7155\n",
      "7156\n",
      "7157\n",
      "7158\n",
      "7159\n",
      "7160\n",
      "7161\n",
      "7162\n",
      "7163\n",
      "7164\n",
      "7165\n",
      "7166\n",
      "7167\n",
      "7168\n",
      "7169\n",
      "7170\n",
      "7171\n",
      "7172\n",
      "7173\n",
      "7174\n",
      "7175\n",
      "7176\n",
      "7177\n",
      "7178\n",
      "7179\n",
      "7180\n",
      "7181\n",
      "7182\n",
      "7183\n",
      "7184\n",
      "7185\n",
      "7186\n",
      "7187\n",
      "7188\n",
      "7189\n",
      "7190\n",
      "7191\n",
      "7192\n",
      "7193\n",
      "7194\n",
      "7195\n",
      "7196\n",
      "7197\n",
      "7198\n",
      "7199\n",
      "7200\n",
      "7201\n",
      "7202\n",
      "7203\n",
      "7204\n",
      "7205\n",
      "7206\n",
      "7207\n",
      "7208\n",
      "7209\n",
      "7210\n",
      "7211\n",
      "7212\n",
      "7213\n",
      "7214\n",
      "7215\n",
      "7216\n",
      "7217\n",
      "7218\n",
      "7219\n",
      "7220\n",
      "7221\n",
      "7222\n",
      "7223\n",
      "7224\n",
      "7225\n",
      "7226\n",
      "7227\n",
      "7228\n",
      "7229\n",
      "7230\n",
      "7231\n",
      "7232\n",
      "7233\n",
      "7234\n",
      "7235\n",
      "7236\n",
      "7237\n",
      "7238\n",
      "7239\n",
      "7240\n",
      "7241\n",
      "7242\n",
      "7243\n",
      "7244\n",
      "7245\n",
      "7246\n",
      "7247\n",
      "7248\n",
      "7249\n",
      "7250\n",
      "7251\n",
      "7252\n",
      "7253\n",
      "7254\n",
      "7255\n",
      "7256\n",
      "7257\n",
      "7258\n",
      "7259\n",
      "7260\n",
      "7261\n",
      "7262\n",
      "7263\n",
      "7264\n",
      "7265\n",
      "7266\n",
      "7267\n",
      "7268\n",
      "7269\n",
      "7270\n",
      "7271\n",
      "7272\n",
      "7273\n",
      "7274\n",
      "7275\n",
      "7276\n",
      "7277\n",
      "7278\n",
      "7279\n",
      "7280\n",
      "7281\n",
      "7282\n",
      "7283\n",
      "7284\n",
      "7285\n",
      "7286\n",
      "7287\n",
      "7288\n",
      "7289\n",
      "7290\n",
      "7291\n",
      "7292\n",
      "7293\n",
      "7294\n",
      "7295\n",
      "7296\n",
      "7297\n",
      "7298\n",
      "7299\n",
      "7300\n",
      "7301\n",
      "7302\n",
      "7303\n",
      "7304\n",
      "7305\n",
      "7306\n",
      "7307\n",
      "7308\n",
      "7309\n",
      "7310\n",
      "7311\n",
      "7312\n",
      "7313\n",
      "7314\n",
      "7315\n",
      "7316\n",
      "7317\n",
      "7318\n",
      "7319\n",
      "7320\n",
      "7321\n",
      "7322\n",
      "7323\n",
      "7324\n",
      "7325\n",
      "7326\n",
      "7327\n",
      "7328\n",
      "7329\n",
      "7330\n",
      "7331\n",
      "7332\n",
      "7333\n",
      "7334\n",
      "7335\n",
      "7336\n",
      "7337\n",
      "7338\n",
      "7339\n",
      "7340\n",
      "7341\n",
      "7342\n",
      "7343\n",
      "7344\n",
      "7345\n",
      "7346\n",
      "7347\n",
      "7348\n",
      "7349\n",
      "7350\n",
      "7351\n",
      "7352\n",
      "7353\n",
      "7354\n",
      "7355\n",
      "7356\n",
      "7357\n",
      "7358\n",
      "7359\n",
      "7360\n",
      "7361\n",
      "7362\n",
      "7363\n",
      "7364\n",
      "7365\n",
      "7366\n",
      "7367\n",
      "7368\n",
      "7369\n",
      "7370\n",
      "7371\n",
      "7372\n",
      "7373\n",
      "7374\n",
      "7375\n",
      "7376\n",
      "7377\n",
      "7378\n",
      "7379\n",
      "7380\n",
      "7381\n",
      "7382\n",
      "7383\n",
      "7384\n",
      "7385\n",
      "7386\n",
      "7387\n",
      "7388\n",
      "7389\n",
      "7390\n",
      "7391\n",
      "7392\n",
      "7393\n",
      "7394\n",
      "7395\n",
      "7396\n",
      "7397\n",
      "7398\n",
      "7399\n",
      "7400\n",
      "7401\n",
      "7402\n",
      "7403\n",
      "7404\n",
      "7405\n",
      "7406\n",
      "7407\n",
      "7408\n",
      "7409\n",
      "7410\n",
      "7411\n",
      "7412\n",
      "7413\n",
      "7414\n",
      "7415\n",
      "7416\n",
      "7417\n",
      "7418\n",
      "7419\n",
      "7420\n",
      "7421\n",
      "7422\n",
      "7423\n",
      "7424\n",
      "7425\n",
      "7426\n",
      "7427\n",
      "7428\n",
      "7429\n",
      "7430\n",
      "7431\n",
      "7432\n",
      "7433\n",
      "7434\n",
      "7435\n",
      "7436\n",
      "7437\n",
      "7438\n",
      "7439\n",
      "7440\n",
      "7441\n",
      "7442\n",
      "7443\n",
      "7444\n",
      "7445\n",
      "7446\n",
      "7447\n",
      "7448\n",
      "7449\n",
      "7450\n",
      "7451\n",
      "7452\n",
      "7453\n",
      "7454\n",
      "7455\n",
      "7456\n",
      "7457\n",
      "7458\n",
      "7459\n",
      "7460\n",
      "7461\n",
      "7462\n",
      "7463\n",
      "7464\n",
      "7465\n",
      "7466\n",
      "7467\n",
      "7468\n",
      "7469\n",
      "7470\n",
      "7471\n",
      "7472\n",
      "7473\n",
      "7474\n",
      "7475\n",
      "7476\n",
      "7477\n",
      "7478\n",
      "7479\n",
      "7480\n",
      "7481\n",
      "7482\n",
      "7483\n",
      "7484\n",
      "7485\n",
      "7486\n",
      "7487\n",
      "7488\n",
      "7489\n",
      "7490\n",
      "7491\n",
      "7492\n",
      "7493\n",
      "7494\n",
      "7495\n",
      "7496\n",
      "7497\n",
      "7498\n",
      "7499\n",
      "7500\n",
      "7501\n",
      "7502\n",
      "7503\n",
      "7504\n",
      "7505\n",
      "7506\n",
      "7507\n",
      "7508\n",
      "7509\n",
      "7510\n",
      "7511\n",
      "7512\n",
      "7513\n",
      "7514\n",
      "7515\n",
      "7516\n",
      "7517\n",
      "7518\n",
      "7519\n",
      "7520\n",
      "7521\n",
      "7522\n",
      "7523\n",
      "7524\n",
      "7525\n",
      "7526\n",
      "7527\n",
      "7528\n",
      "7529\n",
      "7530\n",
      "7531\n",
      "7532\n",
      "7533\n",
      "7534\n",
      "7535\n",
      "7536\n",
      "7537\n",
      "7538\n",
      "7539\n",
      "7540\n",
      "7541\n",
      "7542\n",
      "7543\n",
      "7544\n",
      "7545\n",
      "7546\n",
      "7547\n",
      "7548\n",
      "7549\n",
      "7550\n",
      "7551\n",
      "7552\n",
      "7553\n",
      "7554\n",
      "7555\n",
      "7556\n",
      "7557\n",
      "7558\n",
      "7559\n",
      "7560\n",
      "7561\n",
      "7562\n",
      "7563\n",
      "7564\n",
      "7565\n",
      "7566\n",
      "7567\n",
      "7568\n",
      "7569\n",
      "7570\n",
      "7571\n",
      "7572\n",
      "7573\n",
      "7574\n",
      "7575\n",
      "7576\n",
      "7577\n",
      "7578\n",
      "7579\n",
      "7580\n",
      "7581\n",
      "7582\n",
      "7583\n",
      "7584\n",
      "7585\n",
      "7586\n",
      "7587\n",
      "7588\n",
      "7589\n",
      "7590\n",
      "7591\n",
      "7592\n",
      "7593\n",
      "7594\n",
      "7595\n",
      "7596\n",
      "7597\n",
      "7598\n",
      "7599\n",
      "7600\n",
      "7601\n",
      "7602\n",
      "7603\n",
      "7604\n",
      "7605\n",
      "7606\n",
      "7607\n",
      "7608\n",
      "7609\n",
      "7610\n",
      "7611\n",
      "7612\n",
      "7613\n",
      "7614\n",
      "7615\n",
      "7616\n",
      "7617\n",
      "7618\n",
      "7619\n",
      "7620\n",
      "7621\n",
      "7622\n",
      "7623\n",
      "7624\n",
      "7625\n",
      "7626\n",
      "7627\n",
      "7628\n",
      "7629\n",
      "7630\n",
      "7631\n",
      "7632\n",
      "7633\n",
      "7634\n",
      "7635\n",
      "7636\n",
      "7637\n",
      "7638\n",
      "7639\n",
      "7640\n",
      "7641\n",
      "7642\n",
      "7643\n",
      "7644\n",
      "7645\n",
      "7646\n",
      "7647\n",
      "7648\n",
      "7649\n",
      "7650\n",
      "7651\n",
      "7652\n",
      "7653\n",
      "7654\n",
      "7655\n",
      "7656\n",
      "7657\n",
      "7658\n",
      "7659\n",
      "7660\n",
      "7661\n",
      "7662\n",
      "7663\n",
      "7664\n",
      "7665\n",
      "7666\n",
      "7667\n",
      "7668\n",
      "7669\n",
      "7670\n",
      "7671\n",
      "7672\n",
      "7673\n",
      "7674\n",
      "7675\n",
      "7676\n",
      "7677\n",
      "7678\n",
      "7679\n",
      "7680\n",
      "7681\n",
      "7682\n",
      "7683\n",
      "7684\n",
      "7685\n",
      "7686\n",
      "7687\n",
      "7688\n",
      "7689\n",
      "7690\n",
      "7691\n",
      "7692\n",
      "7693\n",
      "7694\n",
      "7695\n",
      "7696\n",
      "7697\n",
      "7698\n",
      "7699\n",
      "7700\n",
      "7701\n",
      "7702\n",
      "7703\n",
      "7704\n",
      "7705\n",
      "7706\n",
      "7707\n",
      "7708\n",
      "7709\n",
      "7710\n",
      "7711\n",
      "7712\n",
      "7713\n",
      "7714\n",
      "7715\n",
      "7716\n",
      "7717\n",
      "7718\n",
      "7719\n",
      "7720\n",
      "7721\n",
      "7722\n",
      "7723\n",
      "7724\n",
      "7725\n",
      "7726\n",
      "7727\n",
      "7728\n",
      "7729\n",
      "7730\n",
      "7731\n",
      "7732\n",
      "7733\n",
      "7734\n",
      "7735\n",
      "7736\n",
      "7737\n",
      "7738\n",
      "7739\n",
      "7740\n",
      "7741\n",
      "7742\n",
      "7743\n",
      "7744\n",
      "7745\n",
      "7746\n",
      "7747\n",
      "7748\n",
      "7749\n",
      "7750\n",
      "7751\n",
      "7752\n",
      "7753\n",
      "7754\n",
      "7755\n",
      "7756\n",
      "7757\n",
      "7758\n",
      "7759\n",
      "7760\n",
      "7761\n",
      "7762\n",
      "7763\n",
      "7764\n",
      "7765\n",
      "7766\n",
      "7767\n",
      "7768\n",
      "7769\n",
      "7770\n",
      "7771\n",
      "7772\n",
      "7773\n",
      "7774\n",
      "7775\n",
      "7776\n",
      "7777\n",
      "7778\n",
      "7779\n",
      "7780\n",
      "7781\n",
      "7782\n",
      "7783\n",
      "7784\n",
      "7785\n",
      "7786\n",
      "7787\n",
      "7788\n",
      "7789\n",
      "7790\n",
      "7791\n",
      "7792\n",
      "7793\n",
      "7794\n",
      "7795\n",
      "7796\n",
      "7797\n",
      "7798\n",
      "7799\n",
      "7800\n",
      "7801\n",
      "7802\n",
      "7803\n",
      "7804\n",
      "7805\n",
      "7806\n",
      "7807\n",
      "7808\n",
      "7809\n",
      "7810\n",
      "7811\n",
      "7812\n",
      "7813\n",
      "7814\n",
      "7815\n",
      "7816\n",
      "7817\n",
      "7818\n",
      "7819\n",
      "7820\n",
      "7821\n",
      "7822\n",
      "7823\n",
      "7824\n",
      "7825\n",
      "7826\n",
      "7827\n",
      "7828\n",
      "7829\n",
      "7830\n",
      "7831\n",
      "7832\n",
      "7833\n",
      "7834\n",
      "7835\n",
      "7836\n",
      "7837\n",
      "7838\n",
      "7839\n",
      "7840\n",
      "7841\n",
      "7842\n",
      "7843\n",
      "7844\n",
      "7845\n",
      "7846\n",
      "7847\n",
      "7848\n",
      "7849\n",
      "7850\n",
      "7851\n",
      "7852\n",
      "7853\n",
      "7854\n",
      "7855\n",
      "7856\n",
      "7857\n",
      "7858\n",
      "7859\n",
      "7860\n",
      "7861\n",
      "7862\n",
      "7863\n",
      "7864\n",
      "7865\n",
      "7866\n",
      "7867\n",
      "7868\n",
      "7869\n",
      "7870\n",
      "7871\n",
      "7872\n",
      "7873\n",
      "7874\n",
      "7875\n",
      "7876\n",
      "7877\n",
      "7878\n",
      "7879\n",
      "7880\n",
      "7881\n",
      "7882\n",
      "7883\n",
      "7884\n",
      "7885\n",
      "7886\n",
      "7887\n",
      "7888\n",
      "7889\n",
      "7890\n",
      "7891\n",
      "7892\n",
      "7893\n",
      "7894\n",
      "7895\n",
      "7896\n",
      "7897\n",
      "7898\n",
      "7899\n",
      "7900\n",
      "7901\n",
      "7902\n",
      "7903\n",
      "7904\n",
      "7905\n",
      "7906\n",
      "7907\n",
      "7908\n",
      "7909\n",
      "7910\n",
      "7911\n",
      "7912\n",
      "7913\n",
      "7914\n",
      "7915\n",
      "7916\n",
      "7917\n",
      "7918\n",
      "7919\n",
      "7920\n",
      "7921\n",
      "7922\n",
      "7923\n",
      "7924\n",
      "7925\n",
      "7926\n",
      "7927\n",
      "7928\n",
      "7929\n",
      "7930\n",
      "7931\n",
      "7932\n",
      "7933\n",
      "7934\n",
      "7935\n",
      "7936\n",
      "7937\n",
      "7938\n",
      "7939\n",
      "7940\n",
      "7941\n",
      "7942\n",
      "7943\n",
      "7944\n",
      "7945\n",
      "7946\n",
      "7947\n",
      "7948\n",
      "7949\n",
      "7950\n",
      "7951\n",
      "7952\n",
      "7953\n",
      "7954\n",
      "7955\n",
      "7956\n",
      "7957\n",
      "7958\n",
      "7959\n",
      "7960\n",
      "7961\n",
      "7962\n",
      "7963\n",
      "7964\n",
      "7965\n",
      "7966\n",
      "7967\n",
      "7968\n",
      "7969\n",
      "7970\n",
      "7971\n",
      "7972\n",
      "7973\n",
      "7974\n",
      "7975\n",
      "7976\n",
      "7977\n",
      "7978\n",
      "7979\n",
      "7980\n",
      "7981\n",
      "7982\n",
      "7983\n",
      "7984\n",
      "7985\n",
      "7986\n",
      "7987\n",
      "7988\n",
      "7989\n",
      "7990\n",
      "7991\n",
      "7992\n",
      "7993\n",
      "7994\n",
      "7995\n",
      "7996\n",
      "7997\n",
      "7998\n",
      "7999\n",
      "8000\n",
      "8001\n",
      "8002\n",
      "8003\n",
      "8004\n",
      "8005\n",
      "8006\n",
      "8007\n",
      "8008\n",
      "8009\n",
      "8010\n",
      "8011\n",
      "8012\n",
      "8013\n",
      "8014\n",
      "8015\n",
      "8016\n",
      "8017\n",
      "8018\n",
      "8019\n",
      "8020\n",
      "8021\n",
      "8022\n",
      "8023\n",
      "8024\n",
      "8025\n",
      "8026\n",
      "8027\n",
      "8028\n",
      "8029\n",
      "8030\n",
      "8031\n",
      "8032\n",
      "8033\n",
      "8034\n",
      "8035\n",
      "8036\n",
      "8037\n",
      "8038\n",
      "8039\n",
      "8040\n",
      "8041\n",
      "8042\n",
      "8043\n",
      "8044\n",
      "8045\n",
      "8046\n",
      "8047\n",
      "8048\n",
      "8049\n",
      "8050\n",
      "8051\n",
      "8052\n",
      "8053\n",
      "8054\n",
      "8055\n",
      "8056\n",
      "8057\n",
      "8058\n",
      "8059\n",
      "8060\n",
      "8061\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8065\n",
      "8066\n",
      "8067\n",
      "8068\n",
      "8069\n",
      "8070\n",
      "8071\n",
      "8072\n",
      "8073\n",
      "8074\n",
      "8075\n",
      "8076\n",
      "8077\n",
      "8078\n",
      "8079\n",
      "8080\n",
      "8081\n",
      "8082\n",
      "8083\n",
      "8084\n",
      "8085\n",
      "8086\n",
      "8087\n",
      "8088\n",
      "8089\n",
      "8090\n",
      "8091\n",
      "8092\n",
      "8093\n",
      "8094\n",
      "8095\n",
      "8096\n",
      "8097\n",
      "8098\n",
      "8099\n",
      "8100\n",
      "8101\n",
      "8102\n",
      "8103\n",
      "8104\n",
      "8105\n",
      "8106\n",
      "8107\n",
      "8108\n",
      "8109\n",
      "8110\n",
      "8111\n",
      "8112\n",
      "8113\n",
      "8114\n",
      "8115\n",
      "8116\n",
      "8117\n",
      "8118\n",
      "8119\n",
      "8120\n",
      "8121\n",
      "8122\n",
      "8123\n",
      "8124\n",
      "8125\n",
      "8126\n",
      "8127\n",
      "8128\n",
      "8129\n",
      "8130\n",
      "8131\n",
      "8132\n",
      "8133\n",
      "8134\n",
      "8135\n",
      "8136\n",
      "8137\n",
      "8138\n",
      "8139\n",
      "8140\n",
      "8141\n",
      "8142\n",
      "8143\n",
      "8144\n",
      "8145\n",
      "8146\n",
      "8147\n",
      "8148\n",
      "8149\n",
      "8150\n",
      "8151\n",
      "8152\n",
      "8153\n",
      "8154\n",
      "8155\n",
      "8156\n",
      "8157\n",
      "8158\n",
      "8159\n",
      "8160\n",
      "8161\n",
      "8162\n",
      "8163\n",
      "8164\n",
      "8165\n",
      "8166\n",
      "8167\n",
      "8168\n",
      "8169\n",
      "8170\n",
      "8171\n",
      "8172\n",
      "8173\n",
      "8174\n",
      "8175\n",
      "8176\n",
      "8177\n",
      "8178\n",
      "8179\n",
      "8180\n",
      "8181\n",
      "8182\n",
      "8183\n",
      "8184\n",
      "8185\n",
      "8186\n",
      "8187\n",
      "8188\n",
      "8189\n",
      "8190\n",
      "8191\n",
      "8192\n",
      "8193\n",
      "8194\n",
      "8195\n",
      "8196\n",
      "8197\n",
      "8198\n",
      "8199\n",
      "8200\n",
      "8201\n",
      "8202\n",
      "8203\n",
      "8204\n",
      "8205\n",
      "8206\n",
      "8207\n",
      "8208\n",
      "8209\n",
      "8210\n",
      "8211\n",
      "8212\n",
      "8213\n",
      "8214\n",
      "8215\n",
      "8216\n",
      "8217\n",
      "8218\n",
      "8219\n",
      "8220\n",
      "8221\n",
      "8222\n",
      "8223\n",
      "8224\n",
      "8225\n",
      "8226\n",
      "8227\n",
      "8228\n",
      "8229\n",
      "8230\n",
      "8231\n",
      "8232\n",
      "8233\n",
      "8234\n",
      "8235\n",
      "8236\n",
      "8237\n",
      "8238\n",
      "8239\n",
      "8240\n",
      "8241\n",
      "8242\n",
      "8243\n",
      "8244\n",
      "8245\n",
      "8246\n",
      "8247\n",
      "8248\n",
      "8249\n",
      "8250\n",
      "8251\n",
      "8252\n",
      "8253\n",
      "8254\n",
      "8255\n",
      "8256\n",
      "8257\n",
      "8258\n",
      "8259\n",
      "8260\n",
      "8261\n",
      "8262\n",
      "8263\n",
      "8264\n",
      "8265\n",
      "8266\n",
      "8267\n",
      "8268\n",
      "8269\n",
      "8270\n",
      "8271\n",
      "8272\n",
      "8273\n",
      "8274\n",
      "8275\n",
      "8276\n",
      "8277\n",
      "8278\n",
      "8279\n",
      "8280\n",
      "8281\n",
      "8282\n",
      "8283\n",
      "8284\n",
      "8285\n",
      "8286\n",
      "8287\n",
      "8288\n",
      "8289\n",
      "8290\n",
      "8291\n",
      "8292\n",
      "8293\n",
      "8294\n",
      "8295\n",
      "8296\n",
      "8297\n",
      "8298\n",
      "8299\n",
      "8300\n",
      "8301\n",
      "8302\n",
      "8303\n",
      "8304\n",
      "8305\n",
      "8306\n",
      "8307\n",
      "8308\n",
      "8309\n",
      "8310\n",
      "8311\n",
      "8312\n",
      "8313\n",
      "8314\n",
      "8315\n",
      "8316\n",
      "8317\n",
      "8318\n",
      "8319\n",
      "8320\n",
      "8321\n",
      "8322\n",
      "8323\n",
      "8324\n",
      "8325\n",
      "8326\n",
      "8327\n",
      "8328\n",
      "8329\n",
      "8330\n",
      "8331\n",
      "8332\n",
      "8333\n",
      "8334\n",
      "8335\n",
      "8336\n",
      "8337\n",
      "8338\n",
      "8339\n",
      "8340\n",
      "8341\n",
      "8342\n",
      "8343\n",
      "8344\n",
      "8345\n",
      "8346\n",
      "8347\n",
      "8348\n",
      "8349\n",
      "8350\n",
      "8351\n",
      "8352\n",
      "8353\n",
      "8354\n",
      "8355\n",
      "8356\n",
      "8357\n",
      "8358\n",
      "8359\n",
      "8360\n",
      "8361\n",
      "8362\n",
      "8363\n",
      "8364\n",
      "8365\n",
      "8366\n",
      "8367\n",
      "8368\n",
      "8369\n",
      "8370\n",
      "8371\n",
      "8372\n",
      "8373\n",
      "8374\n",
      "8375\n",
      "8376\n",
      "8377\n",
      "8378\n",
      "8379\n",
      "8380\n",
      "8381\n",
      "8382\n",
      "8383\n",
      "8384\n",
      "8385\n",
      "8386\n",
      "8387\n",
      "8388\n",
      "8389\n",
      "8390\n",
      "8391\n",
      "8392\n",
      "8393\n",
      "8394\n",
      "8395\n",
      "8396\n",
      "8397\n",
      "8398\n",
      "8399\n",
      "8400\n",
      "8401\n",
      "8402\n",
      "8403\n",
      "8404\n",
      "8405\n",
      "8406\n",
      "8407\n",
      "8408\n",
      "8409\n",
      "8410\n",
      "8411\n",
      "8412\n",
      "8413\n",
      "8414\n",
      "8415\n",
      "8416\n",
      "8417\n",
      "8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8419\n",
      "8420\n",
      "8421\n",
      "8422\n",
      "8423\n",
      "8424\n",
      "8425\n",
      "8426\n",
      "8427\n",
      "8428\n",
      "8429\n",
      "8430\n",
      "8431\n",
      "8432\n",
      "8433\n",
      "8434\n",
      "8435\n",
      "8436\n",
      "8437\n",
      "8438\n",
      "8439\n",
      "8440\n",
      "8441\n",
      "8442\n",
      "8443\n",
      "8444\n",
      "8445\n",
      "8446\n",
      "8447\n",
      "8448\n",
      "8449\n",
      "8450\n",
      "8451\n",
      "8452\n",
      "8453\n",
      "8454\n",
      "8455\n",
      "8456\n",
      "8457\n",
      "8458\n",
      "8459\n",
      "8460\n",
      "8461\n",
      "8462\n",
      "8463\n",
      "8464\n",
      "8465\n",
      "8466\n",
      "8467\n",
      "8468\n",
      "8469\n",
      "8470\n",
      "8471\n",
      "8472\n",
      "8473\n",
      "8474\n",
      "8475\n",
      "8476\n",
      "8477\n",
      "8478\n",
      "8479\n",
      "8480\n",
      "8481\n",
      "8482\n",
      "8483\n",
      "8484\n",
      "8485\n",
      "8486\n",
      "8487\n",
      "8488\n",
      "8489\n",
      "8490\n",
      "8491\n",
      "8492\n",
      "8493\n",
      "8494\n",
      "8495\n",
      "8496\n",
      "8497\n",
      "8498\n",
      "8499\n",
      "8500\n",
      "8501\n",
      "8502\n",
      "8503\n",
      "8504\n",
      "8505\n",
      "8506\n",
      "8507\n",
      "8508\n",
      "8509\n",
      "8510\n",
      "8511\n",
      "8512\n",
      "8513\n",
      "8514\n",
      "8515\n",
      "8516\n",
      "8517\n",
      "8518\n",
      "8519\n",
      "8520\n",
      "8521\n",
      "8522\n",
      "8523\n",
      "8524\n",
      "8525\n",
      "8526\n",
      "8527\n",
      "8528\n",
      "8529\n",
      "8530\n",
      "8531\n",
      "8532\n",
      "8533\n",
      "8534\n",
      "8535\n",
      "8536\n",
      "8537\n",
      "8538\n",
      "8539\n",
      "8540\n",
      "8541\n",
      "8542\n",
      "8543\n",
      "8544\n",
      "8545\n",
      "8546\n",
      "8547\n",
      "8548\n",
      "8549\n",
      "8550\n",
      "8551\n",
      "8552\n",
      "8553\n",
      "8554\n",
      "8555\n",
      "8556\n",
      "8557\n",
      "8558\n",
      "8559\n",
      "8560\n",
      "8561\n",
      "8562\n",
      "8563\n",
      "8564\n",
      "8565\n",
      "8566\n",
      "8567\n",
      "8568\n",
      "8569\n",
      "8570\n",
      "8571\n",
      "8572\n",
      "8573\n",
      "8574\n",
      "8575\n",
      "8576\n",
      "8577\n",
      "8578\n",
      "8579\n",
      "8580\n",
      "8581\n",
      "8582\n",
      "8583\n",
      "8584\n",
      "8585\n",
      "8586\n",
      "8587\n",
      "8588\n",
      "8589\n",
      "8590\n",
      "8591\n",
      "8592\n",
      "8593\n",
      "8594\n",
      "8595\n",
      "8596\n",
      "8597\n",
      "8598\n",
      "8599\n",
      "8600\n",
      "8601\n",
      "8602\n",
      "8603\n",
      "8604\n",
      "8605\n",
      "8606\n",
      "8607\n",
      "8608\n",
      "8609\n",
      "8610\n",
      "8611\n",
      "8612\n",
      "8613\n",
      "8614\n",
      "8615\n",
      "8616\n",
      "8617\n",
      "8618\n",
      "8619\n",
      "8620\n",
      "8621\n",
      "8622\n",
      "8623\n",
      "8624\n",
      "8625\n",
      "8626\n",
      "8627\n",
      "8628\n",
      "8629\n",
      "8630\n",
      "8631\n",
      "8632\n",
      "8633\n",
      "8634\n",
      "8635\n",
      "8636\n",
      "8637\n",
      "8638\n",
      "8639\n",
      "8640\n",
      "8641\n",
      "8642\n",
      "8643\n",
      "8644\n",
      "8645\n",
      "8646\n",
      "8647\n",
      "8648\n",
      "8649\n",
      "8650\n",
      "8651\n",
      "8652\n",
      "8653\n",
      "8654\n",
      "8655\n",
      "8656\n",
      "8657\n",
      "8658\n",
      "8659\n",
      "8660\n",
      "8661\n",
      "8662\n",
      "8663\n",
      "8664\n",
      "8665\n",
      "8666\n",
      "8667\n",
      "8668\n",
      "8669\n",
      "8670\n",
      "8671\n",
      "8672\n",
      "8673\n",
      "8674\n",
      "8675\n",
      "8676\n",
      "8677\n",
      "8678\n",
      "8679\n",
      "8680\n",
      "8681\n",
      "8682\n",
      "8683\n",
      "8684\n",
      "8685\n",
      "8686\n",
      "8687\n",
      "8688\n",
      "8689\n",
      "8690\n",
      "8691\n",
      "8692\n",
      "8693\n",
      "8694\n",
      "8695\n",
      "8696\n",
      "8697\n",
      "8698\n",
      "8699\n",
      "8700\n",
      "8701\n",
      "8702\n",
      "8703\n",
      "8704\n",
      "8705\n",
      "8706\n",
      "8707\n",
      "8708\n",
      "8709\n",
      "8710\n",
      "8711\n",
      "8712\n",
      "8713\n",
      "8714\n",
      "8715\n",
      "8716\n",
      "8717\n",
      "8718\n",
      "8719\n",
      "8720\n",
      "8721\n",
      "8722\n",
      "8723\n",
      "8724\n",
      "8725\n",
      "8726\n",
      "8727\n",
      "8728\n",
      "8729\n",
      "8730\n",
      "8731\n",
      "8732\n",
      "8733\n",
      "8734\n",
      "8735\n",
      "8736\n",
      "8737\n",
      "8738\n",
      "8739\n",
      "8740\n",
      "8741\n",
      "8742\n",
      "8743\n",
      "8744\n",
      "8745\n",
      "8746\n",
      "8747\n",
      "8748\n",
      "8749\n",
      "8750\n",
      "8751\n",
      "8752\n",
      "8753\n",
      "8754\n",
      "8755\n",
      "8756\n",
      "8757\n",
      "8758\n",
      "8759\n",
      "8760\n",
      "8761\n",
      "8762\n",
      "8763\n",
      "8764\n",
      "8765\n",
      "8766\n",
      "8767\n",
      "8768\n",
      "8769\n",
      "8770\n",
      "8771\n",
      "8772\n",
      "8773\n",
      "8774\n",
      "8775\n",
      "8776\n",
      "8777\n",
      "8778\n",
      "8779\n",
      "8780\n",
      "8781\n",
      "8782\n",
      "8783\n",
      "8784\n",
      "8785\n",
      "8786\n",
      "8787\n",
      "8788\n",
      "8789\n",
      "8790\n",
      "8791\n",
      "8792\n",
      "8793\n",
      "8794\n",
      "8795\n",
      "8796\n",
      "8797\n",
      "8798\n",
      "8799\n",
      "8800\n",
      "8801\n",
      "8802\n",
      "8803\n",
      "8804\n",
      "8805\n",
      "8806\n",
      "8807\n",
      "8808\n",
      "8809\n",
      "8810\n",
      "8811\n",
      "8812\n",
      "8813\n",
      "8814\n",
      "8815\n",
      "8816\n",
      "8817\n",
      "8818\n",
      "8819\n",
      "8820\n",
      "8821\n",
      "8822\n",
      "8823\n",
      "8824\n",
      "8825\n",
      "8826\n",
      "8827\n",
      "8828\n",
      "8829\n",
      "8830\n",
      "8831\n",
      "8832\n",
      "8833\n",
      "8834\n",
      "8835\n",
      "8836\n",
      "8837\n",
      "8838\n",
      "8839\n",
      "8840\n",
      "8841\n",
      "8842\n",
      "8843\n",
      "8844\n",
      "8845\n",
      "8846\n",
      "8847\n",
      "8848\n",
      "8849\n",
      "8850\n",
      "8851\n",
      "8852\n",
      "8853\n",
      "8854\n",
      "8855\n",
      "8856\n",
      "8857\n",
      "8858\n",
      "8859\n",
      "8860\n",
      "8861\n",
      "8862\n",
      "8863\n",
      "8864\n",
      "8865\n",
      "8866\n",
      "8867\n",
      "8868\n",
      "8869\n",
      "8870\n",
      "8871\n",
      "8872\n",
      "8873\n",
      "8874\n",
      "8875\n",
      "8876\n",
      "8877\n",
      "8878\n",
      "8879\n",
      "8880\n",
      "8881\n",
      "8882\n",
      "8883\n",
      "8884\n",
      "8885\n",
      "8886\n",
      "8887\n",
      "8888\n",
      "8889\n",
      "8890\n",
      "8891\n",
      "8892\n",
      "8893\n",
      "8894\n",
      "8895\n",
      "8896\n",
      "8897\n",
      "8898\n",
      "8899\n",
      "8900\n",
      "8901\n",
      "8902\n",
      "8903\n",
      "8904\n",
      "8905\n",
      "8906\n",
      "8907\n",
      "8908\n",
      "8909\n",
      "8910\n",
      "8911\n",
      "8912\n",
      "8913\n",
      "8914\n",
      "8915\n",
      "8916\n",
      "8917\n",
      "8918\n",
      "8919\n",
      "8920\n",
      "8921\n",
      "8922\n",
      "8923\n",
      "8924\n",
      "8925\n",
      "8926\n",
      "8927\n",
      "8928\n",
      "8929\n",
      "8930\n",
      "8931\n",
      "8932\n",
      "8933\n",
      "8934\n",
      "8935\n",
      "8936\n",
      "8937\n",
      "8938\n",
      "8939\n",
      "8940\n",
      "8941\n",
      "8942\n",
      "8943\n",
      "8944\n",
      "8945\n",
      "8946\n",
      "8947\n",
      "8948\n",
      "8949\n",
      "8950\n",
      "8951\n",
      "8952\n",
      "8953\n",
      "8954\n",
      "8955\n",
      "8956\n",
      "8957\n",
      "8958\n",
      "8959\n",
      "8960\n",
      "8961\n",
      "8962\n",
      "8963\n",
      "8964\n",
      "8965\n",
      "8966\n",
      "8967\n",
      "8968\n",
      "8969\n",
      "8970\n",
      "8971\n",
      "8972\n",
      "8973\n",
      "8974\n",
      "8975\n",
      "8976\n",
      "8977\n",
      "8978\n",
      "8979\n",
      "8980\n",
      "8981\n",
      "8982\n",
      "8983\n",
      "8984\n",
      "8985\n",
      "8986\n",
      "8987\n",
      "8988\n",
      "8989\n",
      "8990\n",
      "8991\n",
      "8992\n",
      "8993\n",
      "8994\n",
      "8995\n",
      "8996\n",
      "8997\n",
      "8998\n",
      "8999\n",
      "9000\n",
      "9001\n",
      "9002\n",
      "9003\n",
      "9004\n",
      "9005\n",
      "9006\n",
      "9007\n",
      "9008\n",
      "9009\n",
      "9010\n",
      "9011\n",
      "9012\n",
      "9013\n",
      "9014\n",
      "9015\n",
      "9016\n",
      "9017\n",
      "9018\n",
      "9019\n",
      "9020\n",
      "9021\n",
      "9022\n",
      "9023\n",
      "9024\n",
      "9025\n",
      "9026\n",
      "9027\n",
      "9028\n",
      "9029\n",
      "9030\n",
      "9031\n",
      "9032\n",
      "9033\n",
      "9034\n",
      "9035\n",
      "9036\n",
      "9037\n",
      "9038\n",
      "9039\n",
      "9040\n",
      "9041\n",
      "9042\n",
      "9043\n",
      "9044\n",
      "9045\n",
      "9046\n",
      "9047\n",
      "9048\n",
      "9049\n",
      "9050\n",
      "9051\n",
      "9052\n",
      "9053\n",
      "9054\n",
      "9055\n",
      "9056\n",
      "9057\n",
      "9058\n",
      "9059\n",
      "9060\n",
      "9061\n",
      "9062\n",
      "9063\n",
      "9064\n",
      "9065\n",
      "9066\n",
      "9067\n",
      "9068\n",
      "9069\n",
      "9070\n",
      "9071\n",
      "9072\n",
      "9073\n",
      "9074\n",
      "9075\n",
      "9076\n",
      "9077\n",
      "9078\n",
      "9079\n",
      "9080\n",
      "9081\n",
      "9082\n",
      "9083\n",
      "9084\n",
      "9085\n",
      "9086\n",
      "9087\n",
      "9088\n",
      "9089\n",
      "9090\n",
      "9091\n",
      "9092\n",
      "9093\n",
      "9094\n",
      "9095\n",
      "9096\n",
      "9097\n",
      "9098\n",
      "9099\n",
      "9100\n",
      "9101\n",
      "9102\n",
      "9103\n",
      "9104\n",
      "9105\n",
      "9106\n",
      "9107\n",
      "9108\n",
      "9109\n",
      "9110\n",
      "9111\n",
      "9112\n",
      "9113\n",
      "9114\n",
      "9115\n",
      "9116\n",
      "9117\n",
      "9118\n",
      "9119\n",
      "9120\n",
      "9121\n",
      "9122\n",
      "9123\n",
      "9124\n",
      "9125\n",
      "9126\n",
      "9127\n",
      "9128\n",
      "9129\n",
      "9130\n",
      "9131\n",
      "9132\n",
      "9133\n",
      "9134\n",
      "9135\n",
      "9136\n",
      "9137\n",
      "9138\n",
      "9139\n",
      "9140\n",
      "9141\n",
      "9142\n",
      "9143\n",
      "9144\n",
      "9145\n",
      "9146\n",
      "9147\n",
      "9148\n",
      "9149\n",
      "9150\n",
      "9151\n",
      "9152\n",
      "9153\n",
      "9154\n",
      "9155\n",
      "9156\n",
      "9157\n",
      "9158\n",
      "9159\n",
      "9160\n",
      "9161\n",
      "9162\n",
      "9163\n",
      "9164\n",
      "9165\n",
      "9166\n",
      "9167\n",
      "9168\n",
      "9169\n",
      "9170\n",
      "9171\n",
      "9172\n",
      "9173\n",
      "9174\n",
      "9175\n",
      "9176\n",
      "9177\n",
      "9178\n",
      "9179\n",
      "9180\n",
      "9181\n",
      "9182\n",
      "9183\n",
      "9184\n",
      "9185\n",
      "9186\n",
      "9187\n",
      "9188\n",
      "9189\n",
      "9190\n",
      "9191\n",
      "9192\n",
      "9193\n",
      "9194\n",
      "9195\n",
      "9196\n",
      "9197\n",
      "9198\n",
      "9199\n",
      "9200\n",
      "9201\n",
      "9202\n",
      "9203\n",
      "9204\n",
      "9205\n",
      "9206\n",
      "9207\n",
      "9208\n",
      "9209\n",
      "9210\n",
      "9211\n",
      "9212\n",
      "9213\n",
      "9214\n",
      "9215\n",
      "9216\n",
      "9217\n",
      "9218\n",
      "9219\n",
      "9220\n",
      "9221\n",
      "9222\n",
      "9223\n",
      "9224\n",
      "9225\n",
      "9226\n",
      "9227\n",
      "9228\n",
      "9229\n",
      "9230\n",
      "9231\n",
      "9232\n",
      "9233\n",
      "9234\n",
      "9235\n",
      "9236\n",
      "9237\n",
      "9238\n",
      "9239\n",
      "9240\n",
      "9241\n",
      "9242\n",
      "9243\n",
      "9244\n",
      "9245\n",
      "9246\n",
      "9247\n",
      "9248\n",
      "9249\n",
      "9250\n",
      "9251\n",
      "9252\n",
      "9253\n",
      "9254\n",
      "9255\n",
      "9256\n",
      "9257\n",
      "9258\n",
      "9259\n",
      "9260\n",
      "9261\n",
      "9262\n",
      "9263\n",
      "9264\n",
      "9265\n",
      "9266\n",
      "9267\n",
      "9268\n",
      "9269\n",
      "9270\n",
      "9271\n",
      "9272\n",
      "9273\n",
      "9274\n",
      "9275\n",
      "9276\n",
      "9277\n",
      "9278\n",
      "9279\n",
      "9280\n",
      "9281\n",
      "9282\n",
      "9283\n",
      "9284\n",
      "9285\n",
      "9286\n",
      "9287\n",
      "9288\n",
      "9289\n",
      "9290\n",
      "9291\n",
      "9292\n",
      "9293\n",
      "9294\n",
      "9295\n",
      "9296\n",
      "9297\n",
      "9298\n",
      "9299\n",
      "9300\n",
      "9301\n",
      "9302\n",
      "9303\n",
      "9304\n",
      "9305\n",
      "9306\n",
      "9307\n",
      "9308\n",
      "9309\n",
      "9310\n",
      "9311\n",
      "9312\n",
      "9313\n",
      "9314\n",
      "9315\n",
      "9316\n",
      "9317\n",
      "9318\n",
      "9319\n",
      "9320\n",
      "9321\n",
      "9322\n",
      "9323\n",
      "9324\n",
      "9325\n",
      "9326\n",
      "9327\n",
      "9328\n",
      "9329\n",
      "9330\n",
      "9331\n",
      "9332\n",
      "9333\n",
      "9334\n",
      "9335\n",
      "9336\n",
      "9337\n",
      "9338\n",
      "9339\n",
      "9340\n",
      "9341\n",
      "9342\n",
      "9343\n",
      "9344\n",
      "9345\n",
      "9346\n",
      "9347\n",
      "9348\n",
      "9349\n",
      "9350\n",
      "9351\n",
      "9352\n",
      "9353\n",
      "9354\n",
      "9355\n",
      "9356\n",
      "9357\n",
      "9358\n",
      "9359\n",
      "9360\n",
      "9361\n",
      "9362\n",
      "9363\n",
      "9364\n",
      "9365\n",
      "9366\n",
      "9367\n",
      "9368\n",
      "9369\n",
      "9370\n",
      "9371\n",
      "9372\n",
      "9373\n",
      "9374\n",
      "9375\n",
      "9376\n",
      "9377\n",
      "9378\n",
      "9379\n",
      "9380\n",
      "9381\n",
      "9382\n",
      "9383\n",
      "9384\n",
      "9385\n",
      "9386\n",
      "9387\n",
      "9388\n",
      "9389\n",
      "9390\n",
      "9391\n",
      "9392\n",
      "9393\n",
      "9394\n",
      "9395\n",
      "9396\n",
      "9397\n",
      "9398\n",
      "9399\n",
      "9400\n",
      "9401\n",
      "9402\n",
      "9403\n",
      "9404\n",
      "9405\n",
      "9406\n",
      "9407\n",
      "9408\n",
      "9409\n",
      "9410\n",
      "9411\n",
      "9412\n",
      "9413\n",
      "9414\n",
      "9415\n",
      "9416\n",
      "9417\n",
      "9418\n",
      "9419\n",
      "9420\n",
      "9421\n",
      "9422\n",
      "9423\n",
      "9424\n",
      "9425\n",
      "9426\n",
      "9427\n",
      "9428\n",
      "9429\n",
      "9430\n",
      "9431\n",
      "9432\n",
      "9433\n",
      "9434\n",
      "9435\n",
      "9436\n",
      "9437\n",
      "9438\n",
      "9439\n",
      "9440\n",
      "9441\n",
      "9442\n",
      "9443\n",
      "9444\n",
      "9445\n",
      "9446\n",
      "9447\n",
      "9448\n",
      "9449\n",
      "9450\n",
      "9451\n",
      "9452\n",
      "9453\n",
      "9454\n",
      "9455\n",
      "9456\n",
      "9457\n",
      "9458\n",
      "9459\n",
      "9460\n",
      "9461\n",
      "9462\n",
      "9463\n",
      "9464\n",
      "9465\n",
      "9466\n",
      "9467\n",
      "9468\n",
      "9469\n",
      "9470\n",
      "9471\n",
      "9472\n",
      "9473\n",
      "9474\n",
      "9475\n",
      "9476\n",
      "9477\n",
      "9478\n",
      "9479\n",
      "9480\n",
      "9481\n",
      "9482\n",
      "9483\n",
      "9484\n",
      "9485\n",
      "9486\n",
      "9487\n",
      "9488\n",
      "9489\n",
      "9490\n",
      "9491\n",
      "9492\n",
      "9493\n",
      "9494\n",
      "9495\n",
      "9496\n",
      "9497\n",
      "9498\n",
      "9499\n",
      "9500\n",
      "9501\n",
      "9502\n",
      "9503\n",
      "9504\n",
      "9505\n",
      "9506\n",
      "9507\n",
      "9508\n",
      "9509\n",
      "9510\n",
      "9511\n",
      "9512\n",
      "9513\n",
      "9514\n",
      "9515\n",
      "9516\n",
      "9517\n",
      "9518\n",
      "9519\n",
      "9520\n",
      "9521\n",
      "9522\n",
      "9523\n",
      "9524\n",
      "9525\n",
      "9526\n",
      "9527\n",
      "9528\n",
      "9529\n",
      "9530\n",
      "9531\n",
      "9532\n",
      "9533\n",
      "9534\n",
      "9535\n",
      "9536\n",
      "9537\n",
      "9538\n",
      "9539\n",
      "9540\n",
      "9541\n",
      "9542\n",
      "9543\n",
      "9544\n",
      "9545\n",
      "9546\n",
      "9547\n",
      "9548\n",
      "9549\n",
      "9550\n",
      "9551\n",
      "9552\n",
      "9553\n",
      "9554\n",
      "9555\n",
      "9556\n",
      "9557\n",
      "9558\n",
      "9559\n",
      "9560\n",
      "9561\n",
      "9562\n",
      "9563\n",
      "9564\n",
      "9565\n",
      "9566\n",
      "9567\n",
      "9568\n",
      "9569\n",
      "9570\n",
      "9571\n",
      "9572\n",
      "9573\n",
      "9574\n",
      "9575\n",
      "9576\n",
      "9577\n",
      "9578\n",
      "9579\n",
      "9580\n",
      "9581\n",
      "9582\n",
      "9583\n",
      "9584\n",
      "9585\n",
      "9586\n",
      "9587\n",
      "9588\n",
      "9589\n",
      "9590\n",
      "9591\n",
      "9592\n",
      "9593\n",
      "9594\n",
      "9595\n",
      "9596\n",
      "9597\n",
      "9598\n",
      "9599\n",
      "9600\n",
      "9601\n",
      "9602\n",
      "9603\n",
      "9604\n",
      "9605\n",
      "9606\n",
      "9607\n",
      "9608\n",
      "9609\n",
      "9610\n",
      "9611\n",
      "9612\n",
      "9613\n",
      "9614\n",
      "9615\n",
      "9616\n",
      "9617\n",
      "9618\n",
      "9619\n",
      "9620\n",
      "9621\n",
      "9622\n",
      "9623\n",
      "9624\n",
      "9625\n",
      "9626\n",
      "9627\n",
      "9628\n",
      "9629\n",
      "9630\n",
      "9631\n",
      "9632\n",
      "9633\n",
      "9634\n",
      "9635\n",
      "9636\n",
      "9637\n",
      "9638\n",
      "9639\n",
      "9640\n",
      "9641\n",
      "9642\n",
      "9643\n",
      "9644\n",
      "9645\n",
      "9646\n",
      "9647\n",
      "9648\n",
      "9649\n",
      "9650\n",
      "9651\n",
      "9652\n",
      "9653\n",
      "9654\n",
      "9655\n",
      "9656\n",
      "9657\n",
      "9658\n",
      "9659\n",
      "9660\n",
      "9661\n",
      "9662\n",
      "9663\n",
      "9664\n",
      "9665\n",
      "9666\n",
      "9667\n",
      "9668\n",
      "9669\n",
      "9670\n",
      "9671\n",
      "9672\n",
      "9673\n",
      "9674\n",
      "9675\n",
      "9676\n",
      "9677\n",
      "9678\n",
      "9679\n",
      "9680\n",
      "9681\n",
      "9682\n",
      "9683\n",
      "9684\n",
      "9685\n",
      "9686\n",
      "9687\n",
      "9688\n",
      "9689\n",
      "9690\n",
      "9691\n",
      "9692\n",
      "9693\n",
      "9694\n",
      "9695\n",
      "9696\n",
      "9697\n",
      "9698\n",
      "9699\n",
      "9700\n",
      "9701\n",
      "9702\n",
      "9703\n",
      "9704\n",
      "9705\n",
      "9706\n",
      "9707\n",
      "9708\n",
      "9709\n",
      "9710\n",
      "9711\n",
      "9712\n",
      "9713\n",
      "9714\n",
      "9715\n",
      "9716\n",
      "9717\n",
      "9718\n",
      "9719\n",
      "9720\n",
      "9721\n",
      "9722\n",
      "9723\n",
      "9724\n",
      "9725\n",
      "9726\n",
      "9727\n",
      "9728\n",
      "9729\n",
      "9730\n",
      "9731\n",
      "9732\n",
      "9733\n",
      "9734\n",
      "9735\n",
      "9736\n",
      "9737\n",
      "9738\n",
      "9739\n",
      "9740\n",
      "9741\n",
      "9742\n",
      "9743\n",
      "9744\n",
      "9745\n",
      "9746\n",
      "9747\n",
      "9748\n",
      "9749\n",
      "9750\n",
      "9751\n",
      "9752\n",
      "9753\n",
      "9754\n",
      "9755\n",
      "9756\n",
      "9757\n",
      "9758\n",
      "9759\n",
      "9760\n",
      "9761\n",
      "9762\n",
      "9763\n",
      "9764\n",
      "9765\n",
      "9766\n",
      "9767\n",
      "9768\n",
      "9769\n",
      "9770\n",
      "9771\n",
      "9772\n",
      "9773\n",
      "9774\n",
      "9775\n",
      "9776\n",
      "9777\n",
      "9778\n",
      "9779\n",
      "9780\n",
      "9781\n",
      "9782\n",
      "9783\n",
      "9784\n",
      "9785\n",
      "9786\n",
      "9787\n",
      "9788\n",
      "9789\n",
      "9790\n",
      "9791\n",
      "9792\n",
      "9793\n",
      "9794\n",
      "9795\n",
      "9796\n",
      "9797\n",
      "9798\n",
      "9799\n",
      "9800\n",
      "9801\n",
      "9802\n",
      "9803\n",
      "9804\n",
      "9805\n",
      "9806\n",
      "9807\n",
      "9808\n",
      "9809\n",
      "9810\n",
      "9811\n",
      "9812\n",
      "9813\n",
      "9814\n",
      "9815\n",
      "9816\n",
      "9817\n",
      "9818\n",
      "9819\n",
      "9820\n",
      "9821\n",
      "9822\n",
      "9823\n",
      "9824\n",
      "9825\n",
      "9826\n",
      "9827\n",
      "9828\n",
      "9829\n",
      "9830\n",
      "9831\n",
      "9832\n",
      "9833\n",
      "9834\n",
      "9835\n",
      "9836\n",
      "9837\n",
      "9838\n",
      "9839\n",
      "9840\n",
      "9841\n",
      "9842\n",
      "9843\n",
      "9844\n",
      "9845\n",
      "9846\n",
      "9847\n",
      "9848\n",
      "9849\n",
      "9850\n",
      "9851\n",
      "9852\n",
      "9853\n",
      "9854\n",
      "9855\n",
      "9856\n",
      "9857\n",
      "9858\n",
      "9859\n",
      "9860\n",
      "9861\n",
      "9862\n",
      "9863\n",
      "9864\n",
      "9865\n",
      "9866\n",
      "9867\n",
      "9868\n",
      "9869\n",
      "9870\n",
      "9871\n",
      "9872\n",
      "9873\n",
      "9874\n",
      "9875\n",
      "9876\n",
      "9877\n",
      "9878\n",
      "9879\n",
      "9880\n",
      "9881\n",
      "9882\n",
      "9883\n",
      "9884\n",
      "9885\n",
      "9886\n",
      "9887\n",
      "9888\n",
      "9889\n",
      "9890\n",
      "9891\n",
      "9892\n",
      "9893\n",
      "9894\n",
      "9895\n",
      "9896\n",
      "9897\n",
      "9898\n",
      "9899\n",
      "9900\n",
      "9901\n",
      "9902\n",
      "9903\n",
      "9904\n",
      "9905\n",
      "9906\n",
      "9907\n",
      "9908\n",
      "9909\n",
      "9910\n",
      "9911\n",
      "9912\n",
      "9913\n",
      "9914\n",
      "9915\n",
      "9916\n",
      "9917\n",
      "9918\n",
      "9919\n",
      "9920\n",
      "9921\n",
      "9922\n",
      "9923\n",
      "9924\n",
      "9925\n",
      "9926\n",
      "9927\n",
      "9928\n",
      "9929\n",
      "9930\n",
      "9931\n",
      "9932\n",
      "9933\n",
      "9934\n",
      "9935\n",
      "9936\n",
      "9937\n",
      "9938\n",
      "9939\n",
      "9940\n",
      "9941\n",
      "9942\n",
      "9943\n",
      "9944\n",
      "9945\n",
      "9946\n",
      "9947\n",
      "9948\n",
      "9949\n",
      "9950\n",
      "9951\n",
      "9952\n",
      "9953\n",
      "9954\n",
      "9955\n",
      "9956\n",
      "9957\n",
      "9958\n",
      "9959\n",
      "9960\n",
      "9961\n",
      "9962\n",
      "9963\n",
      "9964\n",
      "9965\n",
      "9966\n",
      "9967\n",
      "9968\n",
      "9969\n",
      "9970\n",
      "9971\n",
      "9972\n",
      "9973\n",
      "9974\n",
      "9975\n",
      "9976\n",
      "9977\n",
      "9978\n",
      "9979\n",
      "9980\n",
      "9981\n",
      "9982\n",
      "9983\n",
      "9984\n",
      "9985\n",
      "9986\n",
      "9987\n",
      "9988\n",
      "9989\n",
      "9990\n",
      "9991\n",
      "9992\n",
      "9993\n",
      "9994\n",
      "9995\n",
      "9996\n",
      "9997\n",
      "9998\n",
      "9999\n",
      "10000\n",
      "10001\n",
      "10002\n",
      "10003\n",
      "10004\n",
      "10005\n",
      "10006\n",
      "10007\n",
      "10008\n",
      "10009\n",
      "10010\n",
      "10011\n",
      "10012\n",
      "10013\n",
      "10014\n",
      "10015\n",
      "10016\n",
      "10017\n",
      "10018\n",
      "10019\n",
      "10020\n",
      "10021\n",
      "10022\n",
      "10023\n",
      "10024\n",
      "10025\n",
      "10026\n",
      "10027\n",
      "10028\n",
      "10029\n",
      "10030\n",
      "10031\n",
      "10032\n",
      "10033\n",
      "10034\n",
      "10035\n",
      "10036\n",
      "10037\n",
      "10038\n",
      "10039\n",
      "10040\n",
      "10041\n",
      "10042\n",
      "10043\n",
      "10044\n",
      "10045\n",
      "10046\n",
      "10047\n",
      "10048\n",
      "10049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10050\n",
      "10051\n",
      "10052\n",
      "10053\n",
      "10054\n",
      "10055\n",
      "10056\n",
      "10057\n",
      "10058\n",
      "10059\n",
      "10060\n",
      "10061\n",
      "10062\n",
      "10063\n",
      "10064\n",
      "10065\n",
      "10066\n",
      "10067\n",
      "10068\n",
      "10069\n",
      "10070\n",
      "10071\n",
      "10072\n",
      "10073\n",
      "10074\n",
      "10075\n",
      "10076\n",
      "10077\n",
      "10078\n",
      "10079\n",
      "10080\n",
      "10081\n",
      "10082\n",
      "10083\n",
      "10084\n",
      "10085\n",
      "10086\n",
      "10087\n",
      "10088\n",
      "10089\n",
      "10090\n",
      "10091\n",
      "10092\n",
      "10093\n",
      "10094\n",
      "10095\n",
      "10096\n",
      "10097\n",
      "10098\n",
      "10099\n",
      "10100\n",
      "10101\n",
      "10102\n",
      "10103\n",
      "10104\n",
      "10105\n",
      "10106\n",
      "10107\n",
      "10108\n",
      "10109\n",
      "10110\n",
      "10111\n",
      "10112\n",
      "10113\n",
      "10114\n",
      "10115\n",
      "10116\n",
      "10117\n",
      "10118\n",
      "10119\n",
      "10120\n",
      "10121\n",
      "10122\n",
      "10123\n",
      "10124\n",
      "10125\n",
      "10126\n",
      "10127\n",
      "10128\n",
      "10129\n",
      "10130\n",
      "10131\n",
      "10132\n",
      "10133\n",
      "10134\n",
      "10135\n",
      "10136\n",
      "10137\n",
      "10138\n",
      "10139\n",
      "10140\n",
      "10141\n",
      "10142\n",
      "10143\n",
      "10144\n",
      "10145\n",
      "10146\n",
      "10147\n",
      "10148\n",
      "10149\n",
      "10150\n",
      "10151\n",
      "10152\n",
      "10153\n",
      "10154\n",
      "10155\n",
      "10156\n",
      "10157\n",
      "10158\n",
      "10159\n",
      "10160\n",
      "10161\n",
      "10162\n",
      "10163\n",
      "10164\n",
      "10165\n",
      "10166\n",
      "10167\n",
      "10168\n",
      "10169\n",
      "10170\n",
      "10171\n",
      "10172\n",
      "10173\n",
      "10174\n",
      "10175\n",
      "10176\n",
      "10177\n",
      "10178\n",
      "10179\n",
      "10180\n",
      "10181\n",
      "10182\n",
      "10183\n",
      "10184\n",
      "10185\n",
      "10186\n",
      "10187\n",
      "10188\n",
      "10189\n",
      "10190\n",
      "10191\n",
      "10192\n",
      "10193\n",
      "10194\n",
      "10195\n",
      "10196\n",
      "10197\n",
      "10198\n",
      "10199\n",
      "10200\n",
      "10201\n",
      "10202\n",
      "10203\n",
      "10204\n",
      "10205\n",
      "10206\n",
      "10207\n",
      "10208\n",
      "10209\n",
      "10210\n",
      "10211\n",
      "10212\n",
      "10213\n",
      "10214\n",
      "10215\n",
      "10216\n",
      "10217\n",
      "10218\n",
      "10219\n",
      "10220\n",
      "10221\n",
      "10222\n",
      "10223\n",
      "10224\n",
      "10225\n",
      "10226\n",
      "10227\n",
      "10228\n",
      "10229\n",
      "10230\n",
      "10231\n",
      "10232\n",
      "10233\n",
      "10234\n",
      "10235\n",
      "10236\n",
      "10237\n",
      "10238\n",
      "10239\n",
      "10240\n",
      "10241\n",
      "10242\n",
      "10243\n",
      "10244\n",
      "10245\n",
      "10246\n",
      "10247\n",
      "10248\n",
      "10249\n",
      "10250\n",
      "10251\n",
      "10252\n",
      "10253\n",
      "10254\n",
      "10255\n",
      "10256\n",
      "10257\n",
      "10258\n",
      "10259\n",
      "10260\n",
      "10261\n",
      "10262\n",
      "10263\n",
      "10264\n",
      "10265\n",
      "10266\n",
      "10267\n",
      "10268\n",
      "10269\n",
      "10270\n",
      "10271\n",
      "10272\n",
      "10273\n",
      "10274\n",
      "10275\n",
      "10276\n",
      "10277\n",
      "10278\n",
      "10279\n",
      "10280\n",
      "10281\n",
      "10282\n",
      "10283\n",
      "10284\n",
      "10285\n",
      "10286\n",
      "10287\n",
      "10288\n",
      "10289\n",
      "10290\n",
      "10291\n",
      "10292\n",
      "10293\n",
      "10294\n",
      "10295\n",
      "10296\n",
      "10297\n",
      "10298\n",
      "10299\n",
      "10300\n",
      "10301\n",
      "10302\n",
      "10303\n",
      "10304\n",
      "10305\n",
      "10306\n",
      "10307\n",
      "10308\n",
      "10309\n",
      "10310\n",
      "10311\n",
      "10312\n",
      "10313\n",
      "10314\n",
      "10315\n",
      "10316\n",
      "10317\n",
      "10318\n",
      "10319\n",
      "10320\n",
      "10321\n",
      "10322\n",
      "10323\n",
      "10324\n",
      "10325\n",
      "10326\n",
      "10327\n",
      "10328\n",
      "10329\n",
      "10330\n",
      "10331\n",
      "10332\n",
      "10333\n",
      "10334\n",
      "10335\n",
      "10336\n",
      "10337\n",
      "10338\n",
      "10339\n",
      "10340\n",
      "10341\n",
      "10342\n",
      "10343\n",
      "10344\n",
      "10345\n",
      "10346\n",
      "10347\n",
      "10348\n",
      "10349\n",
      "10350\n",
      "10351\n",
      "10352\n",
      "10353\n",
      "10354\n",
      "10355\n",
      "10356\n",
      "10357\n",
      "10358\n",
      "10359\n",
      "10360\n",
      "10361\n",
      "10362\n",
      "10363\n",
      "10364\n",
      "10365\n",
      "10366\n",
      "10367\n",
      "10368\n",
      "10369\n",
      "10370\n",
      "10371\n",
      "10372\n",
      "10373\n",
      "10374\n",
      "10375\n",
      "10376\n",
      "10377\n",
      "10378\n",
      "10379\n",
      "10380\n",
      "10381\n",
      "10382\n",
      "10383\n",
      "10384\n",
      "10385\n",
      "10386\n",
      "10387\n",
      "10388\n",
      "10389\n",
      "10390\n",
      "10391\n",
      "10392\n",
      "10393\n",
      "10394\n",
      "10395\n",
      "10396\n",
      "10397\n",
      "10398\n",
      "10399\n",
      "10400\n",
      "10401\n",
      "10402\n",
      "10403\n",
      "10404\n",
      "10405\n",
      "10406\n",
      "10407\n",
      "10408\n",
      "10409\n",
      "10410\n",
      "10411\n",
      "10412\n",
      "10413\n",
      "10414\n",
      "10415\n",
      "10416\n",
      "10417\n",
      "10418\n",
      "10419\n",
      "10420\n",
      "10421\n",
      "10422\n",
      "10423\n",
      "10424\n",
      "10425\n",
      "10426\n",
      "10427\n",
      "10428\n",
      "10429\n",
      "10430\n",
      "10431\n",
      "10432\n",
      "10433\n",
      "10434\n",
      "10435\n",
      "10436\n",
      "10437\n",
      "10438\n",
      "10439\n",
      "10440\n",
      "10441\n",
      "10442\n",
      "10443\n",
      "10444\n",
      "10445\n",
      "10446\n",
      "10447\n",
      "10448\n",
      "10449\n",
      "10450\n",
      "10451\n",
      "10452\n",
      "10453\n",
      "10454\n",
      "10455\n",
      "10456\n",
      "10457\n",
      "10458\n",
      "10459\n",
      "10460\n",
      "10461\n",
      "10462\n",
      "10463\n",
      "10464\n",
      "10465\n",
      "10466\n",
      "10467\n",
      "10468\n",
      "10469\n",
      "10470\n",
      "10471\n",
      "10472\n",
      "10473\n",
      "10474\n",
      "10475\n",
      "10476\n",
      "10477\n",
      "10478\n",
      "10479\n",
      "10480\n",
      "10481\n",
      "10482\n",
      "10483\n",
      "10484\n",
      "10485\n",
      "10486\n",
      "10487\n",
      "10488\n",
      "10489\n",
      "10490\n",
      "10491\n",
      "10492\n",
      "10493\n",
      "10494\n",
      "10495\n",
      "10496\n",
      "10497\n",
      "10498\n",
      "10499\n",
      "10500\n",
      "10501\n",
      "10502\n",
      "10503\n",
      "10504\n",
      "10505\n",
      "10506\n",
      "10507\n",
      "10508\n",
      "10509\n",
      "10510\n",
      "10511\n",
      "10512\n",
      "10513\n",
      "10514\n",
      "10515\n",
      "10516\n",
      "10517\n",
      "10518\n",
      "10519\n",
      "10520\n",
      "10521\n",
      "10522\n",
      "10523\n",
      "10524\n",
      "10525\n",
      "10526\n",
      "10527\n",
      "10528\n",
      "10529\n",
      "10530\n",
      "10531\n",
      "10532\n",
      "10533\n",
      "10534\n",
      "10535\n",
      "10536\n",
      "10537\n",
      "10538\n",
      "10539\n",
      "10540\n",
      "10541\n",
      "10542\n",
      "10543\n",
      "10544\n",
      "10545\n",
      "10546\n",
      "10547\n",
      "10548\n",
      "10549\n",
      "10550\n",
      "10551\n",
      "10552\n",
      "10553\n",
      "10554\n",
      "10555\n",
      "10556\n",
      "10557\n",
      "10558\n",
      "10559\n",
      "10560\n",
      "10561\n",
      "10562\n",
      "10563\n",
      "10564\n",
      "10565\n",
      "10566\n",
      "10567\n",
      "10568\n",
      "10569\n",
      "10570\n",
      "10571\n",
      "10572\n",
      "10573\n",
      "10574\n",
      "10575\n",
      "10576\n",
      "10577\n",
      "10578\n",
      "10579\n",
      "10580\n",
      "10581\n",
      "10582\n",
      "10583\n",
      "10584\n",
      "10585\n",
      "10586\n",
      "10587\n",
      "10588\n",
      "10589\n",
      "10590\n",
      "10591\n",
      "10592\n",
      "10593\n",
      "10594\n",
      "10595\n",
      "10596\n",
      "10597\n",
      "10598\n",
      "10599\n",
      "10600\n",
      "10601\n",
      "10602\n",
      "10603\n",
      "10604\n",
      "10605\n",
      "10606\n",
      "10607\n",
      "10608\n",
      "10609\n",
      "10610\n",
      "10611\n",
      "10612\n",
      "10613\n",
      "10614\n",
      "10615\n",
      "10616\n",
      "10617\n",
      "10618\n",
      "10619\n",
      "10620\n",
      "10621\n",
      "10622\n",
      "10623\n",
      "10624\n",
      "10625\n",
      "10626\n",
      "10627\n",
      "10628\n",
      "10629\n",
      "10630\n",
      "10631\n",
      "10632\n",
      "10633\n",
      "10634\n",
      "10635\n",
      "10636\n",
      "10637\n",
      "10638\n",
      "10639\n",
      "10640\n",
      "10641\n",
      "10642\n",
      "10643\n",
      "10644\n",
      "10645\n",
      "10646\n",
      "10647\n",
      "10648\n",
      "10649\n",
      "10650\n",
      "10651\n",
      "10652\n",
      "10653\n",
      "10654\n",
      "10655\n",
      "10656\n",
      "10657\n",
      "10658\n",
      "10659\n",
      "10660\n",
      "10661\n",
      "10662\n",
      "10663\n",
      "10664\n",
      "10665\n",
      "10666\n",
      "10667\n",
      "10668\n",
      "10669\n",
      "10670\n",
      "10671\n",
      "10672\n",
      "10673\n",
      "10674\n",
      "10675\n",
      "10676\n",
      "10677\n",
      "10678\n",
      "10679\n",
      "10680\n",
      "10681\n",
      "10682\n",
      "10683\n",
      "10684\n",
      "10685\n",
      "10686\n",
      "10687\n",
      "10688\n",
      "10689\n",
      "10690\n",
      "10691\n",
      "10692\n",
      "10693\n",
      "10694\n",
      "10695\n",
      "10696\n",
      "10697\n",
      "10698\n",
      "10699\n",
      "10700\n",
      "10701\n",
      "10702\n",
      "10703\n",
      "10704\n",
      "10705\n",
      "10706\n",
      "10707\n",
      "10708\n",
      "10709\n",
      "10710\n",
      "10711\n",
      "10712\n",
      "10713\n",
      "10714\n",
      "10715\n",
      "10716\n",
      "10717\n",
      "10718\n",
      "10719\n",
      "10720\n",
      "10721\n",
      "10722\n",
      "10723\n",
      "10724\n",
      "10725\n",
      "10726\n",
      "10727\n",
      "10728\n",
      "10729\n",
      "10730\n",
      "10731\n",
      "10732\n",
      "10733\n",
      "10734\n",
      "10735\n",
      "10736\n",
      "10737\n",
      "10738\n",
      "10739\n",
      "10740\n",
      "10741\n",
      "10742\n",
      "10743\n",
      "10744\n",
      "10745\n",
      "10746\n",
      "10747\n",
      "10748\n",
      "10749\n",
      "10750\n",
      "10751\n",
      "10752\n",
      "10753\n",
      "10754\n",
      "10755\n",
      "10756\n",
      "10757\n",
      "10758\n",
      "10759\n",
      "10760\n",
      "10761\n",
      "10762\n",
      "10763\n",
      "10764\n",
      "10765\n",
      "10766\n",
      "10767\n",
      "10768\n",
      "10769\n",
      "10770\n",
      "10771\n",
      "10772\n",
      "10773\n",
      "10774\n",
      "10775\n",
      "10776\n",
      "10777\n",
      "10778\n",
      "10779\n",
      "10780\n",
      "10781\n",
      "10782\n",
      "10783\n",
      "10784\n",
      "10785\n",
      "10786\n",
      "10787\n",
      "10788\n",
      "10789\n",
      "10790\n",
      "10791\n",
      "10792\n",
      "10793\n",
      "10794\n",
      "10795\n",
      "10796\n",
      "10797\n",
      "10798\n",
      "10799\n",
      "10800\n",
      "10801\n",
      "10802\n",
      "10803\n",
      "10804\n",
      "10805\n",
      "10806\n",
      "10807\n",
      "10808\n",
      "10809\n",
      "10810\n",
      "10811\n",
      "10812\n",
      "10813\n",
      "10814\n",
      "10815\n",
      "10816\n",
      "10817\n",
      "10818\n",
      "10819\n",
      "10820\n",
      "10821\n",
      "10822\n",
      "10823\n",
      "10824\n",
      "10825\n",
      "10826\n",
      "10827\n",
      "10828\n",
      "10829\n",
      "10830\n",
      "10831\n",
      "10832\n",
      "10833\n",
      "10834\n",
      "10835\n",
      "10836\n",
      "10837\n",
      "10838\n",
      "10839\n",
      "10840\n",
      "10841\n",
      "10842\n",
      "10843\n",
      "10844\n",
      "10845\n",
      "10846\n",
      "10847\n",
      "10848\n",
      "10849\n",
      "10850\n",
      "10851\n",
      "10852\n",
      "10853\n",
      "10854\n",
      "10855\n",
      "10856\n",
      "10857\n",
      "10858\n",
      "10859\n",
      "10860\n",
      "10861\n",
      "10862\n",
      "10863\n",
      "10864\n",
      "10865\n",
      "10866\n",
      "10867\n",
      "10868\n",
      "10869\n",
      "10870\n",
      "10871\n",
      "10872\n",
      "10873\n",
      "10874\n",
      "10875\n",
      "10876\n",
      "10877\n",
      "10878\n",
      "10879\n",
      "10880\n",
      "10881\n",
      "10882\n",
      "10883\n",
      "10884\n",
      "10885\n",
      "10886\n",
      "10887\n",
      "10888\n",
      "10889\n",
      "10890\n",
      "10891\n",
      "10892\n",
      "10893\n",
      "10894\n",
      "10895\n",
      "10896\n",
      "10897\n",
      "10898\n",
      "10899\n",
      "10900\n",
      "10901\n",
      "10902\n",
      "10903\n",
      "10904\n",
      "10905\n",
      "10906\n",
      "10907\n",
      "10908\n",
      "10909\n",
      "10910\n",
      "10911\n",
      "10912\n",
      "10913\n",
      "10914\n",
      "10915\n",
      "10916\n",
      "10917\n",
      "10918\n",
      "10919\n",
      "10920\n",
      "10921\n",
      "10922\n",
      "10923\n",
      "10924\n",
      "10925\n",
      "10926\n",
      "10927\n",
      "10928\n",
      "10929\n",
      "10930\n",
      "10931\n",
      "10932\n",
      "10933\n",
      "10934\n",
      "10935\n",
      "10936\n",
      "10937\n",
      "10938\n",
      "10939\n",
      "10940\n",
      "10941\n",
      "10942\n",
      "10943\n",
      "10944\n",
      "10945\n",
      "10946\n",
      "10947\n",
      "10948\n",
      "10949\n",
      "10950\n",
      "10951\n",
      "10952\n",
      "10953\n",
      "10954\n",
      "10955\n",
      "10956\n",
      "10957\n",
      "10958\n",
      "10959\n",
      "10960\n",
      "10961\n",
      "10962\n",
      "10963\n",
      "10964\n",
      "10965\n",
      "10966\n",
      "10967\n",
      "10968\n",
      "10969\n",
      "10970\n",
      "10971\n",
      "10972\n",
      "10973\n",
      "10974\n",
      "10975\n",
      "10976\n",
      "10977\n",
      "10978\n",
      "10979\n",
      "10980\n",
      "10981\n",
      "10982\n",
      "10983\n",
      "10984\n",
      "10985\n",
      "10986\n",
      "10987\n",
      "10988\n",
      "10989\n",
      "10990\n",
      "10991\n",
      "10992\n",
      "10993\n",
      "10994\n",
      "10995\n",
      "10996\n",
      "10997\n",
      "10998\n",
      "10999\n",
      "11000\n",
      "11001\n",
      "11002\n",
      "11003\n",
      "11004\n",
      "11005\n",
      "11006\n",
      "11007\n",
      "11008\n",
      "11009\n",
      "11010\n",
      "11011\n",
      "11012\n",
      "11013\n",
      "11014\n",
      "11015\n",
      "11016\n",
      "11017\n",
      "11018\n",
      "11019\n",
      "11020\n",
      "11021\n",
      "11022\n",
      "11023\n",
      "11024\n",
      "11025\n",
      "11026\n",
      "11027\n",
      "11028\n",
      "11029\n",
      "11030\n",
      "11031\n",
      "11032\n",
      "11033\n",
      "11034\n",
      "11035\n",
      "11036\n",
      "11037\n",
      "11038\n",
      "11039\n",
      "11040\n",
      "11041\n",
      "11042\n",
      "11043\n",
      "11044\n",
      "11045\n",
      "11046\n",
      "11047\n",
      "11048\n",
      "11049\n",
      "11050\n",
      "11051\n",
      "11052\n",
      "11053\n",
      "11054\n",
      "11055\n",
      "11056\n",
      "11057\n",
      "11058\n",
      "11059\n",
      "11060\n",
      "11061\n",
      "11062\n",
      "11063\n",
      "11064\n",
      "11065\n",
      "11066\n",
      "11067\n",
      "11068\n",
      "11069\n",
      "11070\n",
      "11071\n",
      "11072\n",
      "11073\n",
      "11074\n",
      "11075\n",
      "11076\n",
      "11077\n",
      "11078\n",
      "11079\n",
      "11080\n",
      "11081\n",
      "11082\n",
      "11083\n",
      "11084\n",
      "11085\n",
      "11086\n",
      "11087\n",
      "11088\n",
      "11089\n",
      "11090\n",
      "11091\n",
      "11092\n",
      "11093\n",
      "11094\n",
      "11095\n",
      "11096\n",
      "11097\n",
      "11098\n",
      "11099\n",
      "11100\n",
      "11101\n",
      "11102\n",
      "11103\n",
      "11104\n",
      "11105\n",
      "11106\n",
      "11107\n",
      "11108\n",
      "11109\n",
      "11110\n",
      "11111\n",
      "11112\n",
      "11113\n",
      "11114\n",
      "11115\n",
      "11116\n",
      "11117\n",
      "11118\n",
      "11119\n",
      "11120\n",
      "11121\n",
      "11122\n",
      "11123\n",
      "11124\n",
      "11125\n",
      "11126\n",
      "11127\n",
      "11128\n",
      "11129\n",
      "11130\n",
      "11131\n",
      "11132\n",
      "11133\n",
      "11134\n",
      "11135\n",
      "11136\n",
      "11137\n",
      "11138\n",
      "11139\n",
      "11140\n",
      "11141\n",
      "11142\n",
      "11143\n",
      "11144\n",
      "11145\n",
      "11146\n",
      "11147\n",
      "11148\n",
      "11149\n",
      "11150\n",
      "11151\n",
      "11152\n",
      "11153\n",
      "11154\n",
      "11155\n",
      "11156\n",
      "11157\n",
      "11158\n",
      "11159\n",
      "11160\n",
      "11161\n",
      "11162\n",
      "11163\n",
      "11164\n",
      "11165\n",
      "11166\n",
      "11167\n",
      "11168\n",
      "11169\n",
      "11170\n",
      "11171\n",
      "11172\n",
      "11173\n",
      "11174\n",
      "11175\n",
      "11176\n",
      "11177\n",
      "11178\n",
      "11179\n",
      "11180\n",
      "11181\n",
      "11182\n",
      "11183\n",
      "11184\n",
      "11185\n",
      "11186\n",
      "11187\n",
      "11188\n",
      "11189\n",
      "11190\n",
      "11191\n",
      "11192\n",
      "11193\n",
      "11194\n",
      "11195\n",
      "11196\n",
      "11197\n",
      "11198\n",
      "11199\n",
      "11200\n",
      "11201\n",
      "11202\n",
      "11203\n",
      "11204\n",
      "11205\n",
      "11206\n",
      "11207\n",
      "11208\n",
      "11209\n",
      "11210\n",
      "11211\n",
      "11212\n",
      "11213\n",
      "11214\n",
      "11215\n",
      "11216\n",
      "11217\n",
      "11218\n",
      "11219\n",
      "11220\n",
      "11221\n",
      "11222\n",
      "11223\n",
      "11224\n",
      "11225\n",
      "11226\n",
      "11227\n",
      "11228\n",
      "11229\n",
      "11230\n",
      "11231\n",
      "11232\n",
      "11233\n",
      "11234\n",
      "11235\n",
      "11236\n",
      "11237\n",
      "11238\n",
      "11239\n",
      "11240\n",
      "11241\n",
      "11242\n",
      "11243\n",
      "11244\n",
      "11245\n",
      "11246\n",
      "11247\n",
      "11248\n",
      "11249\n",
      "11250\n",
      "11251\n",
      "11252\n",
      "11253\n",
      "11254\n",
      "11255\n",
      "11256\n",
      "11257\n",
      "11258\n",
      "11259\n",
      "11260\n",
      "11261\n",
      "11262\n",
      "11263\n",
      "11264\n",
      "11265\n",
      "11266\n",
      "11267\n",
      "11268\n",
      "11269\n",
      "11270\n",
      "11271\n",
      "11272\n",
      "11273\n",
      "11274\n",
      "11275\n",
      "11276\n",
      "11277\n",
      "11278\n",
      "11279\n",
      "11280\n",
      "11281\n",
      "11282\n",
      "11283\n",
      "11284\n",
      "11285\n",
      "11286\n",
      "11287\n",
      "11288\n",
      "11289\n",
      "11290\n",
      "11291\n",
      "11292\n",
      "11293\n",
      "11294\n",
      "11295\n",
      "11296\n",
      "11297\n",
      "11298\n",
      "11299\n",
      "11300\n",
      "11301\n",
      "11302\n",
      "11303\n",
      "11304\n",
      "11305\n",
      "11306\n",
      "11307\n",
      "11308\n",
      "11309\n",
      "11310\n",
      "11311\n",
      "11312\n",
      "11313\n",
      "11314\n",
      "11315\n",
      "11316\n",
      "11317\n",
      "11318\n",
      "11319\n",
      "11320\n",
      "11321\n",
      "11322\n",
      "11323\n",
      "11324\n",
      "11325\n",
      "11326\n",
      "11327\n",
      "11328\n",
      "11329\n",
      "11330\n",
      "11331\n",
      "11332\n",
      "11333\n",
      "11334\n",
      "11335\n",
      "11336\n",
      "11337\n",
      "11338\n",
      "11339\n",
      "11340\n",
      "11341\n",
      "11342\n",
      "11343\n",
      "11344\n",
      "11345\n",
      "11346\n",
      "11347\n",
      "11348\n",
      "11349\n",
      "11350\n",
      "11351\n",
      "11352\n",
      "11353\n",
      "11354\n",
      "11355\n",
      "11356\n",
      "11357\n",
      "11358\n",
      "11359\n",
      "11360\n",
      "11361\n",
      "11362\n",
      "11363\n",
      "11364\n",
      "11365\n",
      "11366\n",
      "11367\n",
      "11368\n",
      "11369\n",
      "11370\n",
      "11371\n",
      "11372\n",
      "11373\n",
      "11374\n",
      "11375\n",
      "11376\n",
      "11377\n",
      "11378\n",
      "11379\n",
      "11380\n",
      "11381\n",
      "11382\n",
      "11383\n",
      "11384\n",
      "11385\n",
      "11386\n",
      "11387\n",
      "11388\n",
      "11389\n",
      "11390\n",
      "11391\n",
      "11392\n",
      "11393\n",
      "11394\n",
      "11395\n",
      "11396\n",
      "11397\n",
      "11398\n",
      "11399\n",
      "11400\n",
      "11401\n",
      "11402\n",
      "11403\n",
      "11404\n",
      "11405\n",
      "11406\n",
      "11407\n",
      "11408\n",
      "11409\n",
      "11410\n",
      "11411\n",
      "11412\n",
      "11413\n",
      "11414\n",
      "11415\n",
      "11416\n",
      "11417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11418\n",
      "11419\n",
      "11420\n",
      "11421\n",
      "11422\n",
      "11423\n",
      "11424\n",
      "11425\n",
      "11426\n",
      "11427\n",
      "11428\n",
      "11429\n",
      "11430\n",
      "11431\n",
      "11432\n",
      "11433\n",
      "11434\n",
      "11435\n",
      "11436\n",
      "11437\n",
      "11438\n",
      "11439\n",
      "11440\n",
      "11441\n",
      "11442\n",
      "11443\n",
      "11444\n",
      "11445\n",
      "11446\n",
      "11447\n",
      "11448\n",
      "11449\n",
      "11450\n",
      "11451\n",
      "11452\n",
      "11453\n",
      "11454\n",
      "11455\n",
      "11456\n",
      "11457\n",
      "11458\n",
      "11459\n",
      "11460\n",
      "11461\n",
      "11462\n",
      "11463\n",
      "11464\n",
      "11465\n",
      "11466\n",
      "11467\n",
      "11468\n",
      "11469\n",
      "11470\n",
      "11471\n",
      "11472\n",
      "11473\n",
      "11474\n",
      "11475\n",
      "11476\n",
      "11477\n",
      "11478\n",
      "11479\n",
      "11480\n",
      "11481\n",
      "11482\n",
      "11483\n",
      "11484\n",
      "11485\n",
      "11486\n",
      "11487\n",
      "11488\n",
      "11489\n",
      "11490\n",
      "11491\n",
      "11492\n",
      "11493\n",
      "11494\n",
      "11495\n",
      "11496\n",
      "11497\n",
      "11498\n",
      "11499\n",
      "11500\n",
      "11501\n",
      "11502\n",
      "11503\n",
      "11504\n",
      "11505\n",
      "11506\n",
      "11507\n",
      "11508\n",
      "11509\n",
      "11510\n",
      "11511\n",
      "11512\n",
      "11513\n",
      "11514\n",
      "11515\n",
      "11516\n",
      "11517\n",
      "11518\n",
      "11519\n",
      "11520\n",
      "11521\n",
      "11522\n",
      "11523\n",
      "11524\n",
      "11525\n",
      "11526\n",
      "11527\n",
      "11528\n",
      "11529\n",
      "11530\n",
      "11531\n",
      "11532\n",
      "11533\n",
      "11534\n",
      "11535\n",
      "11536\n",
      "11537\n",
      "11538\n",
      "11539\n",
      "11540\n",
      "11541\n",
      "11542\n",
      "11543\n",
      "11544\n",
      "11545\n",
      "11546\n",
      "11547\n",
      "11548\n",
      "11549\n",
      "11550\n",
      "11551\n",
      "11552\n",
      "11553\n",
      "11554\n",
      "11555\n",
      "11556\n",
      "11557\n",
      "11558\n",
      "11559\n",
      "11560\n",
      "11561\n",
      "11562\n",
      "11563\n",
      "11564\n",
      "11565\n",
      "11566\n",
      "11567\n",
      "11568\n",
      "11569\n",
      "11570\n",
      "11571\n",
      "11572\n",
      "11573\n",
      "11574\n",
      "11575\n",
      "11576\n",
      "11577\n",
      "11578\n",
      "11579\n",
      "11580\n",
      "11581\n",
      "11582\n",
      "11583\n",
      "11584\n",
      "11585\n",
      "11586\n",
      "11587\n",
      "11588\n",
      "11589\n",
      "11590\n",
      "11591\n",
      "11592\n",
      "11593\n",
      "11594\n",
      "11595\n",
      "11596\n",
      "11597\n",
      "11598\n",
      "11599\n",
      "11600\n",
      "11601\n",
      "11602\n",
      "11603\n",
      "11604\n",
      "11605\n",
      "11606\n",
      "11607\n",
      "11608\n",
      "11609\n",
      "11610\n",
      "11611\n",
      "11612\n",
      "11613\n",
      "11614\n",
      "11615\n",
      "11616\n",
      "11617\n",
      "11618\n",
      "11619\n",
      "11620\n",
      "11621\n",
      "11622\n",
      "11623\n",
      "11624\n",
      "11625\n",
      "11626\n",
      "11627\n",
      "11628\n",
      "11629\n",
      "11630\n",
      "11631\n",
      "11632\n",
      "11633\n",
      "11634\n",
      "11635\n",
      "11636\n",
      "11637\n",
      "11638\n",
      "11639\n",
      "11640\n",
      "11641\n",
      "11642\n",
      "11643\n",
      "11644\n",
      "11645\n",
      "11646\n",
      "11647\n",
      "11648\n",
      "11649\n",
      "11650\n",
      "11651\n",
      "11652\n",
      "11653\n",
      "11654\n",
      "11655\n",
      "11656\n",
      "11657\n",
      "11658\n",
      "11659\n",
      "11660\n",
      "11661\n",
      "11662\n",
      "11663\n",
      "11664\n",
      "11665\n",
      "11666\n",
      "11667\n",
      "11668\n",
      "11669\n",
      "11670\n",
      "11671\n",
      "11672\n",
      "11673\n",
      "11674\n",
      "11675\n",
      "11676\n",
      "11677\n",
      "11678\n",
      "11679\n",
      "11680\n",
      "11681\n",
      "11682\n",
      "11683\n",
      "11684\n",
      "11685\n",
      "11686\n",
      "11687\n",
      "11688\n",
      "11689\n",
      "11690\n",
      "11691\n",
      "11692\n",
      "11693\n",
      "11694\n",
      "11695\n",
      "11696\n",
      "11697\n",
      "11698\n",
      "11699\n",
      "11700\n",
      "11701\n",
      "11702\n",
      "11703\n",
      "11704\n",
      "11705\n",
      "11706\n",
      "11707\n",
      "11708\n",
      "11709\n",
      "11710\n",
      "11711\n",
      "11712\n",
      "11713\n",
      "11714\n",
      "11715\n",
      "11716\n",
      "11717\n",
      "11718\n",
      "11719\n",
      "11720\n",
      "11721\n",
      "11722\n",
      "11723\n",
      "11724\n",
      "11725\n",
      "11726\n",
      "11727\n",
      "11728\n",
      "11729\n",
      "11730\n",
      "11731\n",
      "11732\n",
      "11733\n",
      "11734\n",
      "11735\n",
      "11736\n",
      "11737\n",
      "11738\n",
      "11739\n",
      "11740\n",
      "11741\n",
      "11742\n",
      "11743\n",
      "11744\n",
      "11745\n",
      "11746\n",
      "11747\n",
      "11748\n",
      "11749\n",
      "11750\n",
      "11751\n",
      "11752\n",
      "11753\n",
      "11754\n",
      "11755\n",
      "11756\n",
      "11757\n",
      "11758\n",
      "11759\n",
      "11760\n",
      "11761\n",
      "11762\n",
      "11763\n",
      "11764\n",
      "11765\n",
      "11766\n",
      "11767\n",
      "11768\n",
      "11769\n",
      "11770\n",
      "11771\n",
      "11772\n",
      "11773\n",
      "11774\n",
      "11775\n",
      "11776\n",
      "11777\n",
      "11778\n",
      "11779\n",
      "11780\n",
      "11781\n",
      "11782\n",
      "11783\n",
      "11784\n",
      "11785\n",
      "11786\n",
      "11787\n",
      "11788\n",
      "11789\n",
      "11790\n",
      "11791\n",
      "11792\n",
      "11793\n",
      "11794\n",
      "11795\n",
      "11796\n",
      "11797\n",
      "11798\n",
      "11799\n",
      "11800\n",
      "11801\n",
      "11802\n",
      "11803\n",
      "11804\n",
      "11805\n",
      "11806\n",
      "11807\n",
      "11808\n",
      "11809\n",
      "11810\n",
      "11811\n",
      "11812\n",
      "11813\n",
      "11814\n",
      "11815\n",
      "11816\n",
      "11817\n",
      "11818\n",
      "11819\n",
      "11820\n",
      "11821\n",
      "11822\n",
      "11823\n",
      "11824\n",
      "11825\n",
      "11826\n",
      "11827\n",
      "11828\n",
      "11829\n",
      "11830\n",
      "11831\n",
      "11832\n",
      "11833\n",
      "11834\n",
      "11835\n",
      "11836\n",
      "11837\n",
      "11838\n",
      "11839\n",
      "11840\n",
      "11841\n",
      "11842\n",
      "11843\n",
      "11844\n",
      "11845\n",
      "11846\n",
      "11847\n",
      "11848\n",
      "11849\n",
      "11850\n",
      "11851\n",
      "11852\n",
      "11853\n",
      "11854\n",
      "11855\n",
      "11856\n",
      "11857\n",
      "11858\n",
      "11859\n",
      "11860\n",
      "11861\n",
      "11862\n",
      "11863\n",
      "11864\n",
      "11865\n",
      "11866\n",
      "11867\n",
      "11868\n",
      "11869\n",
      "11870\n",
      "11871\n",
      "11872\n",
      "11873\n",
      "11874\n",
      "11875\n",
      "11876\n",
      "11877\n",
      "11878\n",
      "11879\n",
      "11880\n",
      "11881\n",
      "11882\n",
      "11883\n",
      "11884\n",
      "11885\n",
      "11886\n",
      "11887\n",
      "11888\n",
      "11889\n",
      "11890\n",
      "11891\n",
      "11892\n",
      "11893\n",
      "11894\n",
      "11895\n",
      "11896\n",
      "11897\n",
      "11898\n",
      "11899\n",
      "11900\n",
      "11901\n",
      "11902\n",
      "11903\n",
      "11904\n",
      "11905\n",
      "11906\n",
      "11907\n",
      "11908\n",
      "11909\n",
      "11910\n",
      "11911\n",
      "11912\n",
      "11913\n",
      "11914\n",
      "11915\n",
      "11916\n",
      "11917\n",
      "11918\n",
      "11919\n",
      "11920\n",
      "11921\n",
      "11922\n",
      "11923\n",
      "11924\n",
      "11925\n",
      "11926\n",
      "11927\n",
      "11928\n",
      "11929\n",
      "11930\n",
      "11931\n",
      "11932\n",
      "11933\n",
      "11934\n",
      "11935\n",
      "11936\n",
      "11937\n",
      "11938\n",
      "11939\n",
      "11940\n",
      "11941\n",
      "11942\n",
      "11943\n",
      "11944\n",
      "11945\n",
      "11946\n",
      "11947\n",
      "11948\n",
      "11949\n",
      "11950\n",
      "11951\n",
      "11952\n",
      "11953\n",
      "11954\n",
      "11955\n",
      "11956\n",
      "11957\n",
      "11958\n",
      "11959\n",
      "11960\n",
      "11961\n",
      "11962\n",
      "11963\n",
      "11964\n",
      "11965\n",
      "11966\n",
      "11967\n",
      "11968\n",
      "11969\n",
      "11970\n",
      "11971\n",
      "11972\n",
      "11973\n",
      "11974\n",
      "11975\n",
      "11976\n",
      "11977\n",
      "11978\n",
      "11979\n",
      "11980\n",
      "11981\n",
      "11982\n",
      "11983\n",
      "11984\n",
      "11985\n",
      "11986\n",
      "11987\n",
      "11988\n",
      "11989\n",
      "11990\n",
      "11991\n",
      "11992\n",
      "11993\n",
      "11994\n",
      "11995\n",
      "11996\n",
      "11997\n",
      "11998\n",
      "11999\n",
      "12000\n",
      "12001\n",
      "12002\n",
      "12003\n",
      "12004\n",
      "12005\n",
      "12006\n",
      "12007\n",
      "12008\n",
      "12009\n",
      "12010\n",
      "12011\n",
      "12012\n",
      "12013\n",
      "12014\n",
      "12015\n",
      "12016\n",
      "12017\n",
      "12018\n",
      "12019\n",
      "12020\n",
      "12021\n",
      "12022\n",
      "12023\n",
      "12024\n",
      "12025\n",
      "12026\n",
      "12027\n",
      "12028\n",
      "12029\n",
      "12030\n",
      "12031\n",
      "12032\n",
      "12033\n",
      "12034\n",
      "12035\n",
      "12036\n",
      "12037\n",
      "12038\n",
      "12039\n",
      "12040\n",
      "12041\n",
      "12042\n",
      "12043\n",
      "12044\n",
      "12045\n",
      "12046\n",
      "12047\n",
      "12048\n",
      "12049\n",
      "12050\n",
      "12051\n",
      "12052\n",
      "12053\n",
      "12054\n",
      "12055\n",
      "12056\n",
      "12057\n",
      "12058\n",
      "12059\n",
      "12060\n",
      "12061\n",
      "12062\n",
      "12063\n",
      "12064\n",
      "12065\n",
      "12066\n",
      "12067\n",
      "12068\n",
      "12069\n",
      "12070\n",
      "12071\n",
      "12072\n",
      "12073\n",
      "12074\n",
      "12075\n",
      "12076\n",
      "12077\n",
      "12078\n",
      "12079\n",
      "12080\n",
      "12081\n",
      "12082\n",
      "12083\n",
      "12084\n",
      "12085\n",
      "12086\n",
      "12087\n",
      "12088\n",
      "12089\n",
      "12090\n",
      "12091\n",
      "12092\n",
      "12093\n",
      "12094\n",
      "12095\n",
      "12096\n",
      "12097\n",
      "12098\n",
      "12099\n",
      "12100\n",
      "12101\n",
      "12102\n",
      "12103\n",
      "12104\n",
      "12105\n",
      "12106\n",
      "12107\n",
      "12108\n",
      "12109\n",
      "12110\n",
      "12111\n",
      "12112\n",
      "12113\n",
      "12114\n",
      "12115\n",
      "12116\n",
      "12117\n",
      "12118\n",
      "12119\n",
      "12120\n",
      "12121\n",
      "12122\n",
      "12123\n",
      "12124\n",
      "12125\n",
      "12126\n",
      "12127\n",
      "12128\n",
      "12129\n",
      "12130\n",
      "12131\n",
      "12132\n",
      "12133\n",
      "12134\n",
      "12135\n",
      "12136\n",
      "12137\n",
      "12138\n",
      "12139\n",
      "12140\n",
      "12141\n",
      "12142\n",
      "12143\n",
      "12144\n",
      "12145\n",
      "12146\n",
      "12147\n",
      "12148\n",
      "12149\n",
      "12150\n",
      "12151\n",
      "12152\n",
      "12153\n",
      "12154\n",
      "12155\n",
      "12156\n",
      "12157\n",
      "12158\n",
      "12159\n",
      "12160\n",
      "12161\n",
      "12162\n",
      "12163\n",
      "12164\n",
      "12165\n",
      "12166\n",
      "12167\n",
      "12168\n",
      "12169\n",
      "12170\n",
      "12171\n",
      "12172\n",
      "12173\n",
      "12174\n",
      "12175\n",
      "12176\n",
      "12177\n",
      "12178\n",
      "12179\n",
      "12180\n",
      "12181\n",
      "12182\n",
      "12183\n",
      "12184\n",
      "12185\n",
      "12186\n",
      "12187\n",
      "12188\n",
      "12189\n",
      "12190\n",
      "12191\n",
      "12192\n",
      "12193\n",
      "12194\n",
      "12195\n",
      "12196\n",
      "12197\n",
      "12198\n",
      "12199\n",
      "12200\n",
      "12201\n",
      "12202\n",
      "12203\n",
      "12204\n",
      "12205\n",
      "12206\n",
      "12207\n",
      "12208\n",
      "12209\n",
      "12210\n",
      "12211\n",
      "12212\n",
      "12213\n",
      "12214\n",
      "12215\n",
      "12216\n",
      "12217\n",
      "12218\n",
      "12219\n",
      "12220\n",
      "12221\n",
      "12222\n",
      "12223\n",
      "12224\n",
      "12225\n",
      "12226\n",
      "12227\n",
      "12228\n",
      "12229\n",
      "12230\n",
      "12231\n",
      "12232\n",
      "12233\n",
      "12234\n",
      "12235\n",
      "12236\n",
      "12237\n",
      "12238\n",
      "12239\n",
      "12240\n",
      "12241\n",
      "12242\n",
      "12243\n",
      "12244\n",
      "12245\n",
      "12246\n",
      "12247\n",
      "12248\n",
      "12249\n",
      "12250\n",
      "12251\n",
      "12252\n",
      "12253\n",
      "12254\n",
      "12255\n",
      "12256\n",
      "12257\n",
      "12258\n",
      "12259\n",
      "12260\n",
      "12261\n",
      "12262\n",
      "12263\n",
      "12264\n",
      "12265\n",
      "12266\n",
      "12267\n",
      "12268\n",
      "12269\n",
      "12270\n",
      "12271\n",
      "12272\n",
      "12273\n",
      "12274\n",
      "12275\n",
      "12276\n",
      "12277\n",
      "12278\n",
      "12279\n",
      "12280\n",
      "12281\n",
      "12282\n",
      "12283\n",
      "12284\n",
      "12285\n",
      "12286\n",
      "12287\n",
      "12288\n",
      "12289\n",
      "12290\n",
      "12291\n",
      "12292\n",
      "12293\n",
      "12294\n",
      "12295\n",
      "12296\n",
      "12297\n",
      "12298\n",
      "12299\n",
      "12300\n",
      "12301\n",
      "12302\n",
      "12303\n",
      "12304\n",
      "12305\n",
      "12306\n",
      "12307\n",
      "12308\n",
      "12309\n",
      "12310\n",
      "12311\n",
      "12312\n",
      "12313\n",
      "12314\n",
      "12315\n",
      "12316\n",
      "12317\n",
      "12318\n",
      "12319\n",
      "12320\n",
      "12321\n",
      "12322\n",
      "12323\n",
      "12324\n",
      "12325\n",
      "12326\n",
      "12327\n",
      "12328\n",
      "12329\n",
      "12330\n",
      "12331\n",
      "12332\n",
      "12333\n",
      "12334\n",
      "12335\n",
      "12336\n",
      "12337\n",
      "12338\n",
      "12339\n",
      "12340\n",
      "12341\n",
      "12342\n",
      "12343\n",
      "12344\n",
      "12345\n",
      "12346\n",
      "12347\n",
      "12348\n",
      "12349\n",
      "12350\n",
      "12351\n",
      "12352\n",
      "12353\n",
      "12354\n",
      "12355\n",
      "12356\n",
      "12357\n",
      "12358\n",
      "12359\n",
      "12360\n",
      "12361\n",
      "12362\n",
      "12363\n",
      "12364\n",
      "12365\n",
      "12366\n",
      "12367\n",
      "12368\n",
      "12369\n",
      "12370\n",
      "12371\n",
      "12372\n",
      "12373\n",
      "12374\n",
      "12375\n",
      "12376\n",
      "12377\n",
      "12378\n",
      "12379\n",
      "12380\n",
      "12381\n",
      "12382\n",
      "12383\n",
      "12384\n",
      "12385\n",
      "12386\n",
      "12387\n",
      "12388\n",
      "12389\n",
      "12390\n",
      "12391\n",
      "12392\n",
      "12393\n",
      "12394\n",
      "12395\n",
      "12396\n",
      "12397\n",
      "12398\n",
      "12399\n",
      "12400\n",
      "12401\n",
      "12402\n",
      "12403\n",
      "12404\n",
      "12405\n",
      "12406\n",
      "12407\n",
      "12408\n",
      "12409\n",
      "12410\n",
      "12411\n",
      "12412\n",
      "12413\n",
      "12414\n",
      "12415\n",
      "12416\n",
      "12417\n",
      "12418\n",
      "12419\n",
      "12420\n",
      "12421\n",
      "12422\n",
      "12423\n",
      "12424\n",
      "12425\n",
      "12426\n",
      "12427\n",
      "12428\n",
      "12429\n",
      "12430\n",
      "12431\n",
      "12432\n",
      "12433\n",
      "12434\n",
      "12435\n",
      "12436\n",
      "12437\n",
      "12438\n",
      "12439\n",
      "12440\n",
      "12441\n",
      "12442\n",
      "12443\n",
      "12444\n",
      "12445\n",
      "12446\n",
      "12447\n",
      "12448\n",
      "12449\n",
      "12450\n",
      "12451\n",
      "12452\n",
      "12453\n",
      "12454\n",
      "12455\n",
      "12456\n",
      "12457\n",
      "12458\n",
      "12459\n",
      "12460\n",
      "12461\n",
      "12462\n",
      "12463\n",
      "12464\n",
      "12465\n",
      "12466\n",
      "12467\n",
      "12468\n",
      "12469\n",
      "12470\n",
      "12471\n",
      "12472\n",
      "12473\n",
      "12474\n",
      "12475\n",
      "12476\n",
      "12477\n",
      "12478\n",
      "12479\n",
      "12480\n",
      "12481\n",
      "12482\n",
      "12483\n",
      "12484\n",
      "12485\n",
      "12486\n",
      "12487\n",
      "12488\n",
      "12489\n",
      "12490\n",
      "12491\n",
      "12492\n",
      "12493\n",
      "12494\n",
      "12495\n",
      "12496\n",
      "12497\n",
      "12498\n",
      "12499\n",
      "12500\n",
      "12501\n",
      "12502\n",
      "12503\n",
      "12504\n",
      "12505\n",
      "12506\n",
      "12507\n",
      "12508\n",
      "12509\n",
      "12510\n",
      "12511\n",
      "12512\n",
      "12513\n",
      "12514\n",
      "12515\n",
      "12516\n",
      "12517\n",
      "12518\n",
      "12519\n",
      "12520\n",
      "12521\n",
      "12522\n",
      "12523\n",
      "12524\n",
      "12525\n",
      "12526\n",
      "12527\n",
      "12528\n",
      "12529\n",
      "12530\n",
      "12531\n",
      "12532\n",
      "12533\n",
      "12534\n",
      "12535\n",
      "12536\n",
      "12537\n",
      "12538\n",
      "12539\n",
      "12540\n",
      "12541\n",
      "12542\n",
      "12543\n",
      "12544\n",
      "12545\n",
      "12546\n",
      "12547\n",
      "12548\n",
      "12549\n",
      "12550\n",
      "12551\n",
      "12552\n",
      "12553\n",
      "12554\n",
      "12555\n",
      "12556\n",
      "12557\n",
      "12558\n",
      "12559\n",
      "12560\n",
      "12561\n",
      "12562\n",
      "12563\n",
      "12564\n",
      "12565\n",
      "12566\n",
      "12567\n",
      "12568\n",
      "12569\n",
      "12570\n",
      "12571\n",
      "12572\n",
      "12573\n",
      "12574\n",
      "12575\n",
      "12576\n",
      "12577\n",
      "12578\n",
      "12579\n",
      "12580\n",
      "12581\n",
      "12582\n",
      "12583\n",
      "12584\n",
      "12585\n",
      "12586\n",
      "12587\n",
      "12588\n",
      "12589\n",
      "12590\n",
      "12591\n",
      "12592\n",
      "12593\n",
      "12594\n",
      "12595\n",
      "12596\n",
      "12597\n",
      "12598\n",
      "12599\n",
      "12600\n",
      "12601\n",
      "12602\n",
      "12603\n",
      "12604\n",
      "12605\n",
      "12606\n",
      "12607\n",
      "12608\n",
      "12609\n",
      "12610\n",
      "12611\n",
      "12612\n",
      "12613\n",
      "12614\n",
      "12615\n",
      "12616\n",
      "12617\n",
      "12618\n",
      "12619\n",
      "12620\n",
      "12621\n",
      "12622\n",
      "12623\n",
      "12624\n",
      "12625\n",
      "12626\n",
      "12627\n",
      "12628\n",
      "12629\n",
      "12630\n",
      "12631\n",
      "12632\n",
      "12633\n",
      "12634\n",
      "12635\n",
      "12636\n",
      "12637\n",
      "12638\n",
      "12639\n",
      "12640\n",
      "12641\n",
      "12642\n",
      "12643\n",
      "12644\n",
      "12645\n",
      "12646\n",
      "12647\n",
      "12648\n",
      "12649\n",
      "12650\n",
      "12651\n",
      "12652\n",
      "12653\n",
      "12654\n",
      "12655\n",
      "12656\n",
      "12657\n",
      "12658\n",
      "12659\n",
      "12660\n",
      "12661\n",
      "12662\n",
      "12663\n",
      "12664\n",
      "12665\n",
      "12666\n",
      "12667\n",
      "12668\n",
      "12669\n",
      "12670\n",
      "12671\n",
      "12672\n",
      "12673\n",
      "12674\n",
      "12675\n",
      "12676\n",
      "12677\n",
      "12678\n",
      "12679\n",
      "12680\n",
      "12681\n",
      "12682\n",
      "12683\n",
      "12684\n",
      "12685\n",
      "12686\n",
      "12687\n",
      "12688\n",
      "12689\n",
      "12690\n",
      "12691\n",
      "12692\n",
      "12693\n",
      "12694\n",
      "12695\n",
      "12696\n",
      "12697\n",
      "12698\n",
      "12699\n",
      "12700\n",
      "12701\n",
      "12702\n",
      "12703\n",
      "12704\n",
      "12705\n",
      "12706\n",
      "12707\n",
      "12708\n",
      "12709\n",
      "12710\n",
      "12711\n",
      "12712\n",
      "12713\n",
      "12714\n",
      "12715\n",
      "12716\n",
      "12717\n",
      "12718\n",
      "12719\n",
      "12720\n",
      "12721\n",
      "12722\n",
      "12723\n",
      "12724\n",
      "12725\n",
      "12726\n",
      "12727\n",
      "12728\n",
      "12729\n",
      "12730\n",
      "12731\n",
      "12732\n",
      "12733\n",
      "12734\n",
      "12735\n",
      "12736\n",
      "12737\n",
      "12738\n",
      "12739\n",
      "12740\n",
      "12741\n",
      "12742\n",
      "12743\n",
      "12744\n",
      "12745\n",
      "12746\n",
      "12747\n",
      "12748\n",
      "12749\n",
      "12750\n",
      "12751\n",
      "12752\n",
      "12753\n",
      "12754\n",
      "12755\n",
      "12756\n",
      "12757\n",
      "12758\n",
      "12759\n",
      "12760\n",
      "12761\n",
      "12762\n",
      "12763\n",
      "12764\n",
      "12765\n",
      "12766\n",
      "12767\n",
      "12768\n",
      "12769\n",
      "12770\n",
      "12771\n",
      "12772\n",
      "12773\n",
      "12774\n",
      "12775\n",
      "12776\n",
      "12777\n",
      "12778\n",
      "12779\n",
      "12780\n",
      "12781\n",
      "12782\n",
      "12783\n",
      "12784\n",
      "12785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12786\n",
      "12787\n",
      "12788\n",
      "12789\n",
      "12790\n",
      "12791\n",
      "12792\n",
      "12793\n",
      "12794\n",
      "12795\n",
      "12796\n",
      "12797\n",
      "12798\n",
      "12799\n",
      "12800\n",
      "12801\n",
      "12802\n",
      "12803\n",
      "12804\n",
      "12805\n",
      "12806\n",
      "12807\n",
      "12808\n",
      "12809\n",
      "12810\n",
      "12811\n",
      "12812\n",
      "12813\n",
      "12814\n",
      "12815\n",
      "12816\n",
      "12817\n",
      "12818\n",
      "12819\n",
      "12820\n",
      "12821\n",
      "12822\n",
      "12823\n",
      "12824\n",
      "12825\n",
      "12826\n",
      "12827\n",
      "12828\n",
      "12829\n",
      "12830\n",
      "12831\n",
      "12832\n",
      "12833\n",
      "12834\n",
      "12835\n",
      "12836\n",
      "12837\n",
      "12838\n",
      "12839\n",
      "12840\n",
      "12841\n",
      "12842\n",
      "12843\n",
      "12844\n",
      "12845\n",
      "12846\n",
      "12847\n",
      "12848\n",
      "12849\n",
      "12850\n",
      "12851\n",
      "12852\n",
      "12853\n",
      "12854\n",
      "12855\n",
      "12856\n",
      "12857\n",
      "12858\n",
      "12859\n",
      "12860\n",
      "12861\n",
      "12862\n",
      "12863\n",
      "12864\n",
      "12865\n",
      "12866\n",
      "12867\n",
      "12868\n",
      "12869\n",
      "12870\n",
      "12871\n",
      "12872\n",
      "12873\n",
      "12874\n",
      "12875\n",
      "12876\n",
      "12877\n",
      "12878\n",
      "12879\n",
      "12880\n",
      "12881\n",
      "12882\n",
      "12883\n",
      "12884\n",
      "12885\n",
      "12886\n",
      "12887\n",
      "12888\n",
      "12889\n",
      "12890\n",
      "12891\n",
      "12892\n",
      "12893\n",
      "12894\n",
      "12895\n",
      "12896\n",
      "12897\n",
      "12898\n",
      "12899\n",
      "12900\n",
      "12901\n",
      "12902\n",
      "12903\n",
      "12904\n",
      "12905\n",
      "12906\n",
      "12907\n",
      "12908\n",
      "12909\n",
      "12910\n",
      "12911\n",
      "12912\n",
      "12913\n",
      "12914\n",
      "12915\n",
      "12916\n",
      "12917\n",
      "12918\n",
      "12919\n",
      "12920\n",
      "12921\n",
      "12922\n",
      "12923\n",
      "12924\n",
      "12925\n",
      "12926\n",
      "12927\n",
      "12928\n",
      "12929\n",
      "12930\n",
      "12931\n",
      "12932\n",
      "12933\n",
      "12934\n",
      "12935\n",
      "12936\n",
      "12937\n",
      "12938\n",
      "12939\n",
      "12940\n",
      "12941\n",
      "12942\n",
      "12943\n",
      "12944\n",
      "12945\n",
      "12946\n",
      "12947\n",
      "12948\n",
      "12949\n",
      "12950\n",
      "12951\n",
      "12952\n",
      "12953\n",
      "12954\n",
      "12955\n",
      "12956\n",
      "12957\n",
      "12958\n",
      "12959\n",
      "12960\n",
      "12961\n",
      "12962\n",
      "12963\n",
      "12964\n",
      "12965\n",
      "12966\n",
      "12967\n",
      "12968\n",
      "12969\n",
      "12970\n",
      "12971\n",
      "12972\n",
      "12973\n",
      "12974\n",
      "12975\n",
      "12976\n",
      "12977\n",
      "12978\n",
      "12979\n",
      "12980\n",
      "12981\n",
      "12982\n",
      "12983\n",
      "12984\n",
      "12985\n",
      "12986\n",
      "12987\n",
      "12988\n",
      "12989\n",
      "12990\n",
      "12991\n",
      "12992\n",
      "12993\n",
      "12994\n",
      "12995\n",
      "12996\n",
      "12997\n",
      "12998\n",
      "12999\n",
      "13000\n",
      "13001\n",
      "13002\n",
      "13003\n",
      "13004\n",
      "13005\n",
      "13006\n",
      "13007\n",
      "13008\n",
      "13009\n",
      "13010\n",
      "13011\n",
      "13012\n",
      "13013\n",
      "13014\n",
      "13015\n",
      "13016\n",
      "13017\n",
      "13018\n",
      "13019\n",
      "13020\n",
      "13021\n",
      "13022\n",
      "13023\n",
      "13024\n",
      "13025\n",
      "13026\n",
      "13027\n",
      "13028\n",
      "13029\n",
      "13030\n",
      "13031\n",
      "13032\n",
      "13033\n",
      "13034\n",
      "13035\n",
      "13036\n",
      "13037\n",
      "13038\n",
      "13039\n",
      "13040\n",
      "13041\n",
      "13042\n",
      "13043\n",
      "13044\n",
      "13045\n",
      "13046\n",
      "13047\n",
      "13048\n",
      "13049\n",
      "13050\n",
      "13051\n",
      "13052\n",
      "13053\n",
      "13054\n",
      "13055\n",
      "13056\n",
      "13057\n",
      "13058\n",
      "13059\n",
      "13060\n",
      "13061\n",
      "13062\n",
      "13063\n",
      "13064\n",
      "13065\n",
      "13066\n",
      "13067\n",
      "13068\n",
      "13069\n",
      "13070\n",
      "13071\n",
      "13072\n",
      "13073\n",
      "13074\n",
      "13075\n",
      "13076\n",
      "13077\n",
      "13078\n",
      "13079\n",
      "13080\n",
      "13081\n",
      "13082\n",
      "13083\n",
      "13084\n",
      "13085\n",
      "13086\n",
      "13087\n",
      "13088\n",
      "13089\n",
      "13090\n",
      "13091\n",
      "13092\n",
      "13093\n",
      "13094\n",
      "13095\n",
      "13096\n",
      "13097\n",
      "13098\n",
      "13099\n",
      "13100\n",
      "13101\n",
      "13102\n",
      "13103\n",
      "13104\n",
      "13105\n",
      "13106\n",
      "13107\n",
      "13108\n",
      "13109\n",
      "13110\n",
      "13111\n",
      "13112\n",
      "13113\n",
      "13114\n",
      "13115\n",
      "13116\n",
      "13117\n",
      "13118\n",
      "13119\n",
      "13120\n",
      "13121\n",
      "13122\n",
      "13123\n",
      "13124\n",
      "13125\n",
      "13126\n",
      "13127\n",
      "13128\n",
      "13129\n",
      "13130\n",
      "13131\n",
      "13132\n",
      "13133\n",
      "13134\n",
      "13135\n",
      "13136\n",
      "13137\n",
      "13138\n",
      "13139\n",
      "13140\n",
      "13141\n",
      "13142\n",
      "13143\n",
      "13144\n",
      "13145\n",
      "13146\n",
      "13147\n",
      "13148\n",
      "13149\n",
      "13150\n",
      "13151\n",
      "13152\n",
      "13153\n",
      "13154\n",
      "13155\n",
      "13156\n",
      "13157\n",
      "13158\n",
      "13159\n",
      "13160\n",
      "13161\n",
      "13162\n",
      "13163\n",
      "13164\n",
      "13165\n",
      "13166\n",
      "13167\n",
      "13168\n",
      "13169\n",
      "13170\n",
      "13171\n",
      "13172\n",
      "13173\n",
      "13174\n",
      "13175\n",
      "13176\n",
      "13177\n",
      "13178\n",
      "13179\n",
      "13180\n",
      "13181\n",
      "13182\n",
      "13183\n",
      "13184\n",
      "13185\n",
      "13186\n",
      "13187\n",
      "13188\n",
      "13189\n",
      "13190\n",
      "13191\n",
      "13192\n",
      "13193\n",
      "13194\n",
      "13195\n",
      "13196\n",
      "13197\n",
      "13198\n",
      "13199\n",
      "13200\n",
      "13201\n",
      "13202\n",
      "13203\n",
      "13204\n",
      "13205\n",
      "13206\n",
      "13207\n",
      "13208\n",
      "13209\n",
      "13210\n",
      "13211\n",
      "13212\n",
      "13213\n",
      "13214\n",
      "13215\n",
      "13216\n",
      "13217\n",
      "13218\n",
      "13219\n",
      "13220\n",
      "13221\n",
      "13222\n",
      "13223\n",
      "13224\n",
      "13225\n",
      "13226\n",
      "13227\n",
      "13228\n",
      "13229\n",
      "13230\n",
      "13231\n",
      "13232\n",
      "13233\n",
      "13234\n",
      "13235\n",
      "13236\n",
      "13237\n",
      "13238\n",
      "13239\n",
      "13240\n",
      "13241\n",
      "13242\n",
      "13243\n",
      "13244\n",
      "13245\n",
      "13246\n",
      "13247\n",
      "13248\n",
      "13249\n",
      "13250\n",
      "13251\n",
      "13252\n",
      "13253\n",
      "13254\n",
      "13255\n",
      "13256\n",
      "13257\n",
      "13258\n",
      "13259\n",
      "13260\n",
      "13261\n",
      "13262\n",
      "13263\n",
      "13264\n",
      "13265\n",
      "13266\n",
      "13267\n",
      "13268\n",
      "13269\n",
      "13270\n",
      "13271\n",
      "13272\n",
      "13273\n",
      "13274\n",
      "13275\n",
      "13276\n",
      "13277\n",
      "13278\n",
      "13279\n",
      "13280\n",
      "13281\n",
      "13282\n",
      "13283\n",
      "13284\n",
      "13285\n",
      "13286\n",
      "13287\n",
      "13288\n",
      "13289\n",
      "13290\n",
      "13291\n",
      "13292\n",
      "13293\n",
      "13294\n",
      "13295\n",
      "13296\n",
      "13297\n",
      "13298\n",
      "13299\n",
      "13300\n",
      "13301\n",
      "13302\n",
      "13303\n",
      "13304\n",
      "13305\n",
      "13306\n",
      "13307\n",
      "13308\n",
      "13309\n",
      "13310\n",
      "13311\n",
      "13312\n",
      "13313\n",
      "13314\n",
      "13315\n",
      "13316\n",
      "13317\n",
      "13318\n",
      "13319\n",
      "13320\n",
      "13321\n",
      "13322\n",
      "13323\n",
      "13324\n",
      "13325\n",
      "13326\n",
      "13327\n",
      "13328\n",
      "13329\n",
      "13330\n",
      "13331\n",
      "13332\n",
      "13333\n",
      "13334\n",
      "13335\n",
      "13336\n",
      "13337\n",
      "13338\n",
      "13339\n",
      "13340\n",
      "13341\n",
      "13342\n",
      "13343\n",
      "13344\n",
      "13345\n",
      "13346\n",
      "13347\n",
      "13348\n",
      "13349\n",
      "13350\n",
      "13351\n",
      "13352\n",
      "13353\n",
      "13354\n",
      "13355\n",
      "13356\n",
      "13357\n",
      "13358\n",
      "13359\n",
      "13360\n",
      "13361\n",
      "13362\n",
      "13363\n",
      "13364\n",
      "13365\n",
      "13366\n",
      "13367\n",
      "13368\n",
      "13369\n",
      "13370\n",
      "13371\n",
      "13372\n",
      "13373\n",
      "13374\n",
      "13375\n",
      "13376\n",
      "13377\n",
      "13378\n",
      "13379\n",
      "13380\n",
      "13381\n",
      "13382\n",
      "13383\n",
      "13384\n",
      "13385\n",
      "13386\n",
      "13387\n",
      "13388\n",
      "13389\n",
      "13390\n",
      "13391\n",
      "13392\n",
      "13393\n",
      "13394\n",
      "13395\n",
      "13396\n",
      "13397\n",
      "13398\n",
      "13399\n",
      "13400\n",
      "13401\n",
      "13402\n",
      "13403\n",
      "13404\n",
      "13405\n",
      "13406\n",
      "13407\n",
      "13408\n",
      "13409\n",
      "13410\n",
      "13411\n",
      "13412\n",
      "13413\n",
      "13414\n",
      "13415\n",
      "13416\n",
      "13417\n",
      "13418\n",
      "13419\n",
      "13420\n",
      "13421\n",
      "13422\n",
      "13423\n",
      "13424\n",
      "13425\n",
      "13426\n",
      "13427\n",
      "13428\n",
      "13429\n",
      "13430\n",
      "13431\n",
      "13432\n",
      "13433\n",
      "13434\n",
      "13435\n",
      "13436\n",
      "13437\n",
      "13438\n",
      "13439\n",
      "13440\n",
      "13441\n",
      "13442\n",
      "13443\n",
      "13444\n",
      "13445\n",
      "13446\n",
      "13447\n",
      "13448\n",
      "13449\n",
      "13450\n",
      "13451\n",
      "13452\n",
      "13453\n",
      "13454\n",
      "13455\n",
      "13456\n",
      "13457\n",
      "13458\n",
      "13459\n",
      "13460\n",
      "13461\n",
      "13462\n",
      "13463\n",
      "13464\n",
      "13465\n",
      "13466\n",
      "13467\n",
      "13468\n",
      "13469\n",
      "13470\n",
      "13471\n",
      "13472\n",
      "13473\n",
      "13474\n",
      "13475\n",
      "13476\n",
      "13477\n",
      "13478\n",
      "13479\n",
      "13480\n",
      "13481\n",
      "13482\n",
      "13483\n",
      "13484\n",
      "13485\n",
      "13486\n",
      "13487\n",
      "13488\n",
      "13489\n",
      "13490\n",
      "13491\n",
      "13492\n",
      "13493\n",
      "13494\n",
      "13495\n",
      "13496\n",
      "13497\n",
      "13498\n",
      "13499\n",
      "13500\n",
      "13501\n",
      "13502\n",
      "13503\n",
      "13504\n",
      "13505\n",
      "13506\n",
      "13507\n",
      "13508\n",
      "13509\n",
      "13510\n",
      "13511\n",
      "13512\n",
      "13513\n",
      "13514\n",
      "13515\n",
      "13516\n",
      "13517\n",
      "13518\n",
      "13519\n",
      "13520\n",
      "13521\n",
      "13522\n",
      "13523\n",
      "13524\n",
      "13525\n",
      "13526\n",
      "13527\n",
      "13528\n",
      "13529\n",
      "13530\n",
      "13531\n",
      "13532\n",
      "13533\n",
      "13534\n",
      "13535\n",
      "13536\n",
      "13537\n",
      "13538\n",
      "13539\n",
      "13540\n",
      "13541\n",
      "13542\n",
      "13543\n",
      "13544\n",
      "13545\n",
      "13546\n",
      "13547\n",
      "13548\n",
      "13549\n",
      "13550\n",
      "13551\n",
      "13552\n",
      "13553\n",
      "13554\n",
      "13555\n",
      "13556\n",
      "13557\n",
      "13558\n",
      "13559\n",
      "13560\n",
      "13561\n",
      "13562\n",
      "13563\n",
      "13564\n",
      "13565\n",
      "13566\n",
      "13567\n",
      "13568\n",
      "13569\n",
      "13570\n",
      "13571\n",
      "13572\n",
      "13573\n",
      "13574\n",
      "13575\n",
      "13576\n",
      "13577\n",
      "13578\n",
      "13579\n",
      "13580\n",
      "13581\n",
      "13582\n",
      "13583\n",
      "13584\n",
      "13585\n",
      "13586\n",
      "13587\n",
      "13588\n",
      "13589\n",
      "13590\n",
      "13591\n",
      "13592\n",
      "13593\n",
      "13594\n",
      "13595\n",
      "13596\n",
      "13597\n",
      "13598\n",
      "13599\n",
      "13600\n",
      "13601\n",
      "13602\n",
      "13603\n",
      "13604\n",
      "13605\n",
      "13606\n",
      "13607\n",
      "13608\n",
      "13609\n",
      "13610\n",
      "13611\n",
      "13612\n",
      "13613\n",
      "13614\n",
      "13615\n",
      "13616\n",
      "13617\n",
      "13618\n",
      "13619\n",
      "13620\n",
      "13621\n",
      "13622\n",
      "13623\n",
      "13624\n",
      "13625\n",
      "13626\n",
      "13627\n",
      "13628\n",
      "13629\n",
      "13630\n",
      "13631\n",
      "13632\n",
      "13633\n",
      "13634\n",
      "13635\n",
      "13636\n",
      "13637\n",
      "13638\n",
      "13639\n",
      "13640\n",
      "13641\n",
      "13642\n",
      "13643\n",
      "13644\n",
      "13645\n",
      "13646\n",
      "13647\n",
      "13648\n",
      "13649\n",
      "13650\n",
      "13651\n",
      "13652\n",
      "13653\n",
      "13654\n",
      "13655\n",
      "13656\n",
      "13657\n",
      "13658\n",
      "13659\n",
      "13660\n",
      "13661\n",
      "13662\n",
      "13663\n",
      "13664\n",
      "13665\n",
      "13666\n",
      "13667\n",
      "13668\n",
      "13669\n",
      "13670\n",
      "13671\n",
      "13672\n",
      "13673\n",
      "13674\n",
      "13675\n",
      "13676\n",
      "13677\n",
      "13678\n",
      "13679\n",
      "13680\n",
      "13681\n",
      "13682\n",
      "13683\n",
      "13684\n",
      "13685\n",
      "13686\n",
      "13687\n",
      "13688\n",
      "13689\n",
      "13690\n",
      "13691\n",
      "13692\n",
      "13693\n",
      "13694\n",
      "13695\n",
      "13696\n",
      "13697\n",
      "13698\n",
      "13699\n",
      "13700\n",
      "13701\n",
      "13702\n",
      "13703\n",
      "13704\n",
      "13705\n",
      "13706\n",
      "13707\n",
      "13708\n",
      "13709\n",
      "13710\n",
      "13711\n",
      "13712\n",
      "13713\n",
      "13714\n",
      "13715\n",
      "13716\n",
      "13717\n",
      "13718\n",
      "13719\n",
      "13720\n",
      "13721\n",
      "13722\n",
      "13723\n",
      "13724\n",
      "13725\n",
      "13726\n",
      "13727\n",
      "13728\n",
      "13729\n",
      "13730\n",
      "13731\n",
      "13732\n",
      "13733\n",
      "13734\n",
      "13735\n",
      "13736\n",
      "13737\n",
      "13738\n",
      "13739\n",
      "13740\n",
      "13741\n",
      "13742\n",
      "13743\n",
      "13744\n",
      "13745\n",
      "13746\n",
      "13747\n",
      "13748\n",
      "13749\n",
      "13750\n",
      "13751\n",
      "13752\n",
      "13753\n",
      "13754\n",
      "13755\n",
      "13756\n",
      "13757\n",
      "13758\n",
      "13759\n",
      "13760\n",
      "13761\n",
      "13762\n",
      "13763\n",
      "13764\n",
      "13765\n",
      "13766\n",
      "13767\n",
      "13768\n",
      "13769\n",
      "13770\n",
      "13771\n",
      "13772\n",
      "13773\n",
      "13774\n",
      "13775\n",
      "13776\n",
      "13777\n",
      "13778\n",
      "13779\n",
      "13780\n",
      "13781\n",
      "13782\n",
      "13783\n",
      "13784\n",
      "13785\n",
      "13786\n",
      "13787\n",
      "13788\n",
      "13789\n",
      "13790\n",
      "13791\n",
      "13792\n",
      "13793\n",
      "13794\n",
      "13795\n",
      "13796\n",
      "13797\n",
      "13798\n",
      "13799\n",
      "13800\n",
      "13801\n",
      "13802\n",
      "13803\n",
      "13804\n",
      "13805\n",
      "13806\n",
      "13807\n",
      "13808\n",
      "13809\n",
      "13810\n",
      "13811\n",
      "13812\n",
      "13813\n",
      "13814\n",
      "13815\n",
      "13816\n",
      "13817\n",
      "13818\n",
      "13819\n",
      "13820\n",
      "13821\n",
      "13822\n",
      "13823\n",
      "13824\n",
      "13825\n",
      "13826\n",
      "13827\n",
      "13828\n",
      "13829\n",
      "13830\n",
      "13831\n",
      "13832\n",
      "13833\n",
      "13834\n",
      "13835\n",
      "13836\n",
      "13837\n",
      "13838\n",
      "13839\n",
      "13840\n",
      "13841\n",
      "13842\n",
      "13843\n",
      "13844\n",
      "13845\n",
      "13846\n",
      "13847\n",
      "13848\n",
      "13849\n",
      "13850\n",
      "13851\n",
      "13852\n",
      "13853\n",
      "13854\n",
      "13855\n",
      "13856\n",
      "13857\n",
      "13858\n",
      "13859\n",
      "13860\n",
      "13861\n",
      "13862\n",
      "13863\n",
      "13864\n",
      "13865\n",
      "13866\n",
      "13867\n",
      "13868\n",
      "13869\n",
      "13870\n",
      "13871\n",
      "13872\n",
      "13873\n",
      "13874\n",
      "13875\n",
      "13876\n",
      "13877\n",
      "13878\n",
      "13879\n",
      "13880\n",
      "13881\n",
      "13882\n",
      "13883\n",
      "13884\n",
      "13885\n",
      "13886\n",
      "13887\n",
      "13888\n",
      "13889\n",
      "13890\n",
      "13891\n",
      "13892\n",
      "13893\n",
      "13894\n",
      "13895\n",
      "13896\n",
      "13897\n",
      "13898\n",
      "13899\n",
      "13900\n",
      "13901\n",
      "13902\n",
      "13903\n",
      "13904\n",
      "13905\n",
      "13906\n",
      "13907\n",
      "13908\n",
      "13909\n",
      "13910\n",
      "13911\n",
      "13912\n",
      "13913\n",
      "13914\n",
      "13915\n",
      "13916\n",
      "13917\n",
      "13918\n",
      "13919\n",
      "13920\n",
      "13921\n",
      "13922\n",
      "13923\n",
      "13924\n",
      "13925\n",
      "13926\n",
      "13927\n",
      "13928\n",
      "13929\n",
      "13930\n",
      "13931\n",
      "13932\n",
      "13933\n",
      "13934\n",
      "13935\n",
      "13936\n",
      "13937\n",
      "13938\n",
      "13939\n",
      "13940\n",
      "13941\n",
      "13942\n",
      "13943\n",
      "13944\n",
      "13945\n",
      "13946\n",
      "13947\n",
      "13948\n",
      "13949\n",
      "13950\n",
      "13951\n",
      "13952\n",
      "13953\n",
      "13954\n",
      "13955\n",
      "13956\n",
      "13957\n",
      "13958\n",
      "13959\n",
      "13960\n",
      "13961\n",
      "13962\n",
      "13963\n",
      "13964\n",
      "13965\n",
      "13966\n",
      "13967\n",
      "13968\n",
      "13969\n",
      "13970\n",
      "13971\n",
      "13972\n",
      "13973\n",
      "13974\n",
      "13975\n",
      "13976\n",
      "13977\n",
      "13978\n",
      "13979\n",
      "13980\n",
      "13981\n",
      "13982\n",
      "13983\n",
      "13984\n",
      "13985\n",
      "13986\n",
      "13987\n",
      "13988\n",
      "13989\n",
      "13990\n",
      "13991\n",
      "13992\n",
      "13993\n",
      "13994\n",
      "13995\n",
      "13996\n",
      "13997\n",
      "13998\n",
      "13999\n",
      "14000\n",
      "14001\n",
      "14002\n",
      "14003\n",
      "14004\n",
      "14005\n",
      "14006\n",
      "14007\n",
      "14008\n",
      "14009\n",
      "14010\n",
      "14011\n",
      "14012\n",
      "14013\n",
      "14014\n",
      "14015\n",
      "14016\n",
      "14017\n",
      "14018\n",
      "14019\n",
      "14020\n",
      "14021\n",
      "14022\n",
      "14023\n",
      "14024\n",
      "14025\n",
      "14026\n",
      "14027\n",
      "14028\n",
      "14029\n",
      "14030\n",
      "14031\n",
      "14032\n",
      "14033\n",
      "14034\n",
      "14035\n",
      "14036\n",
      "14037\n",
      "14038\n",
      "14039\n",
      "14040\n",
      "14041\n",
      "14042\n",
      "14043\n",
      "14044\n",
      "14045\n",
      "14046\n",
      "14047\n",
      "14048\n",
      "14049\n",
      "14050\n",
      "14051\n",
      "14052\n",
      "14053\n",
      "14054\n",
      "14055\n",
      "14056\n",
      "14057\n",
      "14058\n",
      "14059\n",
      "14060\n",
      "14061\n",
      "14062\n",
      "14063\n",
      "14064\n",
      "14065\n",
      "14066\n",
      "14067\n",
      "14068\n",
      "14069\n",
      "14070\n",
      "14071\n",
      "14072\n",
      "14073\n",
      "14074\n",
      "14075\n",
      "14076\n",
      "14077\n",
      "14078\n",
      "14079\n",
      "14080\n",
      "14081\n",
      "14082\n",
      "14083\n",
      "14084\n",
      "14085\n",
      "14086\n",
      "14087\n",
      "14088\n",
      "14089\n",
      "14090\n",
      "14091\n",
      "14092\n",
      "14093\n",
      "14094\n",
      "14095\n",
      "14096\n",
      "14097\n",
      "14098\n",
      "14099\n",
      "14100\n",
      "14101\n",
      "14102\n",
      "14103\n",
      "14104\n",
      "14105\n",
      "14106\n",
      "14107\n",
      "14108\n",
      "14109\n",
      "14110\n",
      "14111\n",
      "14112\n",
      "14113\n",
      "14114\n",
      "14115\n",
      "14116\n",
      "14117\n",
      "14118\n",
      "14119\n",
      "14120\n",
      "14121\n",
      "14122\n",
      "14123\n",
      "14124\n",
      "14125\n",
      "14126\n",
      "14127\n",
      "14128\n",
      "14129\n",
      "14130\n",
      "14131\n",
      "14132\n",
      "14133\n",
      "14134\n",
      "14135\n",
      "14136\n",
      "14137\n",
      "14138\n",
      "14139\n",
      "14140\n",
      "14141\n",
      "14142\n",
      "14143\n",
      "14144\n",
      "14145\n",
      "14146\n",
      "14147\n",
      "14148\n",
      "14149\n",
      "14150\n",
      "14151\n",
      "14152\n",
      "14153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14154\n",
      "14155\n",
      "14156\n",
      "14157\n",
      "14158\n",
      "14159\n",
      "14160\n",
      "14161\n",
      "14162\n",
      "14163\n",
      "14164\n",
      "14165\n",
      "14166\n",
      "14167\n",
      "14168\n",
      "14169\n",
      "14170\n",
      "14171\n",
      "14172\n",
      "14173\n",
      "14174\n",
      "14175\n",
      "14176\n",
      "14177\n",
      "14178\n",
      "14179\n",
      "14180\n",
      "14181\n",
      "14182\n",
      "14183\n",
      "14184\n",
      "14185\n",
      "14186\n",
      "14187\n",
      "14188\n",
      "14189\n",
      "14190\n",
      "14191\n",
      "14192\n",
      "14193\n",
      "14194\n",
      "14195\n",
      "14196\n",
      "14197\n",
      "14198\n",
      "14199\n",
      "14200\n",
      "14201\n",
      "14202\n",
      "14203\n",
      "14204\n",
      "14205\n",
      "14206\n",
      "14207\n",
      "14208\n",
      "14209\n",
      "14210\n",
      "14211\n",
      "14212\n",
      "14213\n",
      "14214\n",
      "14215\n",
      "14216\n",
      "14217\n",
      "14218\n",
      "14219\n",
      "14220\n",
      "14221\n",
      "14222\n",
      "14223\n",
      "14224\n",
      "14225\n",
      "14226\n",
      "14227\n",
      "14228\n",
      "14229\n",
      "14230\n",
      "14231\n",
      "14232\n",
      "14233\n",
      "14234\n",
      "14235\n",
      "14236\n",
      "14237\n",
      "14238\n",
      "14239\n",
      "14240\n",
      "14241\n",
      "14242\n",
      "14243\n",
      "14244\n",
      "14245\n",
      "14246\n",
      "14247\n",
      "14248\n",
      "14249\n",
      "14250\n",
      "14251\n",
      "14252\n",
      "14253\n",
      "14254\n",
      "14255\n",
      "14256\n",
      "14257\n",
      "14258\n",
      "14259\n",
      "14260\n",
      "14261\n",
      "14262\n",
      "14263\n",
      "14264\n",
      "14265\n",
      "14266\n",
      "14267\n",
      "14268\n",
      "14269\n",
      "14270\n",
      "14271\n",
      "14272\n",
      "14273\n",
      "14274\n",
      "14275\n",
      "14276\n",
      "14277\n",
      "14278\n",
      "14279\n",
      "14280\n",
      "14281\n",
      "14282\n",
      "14283\n",
      "14284\n",
      "14285\n",
      "14286\n",
      "14287\n",
      "14288\n",
      "14289\n",
      "14290\n",
      "14291\n",
      "14292\n",
      "14293\n",
      "14294\n",
      "14295\n",
      "14296\n",
      "14297\n",
      "14298\n",
      "14299\n",
      "14300\n",
      "14301\n",
      "14302\n",
      "14303\n",
      "14304\n",
      "14305\n",
      "14306\n",
      "14307\n",
      "14308\n",
      "14309\n",
      "14310\n",
      "14311\n",
      "14312\n",
      "14313\n",
      "14314\n",
      "14315\n",
      "14316\n",
      "14317\n",
      "14318\n",
      "14319\n",
      "14320\n",
      "14321\n",
      "14322\n",
      "14323\n",
      "14324\n",
      "14325\n",
      "14326\n",
      "14327\n",
      "14328\n",
      "14329\n",
      "14330\n",
      "14331\n",
      "14332\n",
      "14333\n",
      "14334\n",
      "14335\n",
      "14336\n",
      "14337\n",
      "14338\n",
      "14339\n",
      "14340\n",
      "14341\n",
      "14342\n",
      "14343\n",
      "14344\n",
      "14345\n",
      "14346\n",
      "14347\n",
      "14348\n",
      "14349\n",
      "14350\n",
      "14351\n",
      "14352\n",
      "14353\n",
      "14354\n",
      "14355\n",
      "14356\n",
      "14357\n",
      "14358\n",
      "14359\n",
      "14360\n",
      "14361\n",
      "14362\n",
      "14363\n",
      "14364\n",
      "14365\n",
      "14366\n",
      "14367\n",
      "14368\n",
      "14369\n",
      "14370\n",
      "14371\n",
      "14372\n",
      "14373\n",
      "14374\n",
      "14375\n",
      "14376\n",
      "14377\n",
      "14378\n",
      "14379\n",
      "14380\n",
      "14381\n",
      "14382\n",
      "14383\n",
      "14384\n",
      "14385\n",
      "14386\n",
      "14387\n",
      "14388\n",
      "14389\n",
      "14390\n",
      "14391\n",
      "14392\n",
      "14393\n",
      "14394\n",
      "14395\n",
      "14396\n",
      "14397\n",
      "14398\n",
      "14399\n",
      "14400\n",
      "14401\n",
      "14402\n",
      "14403\n",
      "14404\n",
      "14405\n",
      "14406\n",
      "14407\n",
      "14408\n",
      "14409\n",
      "14410\n",
      "14411\n",
      "14412\n",
      "14413\n",
      "14414\n",
      "14415\n",
      "14416\n",
      "14417\n",
      "14418\n",
      "14419\n",
      "14420\n",
      "14421\n",
      "14422\n",
      "14423\n",
      "14424\n",
      "14425\n",
      "14426\n",
      "14427\n",
      "14428\n",
      "14429\n",
      "14430\n",
      "14431\n",
      "14432\n",
      "14433\n",
      "14434\n",
      "14435\n",
      "14436\n",
      "14437\n",
      "14438\n",
      "14439\n",
      "14440\n",
      "14441\n",
      "14442\n",
      "14443\n",
      "14444\n",
      "14445\n",
      "14446\n",
      "14447\n",
      "14448\n",
      "14449\n",
      "14450\n",
      "14451\n",
      "14452\n",
      "14453\n",
      "14454\n",
      "14455\n",
      "14456\n",
      "14457\n",
      "14458\n",
      "14459\n",
      "14460\n",
      "14461\n",
      "14462\n",
      "14463\n",
      "14464\n",
      "14465\n",
      "14466\n",
      "14467\n",
      "14468\n",
      "14469\n",
      "14470\n",
      "14471\n",
      "14472\n",
      "14473\n",
      "14474\n",
      "14475\n",
      "14476\n",
      "14477\n",
      "14478\n",
      "14479\n",
      "14480\n",
      "14481\n",
      "14482\n",
      "14483\n",
      "14484\n",
      "14485\n",
      "14486\n",
      "14487\n",
      "14488\n",
      "14489\n",
      "14490\n",
      "14491\n",
      "14492\n",
      "14493\n",
      "14494\n",
      "14495\n",
      "14496\n",
      "14497\n",
      "14498\n",
      "14499\n",
      "14500\n",
      "14501\n",
      "14502\n",
      "14503\n",
      "14504\n",
      "14505\n",
      "14506\n",
      "14507\n",
      "14508\n",
      "14509\n",
      "14510\n",
      "14511\n",
      "14512\n",
      "14513\n",
      "14514\n",
      "14515\n",
      "14516\n",
      "14517\n",
      "14518\n",
      "14519\n",
      "14520\n",
      "14521\n",
      "14522\n",
      "14523\n",
      "14524\n",
      "14525\n",
      "14526\n",
      "14527\n",
      "14528\n",
      "14529\n",
      "14530\n",
      "14531\n",
      "14532\n",
      "14533\n",
      "14534\n",
      "14535\n",
      "14536\n",
      "14537\n",
      "14538\n",
      "14539\n",
      "14540\n",
      "14541\n",
      "14542\n",
      "14543\n",
      "14544\n",
      "14545\n",
      "14546\n",
      "14547\n",
      "14548\n",
      "14549\n",
      "14550\n",
      "14551\n",
      "14552\n",
      "14553\n",
      "14554\n",
      "14555\n",
      "14556\n",
      "14557\n",
      "14558\n",
      "14559\n",
      "14560\n",
      "14561\n",
      "14562\n",
      "14563\n",
      "14564\n",
      "14565\n",
      "14566\n",
      "14567\n",
      "14568\n",
      "14569\n",
      "14570\n",
      "14571\n",
      "14572\n",
      "14573\n",
      "14574\n",
      "14575\n",
      "14576\n",
      "14577\n",
      "14578\n",
      "14579\n",
      "14580\n",
      "14581\n",
      "14582\n",
      "14583\n",
      "14584\n",
      "14585\n",
      "14586\n",
      "14587\n",
      "14588\n",
      "14589\n",
      "14590\n",
      "14591\n",
      "14592\n",
      "14593\n",
      "14594\n",
      "14595\n",
      "14596\n",
      "14597\n",
      "14598\n",
      "14599\n",
      "14600\n",
      "14601\n",
      "14602\n",
      "14603\n",
      "14604\n",
      "14605\n",
      "14606\n",
      "14607\n",
      "14608\n",
      "14609\n",
      "14610\n",
      "14611\n",
      "14612\n",
      "14613\n",
      "14614\n",
      "14615\n",
      "14616\n",
      "14617\n",
      "14618\n",
      "14619\n",
      "14620\n",
      "14621\n",
      "14622\n",
      "14623\n",
      "14624\n",
      "14625\n",
      "14626\n",
      "14627\n",
      "14628\n",
      "14629\n",
      "14630\n",
      "14631\n",
      "14632\n",
      "14633\n",
      "14634\n",
      "14635\n",
      "14636\n",
      "14637\n",
      "14638\n",
      "14639\n",
      "14640\n",
      "14641\n",
      "14642\n",
      "14643\n",
      "14644\n",
      "14645\n",
      "14646\n",
      "14647\n",
      "14648\n",
      "14649\n",
      "14650\n",
      "14651\n",
      "14652\n",
      "14653\n",
      "14654\n",
      "14655\n",
      "14656\n",
      "14657\n",
      "14658\n",
      "14659\n",
      "14660\n",
      "14661\n",
      "14662\n",
      "14663\n",
      "14664\n",
      "14665\n",
      "14666\n",
      "14667\n",
      "14668\n",
      "14669\n",
      "14670\n",
      "14671\n",
      "14672\n",
      "14673\n",
      "14674\n",
      "14675\n",
      "14676\n",
      "14677\n",
      "14678\n",
      "14679\n",
      "14680\n",
      "14681\n",
      "14682\n",
      "14683\n",
      "14684\n",
      "14685\n",
      "14686\n",
      "14687\n",
      "14688\n",
      "14689\n",
      "14690\n",
      "14691\n",
      "14692\n",
      "14693\n",
      "14694\n",
      "14695\n",
      "14696\n",
      "14697\n",
      "14698\n",
      "14699\n",
      "14700\n",
      "14701\n",
      "14702\n",
      "14703\n",
      "14704\n",
      "14705\n",
      "14706\n",
      "14707\n",
      "14708\n",
      "14709\n",
      "14710\n",
      "14711\n",
      "14712\n",
      "14713\n",
      "14714\n",
      "14715\n",
      "14716\n",
      "14717\n",
      "14718\n",
      "14719\n",
      "14720\n",
      "14721\n",
      "14722\n",
      "14723\n",
      "14724\n",
      "14725\n",
      "14726\n",
      "14727\n",
      "14728\n",
      "14729\n",
      "14730\n",
      "14731\n",
      "14732\n",
      "14733\n",
      "14734\n",
      "14735\n",
      "14736\n",
      "14737\n",
      "14738\n",
      "14739\n",
      "14740\n",
      "14741\n",
      "14742\n",
      "14743\n",
      "14744\n",
      "14745\n",
      "14746\n",
      "14747\n",
      "14748\n",
      "14749\n",
      "14750\n",
      "14751\n",
      "14752\n",
      "14753\n",
      "14754\n",
      "14755\n",
      "14756\n",
      "14757\n",
      "14758\n",
      "14759\n",
      "14760\n",
      "14761\n",
      "14762\n",
      "14763\n",
      "14764\n",
      "14765\n",
      "14766\n",
      "14767\n",
      "14768\n",
      "14769\n",
      "14770\n",
      "14771\n",
      "14772\n",
      "14773\n",
      "14774\n",
      "14775\n",
      "14776\n",
      "14777\n",
      "14778\n",
      "14779\n",
      "14780\n",
      "14781\n",
      "14782\n",
      "14783\n",
      "14784\n",
      "14785\n",
      "14786\n",
      "14787\n",
      "14788\n",
      "14789\n",
      "14790\n",
      "14791\n",
      "14792\n",
      "14793\n",
      "14794\n",
      "14795\n",
      "14796\n",
      "14797\n",
      "14798\n",
      "14799\n",
      "14800\n",
      "14801\n",
      "14802\n",
      "14803\n",
      "14804\n",
      "14805\n",
      "14806\n",
      "14807\n",
      "14808\n",
      "14809\n",
      "14810\n",
      "14811\n",
      "14812\n",
      "14813\n",
      "14814\n",
      "14815\n",
      "14816\n",
      "14817\n",
      "14818\n",
      "14819\n",
      "14820\n",
      "14821\n",
      "14822\n",
      "14823\n",
      "14824\n",
      "14825\n",
      "14826\n",
      "14827\n",
      "14828\n",
      "14829\n",
      "14830\n",
      "14831\n",
      "14832\n",
      "14833\n",
      "14834\n",
      "14835\n",
      "14836\n",
      "14837\n",
      "14838\n",
      "14839\n",
      "14840\n",
      "14841\n",
      "14842\n",
      "14843\n",
      "14844\n",
      "14845\n",
      "14846\n",
      "14847\n",
      "14848\n",
      "14849\n",
      "14850\n",
      "14851\n",
      "14852\n",
      "14853\n",
      "14854\n",
      "14855\n",
      "14856\n",
      "14857\n",
      "14858\n",
      "14859\n",
      "14860\n",
      "14861\n",
      "14862\n",
      "14863\n",
      "14864\n",
      "14865\n",
      "14866\n",
      "14867\n",
      "14868\n",
      "14869\n",
      "14870\n",
      "14871\n",
      "14872\n",
      "14873\n",
      "14874\n",
      "14875\n",
      "14876\n",
      "14877\n",
      "14878\n",
      "14879\n",
      "14880\n",
      "14881\n",
      "14882\n",
      "14883\n",
      "14884\n",
      "14885\n",
      "14886\n",
      "14887\n",
      "14888\n",
      "14889\n",
      "14890\n",
      "14891\n",
      "14892\n",
      "14893\n",
      "14894\n",
      "14895\n",
      "14896\n",
      "14897\n",
      "14898\n",
      "14899\n",
      "14900\n",
      "14901\n",
      "14902\n",
      "14903\n",
      "14904\n",
      "14905\n",
      "14906\n",
      "14907\n",
      "14908\n",
      "14909\n",
      "14910\n",
      "14911\n",
      "14912\n",
      "14913\n",
      "14914\n",
      "14915\n",
      "14916\n",
      "14917\n",
      "14918\n",
      "14919\n",
      "14920\n",
      "14921\n",
      "14922\n",
      "14923\n",
      "14924\n",
      "14925\n",
      "14926\n",
      "14927\n",
      "14928\n",
      "14929\n",
      "14930\n",
      "14931\n",
      "14932\n",
      "14933\n",
      "14934\n",
      "14935\n",
      "14936\n",
      "14937\n",
      "14938\n",
      "14939\n",
      "14940\n",
      "14941\n",
      "14942\n",
      "14943\n",
      "14944\n",
      "14945\n",
      "14946\n",
      "14947\n",
      "14948\n",
      "14949\n",
      "14950\n",
      "14951\n",
      "14952\n",
      "14953\n",
      "14954\n",
      "14955\n",
      "14956\n",
      "14957\n",
      "14958\n",
      "14959\n",
      "14960\n",
      "14961\n",
      "14962\n",
      "14963\n",
      "14964\n",
      "14965\n",
      "14966\n",
      "14967\n",
      "14968\n",
      "14969\n",
      "14970\n",
      "14971\n",
      "14972\n",
      "14973\n",
      "14974\n",
      "14975\n",
      "14976\n",
      "14977\n",
      "14978\n",
      "14979\n",
      "14980\n",
      "14981\n",
      "14982\n",
      "14983\n",
      "14984\n",
      "14985\n",
      "14986\n",
      "14987\n",
      "14988\n",
      "14989\n",
      "14990\n",
      "14991\n",
      "14992\n",
      "14993\n",
      "14994\n",
      "14995\n",
      "14996\n",
      "14997\n",
      "14998\n",
      "14999\n",
      "15000\n",
      "15001\n",
      "15002\n",
      "15003\n",
      "15004\n",
      "15005\n",
      "15006\n",
      "15007\n",
      "15008\n",
      "15009\n",
      "15010\n",
      "15011\n",
      "15012\n",
      "15013\n",
      "15014\n",
      "15015\n",
      "15016\n",
      "15017\n",
      "15018\n",
      "15019\n",
      "15020\n",
      "15021\n",
      "15022\n",
      "15023\n",
      "15024\n",
      "15025\n",
      "15026\n",
      "15027\n",
      "15028\n",
      "15029\n",
      "15030\n",
      "15031\n",
      "15032\n",
      "15033\n",
      "15034\n",
      "15035\n",
      "15036\n",
      "15037\n",
      "15038\n",
      "15039\n",
      "15040\n",
      "15041\n",
      "15042\n",
      "15043\n",
      "15044\n",
      "15045\n",
      "15046\n",
      "15047\n",
      "15048\n",
      "15049\n",
      "15050\n",
      "15051\n",
      "15052\n",
      "15053\n",
      "15054\n",
      "15055\n",
      "15056\n",
      "15057\n",
      "15058\n",
      "15059\n",
      "15060\n",
      "15061\n",
      "15062\n",
      "15063\n",
      "15064\n",
      "15065\n",
      "15066\n",
      "15067\n",
      "15068\n",
      "15069\n",
      "15070\n",
      "15071\n",
      "15072\n",
      "15073\n",
      "15074\n",
      "15075\n",
      "15076\n",
      "15077\n",
      "15078\n",
      "15079\n",
      "15080\n",
      "15081\n",
      "15082\n",
      "15083\n",
      "15084\n",
      "15085\n",
      "15086\n",
      "15087\n",
      "15088\n",
      "15089\n",
      "15090\n",
      "15091\n",
      "15092\n",
      "15093\n",
      "15094\n",
      "15095\n",
      "15096\n",
      "15097\n",
      "15098\n",
      "15099\n",
      "15100\n",
      "15101\n",
      "15102\n",
      "15103\n",
      "15104\n",
      "15105\n",
      "15106\n",
      "15107\n",
      "15108\n",
      "15109\n",
      "15110\n",
      "15111\n",
      "15112\n",
      "15113\n",
      "15114\n",
      "15115\n",
      "15116\n",
      "15117\n",
      "15118\n",
      "15119\n",
      "15120\n",
      "15121\n",
      "15122\n",
      "15123\n",
      "15124\n",
      "15125\n",
      "15126\n",
      "15127\n",
      "15128\n",
      "15129\n",
      "15130\n",
      "15131\n",
      "15132\n",
      "15133\n",
      "15134\n",
      "15135\n",
      "15136\n",
      "15137\n",
      "15138\n",
      "15139\n",
      "15140\n",
      "15141\n",
      "15142\n",
      "15143\n",
      "15144\n",
      "15145\n",
      "15146\n",
      "15147\n",
      "15148\n",
      "15149\n",
      "15150\n",
      "15151\n",
      "15152\n",
      "15153\n",
      "15154\n",
      "15155\n",
      "15156\n",
      "15157\n",
      "15158\n",
      "15159\n",
      "15160\n",
      "15161\n",
      "15162\n",
      "15163\n",
      "15164\n",
      "15165\n",
      "15166\n",
      "15167\n",
      "15168\n",
      "15169\n",
      "15170\n",
      "15171\n",
      "15172\n",
      "15173\n",
      "15174\n",
      "15175\n",
      "15176\n",
      "15177\n",
      "15178\n",
      "15179\n",
      "15180\n",
      "15181\n",
      "15182\n",
      "15183\n",
      "15184\n",
      "15185\n",
      "15186\n",
      "15187\n",
      "15188\n",
      "15189\n",
      "15190\n",
      "15191\n",
      "15192\n",
      "15193\n",
      "15194\n",
      "15195\n",
      "15196\n",
      "15197\n",
      "15198\n",
      "15199\n",
      "15200\n",
      "15201\n",
      "15202\n",
      "15203\n",
      "15204\n",
      "15205\n",
      "15206\n",
      "15207\n",
      "15208\n",
      "15209\n",
      "15210\n",
      "15211\n",
      "15212\n",
      "15213\n",
      "15214\n",
      "15215\n",
      "15216\n",
      "15217\n",
      "15218\n",
      "15219\n",
      "15220\n",
      "15221\n",
      "15222\n",
      "15223\n",
      "15224\n",
      "15225\n",
      "15226\n",
      "15227\n",
      "15228\n",
      "15229\n",
      "15230\n",
      "15231\n",
      "15232\n",
      "15233\n",
      "15234\n",
      "15235\n",
      "15236\n",
      "15237\n",
      "15238\n",
      "15239\n",
      "15240\n",
      "15241\n",
      "15242\n",
      "15243\n",
      "15244\n",
      "15245\n",
      "15246\n",
      "15247\n",
      "15248\n",
      "15249\n",
      "15250\n",
      "15251\n",
      "15252\n",
      "15253\n",
      "15254\n",
      "15255\n",
      "15256\n",
      "15257\n",
      "15258\n",
      "15259\n",
      "15260\n",
      "15261\n",
      "15262\n",
      "15263\n",
      "15264\n",
      "15265\n",
      "15266\n",
      "15267\n",
      "15268\n",
      "15269\n",
      "15270\n",
      "15271\n",
      "15272\n",
      "15273\n",
      "15274\n",
      "15275\n",
      "15276\n",
      "15277\n",
      "15278\n",
      "15279\n",
      "15280\n",
      "15281\n",
      "15282\n",
      "15283\n",
      "15284\n",
      "15285\n",
      "15286\n",
      "15287\n",
      "15288\n",
      "15289\n",
      "15290\n",
      "15291\n",
      "15292\n",
      "15293\n",
      "15294\n",
      "15295\n",
      "15296\n",
      "15297\n",
      "15298\n",
      "15299\n",
      "15300\n",
      "15301\n",
      "15302\n",
      "15303\n",
      "15304\n",
      "15305\n",
      "15306\n",
      "15307\n",
      "15308\n",
      "15309\n",
      "15310\n",
      "15311\n",
      "15312\n",
      "15313\n",
      "15314\n",
      "15315\n",
      "15316\n",
      "15317\n",
      "15318\n",
      "15319\n",
      "15320\n",
      "15321\n",
      "15322\n",
      "15323\n",
      "15324\n",
      "15325\n",
      "15326\n",
      "15327\n",
      "15328\n",
      "15329\n",
      "15330\n",
      "15331\n",
      "15332\n",
      "15333\n",
      "15334\n",
      "15335\n",
      "15336\n",
      "15337\n",
      "15338\n",
      "15339\n",
      "15340\n",
      "15341\n",
      "15342\n",
      "15343\n",
      "15344\n",
      "15345\n",
      "15346\n",
      "15347\n",
      "15348\n",
      "15349\n",
      "15350\n",
      "15351\n",
      "15352\n",
      "15353\n",
      "15354\n",
      "15355\n",
      "15356\n",
      "15357\n",
      "15358\n",
      "15359\n",
      "15360\n",
      "15361\n",
      "15362\n",
      "15363\n",
      "15364\n",
      "15365\n",
      "15366\n",
      "15367\n",
      "15368\n",
      "15369\n",
      "15370\n",
      "15371\n",
      "15372\n",
      "15373\n",
      "15374\n",
      "15375\n",
      "15376\n",
      "15377\n",
      "15378\n",
      "15379\n",
      "15380\n",
      "15381\n",
      "15382\n",
      "15383\n",
      "15384\n",
      "15385\n",
      "15386\n",
      "15387\n",
      "15388\n",
      "15389\n",
      "15390\n",
      "15391\n",
      "15392\n",
      "15393\n",
      "15394\n",
      "15395\n",
      "15396\n",
      "15397\n",
      "15398\n",
      "15399\n",
      "15400\n",
      "15401\n",
      "15402\n",
      "15403\n",
      "15404\n",
      "15405\n",
      "15406\n",
      "15407\n",
      "15408\n",
      "15409\n",
      "15410\n",
      "15411\n",
      "15412\n",
      "15413\n",
      "15414\n",
      "15415\n",
      "15416\n",
      "15417\n",
      "15418\n",
      "15419\n",
      "15420\n",
      "15421\n",
      "15422\n",
      "15423\n",
      "15424\n",
      "15425\n",
      "15426\n",
      "15427\n",
      "15428\n",
      "15429\n",
      "15430\n",
      "15431\n",
      "15432\n",
      "15433\n",
      "15434\n",
      "15435\n",
      "15436\n",
      "15437\n",
      "15438\n",
      "15439\n",
      "15440\n",
      "15441\n",
      "15442\n",
      "15443\n",
      "15444\n",
      "15445\n",
      "15446\n",
      "15447\n",
      "15448\n",
      "15449\n",
      "15450\n",
      "15451\n",
      "15452\n",
      "15453\n",
      "15454\n",
      "15455\n",
      "15456\n",
      "15457\n",
      "15458\n",
      "15459\n",
      "15460\n",
      "15461\n",
      "15462\n",
      "15463\n",
      "15464\n",
      "15465\n",
      "15466\n",
      "15467\n",
      "15468\n",
      "15469\n",
      "15470\n",
      "15471\n",
      "15472\n",
      "15473\n",
      "15474\n",
      "15475\n",
      "15476\n",
      "15477\n",
      "15478\n",
      "15479\n",
      "15480\n",
      "15481\n",
      "15482\n",
      "15483\n",
      "15484\n",
      "15485\n",
      "15486\n",
      "15487\n",
      "15488\n",
      "15489\n",
      "15490\n",
      "15491\n",
      "15492\n",
      "15493\n",
      "15494\n",
      "15495\n",
      "15496\n",
      "15497\n",
      "15498\n",
      "15499\n",
      "15500\n",
      "15501\n",
      "15502\n",
      "15503\n",
      "15504\n",
      "15505\n",
      "15506\n",
      "15507\n",
      "15508\n",
      "15509\n",
      "15510\n",
      "15511\n",
      "15512\n",
      "15513\n",
      "15514\n",
      "15515\n",
      "15516\n",
      "15517\n",
      "15518\n",
      "15519\n",
      "15520\n",
      "15521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15522\n",
      "15523\n",
      "15524\n",
      "15525\n",
      "15526\n",
      "15527\n",
      "15528\n",
      "15529\n",
      "15530\n",
      "15531\n",
      "15532\n",
      "15533\n",
      "15534\n",
      "15535\n",
      "15536\n",
      "15537\n",
      "15538\n",
      "15539\n",
      "15540\n",
      "15541\n",
      "15542\n",
      "15543\n",
      "15544\n",
      "15545\n",
      "15546\n",
      "15547\n",
      "15548\n",
      "15549\n",
      "15550\n",
      "15551\n",
      "15552\n",
      "15553\n",
      "15554\n",
      "15555\n",
      "15556\n",
      "15557\n",
      "15558\n",
      "15559\n",
      "15560\n",
      "15561\n",
      "15562\n",
      "15563\n",
      "15564\n",
      "15565\n",
      "15566\n",
      "15567\n",
      "15568\n",
      "15569\n",
      "15570\n",
      "15571\n",
      "15572\n",
      "15573\n",
      "15574\n",
      "15575\n",
      "15576\n",
      "15577\n",
      "15578\n",
      "15579\n",
      "15580\n",
      "15581\n",
      "15582\n",
      "15583\n",
      "15584\n",
      "15585\n",
      "15586\n",
      "15587\n",
      "15588\n",
      "15589\n",
      "15590\n",
      "15591\n",
      "15592\n",
      "15593\n",
      "15594\n",
      "15595\n",
      "15596\n",
      "15597\n",
      "15598\n",
      "15599\n",
      "15600\n",
      "15601\n",
      "15602\n",
      "15603\n",
      "15604\n",
      "15605\n",
      "15606\n",
      "15607\n",
      "15608\n",
      "15609\n",
      "15610\n",
      "15611\n",
      "15612\n",
      "15613\n",
      "15614\n",
      "15615\n",
      "15616\n",
      "15617\n",
      "15618\n",
      "15619\n",
      "15620\n",
      "15621\n",
      "15622\n",
      "15623\n",
      "15624\n",
      "15625\n",
      "15626\n",
      "15627\n",
      "15628\n",
      "15629\n",
      "15630\n",
      "15631\n",
      "15632\n",
      "15633\n",
      "15634\n",
      "15635\n",
      "15636\n",
      "15637\n",
      "15638\n",
      "15639\n",
      "15640\n",
      "15641\n",
      "15642\n",
      "15643\n",
      "15644\n",
      "15645\n",
      "15646\n",
      "15647\n",
      "15648\n",
      "15649\n",
      "15650\n",
      "15651\n",
      "15652\n",
      "15653\n",
      "15654\n",
      "15655\n",
      "15656\n",
      "15657\n",
      "15658\n",
      "15659\n",
      "15660\n",
      "15661\n",
      "15662\n",
      "15663\n",
      "15664\n",
      "15665\n",
      "15666\n",
      "15667\n",
      "15668\n",
      "15669\n",
      "15670\n",
      "15671\n",
      "15672\n",
      "15673\n",
      "15674\n",
      "15675\n",
      "15676\n",
      "15677\n",
      "15678\n",
      "15679\n",
      "15680\n",
      "15681\n",
      "15682\n",
      "15683\n",
      "15684\n",
      "15685\n",
      "15686\n",
      "15687\n",
      "15688\n",
      "15689\n",
      "15690\n",
      "15691\n",
      "15692\n",
      "15693\n",
      "15694\n",
      "15695\n",
      "15696\n",
      "15697\n",
      "15698\n",
      "15699\n",
      "15700\n",
      "15701\n",
      "15702\n",
      "15703\n",
      "15704\n",
      "15705\n",
      "15706\n",
      "15707\n",
      "15708\n",
      "15709\n",
      "15710\n",
      "15711\n",
      "15712\n",
      "15713\n",
      "15714\n",
      "15715\n",
      "15716\n",
      "15717\n",
      "15718\n",
      "15719\n",
      "15720\n",
      "15721\n",
      "15722\n",
      "15723\n",
      "15724\n",
      "15725\n",
      "15726\n",
      "15727\n",
      "15728\n",
      "15729\n",
      "15730\n",
      "15731\n",
      "15732\n",
      "15733\n",
      "15734\n",
      "15735\n",
      "15736\n",
      "15737\n",
      "15738\n",
      "15739\n",
      "15740\n",
      "15741\n",
      "15742\n",
      "15743\n",
      "15744\n",
      "15745\n",
      "15746\n",
      "15747\n",
      "15748\n",
      "15749\n",
      "15750\n",
      "15751\n",
      "15752\n",
      "15753\n",
      "15754\n",
      "15755\n",
      "15756\n",
      "15757\n",
      "15758\n",
      "15759\n",
      "15760\n",
      "15761\n",
      "15762\n",
      "15763\n",
      "15764\n",
      "15765\n",
      "15766\n",
      "15767\n",
      "15768\n",
      "15769\n",
      "15770\n",
      "15771\n",
      "15772\n",
      "15773\n",
      "15774\n",
      "15775\n",
      "15776\n",
      "15777\n",
      "15778\n",
      "15779\n",
      "15780\n",
      "15781\n",
      "15782\n",
      "15783\n",
      "15784\n",
      "15785\n",
      "15786\n",
      "15787\n",
      "15788\n",
      "15789\n",
      "15790\n",
      "15791\n",
      "15792\n",
      "15793\n",
      "15794\n",
      "15795\n",
      "15796\n",
      "15797\n",
      "15798\n",
      "15799\n",
      "15800\n",
      "15801\n",
      "15802\n",
      "15803\n",
      "15804\n",
      "15805\n",
      "15806\n",
      "15807\n",
      "15808\n",
      "15809\n",
      "15810\n",
      "15811\n",
      "15812\n",
      "15813\n",
      "15814\n",
      "15815\n",
      "15816\n",
      "15817\n",
      "15818\n",
      "15819\n",
      "15820\n",
      "15821\n",
      "15822\n",
      "15823\n",
      "15824\n",
      "15825\n",
      "15826\n",
      "15827\n",
      "15828\n",
      "15829\n",
      "15830\n",
      "15831\n",
      "15832\n",
      "15833\n",
      "15834\n",
      "15835\n",
      "15836\n",
      "15837\n",
      "15838\n",
      "15839\n",
      "15840\n",
      "15841\n",
      "15842\n",
      "15843\n",
      "15844\n",
      "15845\n",
      "15846\n",
      "15847\n",
      "15848\n",
      "15849\n",
      "15850\n",
      "15851\n",
      "15852\n",
      "15853\n",
      "15854\n",
      "15855\n",
      "15856\n",
      "15857\n",
      "15858\n",
      "15859\n",
      "15860\n",
      "15861\n",
      "15862\n",
      "15863\n",
      "15864\n",
      "15865\n",
      "15866\n",
      "15867\n",
      "15868\n",
      "15869\n",
      "15870\n",
      "15871\n",
      "15872\n",
      "15873\n",
      "15874\n",
      "15875\n",
      "15876\n",
      "15877\n",
      "15878\n",
      "15879\n",
      "15880\n",
      "15881\n",
      "15882\n",
      "15883\n",
      "15884\n",
      "15885\n",
      "15886\n",
      "15887\n",
      "15888\n",
      "15889\n",
      "15890\n",
      "15891\n",
      "15892\n",
      "15893\n",
      "15894\n",
      "15895\n",
      "15896\n",
      "15897\n",
      "15898\n",
      "15899\n",
      "15900\n",
      "15901\n",
      "15902\n",
      "15903\n",
      "15904\n",
      "15905\n",
      "15906\n",
      "15907\n",
      "15908\n",
      "15909\n",
      "15910\n",
      "15911\n",
      "15912\n",
      "15913\n",
      "15914\n",
      "15915\n",
      "15916\n",
      "15917\n",
      "15918\n",
      "15919\n",
      "15920\n",
      "15921\n",
      "15922\n",
      "15923\n",
      "15924\n",
      "15925\n",
      "15926\n",
      "15927\n",
      "15928\n",
      "15929\n",
      "15930\n",
      "15931\n",
      "15932\n",
      "15933\n",
      "15934\n",
      "15935\n",
      "15936\n",
      "15937\n",
      "15938\n",
      "15939\n",
      "15940\n",
      "15941\n",
      "15942\n",
      "15943\n",
      "15944\n",
      "15945\n",
      "15946\n",
      "15947\n",
      "15948\n",
      "15949\n",
      "15950\n",
      "15951\n",
      "15952\n",
      "15953\n",
      "15954\n",
      "15955\n",
      "15956\n",
      "15957\n",
      "15958\n",
      "15959\n",
      "15960\n",
      "15961\n",
      "15962\n",
      "15963\n",
      "15964\n",
      "15965\n",
      "15966\n",
      "15967\n",
      "15968\n",
      "15969\n",
      "15970\n",
      "15971\n",
      "15972\n",
      "15973\n",
      "15974\n",
      "15975\n",
      "15976\n",
      "15977\n",
      "15978\n",
      "15979\n",
      "15980\n",
      "15981\n",
      "15982\n",
      "15983\n",
      "15984\n",
      "15985\n",
      "15986\n",
      "15987\n",
      "15988\n",
      "15989\n",
      "15990\n",
      "15991\n",
      "15992\n",
      "15993\n",
      "15994\n",
      "15995\n",
      "15996\n",
      "15997\n",
      "15998\n",
      "15999\n",
      "16000\n",
      "16001\n",
      "16002\n",
      "16003\n",
      "16004\n",
      "16005\n",
      "16006\n",
      "16007\n",
      "16008\n",
      "16009\n",
      "16010\n",
      "16011\n",
      "16012\n",
      "16013\n",
      "16014\n",
      "16015\n",
      "16016\n",
      "16017\n",
      "16018\n",
      "16019\n",
      "16020\n",
      "16021\n",
      "16022\n",
      "16023\n",
      "16024\n",
      "16025\n",
      "16026\n",
      "16027\n",
      "16028\n",
      "16029\n",
      "16030\n",
      "16031\n",
      "16032\n",
      "16033\n",
      "16034\n",
      "16035\n",
      "16036\n",
      "16037\n",
      "16038\n",
      "16039\n",
      "16040\n",
      "16041\n",
      "16042\n",
      "16043\n",
      "16044\n",
      "16045\n",
      "16046\n",
      "16047\n",
      "16048\n",
      "16049\n",
      "16050\n",
      "16051\n",
      "16052\n",
      "16053\n",
      "16054\n",
      "16055\n",
      "16056\n",
      "16057\n",
      "16058\n",
      "16059\n",
      "16060\n",
      "16061\n",
      "16062\n",
      "16063\n",
      "16064\n",
      "16065\n",
      "16066\n",
      "16067\n",
      "16068\n",
      "16069\n",
      "16070\n",
      "16071\n",
      "16072\n",
      "16073\n",
      "16074\n",
      "16075\n",
      "16076\n",
      "16077\n",
      "16078\n",
      "16079\n",
      "16080\n",
      "16081\n",
      "16082\n",
      "16083\n",
      "16084\n",
      "16085\n",
      "16086\n",
      "16087\n",
      "16088\n",
      "16089\n",
      "16090\n",
      "16091\n",
      "16092\n",
      "16093\n",
      "16094\n",
      "16095\n",
      "16096\n",
      "16097\n",
      "16098\n",
      "16099\n",
      "16100\n",
      "16101\n",
      "16102\n",
      "16103\n",
      "16104\n",
      "16105\n",
      "16106\n",
      "16107\n",
      "16108\n",
      "16109\n",
      "16110\n",
      "16111\n",
      "16112\n",
      "16113\n",
      "16114\n",
      "16115\n",
      "16116\n",
      "16117\n",
      "16118\n",
      "16119\n",
      "16120\n",
      "16121\n",
      "16122\n",
      "16123\n",
      "16124\n",
      "16125\n",
      "16126\n",
      "16127\n",
      "16128\n",
      "16129\n",
      "16130\n",
      "16131\n",
      "16132\n",
      "16133\n",
      "16134\n",
      "16135\n",
      "16136\n",
      "16137\n",
      "16138\n",
      "16139\n",
      "16140\n",
      "16141\n",
      "16142\n",
      "16143\n",
      "16144\n",
      "16145\n",
      "16146\n",
      "16147\n",
      "16148\n",
      "16149\n",
      "16150\n",
      "16151\n",
      "16152\n",
      "16153\n",
      "16154\n",
      "16155\n",
      "16156\n",
      "16157\n",
      "16158\n",
      "16159\n",
      "16160\n",
      "16161\n",
      "16162\n",
      "16163\n",
      "16164\n",
      "16165\n",
      "16166\n",
      "16167\n",
      "16168\n",
      "16169\n",
      "16170\n",
      "16171\n",
      "16172\n",
      "16173\n",
      "16174\n",
      "16175\n",
      "16176\n",
      "16177\n",
      "16178\n",
      "16179\n",
      "16180\n",
      "16181\n",
      "16182\n",
      "16183\n",
      "16184\n",
      "16185\n",
      "16186\n",
      "16187\n",
      "16188\n",
      "16189\n",
      "16190\n",
      "16191\n",
      "16192\n",
      "16193\n",
      "16194\n",
      "16195\n",
      "16196\n",
      "16197\n",
      "16198\n",
      "16199\n",
      "16200\n",
      "16201\n",
      "16202\n",
      "16203\n",
      "16204\n",
      "16205\n",
      "16206\n",
      "16207\n",
      "16208\n",
      "16209\n",
      "16210\n",
      "16211\n",
      "16212\n",
      "16213\n",
      "16214\n",
      "16215\n",
      "16216\n",
      "16217\n",
      "16218\n",
      "16219\n",
      "16220\n",
      "16221\n",
      "16222\n",
      "16223\n",
      "16224\n",
      "16225\n",
      "16226\n",
      "16227\n",
      "16228\n",
      "16229\n",
      "16230\n",
      "16231\n",
      "16232\n",
      "16233\n",
      "16234\n",
      "16235\n",
      "16236\n",
      "16237\n",
      "16238\n",
      "16239\n",
      "16240\n",
      "16241\n",
      "16242\n",
      "16243\n",
      "16244\n",
      "16245\n",
      "16246\n",
      "16247\n",
      "16248\n",
      "16249\n",
      "16250\n",
      "16251\n",
      "16252\n",
      "16253\n",
      "16254\n",
      "16255\n",
      "16256\n",
      "16257\n",
      "16258\n",
      "16259\n",
      "16260\n",
      "16261\n",
      "16262\n",
      "16263\n",
      "16264\n",
      "16265\n",
      "16266\n",
      "16267\n",
      "16268\n",
      "16269\n",
      "16270\n",
      "16271\n",
      "16272\n",
      "16273\n",
      "16274\n",
      "16275\n",
      "16276\n",
      "16277\n",
      "16278\n",
      "16279\n",
      "16280\n",
      "16281\n",
      "16282\n",
      "16283\n",
      "16284\n",
      "16285\n",
      "16286\n",
      "16287\n",
      "16288\n",
      "16289\n",
      "16290\n",
      "16291\n",
      "16292\n",
      "16293\n",
      "16294\n",
      "16295\n",
      "16296\n",
      "16297\n",
      "16298\n",
      "16299\n",
      "16300\n",
      "16301\n",
      "16302\n",
      "16303\n",
      "16304\n",
      "16305\n",
      "16306\n",
      "16307\n",
      "16308\n",
      "16309\n",
      "16310\n",
      "16311\n",
      "16312\n",
      "16313\n",
      "16314\n",
      "16315\n",
      "16316\n",
      "16317\n",
      "16318\n",
      "16319\n",
      "16320\n",
      "16321\n",
      "16322\n",
      "16323\n",
      "16324\n",
      "16325\n",
      "16326\n",
      "16327\n",
      "16328\n",
      "16329\n",
      "16330\n",
      "16331\n",
      "16332\n",
      "16333\n",
      "16334\n",
      "16335\n",
      "16336\n",
      "16337\n",
      "16338\n",
      "16339\n",
      "16340\n",
      "16341\n",
      "16342\n",
      "16343\n",
      "16344\n",
      "16345\n",
      "16346\n",
      "16347\n",
      "16348\n",
      "16349\n",
      "16350\n",
      "16351\n",
      "16352\n",
      "16353\n",
      "16354\n",
      "16355\n",
      "16356\n",
      "16357\n",
      "16358\n",
      "16359\n",
      "16360\n",
      "16361\n",
      "16362\n",
      "16363\n",
      "16364\n",
      "16365\n",
      "16366\n",
      "16367\n",
      "16368\n",
      "16369\n",
      "16370\n",
      "16371\n",
      "16372\n",
      "16373\n",
      "16374\n",
      "16375\n",
      "16376\n",
      "16377\n",
      "16378\n",
      "16379\n",
      "16380\n",
      "16381\n",
      "16382\n",
      "16383\n",
      "16384\n",
      "16385\n",
      "16386\n",
      "16387\n",
      "16388\n",
      "16389\n",
      "16390\n",
      "16391\n",
      "16392\n",
      "16393\n",
      "16394\n",
      "16395\n",
      "16396\n",
      "16397\n",
      "16398\n",
      "16399\n",
      "16400\n",
      "16401\n",
      "16402\n",
      "16403\n",
      "16404\n",
      "16405\n",
      "16406\n",
      "16407\n",
      "16408\n",
      "16409\n",
      "16410\n",
      "16411\n",
      "16412\n",
      "16413\n",
      "16414\n",
      "16415\n",
      "16416\n",
      "16417\n",
      "16418\n",
      "16419\n",
      "16420\n",
      "16421\n",
      "16422\n",
      "16423\n",
      "16424\n",
      "16425\n",
      "16426\n",
      "16427\n",
      "16428\n",
      "16429\n",
      "16430\n",
      "16431\n",
      "16432\n",
      "16433\n",
      "16434\n",
      "16435\n",
      "16436\n",
      "16437\n",
      "16438\n",
      "16439\n",
      "16440\n",
      "16441\n",
      "16442\n",
      "16443\n",
      "16444\n",
      "16445\n",
      "16446\n",
      "16447\n",
      "16448\n",
      "16449\n",
      "16450\n",
      "16451\n",
      "16452\n",
      "16453\n",
      "16454\n",
      "16455\n",
      "16456\n",
      "16457\n",
      "16458\n",
      "16459\n",
      "16460\n",
      "16461\n",
      "16462\n",
      "16463\n",
      "16464\n",
      "16465\n",
      "16466\n",
      "16467\n",
      "16468\n",
      "16469\n",
      "16470\n",
      "16471\n",
      "16472\n",
      "16473\n",
      "16474\n",
      "16475\n",
      "16476\n",
      "16477\n",
      "16478\n",
      "16479\n",
      "16480\n",
      "16481\n",
      "16482\n",
      "16483\n",
      "16484\n",
      "16485\n",
      "16486\n",
      "16487\n",
      "16488\n",
      "16489\n",
      "16490\n",
      "16491\n",
      "16492\n",
      "16493\n",
      "16494\n",
      "16495\n",
      "16496\n",
      "16497\n",
      "16498\n",
      "16499\n",
      "16500\n",
      "16501\n",
      "16502\n",
      "16503\n",
      "16504\n",
      "16505\n",
      "16506\n",
      "16507\n",
      "16508\n",
      "16509\n",
      "16510\n",
      "16511\n",
      "16512\n",
      "16513\n",
      "16514\n",
      "16515\n",
      "16516\n",
      "16517\n",
      "16518\n",
      "16519\n",
      "16520\n",
      "16521\n",
      "16522\n",
      "16523\n",
      "16524\n",
      "16525\n",
      "16526\n",
      "16527\n",
      "16528\n",
      "16529\n",
      "16530\n",
      "16531\n",
      "16532\n",
      "16533\n",
      "16534\n",
      "16535\n",
      "16536\n",
      "16537\n",
      "16538\n",
      "16539\n",
      "16540\n",
      "16541\n",
      "16542\n",
      "16543\n",
      "16544\n",
      "16545\n",
      "16546\n",
      "16547\n",
      "16548\n",
      "16549\n",
      "16550\n",
      "16551\n",
      "16552\n",
      "16553\n",
      "16554\n",
      "16555\n",
      "16556\n",
      "16557\n",
      "16558\n",
      "16559\n",
      "16560\n",
      "16561\n",
      "16562\n",
      "16563\n",
      "16564\n",
      "16565\n",
      "16566\n",
      "16567\n",
      "16568\n",
      "16569\n",
      "16570\n",
      "16571\n",
      "16572\n",
      "16573\n",
      "16574\n",
      "16575\n",
      "16576\n",
      "16577\n",
      "16578\n",
      "16579\n",
      "16580\n",
      "16581\n",
      "16582\n",
      "16583\n",
      "16584\n",
      "16585\n",
      "16586\n",
      "16587\n",
      "16588\n",
      "16589\n",
      "16590\n",
      "16591\n",
      "16592\n",
      "16593\n",
      "16594\n",
      "16595\n",
      "16596\n",
      "16597\n",
      "16598\n",
      "16599\n",
      "16600\n",
      "16601\n",
      "16602\n",
      "16603\n",
      "16604\n",
      "16605\n",
      "16606\n",
      "16607\n",
      "16608\n",
      "16609\n",
      "16610\n",
      "16611\n",
      "16612\n",
      "16613\n",
      "16614\n",
      "16615\n",
      "16616\n",
      "16617\n",
      "16618\n",
      "16619\n",
      "16620\n",
      "16621\n",
      "16622\n",
      "16623\n",
      "16624\n",
      "16625\n",
      "16626\n",
      "16627\n",
      "16628\n",
      "16629\n",
      "16630\n",
      "16631\n",
      "16632\n",
      "16633\n",
      "16634\n",
      "16635\n",
      "16636\n",
      "16637\n",
      "16638\n",
      "16639\n",
      "16640\n",
      "16641\n",
      "16642\n",
      "16643\n",
      "16644\n",
      "16645\n",
      "16646\n",
      "16647\n",
      "16648\n",
      "16649\n",
      "16650\n",
      "16651\n",
      "16652\n",
      "16653\n",
      "16654\n",
      "16655\n",
      "16656\n",
      "16657\n",
      "16658\n",
      "16659\n",
      "16660\n",
      "16661\n",
      "16662\n",
      "16663\n",
      "16664\n",
      "16665\n",
      "16666\n",
      "16667\n",
      "16668\n",
      "16669\n",
      "16670\n",
      "16671\n",
      "16672\n",
      "16673\n",
      "16674\n",
      "16675\n",
      "16676\n",
      "16677\n",
      "16678\n",
      "16679\n",
      "16680\n",
      "16681\n",
      "16682\n",
      "16683\n",
      "16684\n",
      "16685\n",
      "16686\n",
      "16687\n",
      "16688\n",
      "16689\n",
      "16690\n",
      "16691\n",
      "16692\n",
      "16693\n",
      "16694\n",
      "16695\n",
      "16696\n",
      "16697\n",
      "16698\n",
      "16699\n",
      "16700\n",
      "16701\n",
      "16702\n",
      "16703\n",
      "16704\n",
      "16705\n",
      "16706\n",
      "16707\n",
      "16708\n",
      "16709\n",
      "16710\n",
      "16711\n",
      "16712\n",
      "16713\n",
      "16714\n",
      "16715\n",
      "16716\n",
      "16717\n",
      "16718\n",
      "16719\n",
      "16720\n",
      "16721\n",
      "16722\n",
      "16723\n",
      "16724\n",
      "16725\n",
      "16726\n",
      "16727\n",
      "16728\n",
      "16729\n",
      "16730\n",
      "16731\n",
      "16732\n",
      "16733\n",
      "16734\n",
      "16735\n",
      "16736\n",
      "16737\n",
      "16738\n",
      "16739\n",
      "16740\n",
      "16741\n",
      "16742\n",
      "16743\n",
      "16744\n",
      "16745\n",
      "16746\n",
      "16747\n",
      "16748\n",
      "16749\n",
      "16750\n",
      "16751\n",
      "16752\n",
      "16753\n",
      "16754\n",
      "16755\n",
      "16756\n",
      "16757\n",
      "16758\n",
      "16759\n",
      "16760\n",
      "16761\n",
      "16762\n",
      "16763\n",
      "16764\n",
      "16765\n",
      "16766\n",
      "16767\n",
      "16768\n",
      "16769\n",
      "16770\n",
      "16771\n",
      "16772\n",
      "16773\n",
      "16774\n",
      "16775\n",
      "16776\n",
      "16777\n",
      "16778\n",
      "16779\n",
      "16780\n",
      "16781\n",
      "16782\n",
      "16783\n",
      "16784\n",
      "16785\n",
      "16786\n",
      "16787\n",
      "16788\n",
      "16789\n",
      "16790\n",
      "16791\n",
      "16792\n",
      "16793\n",
      "16794\n",
      "16795\n",
      "16796\n",
      "16797\n",
      "16798\n",
      "16799\n",
      "16800\n",
      "16801\n",
      "16802\n",
      "16803\n",
      "16804\n",
      "16805\n",
      "16806\n",
      "16807\n",
      "16808\n",
      "16809\n",
      "16810\n",
      "16811\n",
      "16812\n",
      "16813\n",
      "16814\n",
      "16815\n",
      "16816\n",
      "16817\n",
      "16818\n",
      "16819\n",
      "16820\n",
      "16821\n",
      "16822\n",
      "16823\n",
      "16824\n",
      "16825\n",
      "16826\n",
      "16827\n",
      "16828\n",
      "16829\n",
      "16830\n",
      "16831\n",
      "16832\n",
      "16833\n",
      "16834\n",
      "16835\n",
      "16836\n",
      "16837\n",
      "16838\n",
      "16839\n",
      "16840\n",
      "16841\n",
      "16842\n",
      "16843\n",
      "16844\n",
      "16845\n",
      "16846\n",
      "16847\n",
      "16848\n",
      "16849\n",
      "16850\n",
      "16851\n",
      "16852\n",
      "16853\n",
      "16854\n",
      "16855\n",
      "16856\n",
      "16857\n",
      "16858\n",
      "16859\n",
      "16860\n",
      "16861\n",
      "16862\n",
      "16863\n",
      "16864\n",
      "16865\n",
      "16866\n",
      "16867\n",
      "16868\n",
      "16869\n",
      "16870\n",
      "16871\n",
      "16872\n",
      "16873\n",
      "16874\n",
      "16875\n",
      "16876\n",
      "16877\n",
      "16878\n",
      "16879\n",
      "16880\n",
      "16881\n",
      "16882\n",
      "16883\n",
      "16884\n",
      "16885\n",
      "16886\n",
      "16887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16888\n",
      "16889\n",
      "16890\n",
      "16891\n",
      "16892\n",
      "16893\n",
      "16894\n",
      "16895\n",
      "16896\n",
      "16897\n",
      "16898\n",
      "16899\n",
      "16900\n",
      "16901\n",
      "16902\n",
      "16903\n",
      "16904\n",
      "16905\n",
      "16906\n",
      "16907\n",
      "16908\n",
      "16909\n",
      "16910\n",
      "16911\n",
      "16912\n",
      "16913\n",
      "16914\n",
      "16915\n",
      "16916\n",
      "16917\n",
      "16918\n",
      "16919\n",
      "16920\n",
      "16921\n",
      "16922\n",
      "16923\n",
      "16924\n",
      "16925\n",
      "16926\n",
      "16927\n",
      "16928\n",
      "16929\n",
      "16930\n",
      "16931\n",
      "16932\n",
      "16933\n",
      "16934\n",
      "16935\n",
      "16936\n",
      "16937\n",
      "16938\n",
      "16939\n",
      "16940\n",
      "16941\n",
      "16942\n",
      "16943\n",
      "16944\n",
      "16945\n",
      "16946\n",
      "16947\n",
      "16948\n",
      "16949\n",
      "16950\n",
      "16951\n",
      "16952\n",
      "16953\n",
      "16954\n",
      "16955\n",
      "16956\n",
      "16957\n",
      "16958\n",
      "16959\n",
      "16960\n",
      "16961\n",
      "16962\n",
      "16963\n",
      "16964\n",
      "16965\n",
      "16966\n",
      "16967\n",
      "16968\n",
      "16969\n",
      "16970\n",
      "16971\n",
      "16972\n",
      "16973\n",
      "16974\n",
      "16975\n",
      "16976\n",
      "16977\n",
      "16978\n",
      "16979\n",
      "16980\n",
      "16981\n",
      "16982\n",
      "16983\n",
      "16984\n",
      "16985\n",
      "16986\n",
      "16987\n",
      "16988\n",
      "16989\n",
      "16990\n",
      "16991\n",
      "16992\n",
      "16993\n",
      "16994\n",
      "16995\n",
      "16996\n",
      "16997\n",
      "16998\n",
      "16999\n",
      "17000\n",
      "17001\n",
      "17002\n",
      "17003\n",
      "17004\n",
      "17005\n",
      "17006\n",
      "17007\n",
      "17008\n",
      "17009\n",
      "17010\n",
      "17011\n",
      "17012\n",
      "17013\n",
      "17014\n",
      "17015\n",
      "17016\n",
      "17017\n",
      "17018\n",
      "17019\n",
      "17020\n",
      "17021\n",
      "17022\n",
      "17023\n",
      "17024\n",
      "17025\n",
      "17026\n",
      "17027\n",
      "17028\n",
      "17029\n",
      "17030\n",
      "17031\n",
      "17032\n",
      "17033\n",
      "17034\n",
      "17035\n",
      "17036\n",
      "17037\n",
      "17038\n",
      "17039\n",
      "17040\n",
      "17041\n",
      "17042\n",
      "17043\n",
      "17044\n",
      "17045\n",
      "17046\n",
      "17047\n",
      "17048\n",
      "17049\n",
      "17050\n",
      "17051\n",
      "17052\n",
      "17053\n",
      "17054\n",
      "17055\n",
      "17056\n",
      "17057\n",
      "17058\n",
      "17059\n",
      "17060\n",
      "17061\n",
      "17062\n",
      "17063\n",
      "17064\n",
      "17065\n",
      "17066\n",
      "17067\n",
      "17068\n",
      "17069\n",
      "17070\n",
      "17071\n",
      "17072\n",
      "17073\n",
      "17074\n",
      "17075\n",
      "17076\n",
      "17077\n",
      "17078\n",
      "17079\n",
      "17080\n",
      "17081\n",
      "17082\n",
      "17083\n",
      "17084\n",
      "17085\n",
      "17086\n",
      "17087\n",
      "17088\n",
      "17089\n",
      "17090\n",
      "17091\n",
      "17092\n",
      "17093\n",
      "17094\n",
      "17095\n",
      "17096\n",
      "17097\n",
      "17098\n",
      "17099\n",
      "17100\n",
      "17101\n",
      "17102\n",
      "17103\n",
      "17104\n",
      "17105\n",
      "17106\n",
      "17107\n",
      "17108\n",
      "17109\n",
      "17110\n",
      "17111\n",
      "17112\n",
      "17113\n",
      "17114\n",
      "17115\n",
      "17116\n",
      "17117\n",
      "17118\n",
      "17119\n",
      "17120\n",
      "17121\n",
      "17122\n",
      "17123\n",
      "17124\n",
      "17125\n",
      "17126\n",
      "17127\n",
      "17128\n",
      "17129\n",
      "17130\n",
      "17131\n",
      "17132\n",
      "17133\n",
      "17134\n",
      "17135\n",
      "17136\n",
      "17137\n",
      "17138\n",
      "17139\n",
      "17140\n",
      "17141\n",
      "17142\n",
      "17143\n",
      "17144\n",
      "17145\n",
      "17146\n",
      "17147\n",
      "17148\n",
      "17149\n",
      "17150\n",
      "17151\n",
      "17152\n",
      "17153\n",
      "17154\n",
      "17155\n",
      "17156\n",
      "17157\n",
      "17158\n",
      "17159\n",
      "17160\n",
      "17161\n",
      "17162\n",
      "17163\n",
      "17164\n",
      "17165\n",
      "17166\n",
      "17167\n",
      "17168\n",
      "17169\n",
      "17170\n",
      "17171\n",
      "17172\n",
      "17173\n",
      "17174\n",
      "17175\n",
      "17176\n",
      "17177\n",
      "17178\n",
      "17179\n",
      "17180\n",
      "17181\n",
      "17182\n",
      "17183\n",
      "17184\n",
      "17185\n",
      "17186\n",
      "17187\n",
      "17188\n",
      "17189\n",
      "17190\n",
      "17191\n",
      "17192\n",
      "17193\n",
      "17194\n",
      "17195\n",
      "17196\n",
      "17197\n",
      "17198\n",
      "17199\n",
      "17200\n",
      "17201\n",
      "17202\n",
      "17203\n",
      "17204\n",
      "17205\n",
      "17206\n",
      "17207\n",
      "17208\n",
      "17209\n",
      "17210\n",
      "17211\n",
      "17212\n",
      "17213\n",
      "17214\n",
      "17215\n",
      "17216\n",
      "17217\n",
      "17218\n",
      "17219\n",
      "17220\n",
      "17221\n",
      "17222\n",
      "17223\n",
      "17224\n",
      "17225\n",
      "17226\n",
      "17227\n",
      "17228\n",
      "17229\n",
      "17230\n",
      "17231\n",
      "17232\n",
      "17233\n",
      "17234\n",
      "17235\n",
      "17236\n",
      "17237\n",
      "17238\n",
      "17239\n",
      "17240\n",
      "17241\n",
      "17242\n",
      "17243\n",
      "17244\n",
      "17245\n",
      "17246\n",
      "17247\n",
      "17248\n",
      "17249\n",
      "17250\n",
      "17251\n",
      "17252\n",
      "17253\n",
      "17254\n",
      "17255\n",
      "17256\n",
      "17257\n",
      "17258\n",
      "17259\n",
      "17260\n",
      "17261\n",
      "17262\n",
      "17263\n",
      "17264\n",
      "17265\n",
      "17266\n",
      "17267\n",
      "17268\n",
      "17269\n",
      "17270\n",
      "17271\n",
      "17272\n",
      "17273\n",
      "17274\n",
      "17275\n",
      "17276\n",
      "17277\n",
      "17278\n",
      "17279\n",
      "17280\n",
      "17281\n",
      "17282\n",
      "17283\n",
      "17284\n",
      "17285\n",
      "17286\n",
      "17287\n",
      "17288\n",
      "17289\n",
      "17290\n",
      "17291\n",
      "17292\n",
      "17293\n",
      "17294\n",
      "17295\n",
      "17296\n",
      "17297\n",
      "17298\n",
      "17299\n",
      "17300\n",
      "17301\n",
      "17302\n",
      "17303\n",
      "17304\n",
      "17305\n",
      "17306\n",
      "17307\n",
      "17308\n",
      "17309\n",
      "17310\n",
      "17311\n",
      "17312\n",
      "17313\n",
      "17314\n",
      "17315\n",
      "17316\n",
      "17317\n",
      "17318\n",
      "17319\n",
      "17320\n",
      "17321\n",
      "17322\n",
      "17323\n",
      "17324\n",
      "17325\n",
      "17326\n",
      "17327\n",
      "17328\n",
      "17329\n",
      "17330\n",
      "17331\n",
      "17332\n",
      "17333\n",
      "17334\n",
      "17335\n",
      "17336\n",
      "17337\n",
      "17338\n",
      "17339\n",
      "17340\n",
      "17341\n",
      "17342\n",
      "17343\n",
      "17344\n",
      "17345\n",
      "17346\n",
      "17347\n",
      "17348\n",
      "17349\n",
      "17350\n",
      "17351\n",
      "17352\n",
      "17353\n",
      "17354\n",
      "17355\n",
      "17356\n",
      "17357\n",
      "17358\n",
      "17359\n",
      "17360\n",
      "17361\n",
      "17362\n",
      "17363\n",
      "17364\n",
      "17365\n",
      "17366\n",
      "17367\n",
      "17368\n",
      "17369\n",
      "17370\n",
      "17371\n",
      "17372\n",
      "17373\n",
      "17374\n",
      "17375\n",
      "17376\n",
      "17377\n",
      "17378\n",
      "17379\n",
      "17380\n",
      "17381\n",
      "17382\n",
      "17383\n",
      "17384\n",
      "17385\n",
      "17386\n",
      "17387\n",
      "17388\n",
      "17389\n",
      "17390\n",
      "17391\n",
      "17392\n",
      "17393\n",
      "17394\n",
      "17395\n",
      "17396\n",
      "17397\n",
      "17398\n",
      "17399\n",
      "17400\n",
      "17401\n",
      "17402\n",
      "17403\n",
      "17404\n",
      "17405\n",
      "17406\n",
      "17407\n",
      "17408\n",
      "17409\n",
      "17410\n",
      "17411\n",
      "17412\n",
      "17413\n",
      "17414\n",
      "17415\n",
      "17416\n",
      "17417\n",
      "17418\n",
      "17419\n",
      "17420\n",
      "17421\n",
      "17422\n",
      "17423\n",
      "17424\n",
      "17425\n",
      "17426\n",
      "17427\n",
      "17428\n",
      "17429\n",
      "17430\n",
      "17431\n",
      "17432\n",
      "17433\n",
      "17434\n",
      "17435\n",
      "17436\n",
      "17437\n",
      "17438\n",
      "17439\n",
      "17440\n",
      "17441\n",
      "17442\n",
      "17443\n",
      "17444\n",
      "17445\n",
      "17446\n",
      "17447\n",
      "17448\n",
      "17449\n",
      "17450\n",
      "17451\n",
      "17452\n",
      "17453\n",
      "17454\n",
      "17455\n",
      "17456\n",
      "17457\n",
      "17458\n",
      "17459\n",
      "17460\n",
      "17461\n",
      "17462\n",
      "17463\n",
      "17464\n",
      "17465\n",
      "17466\n",
      "17467\n",
      "17468\n",
      "17469\n",
      "17470\n",
      "17471\n",
      "17472\n",
      "17473\n",
      "17474\n",
      "17475\n",
      "17476\n",
      "17477\n",
      "17478\n",
      "17479\n",
      "17480\n",
      "17481\n",
      "17482\n",
      "17483\n",
      "17484\n",
      "17485\n",
      "17486\n",
      "17487\n",
      "17488\n",
      "17489\n",
      "17490\n",
      "17491\n",
      "17492\n",
      "17493\n",
      "17494\n",
      "17495\n",
      "17496\n",
      "17497\n",
      "17498\n",
      "17499\n",
      "17500\n",
      "17501\n",
      "17502\n",
      "17503\n",
      "17504\n",
      "17505\n",
      "17506\n",
      "17507\n",
      "17508\n",
      "17509\n",
      "17510\n",
      "17511\n",
      "17512\n",
      "17513\n",
      "17514\n",
      "17515\n",
      "17516\n",
      "17517\n",
      "17518\n",
      "17519\n",
      "17520\n",
      "17521\n",
      "17522\n",
      "17523\n",
      "17524\n",
      "17525\n",
      "17526\n",
      "17527\n",
      "17528\n",
      "17529\n",
      "17530\n",
      "17531\n",
      "17532\n",
      "17533\n",
      "17534\n",
      "17535\n",
      "17536\n",
      "17537\n",
      "17538\n",
      "17539\n",
      "17540\n",
      "17541\n",
      "17542\n",
      "17543\n",
      "17544\n",
      "17545\n",
      "17546\n",
      "17547\n",
      "17548\n",
      "17549\n",
      "17550\n",
      "17551\n",
      "17552\n",
      "17553\n",
      "17554\n",
      "17555\n",
      "17556\n",
      "17557\n",
      "17558\n",
      "17559\n",
      "17560\n",
      "17561\n",
      "17562\n",
      "17563\n",
      "17564\n",
      "17565\n",
      "17566\n",
      "17567\n",
      "17568\n",
      "17569\n",
      "17570\n",
      "17571\n",
      "17572\n",
      "17573\n",
      "17574\n",
      "17575\n",
      "17576\n",
      "17577\n",
      "17578\n",
      "17579\n",
      "17580\n",
      "17581\n",
      "17582\n",
      "17583\n",
      "17584\n",
      "17585\n",
      "17586\n",
      "17587\n",
      "17588\n",
      "17589\n",
      "17590\n",
      "17591\n",
      "17592\n",
      "17593\n",
      "17594\n",
      "17595\n",
      "17596\n",
      "17597\n",
      "17598\n",
      "17599\n",
      "17600\n",
      "17601\n",
      "17602\n",
      "17603\n",
      "17604\n",
      "17605\n",
      "17606\n",
      "17607\n",
      "17608\n",
      "17609\n",
      "17610\n",
      "17611\n",
      "17612\n",
      "17613\n",
      "17614\n",
      "17615\n",
      "17616\n",
      "17617\n",
      "17618\n",
      "17619\n",
      "17620\n",
      "17621\n",
      "17622\n",
      "17623\n",
      "17624\n",
      "17625\n",
      "17626\n",
      "17627\n",
      "17628\n",
      "17629\n",
      "17630\n",
      "17631\n",
      "17632\n",
      "17633\n",
      "17634\n",
      "17635\n",
      "17636\n",
      "17637\n",
      "17638\n",
      "17639\n",
      "17640\n",
      "17641\n",
      "17642\n",
      "17643\n",
      "17644\n",
      "17645\n",
      "17646\n",
      "17647\n",
      "17648\n",
      "17649\n",
      "17650\n",
      "17651\n",
      "17652\n",
      "17653\n",
      "17654\n",
      "17655\n",
      "17656\n",
      "17657\n",
      "17658\n",
      "17659\n",
      "17660\n",
      "17661\n",
      "17662\n",
      "17663\n",
      "17664\n",
      "17665\n",
      "17666\n",
      "17667\n",
      "17668\n",
      "17669\n",
      "17670\n",
      "17671\n",
      "17672\n",
      "17673\n",
      "17674\n",
      "17675\n",
      "17676\n",
      "17677\n",
      "17678\n",
      "17679\n",
      "17680\n",
      "17681\n",
      "17682\n",
      "17683\n",
      "17684\n",
      "17685\n",
      "17686\n",
      "17687\n",
      "17688\n",
      "17689\n",
      "17690\n",
      "17691\n",
      "17692\n",
      "17693\n",
      "17694\n",
      "17695\n",
      "17696\n",
      "17697\n",
      "17698\n",
      "17699\n",
      "17700\n",
      "17701\n",
      "17702\n",
      "17703\n",
      "17704\n",
      "17705\n",
      "17706\n",
      "17707\n",
      "17708\n",
      "17709\n",
      "17710\n",
      "17711\n",
      "17712\n",
      "17713\n",
      "17714\n",
      "17715\n",
      "17716\n",
      "17717\n",
      "17718\n",
      "17719\n",
      "17720\n",
      "17721\n",
      "17722\n",
      "17723\n",
      "17724\n",
      "17725\n",
      "17726\n",
      "17727\n",
      "17728\n",
      "17729\n",
      "17730\n",
      "17731\n",
      "17732\n",
      "17733\n",
      "17734\n",
      "17735\n",
      "17736\n",
      "17737\n",
      "17738\n",
      "17739\n",
      "17740\n",
      "17741\n",
      "17742\n",
      "17743\n",
      "17744\n",
      "17745\n",
      "17746\n",
      "17747\n",
      "17748\n",
      "17749\n",
      "17750\n",
      "17751\n",
      "17752\n",
      "17753\n",
      "17754\n",
      "17755\n",
      "17756\n",
      "17757\n",
      "17758\n",
      "17759\n",
      "17760\n",
      "17761\n",
      "17762\n",
      "17763\n",
      "17764\n",
      "17765\n",
      "17766\n",
      "17767\n",
      "17768\n",
      "17769\n",
      "17770\n",
      "17771\n",
      "17772\n",
      "17773\n",
      "17774\n",
      "17775\n",
      "17776\n",
      "17777\n",
      "17778\n",
      "17779\n",
      "17780\n",
      "17781\n",
      "17782\n",
      "17783\n",
      "17784\n",
      "17785\n",
      "17786\n",
      "17787\n",
      "17788\n",
      "17789\n",
      "17790\n",
      "17791\n",
      "17792\n",
      "17793\n",
      "17794\n",
      "17795\n",
      "17796\n",
      "17797\n",
      "17798\n",
      "17799\n",
      "17800\n",
      "17801\n",
      "17802\n",
      "17803\n",
      "17804\n",
      "17805\n",
      "17806\n",
      "17807\n",
      "17808\n",
      "17809\n",
      "17810\n",
      "17811\n",
      "17812\n",
      "17813\n",
      "17814\n",
      "17815\n",
      "17816\n",
      "17817\n",
      "17818\n",
      "17819\n",
      "17820\n",
      "17821\n",
      "17822\n",
      "17823\n",
      "17824\n",
      "17825\n",
      "17826\n",
      "17827\n",
      "17828\n",
      "17829\n",
      "17830\n",
      "17831\n",
      "17832\n",
      "17833\n",
      "17834\n",
      "17835\n",
      "17836\n",
      "17837\n",
      "17838\n",
      "17839\n",
      "17840\n",
      "17841\n",
      "17842\n",
      "17843\n",
      "17844\n",
      "17845\n",
      "17846\n",
      "17847\n",
      "17848\n",
      "17849\n",
      "17850\n",
      "17851\n",
      "17852\n",
      "17853\n",
      "17854\n",
      "17855\n",
      "17856\n",
      "17857\n",
      "17858\n",
      "17859\n",
      "17860\n",
      "17861\n",
      "17862\n",
      "17863\n",
      "17864\n",
      "17865\n",
      "17866\n",
      "17867\n",
      "17868\n",
      "17869\n",
      "17870\n",
      "17871\n",
      "17872\n",
      "17873\n",
      "17874\n",
      "17875\n",
      "17876\n",
      "17877\n",
      "17878\n",
      "17879\n",
      "17880\n",
      "17881\n",
      "17882\n",
      "17883\n",
      "17884\n",
      "17885\n",
      "17886\n",
      "17887\n",
      "17888\n",
      "17889\n",
      "17890\n",
      "17891\n",
      "17892\n",
      "17893\n",
      "17894\n",
      "17895\n",
      "17896\n",
      "17897\n",
      "17898\n",
      "17899\n",
      "17900\n",
      "17901\n",
      "17902\n",
      "17903\n",
      "17904\n",
      "17905\n",
      "17906\n",
      "17907\n",
      "17908\n",
      "17909\n",
      "17910\n",
      "17911\n",
      "17912\n",
      "17913\n",
      "17914\n",
      "17915\n",
      "17916\n",
      "17917\n",
      "17918\n",
      "17919\n",
      "17920\n",
      "17921\n",
      "17922\n",
      "17923\n",
      "17924\n",
      "17925\n",
      "17926\n",
      "17927\n",
      "17928\n",
      "17929\n",
      "17930\n",
      "17931\n",
      "17932\n",
      "17933\n",
      "17934\n",
      "17935\n",
      "17936\n",
      "17937\n",
      "17938\n",
      "17939\n",
      "17940\n",
      "17941\n",
      "17942\n",
      "17943\n",
      "17944\n",
      "17945\n",
      "17946\n",
      "17947\n",
      "17948\n",
      "17949\n",
      "17950\n",
      "17951\n",
      "17952\n",
      "17953\n",
      "17954\n",
      "17955\n",
      "17956\n",
      "17957\n",
      "17958\n",
      "17959\n",
      "17960\n",
      "17961\n",
      "17962\n",
      "17963\n",
      "17964\n",
      "17965\n",
      "17966\n",
      "17967\n",
      "17968\n",
      "17969\n",
      "17970\n",
      "17971\n",
      "17972\n",
      "17973\n",
      "17974\n",
      "17975\n",
      "17976\n",
      "17977\n",
      "17978\n",
      "17979\n",
      "17980\n",
      "17981\n",
      "17982\n",
      "17983\n",
      "17984\n",
      "17985\n",
      "17986\n",
      "17987\n",
      "17988\n",
      "17989\n",
      "17990\n",
      "17991\n",
      "17992\n",
      "17993\n",
      "17994\n",
      "17995\n",
      "17996\n",
      "17997\n",
      "17998\n",
      "17999\n",
      "18000\n",
      "18001\n",
      "18002\n",
      "18003\n",
      "18004\n",
      "18005\n",
      "18006\n",
      "18007\n",
      "18008\n",
      "18009\n",
      "18010\n",
      "18011\n",
      "18012\n",
      "18013\n",
      "18014\n",
      "18015\n",
      "18016\n",
      "18017\n",
      "18018\n",
      "18019\n",
      "18020\n",
      "18021\n",
      "18022\n",
      "18023\n",
      "18024\n",
      "18025\n",
      "18026\n",
      "18027\n",
      "18028\n",
      "18029\n",
      "18030\n",
      "18031\n",
      "18032\n",
      "18033\n",
      "18034\n",
      "18035\n",
      "18036\n",
      "18037\n",
      "18038\n",
      "18039\n",
      "18040\n",
      "18041\n",
      "18042\n",
      "18043\n",
      "18044\n",
      "18045\n",
      "18046\n",
      "18047\n",
      "18048\n",
      "18049\n",
      "18050\n",
      "18051\n",
      "18052\n",
      "18053\n",
      "18054\n",
      "18055\n",
      "18056\n",
      "18057\n",
      "18058\n",
      "18059\n",
      "18060\n",
      "18061\n",
      "18062\n",
      "18063\n",
      "18064\n",
      "18065\n",
      "18066\n",
      "18067\n",
      "18068\n",
      "18069\n",
      "18070\n",
      "18071\n",
      "18072\n",
      "18073\n",
      "18074\n",
      "18075\n",
      "18076\n",
      "18077\n",
      "18078\n",
      "18079\n",
      "18080\n",
      "18081\n",
      "18082\n",
      "18083\n",
      "18084\n",
      "18085\n",
      "18086\n",
      "18087\n",
      "18088\n",
      "18089\n",
      "18090\n",
      "18091\n",
      "18092\n",
      "18093\n",
      "18094\n",
      "18095\n",
      "18096\n",
      "18097\n",
      "18098\n",
      "18099\n",
      "18100\n",
      "18101\n",
      "18102\n",
      "18103\n",
      "18104\n",
      "18105\n",
      "18106\n",
      "18107\n",
      "18108\n",
      "18109\n",
      "18110\n",
      "18111\n",
      "18112\n",
      "18113\n",
      "18114\n",
      "18115\n",
      "18116\n",
      "18117\n",
      "18118\n",
      "18119\n",
      "18120\n",
      "18121\n",
      "18122\n",
      "18123\n",
      "18124\n",
      "18125\n",
      "18126\n",
      "18127\n",
      "18128\n",
      "18129\n",
      "18130\n",
      "18131\n",
      "18132\n",
      "18133\n",
      "18134\n",
      "18135\n",
      "18136\n",
      "18137\n",
      "18138\n",
      "18139\n",
      "18140\n",
      "18141\n",
      "18142\n",
      "18143\n",
      "18144\n",
      "18145\n",
      "18146\n",
      "18147\n",
      "18148\n",
      "18149\n",
      "18150\n",
      "18151\n",
      "18152\n",
      "18153\n",
      "18154\n",
      "18155\n",
      "18156\n",
      "18157\n",
      "18158\n",
      "18159\n",
      "18160\n",
      "18161\n",
      "18162\n",
      "18163\n",
      "18164\n",
      "18165\n",
      "18166\n",
      "18167\n",
      "18168\n",
      "18169\n",
      "18170\n",
      "18171\n",
      "18172\n",
      "18173\n",
      "18174\n",
      "18175\n",
      "18176\n",
      "18177\n",
      "18178\n",
      "18179\n",
      "18180\n",
      "18181\n",
      "18182\n",
      "18183\n",
      "18184\n",
      "18185\n",
      "18186\n",
      "18187\n",
      "18188\n",
      "18189\n",
      "18190\n",
      "18191\n",
      "18192\n",
      "18193\n",
      "18194\n",
      "18195\n",
      "18196\n",
      "18197\n",
      "18198\n",
      "18199\n",
      "18200\n",
      "18201\n",
      "18202\n",
      "18203\n",
      "18204\n",
      "18205\n",
      "18206\n",
      "18207\n",
      "18208\n",
      "18209\n",
      "18210\n",
      "18211\n",
      "18212\n",
      "18213\n",
      "18214\n",
      "18215\n",
      "18216\n",
      "18217\n",
      "18218\n",
      "18219\n",
      "18220\n",
      "18221\n",
      "18222\n",
      "18223\n",
      "18224\n",
      "18225\n",
      "18226\n",
      "18227\n",
      "18228\n",
      "18229\n",
      "18230\n",
      "18231\n",
      "18232\n",
      "18233\n",
      "18234\n",
      "18235\n",
      "18236\n",
      "18237\n",
      "18238\n",
      "18239\n",
      "18240\n",
      "18241\n",
      "18242\n",
      "18243\n",
      "18244\n",
      "18245\n",
      "18246\n",
      "18247\n",
      "18248\n",
      "18249\n",
      "18250\n",
      "18251\n",
      "18252\n",
      "18253\n",
      "18254\n",
      "18255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18256\n",
      "18257\n",
      "18258\n",
      "18259\n",
      "18260\n",
      "18261\n",
      "18262\n",
      "18263\n",
      "18264\n",
      "18265\n",
      "18266\n",
      "18267\n",
      "18268\n",
      "18269\n",
      "18270\n",
      "18271\n",
      "18272\n",
      "18273\n",
      "18274\n",
      "18275\n",
      "18276\n",
      "18277\n",
      "18278\n",
      "18279\n",
      "18280\n",
      "18281\n",
      "18282\n",
      "18283\n",
      "18284\n",
      "18285\n",
      "18286\n",
      "18287\n",
      "18288\n",
      "18289\n",
      "18290\n",
      "18291\n",
      "18292\n",
      "18293\n",
      "18294\n",
      "18295\n",
      "18296\n",
      "18297\n",
      "18298\n",
      "18299\n",
      "18300\n",
      "18301\n",
      "18302\n",
      "18303\n",
      "18304\n",
      "18305\n",
      "18306\n",
      "18307\n",
      "18308\n",
      "18309\n",
      "18310\n",
      "18311\n",
      "18312\n",
      "18313\n",
      "18314\n",
      "18315\n",
      "18316\n",
      "18317\n",
      "18318\n",
      "18319\n",
      "18320\n",
      "18321\n",
      "18322\n",
      "18323\n",
      "18324\n",
      "18325\n",
      "18326\n",
      "18327\n",
      "18328\n",
      "18329\n",
      "18330\n",
      "18331\n",
      "18332\n",
      "18333\n",
      "18334\n",
      "18335\n",
      "18336\n",
      "18337\n",
      "18338\n",
      "18339\n",
      "18340\n",
      "18341\n",
      "18342\n",
      "18343\n",
      "18344\n",
      "18345\n",
      "18346\n",
      "18347\n",
      "18348\n",
      "18349\n",
      "18350\n",
      "18351\n",
      "18352\n",
      "18353\n",
      "18354\n",
      "18355\n",
      "18356\n",
      "18357\n",
      "18358\n",
      "18359\n",
      "18360\n",
      "18361\n",
      "18362\n",
      "18363\n",
      "18364\n",
      "18365\n",
      "18366\n",
      "18367\n",
      "18368\n",
      "18369\n",
      "18370\n",
      "18371\n",
      "18372\n",
      "18373\n",
      "18374\n",
      "18375\n",
      "18376\n",
      "18377\n",
      "18378\n",
      "18379\n",
      "18380\n",
      "18381\n",
      "18382\n",
      "18383\n",
      "18384\n",
      "18385\n",
      "18386\n",
      "18387\n",
      "18388\n",
      "18389\n",
      "18390\n",
      "18391\n",
      "18392\n",
      "18393\n",
      "18394\n",
      "18395\n",
      "18396\n",
      "18397\n",
      "18398\n",
      "18399\n",
      "18400\n",
      "18401\n",
      "18402\n",
      "18403\n",
      "18404\n",
      "18405\n",
      "18406\n",
      "18407\n",
      "18408\n",
      "18409\n",
      "18410\n",
      "18411\n",
      "18412\n",
      "18413\n",
      "18414\n",
      "18415\n",
      "18416\n",
      "18417\n",
      "18418\n",
      "18419\n",
      "18420\n",
      "18421\n",
      "18422\n",
      "18423\n",
      "18424\n",
      "18425\n",
      "18426\n",
      "18427\n",
      "18428\n",
      "18429\n",
      "18430\n",
      "18431\n",
      "18432\n",
      "18433\n",
      "18434\n",
      "18435\n",
      "18436\n",
      "18437\n",
      "18438\n",
      "18439\n",
      "18440\n",
      "18441\n",
      "18442\n",
      "18443\n",
      "18444\n",
      "18445\n",
      "18446\n",
      "18447\n",
      "18448\n",
      "18449\n",
      "18450\n",
      "18451\n",
      "18452\n",
      "18453\n",
      "18454\n",
      "18455\n",
      "18456\n",
      "18457\n",
      "18458\n",
      "18459\n",
      "18460\n",
      "18461\n",
      "18462\n",
      "18463\n",
      "18464\n",
      "18465\n",
      "18466\n",
      "18467\n",
      "18468\n",
      "18469\n",
      "18470\n",
      "18471\n",
      "18472\n",
      "18473\n",
      "18474\n",
      "18475\n",
      "18476\n",
      "18477\n",
      "18478\n",
      "18479\n",
      "18480\n",
      "18481\n",
      "18482\n",
      "18483\n",
      "18484\n",
      "18485\n",
      "18486\n",
      "18487\n",
      "18488\n",
      "18489\n",
      "18490\n",
      "18491\n",
      "18492\n",
      "18493\n",
      "18494\n",
      "18495\n",
      "18496\n",
      "18497\n",
      "18498\n",
      "18499\n",
      "18500\n",
      "18501\n",
      "18502\n",
      "18503\n",
      "18504\n",
      "18505\n",
      "18506\n",
      "18507\n",
      "18508\n",
      "18509\n",
      "18510\n",
      "18511\n",
      "18512\n",
      "18513\n",
      "18514\n",
      "18515\n",
      "18516\n",
      "18517\n",
      "18518\n",
      "18519\n",
      "18520\n",
      "18521\n",
      "18522\n",
      "18523\n",
      "18524\n",
      "18525\n",
      "18526\n",
      "18527\n",
      "18528\n",
      "18529\n",
      "18530\n",
      "18531\n",
      "18532\n",
      "18533\n",
      "18534\n",
      "18535\n",
      "18536\n",
      "18537\n",
      "18538\n",
      "18539\n",
      "18540\n",
      "18541\n",
      "18542\n",
      "18543\n",
      "18544\n",
      "18545\n",
      "18546\n",
      "18547\n",
      "18548\n",
      "18549\n",
      "18550\n",
      "18551\n",
      "18552\n",
      "18553\n",
      "18554\n",
      "18555\n",
      "18556\n",
      "18557\n",
      "18558\n",
      "18559\n",
      "18560\n",
      "18561\n",
      "18562\n",
      "18563\n",
      "18564\n",
      "18565\n",
      "18566\n",
      "18567\n",
      "18568\n",
      "18569\n",
      "18570\n",
      "18571\n",
      "18572\n",
      "18573\n",
      "18574\n",
      "18575\n",
      "18576\n",
      "18577\n",
      "18578\n",
      "18579\n",
      "18580\n",
      "18581\n",
      "18582\n",
      "18583\n",
      "18584\n",
      "18585\n",
      "18586\n",
      "18587\n",
      "18588\n",
      "18589\n",
      "18590\n",
      "18591\n",
      "18592\n",
      "18593\n",
      "18594\n",
      "18595\n",
      "18596\n",
      "18597\n",
      "18598\n",
      "18599\n",
      "18600\n",
      "18601\n",
      "18602\n",
      "18603\n",
      "18604\n",
      "18605\n",
      "18606\n",
      "18607\n",
      "18608\n",
      "18609\n",
      "18610\n",
      "18611\n",
      "18612\n",
      "18613\n",
      "18614\n",
      "18615\n",
      "18616\n",
      "18617\n",
      "18618\n",
      "18619\n",
      "18620\n",
      "18621\n",
      "18622\n",
      "18623\n",
      "18624\n",
      "18625\n",
      "18626\n",
      "18627\n",
      "18628\n",
      "18629\n",
      "18630\n",
      "18631\n",
      "18632\n",
      "18633\n",
      "18634\n",
      "18635\n",
      "18636\n",
      "18637\n",
      "18638\n",
      "18639\n",
      "18640\n",
      "18641\n",
      "18642\n",
      "18643\n",
      "18644\n",
      "18645\n",
      "18646\n",
      "18647\n",
      "18648\n",
      "18649\n",
      "18650\n",
      "18651\n",
      "18652\n",
      "18653\n",
      "18654\n",
      "18655\n",
      "18656\n",
      "18657\n",
      "18658\n",
      "18659\n",
      "18660\n",
      "18661\n",
      "18662\n",
      "18663\n",
      "18664\n",
      "18665\n",
      "18666\n",
      "18667\n",
      "18668\n",
      "18669\n",
      "18670\n",
      "18671\n",
      "18672\n",
      "18673\n",
      "18674\n",
      "18675\n",
      "18676\n",
      "18677\n",
      "18678\n",
      "18679\n",
      "18680\n",
      "18681\n",
      "18682\n",
      "18683\n",
      "18684\n",
      "18685\n",
      "18686\n",
      "18687\n",
      "18688\n",
      "18689\n",
      "18690\n",
      "18691\n",
      "18692\n",
      "18693\n",
      "18694\n",
      "18695\n",
      "18696\n",
      "18697\n",
      "18698\n",
      "18699\n",
      "18700\n",
      "18701\n",
      "18702\n",
      "18703\n",
      "18704\n",
      "18705\n",
      "18706\n",
      "18707\n",
      "18708\n",
      "18709\n",
      "18710\n",
      "18711\n",
      "18712\n",
      "18713\n",
      "18714\n",
      "18715\n",
      "18716\n",
      "18717\n",
      "18718\n",
      "18719\n",
      "18720\n",
      "18721\n",
      "18722\n",
      "18723\n",
      "18724\n",
      "18725\n",
      "18726\n",
      "18727\n",
      "18728\n",
      "18729\n",
      "18730\n",
      "18731\n",
      "18732\n",
      "18733\n",
      "18734\n",
      "18735\n",
      "18736\n",
      "18737\n",
      "18738\n",
      "18739\n",
      "18740\n",
      "18741\n",
      "18742\n",
      "18743\n",
      "18744\n",
      "18745\n",
      "18746\n",
      "18747\n",
      "18748\n",
      "18749\n",
      "18750\n",
      "18751\n",
      "18752\n",
      "18753\n",
      "18754\n",
      "18755\n",
      "18756\n",
      "18757\n",
      "18758\n",
      "18759\n",
      "18760\n",
      "18761\n",
      "18762\n",
      "18763\n",
      "18764\n",
      "18765\n",
      "18766\n",
      "18767\n",
      "18768\n",
      "18769\n",
      "18770\n",
      "18771\n",
      "18772\n",
      "18773\n",
      "18774\n",
      "18775\n",
      "18776\n",
      "18777\n",
      "18778\n",
      "18779\n",
      "18780\n",
      "18781\n",
      "18782\n",
      "18783\n",
      "18784\n",
      "18785\n",
      "18786\n",
      "18787\n",
      "18788\n",
      "18789\n",
      "18790\n",
      "18791\n",
      "18792\n",
      "18793\n",
      "18794\n",
      "18795\n",
      "18796\n",
      "18797\n",
      "18798\n",
      "18799\n",
      "18800\n",
      "18801\n",
      "18802\n",
      "18803\n",
      "18804\n",
      "18805\n",
      "18806\n",
      "18807\n",
      "18808\n",
      "18809\n",
      "18810\n",
      "18811\n",
      "18812\n",
      "18813\n",
      "18814\n",
      "18815\n",
      "18816\n",
      "18817\n",
      "18818\n",
      "18819\n",
      "18820\n",
      "18821\n",
      "18822\n",
      "18823\n",
      "18824\n",
      "18825\n",
      "18826\n",
      "18827\n",
      "18828\n",
      "18829\n",
      "18830\n",
      "18831\n",
      "18832\n",
      "18833\n",
      "18834\n",
      "18835\n",
      "18836\n",
      "18837\n",
      "18838\n",
      "18839\n",
      "18840\n",
      "18841\n",
      "18842\n",
      "18843\n",
      "18844\n",
      "18845\n",
      "18846\n",
      "18847\n",
      "18848\n",
      "18849\n",
      "18850\n",
      "18851\n",
      "18852\n",
      "18853\n",
      "18854\n",
      "18855\n",
      "18856\n",
      "18857\n",
      "18858\n",
      "18859\n",
      "18860\n",
      "18861\n",
      "18862\n",
      "18863\n",
      "18864\n",
      "18865\n",
      "18866\n",
      "18867\n",
      "18868\n",
      "18869\n",
      "18870\n",
      "18871\n",
      "18872\n",
      "18873\n",
      "18874\n",
      "18875\n",
      "18876\n",
      "18877\n",
      "18878\n",
      "18879\n",
      "18880\n",
      "18881\n",
      "18882\n",
      "18883\n",
      "18884\n",
      "18885\n",
      "18886\n",
      "18887\n",
      "18888\n",
      "18889\n",
      "18890\n",
      "18891\n",
      "18892\n",
      "18893\n",
      "18894\n",
      "18895\n",
      "18896\n",
      "18897\n",
      "18898\n",
      "18899\n",
      "18900\n",
      "18901\n",
      "18902\n",
      "18903\n",
      "18904\n",
      "18905\n",
      "18906\n",
      "18907\n",
      "18908\n",
      "18909\n",
      "18910\n",
      "18911\n",
      "18912\n",
      "18913\n",
      "18914\n",
      "18915\n",
      "18916\n",
      "18917\n",
      "18918\n",
      "18919\n",
      "18920\n",
      "18921\n",
      "18922\n",
      "18923\n",
      "18924\n",
      "18925\n",
      "18926\n",
      "18927\n",
      "18928\n",
      "18929\n",
      "18930\n",
      "18931\n",
      "18932\n",
      "18933\n",
      "18934\n",
      "18935\n",
      "18936\n",
      "18937\n",
      "18938\n",
      "18939\n",
      "18940\n",
      "18941\n",
      "18942\n",
      "18943\n",
      "18944\n",
      "18945\n",
      "18946\n",
      "18947\n",
      "18948\n",
      "18949\n",
      "18950\n",
      "18951\n",
      "18952\n",
      "18953\n",
      "18954\n",
      "18955\n",
      "18956\n",
      "18957\n",
      "18958\n",
      "18959\n",
      "18960\n",
      "18961\n",
      "18962\n",
      "18963\n",
      "18964\n",
      "18965\n",
      "18966\n",
      "18967\n",
      "18968\n",
      "18969\n",
      "18970\n",
      "18971\n",
      "18972\n",
      "18973\n",
      "18974\n",
      "18975\n",
      "18976\n",
      "18977\n",
      "18978\n",
      "18979\n",
      "18980\n",
      "18981\n",
      "18982\n",
      "18983\n",
      "18984\n",
      "18985\n",
      "18986\n",
      "18987\n",
      "18988\n",
      "18989\n",
      "18990\n",
      "18991\n",
      "18992\n",
      "18993\n",
      "18994\n",
      "18995\n",
      "18996\n",
      "18997\n",
      "18998\n",
      "18999\n",
      "19000\n",
      "19001\n",
      "19002\n",
      "19003\n",
      "19004\n",
      "19005\n",
      "19006\n",
      "19007\n",
      "19008\n",
      "19009\n",
      "19010\n",
      "19011\n",
      "19012\n",
      "19013\n",
      "19014\n",
      "19015\n",
      "19016\n",
      "19017\n",
      "19018\n",
      "19019\n",
      "19020\n",
      "19021\n",
      "19022\n",
      "19023\n",
      "19024\n",
      "19025\n",
      "19026\n",
      "19027\n",
      "19028\n",
      "19029\n",
      "19030\n",
      "19031\n",
      "19032\n",
      "19033\n",
      "19034\n",
      "19035\n",
      "19036\n",
      "19037\n",
      "19038\n",
      "19039\n",
      "19040\n",
      "19041\n",
      "19042\n",
      "19043\n",
      "19044\n",
      "19045\n",
      "19046\n",
      "19047\n",
      "19048\n",
      "19049\n",
      "19050\n",
      "19051\n",
      "19052\n",
      "19053\n",
      "19054\n",
      "19055\n",
      "19056\n",
      "19057\n",
      "19058\n",
      "19059\n",
      "19060\n",
      "19061\n",
      "19062\n",
      "19063\n",
      "19064\n",
      "19065\n",
      "19066\n",
      "19067\n",
      "19068\n",
      "19069\n",
      "19070\n",
      "19071\n",
      "19072\n",
      "19073\n",
      "19074\n",
      "19075\n",
      "19076\n",
      "19077\n",
      "19078\n",
      "19079\n",
      "19080\n",
      "19081\n",
      "19082\n",
      "19083\n",
      "19084\n",
      "19085\n",
      "19086\n",
      "19087\n",
      "19088\n",
      "19089\n",
      "19090\n",
      "19091\n",
      "19092\n",
      "19093\n",
      "19094\n",
      "19095\n",
      "19096\n",
      "19097\n",
      "19098\n",
      "19099\n",
      "19100\n",
      "19101\n",
      "19102\n",
      "19103\n",
      "19104\n",
      "19105\n",
      "19106\n",
      "19107\n",
      "19108\n",
      "19109\n",
      "19110\n",
      "19111\n",
      "19112\n",
      "19113\n",
      "19114\n",
      "19115\n",
      "19116\n",
      "19117\n",
      "19118\n",
      "19119\n",
      "19120\n",
      "19121\n",
      "19122\n",
      "19123\n",
      "19124\n",
      "19125\n",
      "19126\n",
      "19127\n",
      "19128\n",
      "19129\n",
      "19130\n",
      "19131\n",
      "19132\n",
      "19133\n",
      "19134\n",
      "19135\n",
      "19136\n",
      "19137\n",
      "19138\n",
      "19139\n",
      "19140\n",
      "19141\n",
      "19142\n",
      "19143\n",
      "19144\n",
      "19145\n",
      "19146\n",
      "19147\n",
      "19148\n",
      "19149\n",
      "19150\n",
      "19151\n",
      "19152\n",
      "19153\n",
      "19154\n",
      "19155\n",
      "19156\n",
      "19157\n",
      "19158\n",
      "19159\n",
      "19160\n",
      "19161\n",
      "19162\n",
      "19163\n",
      "19164\n",
      "19165\n",
      "19166\n",
      "19167\n",
      "19168\n",
      "19169\n",
      "19170\n",
      "19171\n",
      "19172\n",
      "19173\n",
      "19174\n",
      "19175\n",
      "19176\n",
      "19177\n",
      "19178\n",
      "19179\n",
      "19180\n",
      "19181\n",
      "19182\n",
      "19183\n",
      "19184\n",
      "19185\n",
      "19186\n",
      "19187\n",
      "19188\n",
      "19189\n",
      "19190\n",
      "19191\n",
      "19192\n",
      "19193\n",
      "19194\n",
      "19195\n",
      "19196\n",
      "19197\n",
      "19198\n",
      "19199\n",
      "19200\n",
      "19201\n",
      "19202\n",
      "19203\n",
      "19204\n",
      "19205\n",
      "19206\n",
      "19207\n",
      "19208\n",
      "19209\n",
      "19210\n",
      "19211\n",
      "19212\n",
      "19213\n",
      "19214\n",
      "19215\n",
      "19216\n",
      "19217\n",
      "19218\n",
      "19219\n",
      "19220\n",
      "19221\n",
      "19222\n",
      "19223\n",
      "19224\n",
      "19225\n",
      "19226\n",
      "19227\n",
      "19228\n",
      "19229\n",
      "19230\n",
      "19231\n",
      "19232\n",
      "19233\n",
      "19234\n",
      "19235\n",
      "19236\n",
      "19237\n",
      "19238\n",
      "19239\n",
      "19240\n",
      "19241\n",
      "19242\n",
      "19243\n",
      "19244\n",
      "19245\n",
      "19246\n",
      "19247\n",
      "19248\n",
      "19249\n",
      "19250\n",
      "19251\n",
      "19252\n",
      "19253\n",
      "19254\n",
      "19255\n",
      "19256\n",
      "19257\n",
      "19258\n",
      "19259\n",
      "19260\n",
      "19261\n",
      "19262\n",
      "19263\n",
      "19264\n",
      "19265\n",
      "19266\n",
      "19267\n",
      "19268\n",
      "19269\n",
      "19270\n",
      "19271\n",
      "19272\n",
      "19273\n",
      "19274\n",
      "19275\n",
      "19276\n",
      "19277\n",
      "19278\n",
      "19279\n",
      "19280\n",
      "19281\n",
      "19282\n",
      "19283\n",
      "19284\n",
      "19285\n",
      "19286\n",
      "19287\n",
      "19288\n",
      "19289\n",
      "19290\n",
      "19291\n",
      "19292\n",
      "19293\n",
      "19294\n",
      "19295\n",
      "19296\n",
      "19297\n",
      "19298\n",
      "19299\n",
      "19300\n",
      "19301\n",
      "19302\n",
      "19303\n",
      "19304\n",
      "19305\n",
      "19306\n",
      "19307\n",
      "19308\n",
      "19309\n",
      "19310\n",
      "19311\n",
      "19312\n",
      "19313\n",
      "19314\n",
      "19315\n",
      "19316\n",
      "19317\n",
      "19318\n",
      "19319\n",
      "19320\n",
      "19321\n",
      "19322\n",
      "19323\n",
      "19324\n",
      "19325\n",
      "19326\n",
      "19327\n",
      "19328\n",
      "19329\n",
      "19330\n",
      "19331\n",
      "19332\n",
      "19333\n",
      "19334\n",
      "19335\n",
      "19336\n",
      "19337\n",
      "19338\n",
      "19339\n",
      "19340\n",
      "19341\n",
      "19342\n",
      "19343\n",
      "19344\n",
      "19345\n",
      "19346\n",
      "19347\n",
      "19348\n",
      "19349\n",
      "19350\n",
      "19351\n",
      "19352\n",
      "19353\n",
      "19354\n",
      "19355\n",
      "19356\n",
      "19357\n",
      "19358\n",
      "19359\n",
      "19360\n",
      "19361\n",
      "19362\n",
      "19363\n",
      "19364\n",
      "19365\n",
      "19366\n",
      "19367\n",
      "19368\n",
      "19369\n",
      "19370\n",
      "19371\n",
      "19372\n",
      "19373\n",
      "19374\n",
      "19375\n",
      "19376\n",
      "19377\n",
      "19378\n",
      "19379\n",
      "19380\n",
      "19381\n",
      "19382\n",
      "19383\n",
      "19384\n",
      "19385\n",
      "19386\n",
      "19387\n",
      "19388\n",
      "19389\n",
      "19390\n",
      "19391\n",
      "19392\n",
      "19393\n",
      "19394\n",
      "19395\n",
      "19396\n",
      "19397\n",
      "19398\n",
      "19399\n",
      "19400\n",
      "19401\n",
      "19402\n",
      "19403\n",
      "19404\n",
      "19405\n",
      "19406\n",
      "19407\n",
      "19408\n",
      "19409\n",
      "19410\n",
      "19411\n",
      "19412\n",
      "19413\n",
      "19414\n",
      "19415\n",
      "19416\n",
      "19417\n",
      "19418\n",
      "19419\n",
      "19420\n",
      "19421\n",
      "19422\n",
      "19423\n",
      "19424\n",
      "19425\n",
      "19426\n",
      "19427\n",
      "19428\n",
      "19429\n",
      "19430\n",
      "19431\n",
      "19432\n",
      "19433\n",
      "19434\n",
      "19435\n",
      "19436\n",
      "19437\n",
      "19438\n",
      "19439\n",
      "19440\n",
      "19441\n",
      "19442\n",
      "19443\n",
      "19444\n",
      "19445\n",
      "19446\n",
      "19447\n",
      "19448\n",
      "19449\n",
      "19450\n",
      "19451\n",
      "19452\n",
      "19453\n",
      "19454\n",
      "19455\n",
      "19456\n",
      "19457\n",
      "19458\n",
      "19459\n",
      "19460\n",
      "19461\n",
      "19462\n",
      "19463\n",
      "19464\n",
      "19465\n",
      "19466\n",
      "19467\n",
      "19468\n",
      "19469\n",
      "19470\n",
      "19471\n",
      "19472\n",
      "19473\n",
      "19474\n",
      "19475\n",
      "19476\n",
      "19477\n",
      "19478\n",
      "19479\n",
      "19480\n",
      "19481\n",
      "19482\n",
      "19483\n",
      "19484\n",
      "19485\n",
      "19486\n",
      "19487\n",
      "19488\n",
      "19489\n",
      "19490\n",
      "19491\n",
      "19492\n",
      "19493\n",
      "19494\n",
      "19495\n",
      "19496\n",
      "19497\n",
      "19498\n",
      "19499\n",
      "19500\n",
      "19501\n",
      "19502\n",
      "19503\n",
      "19504\n",
      "19505\n",
      "19506\n",
      "19507\n",
      "19508\n",
      "19509\n",
      "19510\n",
      "19511\n",
      "19512\n",
      "19513\n",
      "19514\n",
      "19515\n",
      "19516\n",
      "19517\n",
      "19518\n",
      "19519\n",
      "19520\n",
      "19521\n",
      "19522\n",
      "19523\n",
      "19524\n",
      "19525\n",
      "19526\n",
      "19527\n",
      "19528\n",
      "19529\n",
      "19530\n",
      "19531\n",
      "19532\n",
      "19533\n",
      "19534\n",
      "19535\n",
      "19536\n",
      "19537\n",
      "19538\n",
      "19539\n",
      "19540\n",
      "19541\n",
      "19542\n",
      "19543\n",
      "19544\n",
      "19545\n",
      "19546\n",
      "19547\n",
      "19548\n",
      "19549\n",
      "19550\n",
      "19551\n",
      "19552\n",
      "19553\n",
      "19554\n",
      "19555\n",
      "19556\n",
      "19557\n",
      "19558\n",
      "19559\n",
      "19560\n",
      "19561\n",
      "19562\n",
      "19563\n",
      "19564\n",
      "19565\n",
      "19566\n",
      "19567\n",
      "19568\n",
      "19569\n",
      "19570\n",
      "19571\n",
      "19572\n",
      "19573\n",
      "19574\n",
      "19575\n",
      "19576\n",
      "19577\n",
      "19578\n",
      "19579\n",
      "19580\n",
      "19581\n",
      "19582\n",
      "19583\n",
      "19584\n",
      "19585\n",
      "19586\n",
      "19587\n",
      "19588\n",
      "19589\n",
      "19590\n",
      "19591\n",
      "19592\n",
      "19593\n",
      "19594\n",
      "19595\n",
      "19596\n",
      "19597\n",
      "19598\n",
      "19599\n",
      "19600\n",
      "19601\n",
      "19602\n",
      "19603\n",
      "19604\n",
      "19605\n",
      "19606\n",
      "19607\n",
      "19608\n",
      "19609\n",
      "19610\n",
      "19611\n",
      "19612\n",
      "19613\n",
      "19614\n",
      "19615\n",
      "19616\n",
      "19617\n",
      "19618\n",
      "19619\n",
      "19620\n",
      "19621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19622\n",
      "19623\n",
      "19624\n",
      "19625\n",
      "19626\n",
      "19627\n",
      "19628\n",
      "19629\n",
      "19630\n",
      "19631\n",
      "19632\n",
      "19633\n",
      "19634\n",
      "19635\n",
      "19636\n",
      "19637\n",
      "19638\n",
      "19639\n",
      "19640\n",
      "19641\n",
      "19642\n",
      "19643\n",
      "19644\n",
      "19645\n",
      "19646\n",
      "19647\n",
      "19648\n",
      "19649\n",
      "19650\n",
      "19651\n",
      "19652\n",
      "19653\n",
      "19654\n",
      "19655\n",
      "19656\n",
      "19657\n",
      "19658\n",
      "19659\n",
      "19660\n",
      "19661\n",
      "19662\n",
      "19663\n",
      "19664\n",
      "19665\n",
      "19666\n",
      "19667\n",
      "19668\n",
      "19669\n",
      "19670\n",
      "19671\n",
      "19672\n",
      "19673\n",
      "19674\n",
      "19675\n",
      "19676\n",
      "19677\n",
      "19678\n",
      "19679\n",
      "19680\n",
      "19681\n",
      "19682\n",
      "19683\n",
      "19684\n",
      "19685\n",
      "19686\n",
      "19687\n",
      "19688\n",
      "19689\n",
      "19690\n",
      "19691\n",
      "19692\n",
      "19693\n",
      "19694\n",
      "19695\n",
      "19696\n",
      "19697\n",
      "19698\n",
      "19699\n",
      "19700\n",
      "19701\n",
      "19702\n",
      "19703\n",
      "19704\n",
      "19705\n",
      "19706\n",
      "19707\n",
      "19708\n",
      "19709\n",
      "19710\n",
      "19711\n",
      "19712\n",
      "19713\n",
      "19714\n",
      "19715\n",
      "19716\n",
      "19717\n",
      "19718\n",
      "19719\n",
      "19720\n",
      "19721\n",
      "19722\n",
      "19723\n",
      "19724\n",
      "19725\n",
      "19726\n",
      "19727\n",
      "19728\n",
      "19729\n",
      "19730\n",
      "19731\n",
      "19732\n",
      "19733\n",
      "19734\n",
      "19735\n",
      "19736\n",
      "19737\n",
      "19738\n",
      "19739\n",
      "19740\n",
      "19741\n",
      "19742\n",
      "19743\n",
      "19744\n",
      "19745\n",
      "19746\n",
      "19747\n",
      "19748\n",
      "19749\n",
      "19750\n",
      "19751\n",
      "19752\n",
      "19753\n",
      "19754\n",
      "19755\n",
      "19756\n",
      "19757\n",
      "19758\n",
      "19759\n",
      "19760\n",
      "19761\n",
      "19762\n",
      "19763\n",
      "19764\n",
      "19765\n",
      "19766\n",
      "19767\n",
      "19768\n",
      "19769\n",
      "19770\n",
      "19771\n",
      "19772\n",
      "19773\n",
      "19774\n",
      "19775\n",
      "19776\n",
      "19777\n",
      "19778\n",
      "19779\n",
      "19780\n",
      "19781\n",
      "19782\n",
      "19783\n",
      "19784\n",
      "19785\n",
      "19786\n",
      "19787\n",
      "19788\n",
      "19789\n",
      "19790\n",
      "19791\n",
      "19792\n",
      "19793\n",
      "19794\n",
      "19795\n",
      "19796\n",
      "19797\n",
      "19798\n",
      "19799\n",
      "19800\n",
      "19801\n",
      "19802\n",
      "19803\n",
      "19804\n",
      "19805\n",
      "19806\n",
      "19807\n",
      "19808\n",
      "19809\n",
      "19810\n",
      "19811\n",
      "19812\n",
      "19813\n",
      "19814\n",
      "19815\n",
      "19816\n",
      "19817\n",
      "19818\n",
      "19819\n",
      "19820\n",
      "19821\n",
      "19822\n",
      "19823\n",
      "19824\n",
      "19825\n",
      "19826\n",
      "19827\n",
      "19828\n",
      "19829\n",
      "19830\n",
      "19831\n",
      "19832\n",
      "19833\n",
      "19834\n",
      "19835\n",
      "19836\n",
      "19837\n",
      "19838\n",
      "19839\n",
      "19840\n",
      "19841\n",
      "19842\n",
      "19843\n",
      "19844\n",
      "19845\n",
      "19846\n",
      "19847\n",
      "19848\n",
      "19849\n",
      "19850\n",
      "19851\n",
      "19852\n",
      "19853\n",
      "19854\n",
      "19855\n",
      "19856\n",
      "19857\n",
      "19858\n",
      "19859\n",
      "19860\n",
      "19861\n",
      "19862\n",
      "19863\n",
      "19864\n",
      "19865\n",
      "19866\n",
      "19867\n",
      "19868\n",
      "19869\n",
      "19870\n",
      "19871\n",
      "19872\n",
      "19873\n",
      "19874\n",
      "19875\n",
      "19876\n",
      "19877\n",
      "19878\n",
      "19879\n",
      "19880\n",
      "19881\n",
      "19882\n",
      "19883\n",
      "19884\n",
      "19885\n",
      "19886\n",
      "19887\n",
      "19888\n",
      "19889\n",
      "19890\n",
      "19891\n",
      "19892\n",
      "19893\n",
      "19894\n",
      "19895\n",
      "19896\n",
      "19897\n",
      "19898\n",
      "19899\n",
      "19900\n",
      "19901\n",
      "19902\n",
      "19903\n",
      "19904\n",
      "19905\n",
      "19906\n",
      "19907\n",
      "19908\n",
      "19909\n",
      "19910\n",
      "19911\n",
      "19912\n",
      "19913\n",
      "19914\n",
      "19915\n",
      "19916\n",
      "19917\n",
      "19918\n",
      "19919\n",
      "19920\n",
      "19921\n",
      "19922\n",
      "19923\n",
      "19924\n",
      "19925\n",
      "19926\n",
      "19927\n",
      "19928\n",
      "19929\n",
      "19930\n",
      "19931\n",
      "19932\n",
      "19933\n",
      "19934\n",
      "19935\n",
      "19936\n",
      "19937\n",
      "19938\n",
      "19939\n",
      "19940\n",
      "19941\n",
      "19942\n",
      "19943\n",
      "19944\n",
      "19945\n",
      "19946\n",
      "19947\n",
      "19948\n",
      "19949\n",
      "19950\n",
      "19951\n",
      "19952\n",
      "19953\n",
      "19954\n",
      "19955\n",
      "19956\n",
      "19957\n",
      "19958\n",
      "19959\n",
      "19960\n",
      "19961\n",
      "19962\n",
      "19963\n",
      "19964\n",
      "19965\n",
      "19966\n",
      "19967\n",
      "19968\n",
      "19969\n",
      "19970\n",
      "19971\n",
      "19972\n",
      "19973\n",
      "19974\n",
      "19975\n",
      "19976\n",
      "19977\n",
      "19978\n",
      "19979\n",
      "19980\n",
      "19981\n",
      "19982\n",
      "19983\n",
      "19984\n",
      "19985\n",
      "19986\n",
      "19987\n",
      "19988\n",
      "19989\n",
      "19990\n",
      "19991\n",
      "19992\n",
      "19993\n",
      "19994\n",
      "19995\n",
      "19996\n",
      "19997\n",
      "19998\n",
      "19999\n",
      "20000\n",
      "20001\n",
      "20002\n",
      "20003\n",
      "20004\n",
      "20005\n",
      "20006\n",
      "20007\n",
      "20008\n",
      "20009\n",
      "20010\n",
      "20011\n",
      "20012\n",
      "20013\n",
      "20014\n",
      "20015\n",
      "20016\n",
      "20017\n",
      "20018\n",
      "20019\n",
      "20020\n",
      "20021\n",
      "20022\n",
      "20023\n",
      "20024\n",
      "20025\n",
      "20026\n",
      "20027\n",
      "20028\n",
      "20029\n",
      "20030\n",
      "20031\n",
      "20032\n",
      "20033\n",
      "20034\n",
      "20035\n",
      "20036\n",
      "20037\n",
      "20038\n",
      "20039\n",
      "20040\n",
      "20041\n",
      "20042\n",
      "20043\n",
      "20044\n",
      "20045\n",
      "20046\n",
      "20047\n",
      "20048\n",
      "20049\n",
      "20050\n",
      "20051\n",
      "20052\n",
      "20053\n",
      "20054\n",
      "20055\n",
      "20056\n",
      "20057\n",
      "20058\n",
      "20059\n",
      "20060\n",
      "20061\n",
      "20062\n",
      "20063\n",
      "20064\n",
      "20065\n",
      "20066\n",
      "20067\n",
      "20068\n",
      "20069\n",
      "20070\n",
      "20071\n",
      "20072\n",
      "20073\n",
      "20074\n",
      "20075\n",
      "20076\n",
      "20077\n",
      "20078\n",
      "20079\n",
      "20080\n",
      "20081\n",
      "20082\n",
      "20083\n",
      "20084\n",
      "20085\n",
      "20086\n",
      "20087\n",
      "20088\n",
      "20089\n",
      "20090\n",
      "20091\n",
      "20092\n",
      "20093\n",
      "20094\n",
      "20095\n",
      "20096\n",
      "20097\n",
      "20098\n",
      "20099\n",
      "20100\n",
      "20101\n",
      "20102\n",
      "20103\n",
      "20104\n",
      "20105\n",
      "20106\n",
      "20107\n",
      "20108\n",
      "20109\n",
      "20110\n",
      "20111\n",
      "20112\n",
      "20113\n",
      "20114\n",
      "20115\n",
      "20116\n",
      "20117\n",
      "20118\n",
      "20119\n",
      "20120\n",
      "20121\n",
      "20122\n",
      "20123\n",
      "20124\n",
      "20125\n",
      "20126\n",
      "20127\n",
      "20128\n",
      "20129\n",
      "20130\n",
      "20131\n",
      "20132\n",
      "20133\n",
      "20134\n",
      "20135\n",
      "20136\n",
      "20137\n",
      "20138\n",
      "20139\n",
      "20140\n",
      "20141\n",
      "20142\n",
      "20143\n",
      "20144\n",
      "20145\n",
      "20146\n",
      "20147\n",
      "20148\n",
      "20149\n",
      "20150\n",
      "20151\n",
      "20152\n",
      "20153\n",
      "20154\n",
      "20155\n",
      "20156\n",
      "20157\n",
      "20158\n",
      "20159\n",
      "20160\n",
      "20161\n",
      "20162\n",
      "20163\n",
      "20164\n",
      "20165\n",
      "20166\n",
      "20167\n",
      "20168\n",
      "20169\n",
      "20170\n",
      "20171\n",
      "20172\n",
      "20173\n",
      "20174\n",
      "20175\n",
      "20176\n",
      "20177\n",
      "20178\n",
      "20179\n",
      "20180\n",
      "20181\n",
      "20182\n",
      "20183\n",
      "20184\n",
      "20185\n",
      "20186\n",
      "20187\n",
      "20188\n",
      "20189\n",
      "20190\n",
      "20191\n",
      "20192\n",
      "20193\n",
      "20194\n",
      "20195\n",
      "20196\n",
      "20197\n",
      "20198\n",
      "20199\n",
      "20200\n",
      "20201\n",
      "20202\n",
      "20203\n",
      "20204\n",
      "20205\n",
      "20206\n",
      "20207\n",
      "20208\n",
      "20209\n",
      "20210\n",
      "20211\n",
      "20212\n",
      "20213\n",
      "20214\n",
      "20215\n",
      "20216\n",
      "20217\n",
      "20218\n",
      "20219\n",
      "20220\n",
      "20221\n",
      "20222\n",
      "20223\n",
      "20224\n",
      "20225\n",
      "20226\n",
      "20227\n",
      "20228\n",
      "20229\n",
      "20230\n",
      "20231\n",
      "20232\n",
      "20233\n",
      "20234\n",
      "20235\n",
      "20236\n",
      "20237\n",
      "20238\n",
      "20239\n",
      "20240\n",
      "20241\n",
      "20242\n",
      "20243\n",
      "20244\n",
      "20245\n",
      "20246\n",
      "20247\n",
      "20248\n",
      "20249\n",
      "20250\n",
      "20251\n",
      "20252\n",
      "20253\n",
      "20254\n",
      "20255\n",
      "20256\n",
      "20257\n",
      "20258\n",
      "20259\n",
      "20260\n",
      "20261\n",
      "20262\n",
      "20263\n",
      "20264\n",
      "20265\n",
      "20266\n",
      "20267\n",
      "20268\n",
      "20269\n",
      "20270\n",
      "20271\n",
      "20272\n",
      "20273\n",
      "20274\n",
      "20275\n",
      "20276\n",
      "20277\n",
      "20278\n",
      "20279\n",
      "20280\n",
      "20281\n",
      "20282\n",
      "20283\n",
      "20284\n",
      "20285\n",
      "20286\n",
      "20287\n",
      "20288\n",
      "20289\n",
      "20290\n",
      "20291\n",
      "20292\n",
      "20293\n",
      "20294\n",
      "20295\n",
      "20296\n",
      "20297\n",
      "20298\n",
      "20299\n",
      "20300\n",
      "20301\n",
      "20302\n",
      "20303\n",
      "20304\n",
      "20305\n",
      "20306\n",
      "20307\n",
      "20308\n",
      "20309\n",
      "20310\n",
      "20311\n",
      "20312\n",
      "20313\n",
      "20314\n",
      "20315\n",
      "20316\n",
      "20317\n",
      "20318\n",
      "20319\n",
      "20320\n",
      "20321\n",
      "20322\n",
      "20323\n",
      "20324\n",
      "20325\n",
      "20326\n",
      "20327\n",
      "20328\n",
      "20329\n",
      "20330\n",
      "20331\n",
      "20332\n",
      "20333\n",
      "20334\n",
      "20335\n",
      "20336\n",
      "20337\n",
      "20338\n",
      "20339\n",
      "20340\n",
      "20341\n",
      "20342\n",
      "20343\n",
      "20344\n",
      "20345\n",
      "20346\n",
      "20347\n",
      "20348\n",
      "20349\n",
      "20350\n",
      "20351\n",
      "20352\n",
      "20353\n",
      "20354\n",
      "20355\n",
      "20356\n",
      "20357\n",
      "20358\n",
      "20359\n",
      "20360\n",
      "20361\n",
      "20362\n",
      "20363\n",
      "20364\n",
      "20365\n",
      "20366\n",
      "20367\n",
      "20368\n",
      "20369\n",
      "20370\n",
      "20371\n",
      "20372\n",
      "20373\n",
      "20374\n",
      "20375\n",
      "20376\n",
      "20377\n",
      "20378\n",
      "20379\n",
      "20380\n",
      "20381\n",
      "20382\n",
      "20383\n",
      "20384\n",
      "20385\n",
      "20386\n",
      "20387\n",
      "20388\n",
      "20389\n",
      "20390\n",
      "20391\n",
      "20392\n",
      "20393\n",
      "20394\n",
      "20395\n",
      "20396\n",
      "20397\n",
      "20398\n",
      "20399\n",
      "20400\n",
      "20401\n",
      "20402\n",
      "20403\n",
      "20404\n",
      "20405\n",
      "20406\n",
      "20407\n",
      "20408\n",
      "20409\n",
      "20410\n",
      "20411\n",
      "20412\n",
      "20413\n",
      "20414\n",
      "20415\n",
      "20416\n",
      "20417\n",
      "20418\n",
      "20419\n",
      "20420\n",
      "20421\n",
      "20422\n",
      "20423\n",
      "20424\n",
      "20425\n",
      "20426\n",
      "20427\n",
      "20428\n",
      "20429\n",
      "20430\n",
      "20431\n",
      "20432\n",
      "20433\n",
      "20434\n",
      "20435\n",
      "20436\n",
      "20437\n",
      "20438\n",
      "20439\n",
      "20440\n",
      "20441\n",
      "20442\n",
      "20443\n",
      "20444\n",
      "20445\n",
      "20446\n",
      "20447\n",
      "20448\n",
      "20449\n",
      "20450\n",
      "20451\n",
      "20452\n",
      "20453\n",
      "20454\n",
      "20455\n",
      "20456\n",
      "20457\n",
      "20458\n",
      "20459\n",
      "20460\n",
      "20461\n",
      "20462\n",
      "20463\n",
      "20464\n",
      "20465\n",
      "20466\n",
      "20467\n",
      "20468\n",
      "20469\n",
      "20470\n",
      "20471\n",
      "20472\n",
      "20473\n",
      "20474\n",
      "20475\n",
      "20476\n",
      "20477\n",
      "20478\n",
      "20479\n",
      "20480\n",
      "20481\n",
      "20482\n",
      "20483\n",
      "20484\n",
      "20485\n",
      "20486\n",
      "20487\n",
      "20488\n",
      "20489\n",
      "20490\n",
      "20491\n",
      "20492\n",
      "20493\n",
      "20494\n",
      "20495\n",
      "20496\n",
      "20497\n",
      "20498\n",
      "20499\n",
      "20500\n",
      "20501\n",
      "20502\n",
      "20503\n",
      "20504\n",
      "20505\n",
      "20506\n",
      "20507\n",
      "20508\n",
      "20509\n",
      "20510\n",
      "20511\n",
      "20512\n",
      "20513\n",
      "20514\n",
      "20515\n",
      "20516\n",
      "20517\n",
      "20518\n",
      "20519\n",
      "20520\n",
      "20521\n",
      "20522\n",
      "20523\n",
      "20524\n",
      "20525\n",
      "20526\n",
      "20527\n",
      "20528\n",
      "20529\n",
      "20530\n",
      "20531\n",
      "20532\n",
      "20533\n",
      "20534\n",
      "20535\n",
      "20536\n",
      "20537\n",
      "20538\n",
      "20539\n",
      "20540\n",
      "20541\n",
      "20542\n",
      "20543\n",
      "20544\n",
      "20545\n",
      "20546\n",
      "20547\n",
      "20548\n",
      "20549\n",
      "20550\n",
      "20551\n",
      "20552\n",
      "20553\n",
      "20554\n",
      "20555\n",
      "20556\n",
      "20557\n",
      "20558\n",
      "20559\n",
      "20560\n",
      "20561\n",
      "20562\n",
      "20563\n",
      "20564\n",
      "20565\n",
      "20566\n",
      "20567\n",
      "20568\n",
      "20569\n",
      "20570\n",
      "20571\n",
      "20572\n",
      "20573\n",
      "20574\n",
      "20575\n",
      "20576\n",
      "20577\n",
      "20578\n",
      "20579\n",
      "20580\n",
      "20581\n",
      "20582\n",
      "20583\n",
      "20584\n",
      "20585\n",
      "20586\n",
      "20587\n",
      "20588\n",
      "20589\n",
      "20590\n",
      "20591\n",
      "20592\n",
      "20593\n",
      "20594\n",
      "20595\n",
      "20596\n",
      "20597\n",
      "20598\n",
      "20599\n",
      "20600\n",
      "20601\n",
      "20602\n",
      "20603\n",
      "20604\n",
      "20605\n",
      "20606\n",
      "20607\n",
      "20608\n",
      "20609\n",
      "20610\n",
      "20611\n",
      "20612\n",
      "20613\n",
      "20614\n",
      "20615\n",
      "20616\n",
      "20617\n",
      "20618\n",
      "20619\n",
      "20620\n",
      "20621\n",
      "20622\n",
      "20623\n",
      "20624\n",
      "20625\n",
      "20626\n",
      "20627\n",
      "20628\n",
      "20629\n",
      "20630\n",
      "20631\n",
      "20632\n",
      "20633\n",
      "20634\n",
      "20635\n",
      "20636\n",
      "20637\n",
      "20638\n",
      "20639\n",
      "20640\n",
      "20641\n",
      "20642\n",
      "20643\n",
      "20644\n",
      "20645\n",
      "20646\n",
      "20647\n",
      "20648\n",
      "20649\n",
      "20650\n",
      "20651\n",
      "20652\n",
      "20653\n",
      "20654\n",
      "20655\n",
      "20656\n",
      "20657\n",
      "20658\n",
      "20659\n",
      "20660\n",
      "20661\n",
      "20662\n",
      "20663\n",
      "20664\n",
      "20665\n",
      "20666\n",
      "20667\n",
      "20668\n",
      "20669\n",
      "20670\n",
      "20671\n",
      "20672\n",
      "20673\n",
      "20674\n",
      "20675\n",
      "20676\n",
      "20677\n",
      "20678\n",
      "20679\n",
      "20680\n",
      "20681\n",
      "20682\n",
      "20683\n",
      "20684\n",
      "20685\n",
      "20686\n",
      "20687\n",
      "20688\n",
      "20689\n",
      "20690\n",
      "20691\n",
      "20692\n",
      "20693\n",
      "20694\n",
      "20695\n",
      "20696\n",
      "20697\n",
      "20698\n",
      "20699\n",
      "20700\n",
      "20701\n",
      "20702\n",
      "20703\n",
      "20704\n",
      "20705\n",
      "20706\n",
      "20707\n",
      "20708\n",
      "20709\n",
      "20710\n",
      "20711\n",
      "20712\n",
      "20713\n",
      "20714\n",
      "20715\n",
      "20716\n",
      "20717\n",
      "20718\n",
      "20719\n",
      "20720\n",
      "20721\n",
      "20722\n",
      "20723\n",
      "20724\n",
      "20725\n",
      "20726\n",
      "20727\n",
      "20728\n",
      "20729\n",
      "20730\n",
      "20731\n",
      "20732\n",
      "20733\n",
      "20734\n",
      "20735\n",
      "20736\n",
      "20737\n",
      "20738\n",
      "20739\n",
      "20740\n",
      "20741\n",
      "20742\n",
      "20743\n",
      "20744\n",
      "20745\n",
      "20746\n",
      "20747\n",
      "20748\n",
      "20749\n",
      "20750\n",
      "20751\n",
      "20752\n",
      "20753\n",
      "20754\n",
      "20755\n",
      "20756\n",
      "20757\n",
      "20758\n",
      "20759\n",
      "20760\n",
      "20761\n",
      "20762\n",
      "20763\n",
      "20764\n",
      "20765\n",
      "20766\n",
      "20767\n",
      "20768\n",
      "20769\n",
      "20770\n",
      "20771\n",
      "20772\n",
      "20773\n",
      "20774\n",
      "20775\n",
      "20776\n",
      "20777\n",
      "20778\n",
      "20779\n",
      "20780\n",
      "20781\n",
      "20782\n",
      "20783\n",
      "20784\n",
      "20785\n",
      "20786\n",
      "20787\n",
      "20788\n",
      "20789\n",
      "20790\n",
      "20791\n",
      "20792\n",
      "20793\n",
      "20794\n",
      "20795\n",
      "20796\n",
      "20797\n",
      "20798\n",
      "20799\n",
      "20800\n",
      "20801\n",
      "20802\n",
      "20803\n",
      "20804\n",
      "20805\n",
      "20806\n",
      "20807\n",
      "20808\n",
      "20809\n",
      "20810\n",
      "20811\n",
      "20812\n",
      "20813\n",
      "20814\n",
      "20815\n",
      "20816\n",
      "20817\n",
      "20818\n",
      "20819\n",
      "20820\n",
      "20821\n",
      "20822\n",
      "20823\n",
      "20824\n",
      "20825\n",
      "20826\n",
      "20827\n",
      "20828\n",
      "20829\n",
      "20830\n",
      "20831\n",
      "20832\n",
      "20833\n",
      "20834\n",
      "20835\n",
      "20836\n",
      "20837\n",
      "20838\n",
      "20839\n",
      "20840\n",
      "20841\n",
      "20842\n",
      "20843\n",
      "20844\n",
      "20845\n",
      "20846\n",
      "20847\n",
      "20848\n",
      "20849\n",
      "20850\n",
      "20851\n",
      "20852\n",
      "20853\n",
      "20854\n",
      "20855\n",
      "20856\n",
      "20857\n",
      "20858\n",
      "20859\n",
      "20860\n",
      "20861\n",
      "20862\n",
      "20863\n",
      "20864\n",
      "20865\n",
      "20866\n",
      "20867\n",
      "20868\n",
      "20869\n",
      "20870\n",
      "20871\n",
      "20872\n",
      "20873\n",
      "20874\n",
      "20875\n",
      "20876\n",
      "20877\n",
      "20878\n",
      "20879\n",
      "20880\n",
      "20881\n",
      "20882\n",
      "20883\n",
      "20884\n",
      "20885\n",
      "20886\n",
      "20887\n",
      "20888\n",
      "20889\n",
      "20890\n",
      "20891\n",
      "20892\n",
      "20893\n",
      "20894\n",
      "20895\n",
      "20896\n",
      "20897\n",
      "20898\n",
      "20899\n",
      "20900\n",
      "20901\n",
      "20902\n",
      "20903\n",
      "20904\n",
      "20905\n",
      "20906\n",
      "20907\n",
      "20908\n",
      "20909\n",
      "20910\n",
      "20911\n",
      "20912\n",
      "20913\n",
      "20914\n",
      "20915\n",
      "20916\n",
      "20917\n",
      "20918\n",
      "20919\n",
      "20920\n",
      "20921\n",
      "20922\n",
      "20923\n",
      "20924\n",
      "20925\n",
      "20926\n",
      "20927\n",
      "20928\n",
      "20929\n",
      "20930\n",
      "20931\n",
      "20932\n",
      "20933\n",
      "20934\n",
      "20935\n",
      "20936\n",
      "20937\n",
      "20938\n",
      "20939\n",
      "20940\n",
      "20941\n",
      "20942\n",
      "20943\n",
      "20944\n",
      "20945\n",
      "20946\n",
      "20947\n",
      "20948\n",
      "20949\n",
      "20950\n",
      "20951\n",
      "20952\n",
      "20953\n",
      "20954\n",
      "20955\n",
      "20956\n",
      "20957\n",
      "20958\n",
      "20959\n",
      "20960\n",
      "20961\n",
      "20962\n",
      "20963\n",
      "20964\n",
      "20965\n",
      "20966\n",
      "20967\n",
      "20968\n",
      "20969\n",
      "20970\n",
      "20971\n",
      "20972\n",
      "20973\n",
      "20974\n",
      "20975\n",
      "20976\n",
      "20977\n",
      "20978\n",
      "20979\n",
      "20980\n",
      "20981\n",
      "20982\n",
      "20983\n",
      "20984\n",
      "20985\n",
      "20986\n",
      "20987\n",
      "20988\n",
      "20989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20990\n",
      "20991\n",
      "20992\n",
      "20993\n",
      "20994\n",
      "20995\n",
      "20996\n",
      "20997\n",
      "20998\n",
      "20999\n",
      "21000\n",
      "21001\n",
      "21002\n",
      "21003\n",
      "21004\n",
      "21005\n",
      "21006\n",
      "21007\n",
      "21008\n",
      "21009\n",
      "21010\n",
      "21011\n",
      "21012\n",
      "21013\n",
      "21014\n",
      "21015\n",
      "21016\n",
      "21017\n",
      "21018\n",
      "21019\n",
      "21020\n",
      "21021\n",
      "21022\n",
      "21023\n",
      "21024\n",
      "21025\n",
      "21026\n",
      "21027\n",
      "21028\n",
      "21029\n",
      "21030\n",
      "21031\n",
      "21032\n",
      "21033\n",
      "21034\n",
      "21035\n",
      "21036\n",
      "21037\n",
      "21038\n",
      "21039\n",
      "21040\n",
      "21041\n",
      "21042\n",
      "21043\n",
      "21044\n",
      "21045\n",
      "21046\n",
      "21047\n",
      "21048\n",
      "21049\n",
      "21050\n",
      "21051\n",
      "21052\n",
      "21053\n",
      "21054\n",
      "21055\n",
      "21056\n",
      "21057\n",
      "21058\n",
      "21059\n",
      "21060\n",
      "21061\n",
      "21062\n",
      "21063\n",
      "21064\n",
      "21065\n",
      "21066\n",
      "21067\n",
      "21068\n",
      "21069\n",
      "21070\n",
      "21071\n",
      "21072\n",
      "21073\n",
      "21074\n",
      "21075\n",
      "21076\n",
      "21077\n",
      "21078\n",
      "21079\n",
      "21080\n",
      "21081\n",
      "21082\n",
      "21083\n",
      "21084\n",
      "21085\n",
      "21086\n",
      "21087\n",
      "21088\n",
      "21089\n",
      "21090\n",
      "21091\n",
      "21092\n",
      "21093\n",
      "21094\n",
      "21095\n",
      "21096\n",
      "21097\n",
      "21098\n",
      "21099\n",
      "21100\n",
      "21101\n",
      "21102\n",
      "21103\n",
      "21104\n",
      "21105\n",
      "21106\n",
      "21107\n",
      "21108\n",
      "21109\n",
      "21110\n",
      "21111\n",
      "21112\n",
      "21113\n",
      "21114\n",
      "21115\n",
      "21116\n",
      "21117\n",
      "21118\n",
      "21119\n",
      "21120\n",
      "21121\n",
      "21122\n",
      "21123\n",
      "21124\n",
      "21125\n",
      "21126\n",
      "21127\n",
      "21128\n",
      "21129\n",
      "21130\n",
      "21131\n",
      "21132\n",
      "21133\n",
      "21134\n",
      "21135\n",
      "21136\n",
      "21137\n",
      "21138\n",
      "21139\n",
      "21140\n",
      "21141\n",
      "21142\n",
      "21143\n",
      "21144\n",
      "21145\n",
      "21146\n",
      "21147\n",
      "21148\n",
      "21149\n",
      "21150\n",
      "21151\n",
      "21152\n",
      "21153\n",
      "21154\n",
      "21155\n",
      "21156\n",
      "21157\n",
      "21158\n",
      "21159\n",
      "21160\n",
      "21161\n",
      "21162\n",
      "21163\n",
      "21164\n",
      "21165\n",
      "21166\n",
      "21167\n",
      "21168\n",
      "21169\n",
      "21170\n",
      "21171\n",
      "21172\n",
      "21173\n",
      "21174\n",
      "21175\n",
      "21176\n",
      "21177\n",
      "21178\n",
      "21179\n",
      "21180\n",
      "21181\n",
      "21182\n",
      "21183\n",
      "21184\n",
      "21185\n",
      "21186\n",
      "21187\n",
      "21188\n",
      "21189\n",
      "21190\n",
      "21191\n",
      "21192\n",
      "21193\n",
      "21194\n",
      "21195\n",
      "21196\n",
      "21197\n",
      "21198\n",
      "21199\n",
      "21200\n",
      "21201\n",
      "21202\n",
      "21203\n",
      "21204\n",
      "21205\n",
      "21206\n",
      "21207\n",
      "21208\n",
      "21209\n",
      "21210\n",
      "21211\n",
      "21212\n",
      "21213\n",
      "21214\n",
      "21215\n",
      "21216\n",
      "21217\n",
      "21218\n",
      "21219\n",
      "21220\n",
      "21221\n",
      "21222\n",
      "21223\n",
      "21224\n",
      "21225\n",
      "21226\n",
      "21227\n",
      "21228\n",
      "21229\n",
      "21230\n",
      "21231\n",
      "21232\n",
      "21233\n",
      "21234\n",
      "21235\n",
      "21236\n",
      "21237\n",
      "21238\n",
      "21239\n",
      "21240\n",
      "21241\n",
      "21242\n",
      "21243\n",
      "21244\n",
      "21245\n",
      "21246\n",
      "21247\n",
      "21248\n",
      "21249\n",
      "21250\n",
      "21251\n",
      "21252\n",
      "21253\n",
      "21254\n",
      "21255\n",
      "21256\n",
      "21257\n",
      "21258\n",
      "21259\n",
      "21260\n",
      "21261\n",
      "21262\n",
      "21263\n",
      "21264\n",
      "21265\n",
      "21266\n",
      "21267\n",
      "21268\n",
      "21269\n",
      "21270\n",
      "21271\n",
      "21272\n",
      "21273\n",
      "21274\n",
      "21275\n",
      "21276\n",
      "21277\n",
      "21278\n",
      "21279\n",
      "21280\n",
      "21281\n",
      "21282\n",
      "21283\n",
      "21284\n",
      "21285\n",
      "21286\n",
      "21287\n",
      "21288\n",
      "21289\n",
      "21290\n",
      "21291\n",
      "21292\n",
      "21293\n",
      "21294\n",
      "21295\n",
      "21296\n",
      "21297\n",
      "21298\n",
      "21299\n",
      "21300\n",
      "21301\n",
      "21302\n",
      "21303\n",
      "21304\n",
      "21305\n",
      "21306\n",
      "21307\n",
      "21308\n",
      "21309\n",
      "21310\n",
      "21311\n",
      "21312\n",
      "21313\n",
      "21314\n",
      "21315\n",
      "21316\n",
      "21317\n",
      "21318\n",
      "21319\n",
      "21320\n",
      "21321\n",
      "21322\n",
      "21323\n",
      "21324\n",
      "21325\n",
      "21326\n",
      "21327\n",
      "21328\n",
      "21329\n",
      "21330\n",
      "21331\n",
      "21332\n",
      "21333\n",
      "21334\n",
      "21335\n",
      "21336\n",
      "21337\n",
      "21338\n",
      "21339\n",
      "21340\n",
      "21341\n",
      "21342\n",
      "21343\n",
      "21344\n",
      "21345\n",
      "21346\n",
      "21347\n",
      "21348\n",
      "21349\n",
      "21350\n",
      "21351\n",
      "21352\n",
      "21353\n",
      "21354\n",
      "21355\n",
      "21356\n",
      "21357\n",
      "21358\n",
      "21359\n",
      "21360\n",
      "21361\n",
      "21362\n",
      "21363\n",
      "21364\n",
      "21365\n",
      "21366\n",
      "21367\n",
      "21368\n",
      "21369\n",
      "21370\n",
      "21371\n",
      "21372\n",
      "21373\n",
      "21374\n",
      "21375\n",
      "21376\n",
      "21377\n",
      "21378\n",
      "21379\n",
      "21380\n",
      "21381\n",
      "21382\n",
      "21383\n",
      "21384\n",
      "21385\n",
      "21386\n",
      "21387\n",
      "21388\n",
      "21389\n",
      "21390\n",
      "21391\n",
      "21392\n",
      "21393\n",
      "21394\n",
      "21395\n",
      "21396\n",
      "21397\n",
      "21398\n",
      "21399\n",
      "21400\n",
      "21401\n",
      "21402\n",
      "21403\n",
      "21404\n",
      "21405\n",
      "21406\n",
      "21407\n",
      "21408\n",
      "21409\n",
      "21410\n",
      "21411\n",
      "21412\n",
      "21413\n",
      "21414\n",
      "21415\n",
      "21416\n",
      "21417\n",
      "21418\n",
      "21419\n",
      "21420\n",
      "21421\n",
      "21422\n",
      "21423\n",
      "21424\n",
      "21425\n",
      "21426\n",
      "21427\n",
      "21428\n",
      "21429\n",
      "21430\n",
      "21431\n",
      "21432\n",
      "21433\n",
      "21434\n",
      "21435\n",
      "21436\n",
      "21437\n",
      "21438\n",
      "21439\n",
      "21440\n",
      "21441\n",
      "21442\n",
      "21443\n",
      "21444\n",
      "21445\n",
      "21446\n",
      "21447\n",
      "21448\n",
      "21449\n",
      "21450\n",
      "21451\n",
      "21452\n",
      "21453\n",
      "21454\n",
      "21455\n",
      "21456\n",
      "21457\n",
      "21458\n",
      "21459\n",
      "21460\n",
      "21461\n",
      "21462\n",
      "21463\n",
      "21464\n",
      "21465\n",
      "21466\n",
      "21467\n",
      "21468\n",
      "21469\n",
      "21470\n",
      "21471\n",
      "21472\n",
      "21473\n",
      "21474\n",
      "21475\n",
      "21476\n",
      "21477\n",
      "21478\n",
      "21479\n",
      "21480\n",
      "21481\n",
      "21482\n",
      "21483\n",
      "21484\n",
      "21485\n",
      "21486\n",
      "21487\n",
      "21488\n",
      "21489\n",
      "21490\n",
      "21491\n",
      "21492\n",
      "21493\n",
      "21494\n",
      "21495\n",
      "21496\n",
      "21497\n",
      "21498\n",
      "21499\n",
      "21500\n",
      "21501\n",
      "21502\n",
      "21503\n",
      "21504\n",
      "21505\n",
      "21506\n",
      "21507\n",
      "21508\n",
      "21509\n",
      "21510\n",
      "21511\n",
      "21512\n",
      "21513\n",
      "21514\n",
      "21515\n",
      "21516\n",
      "21517\n",
      "21518\n",
      "21519\n",
      "21520\n",
      "21521\n",
      "21522\n",
      "21523\n",
      "21524\n",
      "21525\n",
      "21526\n",
      "21527\n",
      "21528\n",
      "21529\n",
      "21530\n",
      "21531\n",
      "21532\n",
      "21533\n",
      "21534\n",
      "21535\n",
      "21536\n",
      "21537\n",
      "21538\n",
      "21539\n",
      "21540\n",
      "21541\n",
      "21542\n",
      "21543\n",
      "21544\n",
      "21545\n",
      "21546\n",
      "21547\n",
      "21548\n",
      "21549\n",
      "21550\n",
      "21551\n",
      "21552\n",
      "21553\n",
      "21554\n",
      "21555\n",
      "21556\n",
      "21557\n",
      "21558\n",
      "21559\n",
      "21560\n",
      "21561\n",
      "21562\n",
      "21563\n",
      "21564\n",
      "21565\n",
      "21566\n",
      "21567\n",
      "21568\n",
      "21569\n",
      "21570\n",
      "21571\n",
      "21572\n",
      "21573\n",
      "21574\n",
      "21575\n",
      "21576\n",
      "21577\n",
      "21578\n",
      "21579\n",
      "21580\n",
      "21581\n",
      "21582\n",
      "21583\n",
      "21584\n",
      "21585\n",
      "21586\n",
      "21587\n",
      "21588\n",
      "21589\n",
      "21590\n",
      "21591\n",
      "21592\n",
      "21593\n",
      "21594\n",
      "21595\n",
      "21596\n",
      "21597\n",
      "21598\n",
      "21599\n",
      "21600\n",
      "21601\n",
      "21602\n",
      "21603\n",
      "21604\n",
      "21605\n",
      "21606\n",
      "21607\n",
      "21608\n",
      "21609\n",
      "21610\n",
      "21611\n",
      "21612\n",
      "21613\n",
      "21614\n",
      "21615\n",
      "21616\n",
      "21617\n",
      "21618\n",
      "21619\n",
      "21620\n",
      "21621\n",
      "21622\n",
      "21623\n",
      "21624\n",
      "21625\n",
      "21626\n",
      "21627\n",
      "21628\n",
      "21629\n",
      "21630\n",
      "21631\n",
      "21632\n",
      "21633\n",
      "21634\n",
      "21635\n",
      "21636\n",
      "21637\n",
      "21638\n",
      "21639\n",
      "21640\n",
      "21641\n",
      "21642\n",
      "21643\n",
      "21644\n",
      "21645\n",
      "21646\n",
      "21647\n",
      "21648\n",
      "21649\n",
      "21650\n",
      "21651\n",
      "21652\n",
      "21653\n",
      "21654\n",
      "21655\n",
      "21656\n",
      "21657\n",
      "21658\n",
      "21659\n",
      "21660\n",
      "21661\n",
      "21662\n",
      "21663\n",
      "21664\n",
      "21665\n",
      "21666\n",
      "21667\n",
      "21668\n",
      "21669\n",
      "21670\n",
      "21671\n",
      "21672\n",
      "21673\n",
      "21674\n",
      "21675\n",
      "21676\n",
      "21677\n",
      "21678\n",
      "21679\n",
      "21680\n",
      "21681\n",
      "21682\n",
      "21683\n",
      "21684\n",
      "21685\n",
      "21686\n",
      "21687\n",
      "21688\n",
      "21689\n",
      "21690\n",
      "21691\n",
      "21692\n",
      "21693\n",
      "21694\n",
      "21695\n",
      "21696\n",
      "21697\n",
      "21698\n",
      "21699\n",
      "21700\n",
      "21701\n",
      "21702\n",
      "21703\n",
      "21704\n",
      "21705\n",
      "21706\n",
      "21707\n",
      "21708\n",
      "21709\n",
      "21710\n",
      "21711\n",
      "21712\n",
      "21713\n",
      "21714\n",
      "21715\n",
      "21716\n",
      "21717\n",
      "21718\n",
      "21719\n",
      "21720\n",
      "21721\n",
      "21722\n",
      "21723\n",
      "21724\n",
      "21725\n",
      "21726\n",
      "21727\n",
      "21728\n",
      "21729\n",
      "21730\n",
      "21731\n",
      "21732\n",
      "21733\n",
      "21734\n",
      "21735\n",
      "21736\n",
      "21737\n",
      "21738\n",
      "21739\n",
      "21740\n",
      "21741\n",
      "21742\n",
      "21743\n",
      "21744\n",
      "21745\n",
      "21746\n",
      "21747\n",
      "21748\n",
      "21749\n",
      "21750\n",
      "21751\n",
      "21752\n",
      "21753\n",
      "21754\n",
      "21755\n",
      "21756\n",
      "21757\n",
      "21758\n",
      "21759\n",
      "21760\n",
      "21761\n",
      "21762\n",
      "21763\n",
      "21764\n",
      "21765\n",
      "21766\n",
      "21767\n",
      "21768\n",
      "21769\n",
      "21770\n",
      "21771\n",
      "21772\n",
      "21773\n",
      "21774\n",
      "21775\n",
      "21776\n",
      "21777\n",
      "21778\n",
      "21779\n",
      "21780\n",
      "21781\n",
      "21782\n",
      "21783\n",
      "21784\n",
      "21785\n",
      "21786\n",
      "21787\n",
      "21788\n",
      "21789\n",
      "21790\n",
      "21791\n",
      "21792\n",
      "21793\n",
      "21794\n",
      "21795\n",
      "21796\n",
      "21797\n",
      "21798\n",
      "21799\n",
      "21800\n",
      "21801\n",
      "21802\n",
      "21803\n",
      "21804\n",
      "21805\n",
      "21806\n",
      "21807\n",
      "21808\n",
      "21809\n",
      "21810\n",
      "21811\n",
      "21812\n",
      "21813\n",
      "21814\n",
      "21815\n",
      "21816\n",
      "21817\n",
      "21818\n",
      "21819\n",
      "21820\n",
      "21821\n",
      "21822\n",
      "21823\n",
      "21824\n",
      "21825\n",
      "21826\n",
      "21827\n",
      "21828\n",
      "21829\n",
      "21830\n",
      "21831\n",
      "21832\n",
      "21833\n",
      "21834\n",
      "21835\n",
      "21836\n",
      "21837\n",
      "21838\n",
      "21839\n",
      "21840\n",
      "21841\n",
      "21842\n",
      "21843\n",
      "21844\n",
      "21845\n",
      "21846\n",
      "21847\n",
      "21848\n",
      "21849\n",
      "21850\n",
      "21851\n",
      "21852\n",
      "21853\n",
      "21854\n",
      "21855\n",
      "21856\n",
      "21857\n",
      "21858\n",
      "21859\n",
      "21860\n",
      "21861\n",
      "21862\n",
      "21863\n",
      "21864\n",
      "21865\n",
      "21866\n",
      "21867\n",
      "21868\n",
      "21869\n",
      "21870\n",
      "21871\n",
      "21872\n",
      "21873\n",
      "21874\n",
      "21875\n",
      "21876\n",
      "21877\n",
      "21878\n",
      "21879\n",
      "21880\n",
      "21881\n",
      "21882\n",
      "21883\n",
      "21884\n",
      "21885\n",
      "21886\n",
      "21887\n",
      "21888\n",
      "21889\n",
      "21890\n",
      "21891\n",
      "21892\n",
      "21893\n",
      "21894\n",
      "21895\n",
      "21896\n",
      "21897\n",
      "21898\n",
      "21899\n",
      "21900\n",
      "21901\n",
      "21902\n",
      "21903\n",
      "21904\n",
      "21905\n",
      "21906\n",
      "21907\n",
      "21908\n",
      "21909\n",
      "21910\n",
      "21911\n",
      "21912\n",
      "21913\n",
      "21914\n",
      "21915\n",
      "21916\n",
      "21917\n",
      "21918\n",
      "21919\n",
      "21920\n",
      "21921\n",
      "21922\n",
      "21923\n",
      "21924\n",
      "21925\n",
      "21926\n",
      "21927\n",
      "21928\n",
      "21929\n",
      "21930\n",
      "21931\n",
      "21932\n",
      "21933\n",
      "21934\n",
      "21935\n",
      "21936\n",
      "21937\n",
      "21938\n",
      "21939\n",
      "21940\n",
      "21941\n",
      "21942\n",
      "21943\n",
      "21944\n",
      "21945\n",
      "21946\n",
      "21947\n",
      "21948\n",
      "21949\n",
      "21950\n",
      "21951\n",
      "21952\n",
      "21953\n",
      "21954\n",
      "21955\n",
      "21956\n",
      "21957\n",
      "21958\n",
      "21959\n",
      "21960\n",
      "21961\n",
      "21962\n",
      "21963\n",
      "21964\n",
      "21965\n",
      "21966\n",
      "21967\n",
      "21968\n",
      "21969\n",
      "21970\n",
      "21971\n",
      "21972\n",
      "21973\n",
      "21974\n",
      "21975\n",
      "21976\n",
      "21977\n",
      "21978\n",
      "21979\n",
      "21980\n",
      "21981\n",
      "21982\n",
      "21983\n",
      "21984\n",
      "21985\n",
      "21986\n",
      "21987\n",
      "21988\n",
      "21989\n",
      "21990\n",
      "21991\n",
      "21992\n",
      "21993\n",
      "21994\n",
      "21995\n",
      "21996\n",
      "21997\n",
      "21998\n",
      "21999\n",
      "22000\n",
      "22001\n",
      "22002\n",
      "22003\n",
      "22004\n",
      "22005\n",
      "22006\n",
      "22007\n",
      "22008\n",
      "22009\n",
      "22010\n",
      "22011\n",
      "22012\n",
      "22013\n",
      "22014\n",
      "22015\n",
      "22016\n",
      "22017\n",
      "22018\n",
      "22019\n",
      "22020\n",
      "22021\n",
      "22022\n",
      "22023\n",
      "22024\n",
      "22025\n",
      "22026\n",
      "22027\n",
      "22028\n",
      "22029\n",
      "22030\n",
      "22031\n",
      "22032\n",
      "22033\n",
      "22034\n",
      "22035\n",
      "22036\n",
      "22037\n",
      "22038\n",
      "22039\n",
      "22040\n",
      "22041\n",
      "22042\n",
      "22043\n",
      "22044\n",
      "22045\n",
      "22046\n",
      "22047\n",
      "22048\n",
      "22049\n",
      "22050\n",
      "22051\n",
      "22052\n",
      "22053\n",
      "22054\n",
      "22055\n",
      "22056\n",
      "22057\n",
      "22058\n",
      "22059\n",
      "22060\n",
      "22061\n",
      "22062\n",
      "22063\n",
      "22064\n",
      "22065\n",
      "22066\n",
      "22067\n",
      "22068\n",
      "22069\n",
      "22070\n",
      "22071\n",
      "22072\n",
      "22073\n",
      "22074\n",
      "22075\n",
      "22076\n",
      "22077\n",
      "22078\n",
      "22079\n",
      "22080\n",
      "22081\n",
      "22082\n",
      "22083\n",
      "22084\n",
      "22085\n",
      "22086\n",
      "22087\n",
      "22088\n",
      "22089\n",
      "22090\n",
      "22091\n",
      "22092\n",
      "22093\n",
      "22094\n",
      "22095\n",
      "22096\n",
      "22097\n",
      "22098\n",
      "22099\n",
      "22100\n",
      "22101\n",
      "22102\n",
      "22103\n",
      "22104\n",
      "22105\n",
      "22106\n",
      "22107\n",
      "22108\n",
      "22109\n",
      "22110\n",
      "22111\n",
      "22112\n",
      "22113\n",
      "22114\n",
      "22115\n",
      "22116\n",
      "22117\n",
      "22118\n",
      "22119\n",
      "22120\n",
      "22121\n",
      "22122\n",
      "22123\n",
      "22124\n",
      "22125\n",
      "22126\n",
      "22127\n",
      "22128\n",
      "22129\n",
      "22130\n",
      "22131\n",
      "22132\n",
      "22133\n",
      "22134\n",
      "22135\n",
      "22136\n",
      "22137\n",
      "22138\n",
      "22139\n",
      "22140\n",
      "22141\n",
      "22142\n",
      "22143\n",
      "22144\n",
      "22145\n",
      "22146\n",
      "22147\n",
      "22148\n",
      "22149\n",
      "22150\n",
      "22151\n",
      "22152\n",
      "22153\n",
      "22154\n",
      "22155\n",
      "22156\n",
      "22157\n",
      "22158\n",
      "22159\n",
      "22160\n",
      "22161\n",
      "22162\n",
      "22163\n",
      "22164\n",
      "22165\n",
      "22166\n",
      "22167\n",
      "22168\n",
      "22169\n",
      "22170\n",
      "22171\n",
      "22172\n",
      "22173\n",
      "22174\n",
      "22175\n",
      "22176\n",
      "22177\n",
      "22178\n",
      "22179\n",
      "22180\n",
      "22181\n",
      "22182\n",
      "22183\n",
      "22184\n",
      "22185\n",
      "22186\n",
      "22187\n",
      "22188\n",
      "22189\n",
      "22190\n",
      "22191\n",
      "22192\n",
      "22193\n",
      "22194\n",
      "22195\n",
      "22196\n",
      "22197\n",
      "22198\n",
      "22199\n",
      "22200\n",
      "22201\n",
      "22202\n",
      "22203\n",
      "22204\n",
      "22205\n",
      "22206\n",
      "22207\n",
      "22208\n",
      "22209\n",
      "22210\n",
      "22211\n",
      "22212\n",
      "22213\n",
      "22214\n",
      "22215\n",
      "22216\n",
      "22217\n",
      "22218\n",
      "22219\n",
      "22220\n",
      "22221\n",
      "22222\n",
      "22223\n",
      "22224\n",
      "22225\n",
      "22226\n",
      "22227\n",
      "22228\n",
      "22229\n",
      "22230\n",
      "22231\n",
      "22232\n",
      "22233\n",
      "22234\n",
      "22235\n",
      "22236\n",
      "22237\n",
      "22238\n",
      "22239\n",
      "22240\n",
      "22241\n",
      "22242\n",
      "22243\n",
      "22244\n",
      "22245\n",
      "22246\n",
      "22247\n",
      "22248\n",
      "22249\n",
      "22250\n",
      "22251\n",
      "22252\n",
      "22253\n",
      "22254\n",
      "22255\n",
      "22256\n",
      "22257\n",
      "22258\n",
      "22259\n",
      "22260\n",
      "22261\n",
      "22262\n",
      "22263\n",
      "22264\n",
      "22265\n",
      "22266\n",
      "22267\n",
      "22268\n",
      "22269\n",
      "22270\n",
      "22271\n",
      "22272\n",
      "22273\n",
      "22274\n",
      "22275\n",
      "22276\n",
      "22277\n",
      "22278\n",
      "22279\n",
      "22280\n",
      "22281\n",
      "22282\n",
      "22283\n",
      "22284\n",
      "22285\n",
      "22286\n",
      "22287\n",
      "22288\n",
      "22289\n",
      "22290\n",
      "22291\n",
      "22292\n",
      "22293\n",
      "22294\n",
      "22295\n",
      "22296\n",
      "22297\n",
      "22298\n",
      "22299\n",
      "22300\n",
      "22301\n",
      "22302\n",
      "22303\n",
      "22304\n",
      "22305\n",
      "22306\n",
      "22307\n",
      "22308\n",
      "22309\n",
      "22310\n",
      "22311\n",
      "22312\n",
      "22313\n",
      "22314\n",
      "22315\n",
      "22316\n",
      "22317\n",
      "22318\n",
      "22319\n",
      "22320\n",
      "22321\n",
      "22322\n",
      "22323\n",
      "22324\n",
      "22325\n",
      "22326\n",
      "22327\n",
      "22328\n",
      "22329\n",
      "22330\n",
      "22331\n",
      "22332\n",
      "22333\n",
      "22334\n",
      "22335\n",
      "22336\n",
      "22337\n",
      "22338\n",
      "22339\n",
      "22340\n",
      "22341\n",
      "22342\n",
      "22343\n",
      "22344\n",
      "22345\n",
      "22346\n",
      "22347\n",
      "22348\n",
      "22349\n",
      "22350\n",
      "22351\n",
      "22352\n",
      "22353\n",
      "22354\n",
      "22355\n",
      "22356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22357\n",
      "22358\n",
      "22359\n",
      "22360\n",
      "22361\n",
      "22362\n",
      "22363\n",
      "22364\n",
      "22365\n",
      "22366\n",
      "22367\n",
      "22368\n",
      "22369\n",
      "22370\n",
      "22371\n",
      "22372\n",
      "22373\n",
      "22374\n",
      "22375\n",
      "22376\n",
      "22377\n",
      "22378\n",
      "22379\n",
      "22380\n",
      "22381\n",
      "22382\n",
      "22383\n",
      "22384\n",
      "22385\n",
      "22386\n",
      "22387\n",
      "22388\n",
      "22389\n",
      "22390\n",
      "22391\n",
      "22392\n",
      "22393\n",
      "22394\n",
      "22395\n",
      "22396\n",
      "22397\n",
      "22398\n",
      "22399\n",
      "22400\n",
      "22401\n",
      "22402\n",
      "22403\n",
      "22404\n",
      "22405\n",
      "22406\n",
      "22407\n",
      "22408\n",
      "22409\n",
      "22410\n",
      "22411\n",
      "22412\n",
      "22413\n",
      "22414\n",
      "22415\n",
      "22416\n",
      "22417\n",
      "22418\n",
      "22419\n",
      "22420\n",
      "22421\n",
      "22422\n",
      "22423\n",
      "22424\n",
      "22425\n",
      "22426\n",
      "22427\n",
      "22428\n",
      "22429\n",
      "22430\n",
      "22431\n",
      "22432\n",
      "22433\n",
      "22434\n",
      "22435\n",
      "22436\n",
      "22437\n",
      "22438\n",
      "22439\n",
      "22440\n",
      "22441\n",
      "22442\n",
      "22443\n",
      "22444\n",
      "22445\n",
      "22446\n",
      "22447\n",
      "22448\n",
      "22449\n",
      "22450\n",
      "22451\n",
      "22452\n",
      "22453\n",
      "22454\n",
      "22455\n",
      "22456\n",
      "22457\n",
      "22458\n",
      "22459\n",
      "22460\n",
      "22461\n",
      "22462\n",
      "22463\n",
      "22464\n",
      "22465\n",
      "22466\n",
      "22467\n",
      "22468\n",
      "22469\n",
      "22470\n",
      "22471\n",
      "22472\n",
      "22473\n",
      "22474\n",
      "22475\n",
      "22476\n",
      "22477\n",
      "22478\n",
      "22479\n",
      "22480\n",
      "22481\n",
      "22482\n",
      "22483\n",
      "22484\n",
      "22485\n",
      "22486\n",
      "22487\n",
      "22488\n",
      "22489\n",
      "22490\n",
      "22491\n",
      "22492\n",
      "22493\n",
      "22494\n",
      "22495\n",
      "22496\n",
      "22497\n",
      "22498\n",
      "22499\n",
      "22500\n",
      "22501\n",
      "22502\n",
      "22503\n",
      "22504\n",
      "22505\n",
      "22506\n",
      "22507\n",
      "22508\n",
      "22509\n",
      "22510\n",
      "22511\n",
      "22512\n",
      "22513\n",
      "22514\n",
      "22515\n",
      "22516\n",
      "22517\n",
      "22518\n",
      "22519\n",
      "22520\n",
      "22521\n",
      "22522\n",
      "22523\n",
      "22524\n",
      "22525\n",
      "22526\n",
      "22527\n",
      "22528\n",
      "22529\n",
      "22530\n",
      "22531\n",
      "22532\n",
      "22533\n",
      "22534\n",
      "22535\n",
      "22536\n",
      "22537\n",
      "22538\n",
      "22539\n",
      "22540\n",
      "22541\n",
      "22542\n",
      "22543\n",
      "22544\n",
      "22545\n",
      "22546\n",
      "22547\n",
      "22548\n",
      "22549\n",
      "22550\n",
      "22551\n",
      "22552\n",
      "22553\n",
      "22554\n",
      "22555\n",
      "22556\n",
      "22557\n",
      "22558\n",
      "22559\n",
      "22560\n",
      "22561\n",
      "22562\n",
      "22563\n",
      "22564\n",
      "22565\n",
      "22566\n",
      "22567\n",
      "22568\n",
      "22569\n",
      "22570\n",
      "22571\n",
      "22572\n",
      "22573\n",
      "22574\n",
      "22575\n",
      "22576\n",
      "22577\n",
      "22578\n",
      "22579\n",
      "22580\n",
      "22581\n",
      "22582\n",
      "22583\n",
      "22584\n",
      "22585\n",
      "22586\n",
      "22587\n",
      "22588\n",
      "22589\n",
      "22590\n",
      "22591\n",
      "22592\n",
      "22593\n",
      "22594\n",
      "22595\n",
      "22596\n",
      "22597\n",
      "22598\n",
      "22599\n",
      "22600\n",
      "22601\n",
      "22602\n",
      "22603\n",
      "22604\n",
      "22605\n",
      "22606\n",
      "22607\n",
      "22608\n",
      "22609\n",
      "22610\n",
      "22611\n",
      "22612\n",
      "22613\n",
      "22614\n",
      "22615\n",
      "22616\n",
      "22617\n",
      "22618\n",
      "22619\n",
      "22620\n",
      "22621\n",
      "22622\n",
      "22623\n",
      "22624\n",
      "22625\n",
      "22626\n",
      "22627\n",
      "22628\n",
      "22629\n",
      "22630\n",
      "22631\n",
      "22632\n",
      "22633\n",
      "22634\n",
      "22635\n",
      "22636\n",
      "22637\n",
      "22638\n",
      "22639\n",
      "22640\n",
      "22641\n",
      "22642\n",
      "22643\n",
      "22644\n",
      "22645\n",
      "22646\n",
      "22647\n",
      "22648\n",
      "22649\n",
      "22650\n",
      "22651\n",
      "22652\n",
      "22653\n",
      "22654\n",
      "22655\n",
      "22656\n",
      "22657\n",
      "22658\n",
      "22659\n",
      "22660\n",
      "22661\n",
      "22662\n",
      "22663\n",
      "22664\n",
      "22665\n",
      "22666\n",
      "22667\n",
      "22668\n",
      "22669\n",
      "22670\n",
      "22671\n",
      "22672\n",
      "22673\n",
      "22674\n",
      "22675\n",
      "22676\n",
      "22677\n",
      "22678\n",
      "22679\n",
      "22680\n",
      "22681\n",
      "22682\n",
      "22683\n",
      "22684\n",
      "22685\n",
      "22686\n",
      "22687\n",
      "22688\n",
      "22689\n",
      "22690\n",
      "22691\n",
      "22692\n",
      "22693\n",
      "22694\n",
      "22695\n",
      "22696\n",
      "22697\n",
      "22698\n",
      "22699\n",
      "22700\n",
      "22701\n",
      "22702\n",
      "22703\n",
      "22704\n",
      "22705\n",
      "22706\n",
      "22707\n",
      "22708\n",
      "22709\n",
      "22710\n",
      "22711\n",
      "22712\n",
      "22713\n",
      "22714\n",
      "22715\n",
      "22716\n",
      "22717\n",
      "22718\n",
      "22719\n",
      "22720\n",
      "22721\n",
      "22722\n",
      "22723\n",
      "22724\n",
      "22725\n",
      "22726\n",
      "22727\n",
      "22728\n",
      "22729\n",
      "22730\n",
      "22731\n",
      "22732\n",
      "22733\n",
      "22734\n",
      "22735\n",
      "22736\n",
      "22737\n",
      "22738\n",
      "22739\n",
      "22740\n",
      "22741\n",
      "22742\n",
      "22743\n",
      "22744\n",
      "22745\n",
      "22746\n",
      "22747\n",
      "22748\n",
      "22749\n",
      "22750\n",
      "22751\n",
      "22752\n",
      "22753\n",
      "22754\n",
      "22755\n",
      "22756\n",
      "22757\n",
      "22758\n",
      "22759\n",
      "22760\n",
      "22761\n",
      "22762\n",
      "22763\n",
      "22764\n",
      "22765\n",
      "22766\n",
      "22767\n",
      "22768\n",
      "22769\n",
      "22770\n",
      "22771\n",
      "22772\n",
      "22773\n",
      "22774\n",
      "22775\n",
      "22776\n",
      "22777\n",
      "22778\n",
      "22779\n",
      "22780\n",
      "22781\n",
      "22782\n",
      "22783\n",
      "22784\n",
      "22785\n",
      "22786\n",
      "22787\n",
      "22788\n",
      "22789\n",
      "22790\n",
      "22791\n",
      "22792\n",
      "22793\n",
      "22794\n",
      "22795\n",
      "22796\n",
      "22797\n",
      "22798\n",
      "22799\n",
      "22800\n",
      "22801\n",
      "22802\n",
      "22803\n",
      "22804\n",
      "22805\n",
      "22806\n",
      "22807\n",
      "22808\n",
      "22809\n",
      "22810\n",
      "22811\n",
      "22812\n",
      "22813\n",
      "22814\n",
      "22815\n",
      "22816\n",
      "22817\n",
      "22818\n",
      "22819\n",
      "22820\n",
      "22821\n",
      "22822\n",
      "22823\n",
      "22824\n",
      "22825\n",
      "22826\n",
      "22827\n",
      "22828\n",
      "22829\n",
      "22830\n",
      "22831\n",
      "22832\n",
      "22833\n",
      "22834\n",
      "22835\n",
      "22836\n",
      "22837\n",
      "22838\n",
      "22839\n",
      "22840\n",
      "22841\n",
      "22842\n",
      "22843\n",
      "22844\n",
      "22845\n",
      "22846\n",
      "22847\n",
      "22848\n",
      "22849\n",
      "22850\n",
      "22851\n",
      "22852\n",
      "22853\n",
      "22854\n",
      "22855\n",
      "22856\n",
      "22857\n",
      "22858\n",
      "22859\n",
      "22860\n",
      "22861\n",
      "22862\n",
      "22863\n",
      "22864\n",
      "22865\n",
      "22866\n",
      "22867\n",
      "22868\n",
      "22869\n",
      "22870\n",
      "22871\n",
      "22872\n",
      "22873\n",
      "22874\n",
      "22875\n",
      "22876\n",
      "22877\n",
      "22878\n",
      "22879\n",
      "22880\n",
      "22881\n",
      "22882\n",
      "22883\n",
      "22884\n",
      "22885\n",
      "22886\n",
      "22887\n",
      "22888\n",
      "22889\n",
      "22890\n",
      "22891\n",
      "22892\n",
      "22893\n",
      "22894\n",
      "22895\n",
      "22896\n",
      "22897\n",
      "22898\n",
      "22899\n",
      "22900\n",
      "22901\n",
      "22902\n",
      "22903\n",
      "22904\n",
      "22905\n",
      "22906\n",
      "22907\n",
      "22908\n",
      "22909\n",
      "22910\n",
      "22911\n",
      "22912\n",
      "22913\n",
      "22914\n",
      "22915\n",
      "22916\n",
      "22917\n",
      "22918\n",
      "22919\n",
      "22920\n",
      "22921\n",
      "22922\n",
      "22923\n",
      "22924\n",
      "22925\n",
      "22926\n",
      "22927\n",
      "22928\n",
      "22929\n",
      "22930\n",
      "22931\n",
      "22932\n",
      "22933\n",
      "22934\n",
      "22935\n",
      "22936\n",
      "22937\n",
      "22938\n",
      "22939\n",
      "22940\n",
      "22941\n",
      "22942\n",
      "22943\n",
      "22944\n",
      "22945\n",
      "22946\n",
      "22947\n",
      "22948\n",
      "22949\n",
      "22950\n",
      "22951\n",
      "22952\n",
      "22953\n",
      "22954\n",
      "22955\n",
      "22956\n",
      "22957\n",
      "22958\n",
      "22959\n",
      "22960\n",
      "22961\n",
      "22962\n",
      "22963\n",
      "22964\n",
      "22965\n",
      "22966\n",
      "22967\n",
      "22968\n",
      "22969\n",
      "22970\n",
      "22971\n",
      "22972\n",
      "22973\n",
      "22974\n",
      "22975\n",
      "22976\n",
      "22977\n",
      "22978\n",
      "22979\n",
      "22980\n",
      "22981\n",
      "22982\n",
      "22983\n",
      "22984\n",
      "22985\n",
      "22986\n",
      "22987\n",
      "22988\n",
      "22989\n",
      "22990\n",
      "22991\n",
      "22992\n",
      "22993\n",
      "22994\n",
      "22995\n",
      "22996\n",
      "22997\n",
      "22998\n",
      "22999\n",
      "23000\n",
      "23001\n",
      "23002\n",
      "23003\n",
      "23004\n",
      "23005\n",
      "23006\n",
      "23007\n",
      "23008\n",
      "23009\n",
      "23010\n",
      "23011\n",
      "23012\n",
      "23013\n",
      "23014\n",
      "23015\n",
      "23016\n",
      "23017\n",
      "23018\n",
      "23019\n",
      "23020\n",
      "23021\n",
      "23022\n",
      "23023\n",
      "23024\n",
      "23025\n",
      "23026\n",
      "23027\n",
      "23028\n",
      "23029\n",
      "23030\n",
      "23031\n",
      "23032\n",
      "23033\n",
      "23034\n",
      "23035\n",
      "23036\n",
      "23037\n",
      "23038\n",
      "23039\n",
      "23040\n",
      "23041\n",
      "23042\n",
      "23043\n",
      "23044\n",
      "23045\n",
      "23046\n",
      "23047\n",
      "23048\n",
      "23049\n",
      "23050\n",
      "23051\n",
      "23052\n",
      "23053\n",
      "23054\n",
      "23055\n",
      "23056\n",
      "23057\n",
      "23058\n",
      "23059\n",
      "23060\n",
      "23061\n",
      "23062\n",
      "23063\n",
      "23064\n",
      "23065\n",
      "23066\n",
      "23067\n",
      "23068\n",
      "23069\n",
      "23070\n",
      "23071\n",
      "23072\n",
      "23073\n",
      "23074\n",
      "23075\n",
      "23076\n",
      "23077\n",
      "23078\n",
      "23079\n",
      "23080\n",
      "23081\n",
      "23082\n",
      "23083\n",
      "23084\n",
      "23085\n",
      "23086\n",
      "23087\n",
      "23088\n",
      "23089\n",
      "23090\n",
      "23091\n",
      "23092\n",
      "23093\n",
      "23094\n",
      "23095\n",
      "23096\n",
      "23097\n",
      "23098\n",
      "23099\n",
      "23100\n",
      "23101\n",
      "23102\n",
      "23103\n",
      "23104\n",
      "23105\n",
      "23106\n",
      "23107\n",
      "23108\n",
      "23109\n",
      "23110\n",
      "23111\n",
      "23112\n",
      "23113\n",
      "23114\n",
      "23115\n",
      "23116\n",
      "23117\n",
      "23118\n",
      "23119\n",
      "23120\n",
      "23121\n",
      "23122\n",
      "23123\n",
      "23124\n",
      "23125\n",
      "23126\n",
      "23127\n",
      "23128\n",
      "23129\n",
      "23130\n",
      "23131\n",
      "23132\n",
      "23133\n",
      "23134\n",
      "23135\n",
      "23136\n",
      "23137\n",
      "23138\n",
      "23139\n",
      "23140\n",
      "23141\n",
      "23142\n",
      "23143\n",
      "23144\n",
      "23145\n",
      "23146\n",
      "23147\n",
      "23148\n",
      "23149\n",
      "23150\n",
      "23151\n",
      "23152\n",
      "23153\n",
      "23154\n",
      "23155\n",
      "23156\n",
      "23157\n",
      "23158\n",
      "23159\n",
      "23160\n",
      "23161\n",
      "23162\n",
      "23163\n",
      "23164\n",
      "23165\n",
      "23166\n",
      "23167\n",
      "23168\n",
      "23169\n",
      "23170\n",
      "23171\n",
      "23172\n",
      "23173\n",
      "23174\n",
      "23175\n",
      "23176\n",
      "23177\n",
      "23178\n",
      "23179\n",
      "23180\n",
      "23181\n",
      "23182\n",
      "23183\n",
      "23184\n",
      "23185\n",
      "23186\n",
      "23187\n",
      "23188\n",
      "23189\n",
      "23190\n",
      "23191\n",
      "23192\n",
      "23193\n",
      "23194\n",
      "23195\n",
      "23196\n",
      "23197\n",
      "23198\n",
      "23199\n",
      "23200\n",
      "23201\n",
      "23202\n",
      "23203\n",
      "23204\n",
      "23205\n",
      "23206\n",
      "23207\n",
      "23208\n",
      "23209\n",
      "23210\n",
      "23211\n",
      "23212\n",
      "23213\n",
      "23214\n",
      "23215\n",
      "23216\n",
      "23217\n",
      "23218\n",
      "23219\n",
      "23220\n",
      "23221\n",
      "23222\n",
      "23223\n",
      "23224\n",
      "23225\n",
      "23226\n",
      "23227\n",
      "23228\n",
      "23229\n",
      "23230\n",
      "23231\n",
      "23232\n",
      "23233\n",
      "23234\n",
      "23235\n",
      "23236\n",
      "23237\n",
      "23238\n",
      "23239\n",
      "23240\n",
      "23241\n",
      "23242\n",
      "23243\n",
      "23244\n",
      "23245\n",
      "23246\n",
      "23247\n",
      "23248\n",
      "23249\n",
      "23250\n",
      "23251\n",
      "23252\n",
      "23253\n",
      "23254\n",
      "23255\n",
      "23256\n",
      "23257\n",
      "23258\n",
      "23259\n",
      "23260\n",
      "23261\n",
      "23262\n",
      "23263\n",
      "23264\n",
      "23265\n",
      "23266\n",
      "23267\n",
      "23268\n",
      "23269\n",
      "23270\n",
      "23271\n",
      "23272\n",
      "23273\n",
      "23274\n",
      "23275\n",
      "23276\n",
      "23277\n",
      "23278\n",
      "23279\n",
      "23280\n",
      "23281\n",
      "23282\n",
      "23283\n",
      "23284\n",
      "23285\n",
      "23286\n",
      "23287\n",
      "23288\n",
      "23289\n",
      "23290\n",
      "23291\n",
      "23292\n",
      "23293\n",
      "23294\n",
      "23295\n",
      "23296\n",
      "23297\n",
      "23298\n",
      "23299\n",
      "23300\n",
      "23301\n",
      "23302\n",
      "23303\n",
      "23304\n",
      "23305\n",
      "23306\n",
      "23307\n",
      "23308\n",
      "23309\n",
      "23310\n",
      "23311\n",
      "23312\n",
      "23313\n",
      "23314\n",
      "23315\n",
      "23316\n",
      "23317\n",
      "23318\n",
      "23319\n",
      "23320\n",
      "23321\n",
      "23322\n",
      "23323\n",
      "23324\n",
      "23325\n",
      "23326\n",
      "23327\n",
      "23328\n",
      "23329\n",
      "23330\n",
      "23331\n",
      "23332\n",
      "23333\n",
      "23334\n",
      "23335\n",
      "23336\n",
      "23337\n",
      "23338\n",
      "23339\n",
      "23340\n",
      "23341\n",
      "23342\n",
      "23343\n",
      "23344\n",
      "23345\n",
      "23346\n",
      "23347\n",
      "23348\n",
      "23349\n",
      "23350\n",
      "23351\n",
      "23352\n",
      "23353\n",
      "23354\n",
      "23355\n",
      "23356\n",
      "23357\n",
      "23358\n",
      "23359\n",
      "23360\n",
      "23361\n",
      "23362\n",
      "23363\n",
      "23364\n",
      "23365\n",
      "23366\n",
      "23367\n",
      "23368\n",
      "23369\n",
      "23370\n",
      "23371\n",
      "23372\n",
      "23373\n",
      "23374\n",
      "23375\n",
      "23376\n",
      "23377\n",
      "23378\n",
      "23379\n",
      "23380\n",
      "23381\n",
      "23382\n",
      "23383\n",
      "23384\n",
      "23385\n",
      "23386\n",
      "23387\n",
      "23388\n",
      "23389\n",
      "23390\n",
      "23391\n",
      "23392\n",
      "23393\n",
      "23394\n",
      "23395\n",
      "23396\n",
      "23397\n",
      "23398\n",
      "23399\n",
      "23400\n",
      "23401\n",
      "23402\n",
      "23403\n",
      "23404\n",
      "23405\n",
      "23406\n",
      "23407\n",
      "23408\n",
      "23409\n",
      "23410\n",
      "23411\n",
      "23412\n",
      "23413\n",
      "23414\n",
      "23415\n",
      "23416\n",
      "23417\n",
      "23418\n",
      "23419\n",
      "23420\n",
      "23421\n",
      "23422\n",
      "23423\n",
      "23424\n",
      "23425\n",
      "23426\n",
      "23427\n",
      "23428\n",
      "23429\n",
      "23430\n",
      "23431\n",
      "23432\n",
      "23433\n",
      "23434\n",
      "23435\n",
      "23436\n",
      "23437\n",
      "23438\n",
      "23439\n",
      "23440\n",
      "23441\n",
      "23442\n",
      "23443\n",
      "23444\n",
      "23445\n",
      "23446\n",
      "23447\n",
      "23448\n",
      "23449\n",
      "23450\n",
      "23451\n",
      "23452\n",
      "23453\n",
      "23454\n",
      "23455\n",
      "23456\n",
      "23457\n",
      "23458\n",
      "23459\n",
      "23460\n",
      "23461\n",
      "23462\n",
      "23463\n",
      "23464\n",
      "23465\n",
      "23466\n",
      "23467\n",
      "23468\n",
      "23469\n",
      "23470\n",
      "23471\n",
      "23472\n",
      "23473\n",
      "23474\n",
      "23475\n",
      "23476\n",
      "23477\n",
      "23478\n",
      "23479\n",
      "23480\n",
      "23481\n",
      "23482\n",
      "23483\n",
      "23484\n",
      "23485\n",
      "23486\n",
      "23487\n",
      "23488\n",
      "23489\n",
      "23490\n",
      "23491\n",
      "23492\n",
      "23493\n",
      "23494\n",
      "23495\n",
      "23496\n",
      "23497\n",
      "23498\n",
      "23499\n",
      "23500\n",
      "23501\n",
      "23502\n",
      "23503\n",
      "23504\n",
      "23505\n",
      "23506\n",
      "23507\n",
      "23508\n",
      "23509\n",
      "23510\n",
      "23511\n",
      "23512\n",
      "23513\n",
      "23514\n",
      "23515\n",
      "23516\n",
      "23517\n",
      "23518\n",
      "23519\n",
      "23520\n",
      "23521\n",
      "23522\n",
      "23523\n",
      "23524\n",
      "23525\n",
      "23526\n",
      "23527\n",
      "23528\n",
      "23529\n",
      "23530\n",
      "23531\n",
      "23532\n",
      "23533\n",
      "23534\n",
      "23535\n",
      "23536\n",
      "23537\n",
      "23538\n",
      "23539\n",
      "23540\n",
      "23541\n",
      "23542\n",
      "23543\n",
      "23544\n",
      "23545\n",
      "23546\n",
      "23547\n",
      "23548\n",
      "23549\n",
      "23550\n",
      "23551\n",
      "23552\n",
      "23553\n",
      "23554\n",
      "23555\n",
      "23556\n",
      "23557\n",
      "23558\n",
      "23559\n",
      "23560\n",
      "23561\n",
      "23562\n",
      "23563\n",
      "23564\n",
      "23565\n",
      "23566\n",
      "23567\n",
      "23568\n",
      "23569\n",
      "23570\n",
      "23571\n",
      "23572\n",
      "23573\n",
      "23574\n",
      "23575\n",
      "23576\n",
      "23577\n",
      "23578\n",
      "23579\n",
      "23580\n",
      "23581\n",
      "23582\n",
      "23583\n",
      "23584\n",
      "23585\n",
      "23586\n",
      "23587\n",
      "23588\n",
      "23589\n",
      "23590\n",
      "23591\n",
      "23592\n",
      "23593\n",
      "23594\n",
      "23595\n",
      "23596\n",
      "23597\n",
      "23598\n",
      "23599\n",
      "23600\n",
      "23601\n",
      "23602\n",
      "23603\n",
      "23604\n",
      "23605\n",
      "23606\n",
      "23607\n",
      "23608\n",
      "23609\n",
      "23610\n",
      "23611\n",
      "23612\n",
      "23613\n",
      "23614\n",
      "23615\n",
      "23616\n",
      "23617\n",
      "23618\n",
      "23619\n",
      "23620\n",
      "23621\n",
      "23622\n",
      "23623\n",
      "23624\n",
      "23625\n",
      "23626\n",
      "23627\n",
      "23628\n",
      "23629\n",
      "23630\n",
      "23631\n",
      "23632\n",
      "23633\n",
      "23634\n",
      "23635\n",
      "23636\n",
      "23637\n",
      "23638\n",
      "23639\n",
      "23640\n",
      "23641\n",
      "23642\n",
      "23643\n",
      "23644\n",
      "23645\n",
      "23646\n",
      "23647\n",
      "23648\n",
      "23649\n",
      "23650\n",
      "23651\n",
      "23652\n",
      "23653\n",
      "23654\n",
      "23655\n",
      "23656\n",
      "23657\n",
      "23658\n",
      "23659\n",
      "23660\n",
      "23661\n",
      "23662\n",
      "23663\n",
      "23664\n",
      "23665\n",
      "23666\n",
      "23667\n",
      "23668\n",
      "23669\n",
      "23670\n",
      "23671\n",
      "23672\n",
      "23673\n",
      "23674\n",
      "23675\n",
      "23676\n",
      "23677\n",
      "23678\n",
      "23679\n",
      "23680\n",
      "23681\n",
      "23682\n",
      "23683\n",
      "23684\n",
      "23685\n",
      "23686\n",
      "23687\n",
      "23688\n",
      "23689\n",
      "23690\n",
      "23691\n",
      "23692\n",
      "23693\n",
      "23694\n",
      "23695\n",
      "23696\n",
      "23697\n",
      "23698\n",
      "23699\n",
      "23700\n",
      "23701\n",
      "23702\n",
      "23703\n",
      "23704\n",
      "23705\n",
      "23706\n",
      "23707\n",
      "23708\n",
      "23709\n",
      "23710\n",
      "23711\n",
      "23712\n",
      "23713\n",
      "23714\n",
      "23715\n",
      "23716\n",
      "23717\n",
      "23718\n",
      "23719\n",
      "23720\n",
      "23721\n",
      "23722\n",
      "23723\n",
      "23724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23725\n",
      "23726\n",
      "23727\n",
      "23728\n",
      "23729\n",
      "23730\n",
      "23731\n",
      "23732\n",
      "23733\n",
      "23734\n",
      "23735\n",
      "23736\n",
      "23737\n",
      "23738\n",
      "23739\n",
      "23740\n",
      "23741\n",
      "23742\n",
      "23743\n",
      "23744\n",
      "23745\n",
      "23746\n",
      "23747\n",
      "23748\n",
      "23749\n",
      "23750\n",
      "23751\n",
      "23752\n",
      "23753\n",
      "23754\n",
      "23755\n",
      "23756\n",
      "23757\n",
      "23758\n",
      "23759\n",
      "23760\n",
      "23761\n",
      "23762\n",
      "23763\n",
      "23764\n",
      "23765\n",
      "23766\n",
      "23767\n",
      "23768\n",
      "23769\n",
      "23770\n",
      "23771\n",
      "23772\n",
      "23773\n",
      "23774\n",
      "23775\n",
      "23776\n",
      "23777\n",
      "23778\n",
      "23779\n",
      "23780\n",
      "23781\n",
      "23782\n",
      "23783\n",
      "23784\n",
      "23785\n",
      "23786\n",
      "23787\n",
      "23788\n",
      "23789\n",
      "23790\n",
      "23791\n",
      "23792\n",
      "23793\n",
      "23794\n",
      "23795\n",
      "23796\n",
      "23797\n",
      "23798\n",
      "23799\n",
      "23800\n",
      "23801\n",
      "23802\n",
      "23803\n",
      "23804\n",
      "23805\n",
      "23806\n",
      "23807\n",
      "23808\n",
      "23809\n",
      "23810\n",
      "23811\n",
      "23812\n",
      "23813\n",
      "23814\n",
      "23815\n",
      "23816\n",
      "23817\n",
      "23818\n",
      "23819\n",
      "23820\n",
      "23821\n",
      "23822\n",
      "23823\n",
      "23824\n",
      "23825\n",
      "23826\n",
      "23827\n",
      "23828\n",
      "23829\n",
      "23830\n",
      "23831\n",
      "23832\n",
      "23833\n",
      "23834\n",
      "23835\n",
      "23836\n",
      "23837\n",
      "23838\n",
      "23839\n",
      "23840\n",
      "23841\n",
      "23842\n",
      "23843\n",
      "23844\n",
      "23845\n",
      "23846\n",
      "23847\n",
      "23848\n",
      "23849\n",
      "23850\n",
      "23851\n",
      "23852\n",
      "23853\n",
      "23854\n",
      "23855\n",
      "23856\n",
      "23857\n",
      "23858\n",
      "23859\n",
      "23860\n",
      "23861\n",
      "23862\n",
      "23863\n",
      "23864\n",
      "23865\n",
      "23866\n",
      "23867\n",
      "23868\n",
      "23869\n",
      "23870\n",
      "23871\n",
      "23872\n",
      "23873\n",
      "23874\n",
      "23875\n",
      "23876\n",
      "23877\n",
      "23878\n",
      "23879\n",
      "23880\n",
      "23881\n",
      "23882\n",
      "23883\n",
      "23884\n",
      "23885\n",
      "23886\n",
      "23887\n",
      "23888\n",
      "23889\n",
      "23890\n",
      "23891\n",
      "23892\n",
      "23893\n",
      "23894\n",
      "23895\n",
      "23896\n",
      "23897\n",
      "23898\n",
      "23899\n",
      "23900\n",
      "23901\n",
      "23902\n",
      "23903\n",
      "23904\n",
      "23905\n",
      "23906\n",
      "23907\n",
      "23908\n",
      "23909\n",
      "23910\n",
      "23911\n",
      "23912\n",
      "23913\n",
      "23914\n",
      "23915\n",
      "23916\n",
      "23917\n",
      "23918\n",
      "23919\n",
      "23920\n",
      "23921\n",
      "23922\n",
      "23923\n",
      "23924\n",
      "23925\n",
      "23926\n",
      "23927\n",
      "23928\n",
      "23929\n",
      "23930\n",
      "23931\n",
      "23932\n",
      "23933\n",
      "23934\n",
      "23935\n",
      "23936\n",
      "23937\n",
      "23938\n",
      "23939\n",
      "23940\n",
      "23941\n",
      "23942\n",
      "23943\n",
      "23944\n",
      "23945\n",
      "23946\n",
      "23947\n",
      "23948\n",
      "23949\n",
      "23950\n",
      "23951\n",
      "23952\n",
      "23953\n",
      "23954\n",
      "23955\n",
      "23956\n",
      "23957\n",
      "23958\n",
      "23959\n",
      "23960\n",
      "23961\n",
      "23962\n",
      "23963\n",
      "23964\n",
      "23965\n",
      "23966\n",
      "23967\n",
      "23968\n",
      "23969\n",
      "23970\n",
      "23971\n",
      "23972\n",
      "23973\n",
      "23974\n",
      "23975\n",
      "23976\n",
      "23977\n",
      "23978\n",
      "23979\n",
      "23980\n",
      "23981\n",
      "23982\n",
      "23983\n",
      "23984\n",
      "23985\n",
      "23986\n",
      "23987\n",
      "23988\n",
      "23989\n",
      "23990\n",
      "23991\n",
      "23992\n",
      "23993\n",
      "23994\n",
      "23995\n",
      "23996\n",
      "23997\n",
      "23998\n",
      "23999\n",
      "24000\n",
      "24001\n",
      "24002\n",
      "24003\n",
      "24004\n",
      "24005\n",
      "24006\n",
      "24007\n",
      "24008\n",
      "24009\n",
      "24010\n",
      "24011\n",
      "24012\n",
      "24013\n",
      "24014\n",
      "24015\n",
      "24016\n",
      "24017\n",
      "24018\n",
      "24019\n",
      "24020\n",
      "24021\n",
      "24022\n",
      "24023\n",
      "24024\n",
      "24025\n",
      "24026\n",
      "24027\n",
      "24028\n",
      "24029\n",
      "24030\n",
      "24031\n",
      "24032\n",
      "24033\n",
      "24034\n",
      "24035\n",
      "24036\n",
      "24037\n",
      "24038\n",
      "24039\n",
      "24040\n",
      "24041\n",
      "24042\n",
      "24043\n",
      "24044\n",
      "24045\n",
      "24046\n",
      "24047\n",
      "24048\n",
      "24049\n",
      "24050\n",
      "24051\n",
      "24052\n",
      "24053\n",
      "24054\n",
      "24055\n",
      "24056\n",
      "24057\n",
      "24058\n",
      "24059\n",
      "24060\n",
      "24061\n",
      "24062\n",
      "24063\n",
      "24064\n",
      "24065\n",
      "24066\n",
      "24067\n",
      "24068\n",
      "24069\n",
      "24070\n",
      "24071\n",
      "24072\n",
      "24073\n",
      "24074\n",
      "24075\n",
      "24076\n",
      "24077\n",
      "24078\n",
      "24079\n",
      "24080\n",
      "24081\n",
      "24082\n",
      "24083\n",
      "24084\n",
      "24085\n",
      "24086\n",
      "24087\n",
      "24088\n",
      "24089\n",
      "24090\n",
      "24091\n",
      "24092\n",
      "24093\n",
      "24094\n",
      "24095\n",
      "24096\n",
      "24097\n",
      "24098\n",
      "24099\n",
      "24100\n",
      "24101\n",
      "24102\n",
      "24103\n",
      "24104\n",
      "24105\n",
      "24106\n",
      "24107\n",
      "24108\n",
      "24109\n",
      "24110\n",
      "24111\n",
      "24112\n",
      "24113\n",
      "24114\n",
      "24115\n",
      "24116\n",
      "24117\n",
      "24118\n",
      "24119\n",
      "24120\n",
      "24121\n",
      "24122\n",
      "24123\n",
      "24124\n",
      "24125\n",
      "24126\n",
      "24127\n",
      "24128\n",
      "24129\n",
      "24130\n",
      "24131\n",
      "24132\n",
      "24133\n",
      "24134\n",
      "24135\n",
      "24136\n",
      "24137\n",
      "24138\n",
      "24139\n",
      "24140\n",
      "24141\n",
      "24142\n",
      "24143\n",
      "24144\n",
      "24145\n",
      "24146\n",
      "24147\n",
      "24148\n",
      "24149\n",
      "24150\n",
      "24151\n",
      "24152\n",
      "24153\n",
      "24154\n",
      "24155\n",
      "24156\n",
      "24157\n",
      "24158\n",
      "24159\n",
      "24160\n",
      "24161\n",
      "24162\n",
      "24163\n",
      "24164\n",
      "24165\n",
      "24166\n",
      "24167\n",
      "24168\n",
      "24169\n",
      "24170\n",
      "24171\n",
      "24172\n",
      "24173\n",
      "24174\n",
      "24175\n",
      "24176\n",
      "24177\n",
      "24178\n",
      "24179\n",
      "24180\n",
      "24181\n",
      "24182\n",
      "24183\n",
      "24184\n",
      "24185\n",
      "24186\n",
      "24187\n",
      "24188\n",
      "24189\n",
      "24190\n",
      "24191\n",
      "24192\n",
      "24193\n",
      "24194\n",
      "24195\n",
      "24196\n",
      "24197\n",
      "24198\n",
      "24199\n",
      "24200\n",
      "24201\n",
      "24202\n",
      "24203\n",
      "24204\n",
      "24205\n",
      "24206\n",
      "24207\n",
      "24208\n",
      "24209\n",
      "24210\n",
      "24211\n",
      "24212\n",
      "24213\n",
      "24214\n",
      "24215\n",
      "24216\n",
      "24217\n",
      "24218\n",
      "24219\n",
      "24220\n",
      "24221\n",
      "24222\n",
      "24223\n",
      "24224\n",
      "24225\n",
      "24226\n",
      "24227\n",
      "24228\n",
      "24229\n",
      "24230\n",
      "24231\n",
      "24232\n",
      "24233\n",
      "24234\n",
      "24235\n",
      "24236\n",
      "24237\n",
      "24238\n",
      "24239\n",
      "24240\n",
      "24241\n",
      "24242\n",
      "24243\n",
      "24244\n",
      "24245\n",
      "24246\n",
      "24247\n",
      "24248\n",
      "24249\n",
      "24250\n",
      "24251\n",
      "24252\n",
      "24253\n",
      "24254\n",
      "24255\n",
      "24256\n",
      "24257\n",
      "24258\n",
      "24259\n",
      "24260\n",
      "24261\n",
      "24262\n",
      "24263\n",
      "24264\n",
      "24265\n",
      "24266\n",
      "24267\n",
      "24268\n",
      "24269\n",
      "24270\n",
      "24271\n",
      "24272\n",
      "24273\n",
      "24274\n",
      "24275\n",
      "24276\n",
      "24277\n",
      "24278\n",
      "24279\n",
      "24280\n",
      "24281\n",
      "24282\n",
      "24283\n",
      "24284\n",
      "24285\n",
      "24286\n",
      "24287\n",
      "24288\n",
      "24289\n",
      "24290\n",
      "24291\n",
      "24292\n",
      "24293\n",
      "24294\n",
      "24295\n",
      "24296\n",
      "24297\n",
      "24298\n",
      "24299\n",
      "24300\n",
      "24301\n",
      "24302\n",
      "24303\n",
      "24304\n",
      "24305\n",
      "24306\n",
      "24307\n",
      "24308\n",
      "24309\n",
      "24310\n",
      "24311\n",
      "24312\n",
      "24313\n",
      "24314\n",
      "24315\n",
      "24316\n",
      "24317\n",
      "24318\n",
      "24319\n",
      "24320\n",
      "24321\n",
      "24322\n",
      "24323\n",
      "24324\n",
      "24325\n",
      "24326\n",
      "24327\n",
      "24328\n",
      "24329\n",
      "24330\n",
      "24331\n",
      "24332\n",
      "24333\n",
      "24334\n",
      "24335\n",
      "24336\n",
      "24337\n",
      "24338\n",
      "24339\n",
      "24340\n",
      "24341\n",
      "24342\n",
      "24343\n",
      "24344\n",
      "24345\n",
      "24346\n",
      "24347\n",
      "24348\n",
      "24349\n",
      "24350\n",
      "24351\n",
      "24352\n",
      "24353\n",
      "24354\n",
      "24355\n",
      "24356\n",
      "24357\n",
      "24358\n",
      "24359\n",
      "24360\n",
      "24361\n",
      "24362\n",
      "24363\n",
      "24364\n",
      "24365\n",
      "24366\n",
      "24367\n",
      "24368\n",
      "24369\n",
      "24370\n",
      "24371\n",
      "24372\n",
      "24373\n",
      "24374\n",
      "24375\n",
      "24376\n",
      "24377\n",
      "24378\n",
      "24379\n",
      "24380\n",
      "24381\n",
      "24382\n",
      "24383\n",
      "24384\n",
      "24385\n",
      "24386\n",
      "24387\n",
      "24388\n",
      "24389\n",
      "24390\n",
      "24391\n",
      "24392\n",
      "24393\n",
      "24394\n",
      "24395\n",
      "24396\n",
      "24397\n",
      "24398\n",
      "24399\n",
      "24400\n",
      "24401\n",
      "24402\n",
      "24403\n",
      "24404\n",
      "24405\n",
      "24406\n",
      "24407\n",
      "24408\n",
      "24409\n",
      "24410\n",
      "24411\n",
      "24412\n",
      "24413\n",
      "24414\n",
      "24415\n",
      "24416\n",
      "24417\n",
      "24418\n",
      "24419\n",
      "24420\n",
      "24421\n",
      "24422\n",
      "24423\n",
      "24424\n",
      "24425\n",
      "24426\n",
      "24427\n",
      "24428\n",
      "24429\n",
      "24430\n",
      "24431\n",
      "24432\n",
      "24433\n",
      "24434\n",
      "24435\n",
      "24436\n",
      "24437\n",
      "24438\n",
      "24439\n",
      "24440\n",
      "24441\n",
      "24442\n",
      "24443\n",
      "24444\n",
      "24445\n",
      "24446\n",
      "24447\n",
      "24448\n",
      "24449\n",
      "24450\n",
      "24451\n",
      "24452\n",
      "24453\n",
      "24454\n",
      "24455\n",
      "24456\n",
      "24457\n",
      "24458\n",
      "24459\n",
      "24460\n",
      "24461\n",
      "24462\n",
      "24463\n",
      "24464\n",
      "24465\n",
      "24466\n",
      "24467\n",
      "24468\n",
      "24469\n",
      "24470\n",
      "24471\n",
      "24472\n",
      "24473\n",
      "24474\n",
      "24475\n",
      "24476\n",
      "24477\n",
      "24478\n",
      "24479\n",
      "24480\n",
      "24481\n",
      "24482\n",
      "24483\n",
      "24484\n",
      "24485\n",
      "24486\n",
      "24487\n",
      "24488\n",
      "24489\n",
      "24490\n",
      "24491\n",
      "24492\n",
      "24493\n",
      "24494\n",
      "24495\n",
      "24496\n",
      "24497\n",
      "24498\n",
      "24499\n",
      "24500\n",
      "24501\n",
      "24502\n",
      "24503\n",
      "24504\n",
      "24505\n",
      "24506\n",
      "24507\n",
      "24508\n",
      "24509\n",
      "24510\n",
      "24511\n",
      "24512\n",
      "24513\n",
      "24514\n",
      "24515\n",
      "24516\n",
      "24517\n",
      "24518\n",
      "24519\n",
      "24520\n",
      "24521\n",
      "24522\n",
      "24523\n",
      "24524\n",
      "24525\n",
      "24526\n",
      "24527\n",
      "24528\n",
      "24529\n",
      "24530\n",
      "24531\n",
      "24532\n",
      "24533\n",
      "24534\n",
      "24535\n",
      "24536\n",
      "24537\n",
      "24538\n",
      "24539\n",
      "24540\n",
      "24541\n",
      "24542\n",
      "24543\n",
      "24544\n",
      "24545\n",
      "24546\n",
      "24547\n",
      "24548\n",
      "24549\n",
      "24550\n",
      "24551\n",
      "24552\n",
      "24553\n",
      "24554\n",
      "24555\n",
      "24556\n",
      "24557\n",
      "24558\n",
      "24559\n",
      "24560\n",
      "24561\n",
      "24562\n",
      "24563\n",
      "24564\n",
      "24565\n",
      "24566\n",
      "24567\n",
      "24568\n",
      "24569\n",
      "24570\n",
      "24571\n",
      "24572\n",
      "24573\n",
      "24574\n",
      "24575\n",
      "24576\n",
      "24577\n",
      "24578\n",
      "24579\n",
      "24580\n",
      "24581\n",
      "24582\n",
      "24583\n",
      "24584\n",
      "24585\n",
      "24586\n",
      "24587\n",
      "24588\n",
      "24589\n",
      "24590\n",
      "24591\n",
      "24592\n",
      "24593\n",
      "24594\n",
      "24595\n",
      "24596\n",
      "24597\n",
      "24598\n",
      "24599\n",
      "24600\n",
      "24601\n",
      "24602\n",
      "24603\n",
      "24604\n",
      "24605\n",
      "24606\n",
      "24607\n",
      "24608\n",
      "24609\n",
      "24610\n",
      "24611\n",
      "24612\n",
      "24613\n",
      "24614\n",
      "24615\n",
      "24616\n",
      "24617\n",
      "24618\n",
      "24619\n",
      "24620\n",
      "24621\n",
      "24622\n",
      "24623\n",
      "24624\n",
      "24625\n",
      "24626\n",
      "24627\n",
      "24628\n",
      "24629\n",
      "24630\n",
      "24631\n",
      "24632\n",
      "24633\n",
      "24634\n",
      "24635\n",
      "24636\n",
      "24637\n",
      "24638\n",
      "24639\n",
      "24640\n",
      "24641\n",
      "24642\n",
      "24643\n",
      "24644\n",
      "24645\n",
      "24646\n",
      "24647\n",
      "24648\n",
      "24649\n",
      "24650\n",
      "24651\n",
      "24652\n",
      "24653\n",
      "24654\n",
      "24655\n",
      "24656\n",
      "24657\n",
      "24658\n",
      "24659\n",
      "24660\n",
      "24661\n",
      "24662\n",
      "24663\n",
      "24664\n",
      "24665\n",
      "24666\n",
      "24667\n",
      "24668\n",
      "24669\n",
      "24670\n",
      "24671\n",
      "24672\n",
      "24673\n",
      "24674\n",
      "24675\n",
      "24676\n",
      "24677\n",
      "24678\n",
      "24679\n",
      "24680\n",
      "24681\n",
      "24682\n",
      "24683\n",
      "24684\n",
      "24685\n",
      "24686\n",
      "24687\n",
      "24688\n",
      "24689\n",
      "24690\n",
      "24691\n",
      "24692\n",
      "24693\n",
      "24694\n",
      "24695\n",
      "24696\n",
      "24697\n",
      "24698\n",
      "24699\n",
      "24700\n",
      "24701\n",
      "24702\n",
      "24703\n",
      "24704\n",
      "24705\n",
      "24706\n",
      "24707\n",
      "24708\n",
      "24709\n",
      "24710\n",
      "24711\n",
      "24712\n",
      "24713\n",
      "24714\n",
      "24715\n",
      "24716\n",
      "24717\n",
      "24718\n",
      "24719\n",
      "24720\n",
      "24721\n",
      "24722\n",
      "24723\n",
      "24724\n",
      "24725\n",
      "24726\n",
      "24727\n",
      "24728\n",
      "24729\n",
      "24730\n",
      "24731\n",
      "24732\n",
      "24733\n",
      "24734\n",
      "24735\n",
      "24736\n",
      "24737\n",
      "24738\n",
      "24739\n",
      "24740\n",
      "24741\n",
      "24742\n",
      "24743\n",
      "24744\n",
      "24745\n",
      "24746\n",
      "24747\n",
      "24748\n",
      "24749\n",
      "24750\n",
      "24751\n",
      "24752\n",
      "24753\n",
      "24754\n",
      "24755\n",
      "24756\n",
      "24757\n",
      "24758\n",
      "24759\n",
      "24760\n",
      "24761\n",
      "24762\n",
      "24763\n",
      "24764\n",
      "24765\n",
      "24766\n",
      "24767\n",
      "24768\n",
      "24769\n",
      "24770\n",
      "24771\n",
      "24772\n",
      "24773\n",
      "24774\n",
      "24775\n",
      "24776\n",
      "24777\n",
      "24778\n",
      "24779\n",
      "24780\n",
      "24781\n",
      "24782\n",
      "24783\n",
      "24784\n",
      "24785\n",
      "24786\n",
      "24787\n",
      "24788\n",
      "24789\n",
      "24790\n",
      "24791\n",
      "24792\n",
      "24793\n",
      "24794\n",
      "24795\n",
      "24796\n",
      "24797\n",
      "24798\n",
      "24799\n",
      "24800\n",
      "24801\n",
      "24802\n",
      "24803\n",
      "24804\n",
      "24805\n",
      "24806\n",
      "24807\n",
      "24808\n",
      "24809\n",
      "24810\n",
      "24811\n",
      "24812\n",
      "24813\n",
      "24814\n",
      "24815\n",
      "24816\n",
      "24817\n",
      "24818\n",
      "24819\n",
      "24820\n",
      "24821\n",
      "24822\n",
      "24823\n",
      "24824\n",
      "24825\n",
      "24826\n",
      "24827\n",
      "24828\n",
      "24829\n",
      "24830\n",
      "24831\n",
      "24832\n",
      "24833\n",
      "24834\n",
      "24835\n",
      "24836\n",
      "24837\n",
      "24838\n",
      "24839\n",
      "24840\n",
      "24841\n",
      "24842\n",
      "24843\n",
      "24844\n",
      "24845\n",
      "24846\n",
      "24847\n",
      "24848\n",
      "24849\n",
      "24850\n",
      "24851\n",
      "24852\n",
      "24853\n",
      "24854\n",
      "24855\n",
      "24856\n",
      "24857\n",
      "24858\n",
      "24859\n",
      "24860\n",
      "24861\n",
      "24862\n",
      "24863\n",
      "24864\n",
      "24865\n",
      "24866\n",
      "24867\n",
      "24868\n",
      "24869\n",
      "24870\n",
      "24871\n",
      "24872\n",
      "24873\n",
      "24874\n",
      "24875\n",
      "24876\n",
      "24877\n",
      "24878\n",
      "24879\n",
      "24880\n",
      "24881\n",
      "24882\n",
      "24883\n",
      "24884\n",
      "24885\n",
      "24886\n",
      "24887\n",
      "24888\n",
      "24889\n",
      "24890\n",
      "24891\n",
      "24892\n",
      "24893\n",
      "24894\n",
      "24895\n",
      "24896\n",
      "24897\n",
      "24898\n",
      "24899\n",
      "24900\n",
      "24901\n",
      "24902\n",
      "24903\n",
      "24904\n",
      "24905\n",
      "24906\n",
      "24907\n",
      "24908\n",
      "24909\n",
      "24910\n",
      "24911\n",
      "24912\n",
      "24913\n",
      "24914\n",
      "24915\n",
      "24916\n",
      "24917\n",
      "24918\n",
      "24919\n",
      "24920\n",
      "24921\n",
      "24922\n",
      "24923\n",
      "24924\n",
      "24925\n",
      "24926\n",
      "24927\n",
      "24928\n",
      "24929\n",
      "24930\n",
      "24931\n",
      "24932\n",
      "24933\n",
      "24934\n",
      "24935\n",
      "24936\n",
      "24937\n",
      "24938\n",
      "24939\n",
      "24940\n",
      "24941\n",
      "24942\n",
      "24943\n",
      "24944\n",
      "24945\n",
      "24946\n",
      "24947\n",
      "24948\n",
      "24949\n",
      "24950\n",
      "24951\n",
      "24952\n",
      "24953\n",
      "24954\n",
      "24955\n",
      "24956\n",
      "24957\n",
      "24958\n",
      "24959\n",
      "24960\n",
      "24961\n",
      "24962\n",
      "24963\n",
      "24964\n",
      "24965\n",
      "24966\n",
      "24967\n",
      "24968\n",
      "24969\n",
      "24970\n",
      "24971\n",
      "24972\n",
      "24973\n",
      "24974\n",
      "24975\n",
      "24976\n",
      "24977\n",
      "24978\n",
      "24979\n",
      "24980\n",
      "24981\n",
      "24982\n",
      "24983\n",
      "24984\n",
      "24985\n",
      "24986\n",
      "24987\n",
      "24988\n",
      "24989\n",
      "24990\n",
      "24991\n",
      "24992\n",
      "24993\n",
      "24994\n",
      "24995\n",
      "24996\n",
      "24997\n",
      "24998\n",
      "24999\n",
      "25000\n",
      "25001\n",
      "25002\n",
      "25003\n",
      "25004\n",
      "25005\n",
      "25006\n",
      "25007\n",
      "25008\n",
      "25009\n",
      "25010\n",
      "25011\n",
      "25012\n",
      "25013\n",
      "25014\n",
      "25015\n",
      "25016\n",
      "25017\n",
      "25018\n",
      "25019\n",
      "25020\n",
      "25021\n",
      "25022\n",
      "25023\n",
      "25024\n",
      "25025\n",
      "25026\n",
      "25027\n",
      "25028\n",
      "25029\n",
      "25030\n",
      "25031\n",
      "25032\n",
      "25033\n",
      "25034\n",
      "25035\n",
      "25036\n",
      "25037\n",
      "25038\n",
      "25039\n",
      "25040\n",
      "25041\n",
      "25042\n",
      "25043\n",
      "25044\n",
      "25045\n",
      "25046\n",
      "25047\n",
      "25048\n",
      "25049\n",
      "25050\n",
      "25051\n",
      "25052\n",
      "25053\n",
      "25054\n",
      "25055\n",
      "25056\n",
      "25057\n",
      "25058\n",
      "25059\n",
      "25060\n",
      "25061\n",
      "25062\n",
      "25063\n",
      "25064\n",
      "25065\n",
      "25066\n",
      "25067\n",
      "25068\n",
      "25069\n",
      "25070\n",
      "25071\n",
      "25072\n",
      "25073\n",
      "25074\n",
      "25075\n",
      "25076\n",
      "25077\n",
      "25078\n",
      "25079\n",
      "25080\n",
      "25081\n",
      "25082\n",
      "25083\n",
      "25084\n",
      "25085\n",
      "25086\n",
      "25087\n",
      "25088\n",
      "25089\n",
      "25090\n",
      "25091\n",
      "25092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25093\n",
      "25094\n",
      "25095\n",
      "25096\n",
      "25097\n",
      "25098\n",
      "25099\n",
      "25100\n",
      "25101\n",
      "25102\n",
      "25103\n",
      "25104\n",
      "25105\n",
      "25106\n",
      "25107\n",
      "25108\n",
      "25109\n",
      "25110\n",
      "25111\n",
      "25112\n",
      "25113\n",
      "25114\n",
      "25115\n",
      "25116\n",
      "25117\n",
      "25118\n",
      "25119\n",
      "25120\n",
      "25121\n",
      "25122\n",
      "25123\n",
      "25124\n",
      "25125\n",
      "25126\n",
      "25127\n",
      "25128\n",
      "25129\n",
      "25130\n",
      "25131\n",
      "25132\n",
      "25133\n",
      "25134\n",
      "25135\n",
      "25136\n",
      "25137\n",
      "25138\n",
      "25139\n",
      "25140\n",
      "25141\n",
      "25142\n",
      "25143\n",
      "25144\n",
      "25145\n",
      "25146\n",
      "25147\n",
      "25148\n",
      "25149\n",
      "25150\n",
      "25151\n",
      "25152\n",
      "25153\n",
      "25154\n",
      "25155\n",
      "25156\n",
      "25157\n",
      "25158\n",
      "25159\n",
      "25160\n",
      "25161\n",
      "25162\n",
      "25163\n",
      "25164\n",
      "25165\n",
      "25166\n",
      "25167\n",
      "25168\n",
      "25169\n",
      "25170\n",
      "25171\n",
      "25172\n",
      "25173\n",
      "25174\n",
      "25175\n",
      "25176\n",
      "25177\n",
      "25178\n",
      "25179\n",
      "25180\n",
      "25181\n",
      "25182\n",
      "25183\n",
      "25184\n",
      "25185\n",
      "25186\n",
      "25187\n",
      "25188\n",
      "25189\n",
      "25190\n",
      "25191\n",
      "25192\n",
      "25193\n",
      "25194\n",
      "25195\n",
      "25196\n",
      "25197\n",
      "25198\n",
      "25199\n",
      "25200\n",
      "25201\n",
      "25202\n",
      "25203\n",
      "25204\n",
      "25205\n",
      "25206\n",
      "25207\n",
      "25208\n",
      "25209\n",
      "25210\n",
      "25211\n",
      "25212\n",
      "25213\n",
      "25214\n",
      "25215\n",
      "25216\n",
      "25217\n",
      "25218\n",
      "25219\n",
      "25220\n",
      "25221\n",
      "25222\n",
      "25223\n",
      "25224\n",
      "25225\n",
      "25226\n",
      "25227\n",
      "25228\n",
      "25229\n",
      "25230\n",
      "25231\n",
      "25232\n",
      "25233\n",
      "25234\n",
      "25235\n",
      "25236\n",
      "25237\n",
      "25238\n",
      "25239\n",
      "25240\n",
      "25241\n",
      "25242\n",
      "25243\n",
      "25244\n",
      "25245\n",
      "25246\n",
      "25247\n",
      "25248\n",
      "25249\n",
      "25250\n",
      "25251\n",
      "25252\n",
      "25253\n",
      "25254\n",
      "25255\n",
      "25256\n",
      "25257\n",
      "25258\n",
      "25259\n",
      "25260\n",
      "25261\n",
      "25262\n",
      "25263\n",
      "25264\n",
      "25265\n",
      "25266\n",
      "25267\n",
      "25268\n",
      "25269\n",
      "25270\n",
      "25271\n",
      "25272\n",
      "25273\n",
      "25274\n",
      "25275\n",
      "25276\n",
      "25277\n",
      "25278\n",
      "25279\n",
      "25280\n",
      "25281\n",
      "25282\n",
      "25283\n",
      "25284\n",
      "25285\n",
      "25286\n",
      "25287\n",
      "25288\n",
      "25289\n",
      "25290\n",
      "25291\n",
      "25292\n",
      "25293\n",
      "25294\n",
      "25295\n",
      "25296\n",
      "25297\n",
      "25298\n",
      "25299\n",
      "25300\n",
      "25301\n",
      "25302\n",
      "25303\n",
      "25304\n",
      "25305\n",
      "25306\n",
      "25307\n",
      "25308\n",
      "25309\n",
      "25310\n",
      "25311\n",
      "25312\n",
      "25313\n",
      "25314\n",
      "25315\n",
      "25316\n",
      "25317\n",
      "25318\n",
      "25319\n",
      "25320\n",
      "25321\n",
      "25322\n",
      "25323\n",
      "25324\n",
      "25325\n",
      "25326\n",
      "25327\n",
      "25328\n",
      "25329\n",
      "25330\n",
      "25331\n",
      "25332\n",
      "25333\n",
      "25334\n",
      "25335\n",
      "25336\n",
      "25337\n",
      "25338\n",
      "25339\n",
      "25340\n",
      "25341\n",
      "25342\n",
      "25343\n",
      "25344\n",
      "25345\n",
      "25346\n",
      "25347\n",
      "25348\n",
      "25349\n",
      "25350\n",
      "25351\n",
      "25352\n",
      "25353\n",
      "25354\n",
      "25355\n",
      "25356\n",
      "25357\n",
      "25358\n",
      "25359\n",
      "25360\n",
      "25361\n",
      "25362\n",
      "25363\n",
      "25364\n",
      "25365\n",
      "25366\n",
      "25367\n",
      "25368\n",
      "25369\n",
      "25370\n",
      "25371\n",
      "25372\n",
      "25373\n",
      "25374\n",
      "25375\n",
      "25376\n",
      "25377\n",
      "25378\n",
      "25379\n",
      "25380\n",
      "25381\n",
      "25382\n",
      "25383\n",
      "25384\n",
      "25385\n",
      "25386\n",
      "25387\n",
      "25388\n",
      "25389\n",
      "25390\n",
      "25391\n",
      "25392\n",
      "25393\n",
      "25394\n",
      "25395\n",
      "25396\n",
      "25397\n",
      "25398\n",
      "25399\n",
      "25400\n",
      "25401\n",
      "25402\n",
      "25403\n",
      "25404\n",
      "25405\n",
      "25406\n",
      "25407\n",
      "25408\n",
      "25409\n",
      "25410\n",
      "25411\n",
      "25412\n",
      "25413\n",
      "25414\n",
      "25415\n",
      "25416\n",
      "25417\n",
      "25418\n",
      "25419\n",
      "25420\n",
      "25421\n",
      "25422\n",
      "25423\n",
      "25424\n",
      "25425\n",
      "25426\n",
      "25427\n",
      "25428\n",
      "25429\n",
      "25430\n",
      "25431\n",
      "25432\n",
      "25433\n",
      "25434\n",
      "25435\n",
      "25436\n",
      "25437\n",
      "25438\n",
      "25439\n",
      "25440\n",
      "25441\n",
      "25442\n",
      "25443\n",
      "25444\n",
      "25445\n",
      "25446\n",
      "25447\n",
      "25448\n",
      "25449\n",
      "25450\n",
      "25451\n",
      "25452\n",
      "25453\n",
      "25454\n",
      "25455\n",
      "25456\n",
      "25457\n",
      "25458\n",
      "25459\n",
      "25460\n",
      "25461\n",
      "25462\n",
      "25463\n",
      "25464\n",
      "25465\n",
      "25466\n",
      "25467\n",
      "25468\n",
      "25469\n",
      "25470\n",
      "25471\n",
      "25472\n",
      "25473\n",
      "25474\n",
      "25475\n",
      "25476\n",
      "25477\n",
      "25478\n",
      "25479\n",
      "25480\n",
      "25481\n",
      "25482\n",
      "25483\n",
      "25484\n",
      "25485\n",
      "25486\n",
      "25487\n",
      "25488\n",
      "25489\n",
      "25490\n",
      "25491\n",
      "25492\n",
      "25493\n",
      "25494\n",
      "25495\n",
      "25496\n",
      "25497\n",
      "25498\n",
      "25499\n",
      "25500\n",
      "25501\n",
      "25502\n",
      "25503\n",
      "25504\n",
      "25505\n",
      "25506\n",
      "25507\n",
      "25508\n",
      "25509\n",
      "25510\n",
      "25511\n",
      "25512\n",
      "25513\n",
      "25514\n",
      "25515\n",
      "25516\n",
      "25517\n",
      "25518\n",
      "25519\n",
      "25520\n",
      "25521\n",
      "25522\n",
      "25523\n",
      "25524\n",
      "25525\n",
      "25526\n",
      "25527\n",
      "25528\n",
      "25529\n",
      "25530\n",
      "25531\n",
      "25532\n",
      "25533\n",
      "25534\n",
      "25535\n",
      "25536\n",
      "25537\n",
      "25538\n",
      "25539\n",
      "25540\n",
      "25541\n",
      "25542\n",
      "25543\n",
      "25544\n",
      "25545\n",
      "25546\n",
      "25547\n",
      "25548\n",
      "25549\n",
      "25550\n",
      "25551\n",
      "25552\n",
      "25553\n",
      "25554\n",
      "25555\n",
      "25556\n",
      "25557\n",
      "25558\n",
      "25559\n",
      "25560\n",
      "25561\n",
      "25562\n",
      "25563\n",
      "25564\n",
      "25565\n",
      "25566\n",
      "25567\n",
      "25568\n",
      "25569\n",
      "25570\n",
      "25571\n",
      "25572\n",
      "25573\n",
      "25574\n",
      "25575\n",
      "25576\n",
      "25577\n",
      "25578\n",
      "25579\n",
      "25580\n",
      "25581\n",
      "25582\n",
      "25583\n",
      "25584\n",
      "25585\n",
      "25586\n",
      "25587\n",
      "25588\n",
      "25589\n",
      "25590\n",
      "25591\n",
      "25592\n",
      "25593\n",
      "25594\n",
      "25595\n",
      "25596\n",
      "25597\n",
      "25598\n",
      "25599\n",
      "25600\n",
      "25601\n",
      "25602\n",
      "25603\n",
      "25604\n",
      "25605\n",
      "25606\n",
      "25607\n",
      "25608\n",
      "25609\n",
      "25610\n",
      "25611\n",
      "25612\n",
      "25613\n",
      "25614\n",
      "25615\n",
      "25616\n",
      "25617\n",
      "25618\n",
      "25619\n",
      "25620\n",
      "25621\n",
      "25622\n",
      "25623\n",
      "25624\n",
      "25625\n",
      "25626\n",
      "25627\n",
      "25628\n",
      "25629\n",
      "25630\n",
      "25631\n",
      "25632\n",
      "25633\n",
      "25634\n",
      "25635\n",
      "25636\n",
      "25637\n",
      "25638\n",
      "25639\n",
      "25640\n",
      "25641\n",
      "25642\n",
      "25643\n",
      "25644\n",
      "25645\n",
      "25646\n",
      "25647\n",
      "25648\n",
      "25649\n",
      "25650\n",
      "25651\n",
      "25652\n",
      "25653\n",
      "25654\n",
      "25655\n",
      "25656\n",
      "25657\n",
      "25658\n",
      "25659\n",
      "25660\n",
      "25661\n",
      "25662\n",
      "25663\n",
      "25664\n",
      "25665\n",
      "25666\n",
      "25667\n",
      "25668\n",
      "25669\n",
      "25670\n",
      "25671\n",
      "25672\n",
      "25673\n",
      "25674\n",
      "25675\n",
      "25676\n",
      "25677\n",
      "25678\n",
      "25679\n",
      "25680\n",
      "25681\n",
      "25682\n",
      "25683\n",
      "25684\n",
      "25685\n",
      "25686\n",
      "25687\n",
      "25688\n",
      "25689\n",
      "25690\n",
      "25691\n",
      "25692\n",
      "25693\n",
      "25694\n",
      "25695\n",
      "25696\n",
      "25697\n",
      "25698\n",
      "25699\n",
      "25700\n",
      "25701\n",
      "25702\n",
      "25703\n",
      "25704\n",
      "25705\n",
      "25706\n",
      "25707\n",
      "25708\n",
      "25709\n",
      "25710\n",
      "25711\n",
      "25712\n",
      "25713\n",
      "25714\n",
      "25715\n",
      "25716\n",
      "25717\n",
      "25718\n",
      "25719\n",
      "25720\n",
      "25721\n",
      "25722\n",
      "25723\n",
      "25724\n",
      "25725\n",
      "25726\n",
      "25727\n",
      "25728\n",
      "25729\n",
      "25730\n",
      "25731\n",
      "25732\n",
      "25733\n",
      "25734\n",
      "25735\n",
      "25736\n",
      "25737\n",
      "25738\n",
      "25739\n",
      "25740\n",
      "25741\n",
      "25742\n",
      "25743\n",
      "25744\n",
      "25745\n",
      "25746\n",
      "25747\n",
      "25748\n",
      "25749\n",
      "25750\n",
      "25751\n",
      "25752\n",
      "25753\n",
      "25754\n",
      "25755\n",
      "25756\n",
      "25757\n",
      "25758\n",
      "25759\n",
      "25760\n",
      "25761\n",
      "25762\n",
      "25763\n",
      "25764\n",
      "25765\n",
      "25766\n",
      "25767\n",
      "25768\n",
      "25769\n",
      "25770\n",
      "25771\n",
      "25772\n",
      "25773\n",
      "25774\n",
      "25775\n",
      "25776\n",
      "25777\n",
      "25778\n",
      "25779\n",
      "25780\n",
      "25781\n",
      "25782\n",
      "25783\n",
      "25784\n",
      "25785\n",
      "25786\n",
      "25787\n",
      "25788\n",
      "25789\n",
      "25790\n",
      "25791\n",
      "25792\n",
      "25793\n",
      "25794\n",
      "25795\n",
      "25796\n",
      "25797\n",
      "25798\n",
      "25799\n",
      "25800\n",
      "25801\n",
      "25802\n",
      "25803\n",
      "25804\n",
      "25805\n",
      "25806\n",
      "25807\n",
      "25808\n",
      "25809\n",
      "25810\n",
      "25811\n",
      "25812\n",
      "25813\n",
      "25814\n",
      "25815\n",
      "25816\n",
      "25817\n",
      "25818\n",
      "25819\n",
      "25820\n",
      "25821\n",
      "25822\n",
      "25823\n",
      "25824\n",
      "25825\n",
      "25826\n",
      "25827\n",
      "25828\n",
      "25829\n",
      "25830\n",
      "25831\n",
      "25832\n",
      "25833\n",
      "25834\n",
      "25835\n",
      "25836\n",
      "25837\n",
      "25838\n",
      "25839\n",
      "25840\n",
      "25841\n",
      "25842\n",
      "25843\n",
      "25844\n",
      "25845\n",
      "25846\n",
      "25847\n",
      "25848\n",
      "25849\n",
      "25850\n",
      "25851\n",
      "25852\n",
      "25853\n",
      "25854\n",
      "25855\n",
      "25856\n",
      "25857\n",
      "25858\n",
      "25859\n",
      "25860\n",
      "25861\n",
      "25862\n",
      "25863\n",
      "25864\n",
      "25865\n",
      "25866\n",
      "25867\n",
      "25868\n",
      "25869\n",
      "25870\n",
      "25871\n",
      "25872\n",
      "25873\n",
      "25874\n",
      "25875\n",
      "25876\n",
      "25877\n",
      "25878\n",
      "25879\n",
      "25880\n",
      "25881\n",
      "25882\n",
      "25883\n",
      "25884\n",
      "25885\n",
      "25886\n",
      "25887\n",
      "25888\n",
      "25889\n",
      "25890\n",
      "25891\n",
      "25892\n",
      "25893\n",
      "25894\n",
      "25895\n",
      "25896\n",
      "25897\n",
      "25898\n",
      "25899\n",
      "25900\n",
      "25901\n",
      "25902\n",
      "25903\n",
      "25904\n",
      "25905\n",
      "25906\n",
      "25907\n",
      "25908\n",
      "25909\n",
      "25910\n",
      "25911\n",
      "25912\n",
      "25913\n",
      "25914\n",
      "25915\n",
      "25916\n",
      "25917\n",
      "25918\n",
      "25919\n",
      "25920\n",
      "25921\n",
      "25922\n",
      "25923\n",
      "25924\n",
      "25925\n",
      "25926\n",
      "25927\n",
      "25928\n",
      "25929\n",
      "25930\n",
      "25931\n",
      "25932\n",
      "25933\n",
      "25934\n",
      "25935\n",
      "25936\n",
      "25937\n",
      "25938\n",
      "25939\n",
      "25940\n",
      "25941\n",
      "25942\n",
      "25943\n",
      "25944\n",
      "25945\n",
      "25946\n",
      "25947\n",
      "25948\n",
      "25949\n",
      "25950\n",
      "25951\n",
      "25952\n",
      "25953\n",
      "25954\n",
      "25955\n",
      "25956\n",
      "25957\n",
      "25958\n",
      "25959\n",
      "25960\n",
      "25961\n",
      "25962\n",
      "25963\n",
      "25964\n",
      "25965\n",
      "25966\n",
      "25967\n",
      "25968\n",
      "25969\n",
      "25970\n",
      "25971\n",
      "25972\n",
      "25973\n",
      "25974\n",
      "25975\n",
      "25976\n",
      "25977\n",
      "25978\n",
      "25979\n",
      "25980\n",
      "25981\n",
      "25982\n",
      "25983\n",
      "25984\n",
      "25985\n",
      "25986\n",
      "25987\n",
      "25988\n",
      "25989\n",
      "25990\n",
      "25991\n",
      "25992\n",
      "25993\n",
      "25994\n",
      "25995\n",
      "25996\n",
      "25997\n",
      "25998\n",
      "25999\n",
      "26000\n",
      "26001\n",
      "26002\n",
      "26003\n",
      "26004\n",
      "26005\n",
      "26006\n",
      "26007\n",
      "26008\n",
      "26009\n",
      "26010\n",
      "26011\n",
      "26012\n",
      "26013\n",
      "26014\n",
      "26015\n",
      "26016\n",
      "26017\n",
      "26018\n",
      "26019\n",
      "26020\n",
      "26021\n",
      "26022\n",
      "26023\n",
      "26024\n",
      "26025\n",
      "26026\n",
      "26027\n",
      "26028\n",
      "26029\n",
      "26030\n",
      "26031\n",
      "26032\n",
      "26033\n",
      "26034\n",
      "26035\n",
      "26036\n",
      "26037\n",
      "26038\n",
      "26039\n",
      "26040\n",
      "26041\n",
      "26042\n",
      "26043\n",
      "26044\n",
      "26045\n",
      "26046\n",
      "26047\n",
      "26048\n",
      "26049\n",
      "26050\n",
      "26051\n",
      "26052\n",
      "26053\n",
      "26054\n",
      "26055\n",
      "26056\n",
      "26057\n",
      "26058\n",
      "26059\n",
      "26060\n",
      "26061\n",
      "26062\n",
      "26063\n",
      "26064\n",
      "26065\n",
      "26066\n",
      "26067\n",
      "26068\n",
      "26069\n",
      "26070\n",
      "26071\n",
      "26072\n",
      "26073\n",
      "26074\n",
      "26075\n",
      "26076\n",
      "26077\n",
      "26078\n",
      "26079\n",
      "26080\n",
      "26081\n",
      "26082\n",
      "26083\n",
      "26084\n",
      "26085\n",
      "26086\n",
      "26087\n",
      "26088\n",
      "26089\n",
      "26090\n",
      "26091\n",
      "26092\n",
      "26093\n",
      "26094\n",
      "26095\n",
      "26096\n",
      "26097\n",
      "26098\n",
      "26099\n",
      "26100\n",
      "26101\n",
      "26102\n",
      "26103\n",
      "26104\n",
      "26105\n",
      "26106\n",
      "26107\n",
      "26108\n",
      "26109\n",
      "26110\n",
      "26111\n",
      "26112\n",
      "26113\n",
      "26114\n",
      "26115\n",
      "26116\n",
      "26117\n",
      "26118\n",
      "26119\n",
      "26120\n",
      "26121\n",
      "26122\n",
      "26123\n",
      "26124\n",
      "26125\n",
      "26126\n",
      "26127\n",
      "26128\n",
      "26129\n",
      "26130\n",
      "26131\n",
      "26132\n",
      "26133\n",
      "26134\n",
      "26135\n",
      "26136\n",
      "26137\n",
      "26138\n",
      "26139\n",
      "26140\n",
      "26141\n",
      "26142\n",
      "26143\n",
      "26144\n",
      "26145\n",
      "26146\n",
      "26147\n",
      "26148\n",
      "26149\n",
      "26150\n",
      "26151\n",
      "26152\n",
      "26153\n",
      "26154\n",
      "26155\n",
      "26156\n",
      "26157\n",
      "26158\n",
      "26159\n",
      "26160\n",
      "26161\n",
      "26162\n",
      "26163\n",
      "26164\n",
      "26165\n",
      "26166\n",
      "26167\n",
      "26168\n",
      "26169\n",
      "26170\n",
      "26171\n",
      "26172\n",
      "26173\n",
      "26174\n",
      "26175\n",
      "26176\n",
      "26177\n",
      "26178\n",
      "26179\n",
      "26180\n",
      "26181\n",
      "26182\n",
      "26183\n",
      "26184\n",
      "26185\n",
      "26186\n",
      "26187\n",
      "26188\n",
      "26189\n",
      "26190\n",
      "26191\n",
      "26192\n",
      "26193\n",
      "26194\n",
      "26195\n",
      "26196\n",
      "26197\n",
      "26198\n",
      "26199\n",
      "26200\n",
      "26201\n",
      "26202\n",
      "26203\n",
      "26204\n",
      "26205\n",
      "26206\n",
      "26207\n",
      "26208\n",
      "26209\n",
      "26210\n",
      "26211\n",
      "26212\n",
      "26213\n",
      "26214\n",
      "26215\n",
      "26216\n",
      "26217\n",
      "26218\n",
      "26219\n",
      "26220\n",
      "26221\n",
      "26222\n",
      "26223\n",
      "26224\n",
      "26225\n",
      "26226\n",
      "26227\n",
      "26228\n",
      "26229\n",
      "26230\n",
      "26231\n",
      "26232\n",
      "26233\n",
      "26234\n",
      "26235\n",
      "26236\n",
      "26237\n",
      "26238\n",
      "26239\n",
      "26240\n",
      "26241\n",
      "26242\n",
      "26243\n",
      "26244\n",
      "26245\n",
      "26246\n",
      "26247\n",
      "26248\n",
      "26249\n",
      "26250\n",
      "26251\n",
      "26252\n",
      "26253\n",
      "26254\n",
      "26255\n",
      "26256\n",
      "26257\n",
      "26258\n",
      "26259\n",
      "26260\n",
      "26261\n",
      "26262\n",
      "26263\n",
      "26264\n",
      "26265\n",
      "26266\n",
      "26267\n",
      "26268\n",
      "26269\n",
      "26270\n",
      "26271\n",
      "26272\n",
      "26273\n",
      "26274\n",
      "26275\n",
      "26276\n",
      "26277\n",
      "26278\n",
      "26279\n",
      "26280\n",
      "26281\n",
      "26282\n",
      "26283\n",
      "26284\n",
      "26285\n",
      "26286\n",
      "26287\n",
      "26288\n",
      "26289\n",
      "26290\n",
      "26291\n",
      "26292\n",
      "26293\n",
      "26294\n",
      "26295\n",
      "26296\n",
      "26297\n",
      "26298\n",
      "26299\n",
      "26300\n",
      "26301\n",
      "26302\n",
      "26303\n",
      "26304\n",
      "26305\n",
      "26306\n",
      "26307\n",
      "26308\n",
      "26309\n",
      "26310\n",
      "26311\n",
      "26312\n",
      "26313\n",
      "26314\n",
      "26315\n",
      "26316\n",
      "26317\n",
      "26318\n",
      "26319\n",
      "26320\n",
      "26321\n",
      "26322\n",
      "26323\n",
      "26324\n",
      "26325\n",
      "26326\n",
      "26327\n",
      "26328\n",
      "26329\n",
      "26330\n",
      "26331\n",
      "26332\n",
      "26333\n",
      "26334\n",
      "26335\n",
      "26336\n",
      "26337\n",
      "26338\n",
      "26339\n",
      "26340\n",
      "26341\n",
      "26342\n",
      "26343\n",
      "26344\n",
      "26345\n",
      "26346\n",
      "26347\n",
      "26348\n",
      "26349\n",
      "26350\n",
      "26351\n",
      "26352\n",
      "26353\n",
      "26354\n",
      "26355\n",
      "26356\n",
      "26357\n",
      "26358\n",
      "26359\n",
      "26360\n",
      "26361\n",
      "26362\n",
      "26363\n",
      "26364\n",
      "26365\n",
      "26366\n",
      "26367\n",
      "26368\n",
      "26369\n",
      "26370\n",
      "26371\n",
      "26372\n",
      "26373\n",
      "26374\n",
      "26375\n",
      "26376\n",
      "26377\n",
      "26378\n",
      "26379\n",
      "26380\n",
      "26381\n",
      "26382\n",
      "26383\n",
      "26384\n",
      "26385\n",
      "26386\n",
      "26387\n",
      "26388\n",
      "26389\n",
      "26390\n",
      "26391\n",
      "26392\n",
      "26393\n",
      "26394\n",
      "26395\n",
      "26396\n",
      "26397\n",
      "26398\n",
      "26399\n",
      "26400\n",
      "26401\n",
      "26402\n",
      "26403\n",
      "26404\n",
      "26405\n",
      "26406\n",
      "26407\n",
      "26408\n",
      "26409\n",
      "26410\n",
      "26411\n",
      "26412\n",
      "26413\n",
      "26414\n",
      "26415\n",
      "26416\n",
      "26417\n",
      "26418\n",
      "26419\n",
      "26420\n",
      "26421\n",
      "26422\n",
      "26423\n",
      "26424\n",
      "26425\n",
      "26426\n",
      "26427\n",
      "26428\n",
      "26429\n",
      "26430\n",
      "26431\n",
      "26432\n",
      "26433\n",
      "26434\n",
      "26435\n",
      "26436\n",
      "26437\n",
      "26438\n",
      "26439\n",
      "26440\n",
      "26441\n",
      "26442\n",
      "26443\n",
      "26444\n",
      "26445\n",
      "26446\n",
      "26447\n",
      "26448\n",
      "26449\n",
      "26450\n",
      "26451\n",
      "26452\n",
      "26453\n",
      "26454\n",
      "26455\n",
      "26456\n",
      "26457\n",
      "26458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26459\n",
      "26460\n",
      "26461\n",
      "26462\n",
      "26463\n",
      "26464\n",
      "26465\n",
      "26466\n",
      "26467\n",
      "26468\n",
      "26469\n",
      "26470\n",
      "26471\n",
      "26472\n",
      "26473\n",
      "26474\n",
      "26475\n",
      "26476\n",
      "26477\n",
      "26478\n",
      "26479\n",
      "26480\n",
      "26481\n",
      "26482\n",
      "26483\n",
      "26484\n",
      "26485\n",
      "26486\n",
      "26487\n",
      "26488\n",
      "26489\n",
      "26490\n",
      "26491\n",
      "26492\n",
      "26493\n",
      "26494\n",
      "26495\n",
      "26496\n",
      "26497\n",
      "26498\n",
      "26499\n",
      "26500\n",
      "26501\n",
      "26502\n",
      "26503\n",
      "26504\n",
      "26505\n",
      "26506\n",
      "26507\n",
      "26508\n",
      "26509\n",
      "26510\n",
      "26511\n",
      "26512\n",
      "26513\n",
      "26514\n",
      "26515\n",
      "26516\n",
      "26517\n",
      "26518\n",
      "26519\n",
      "26520\n",
      "26521\n",
      "26522\n",
      "26523\n",
      "26524\n",
      "26525\n",
      "26526\n",
      "26527\n",
      "26528\n",
      "26529\n",
      "26530\n",
      "26531\n",
      "26532\n",
      "26533\n",
      "26534\n",
      "26535\n",
      "26536\n",
      "26537\n",
      "26538\n",
      "26539\n",
      "26540\n",
      "26541\n",
      "26542\n",
      "26543\n",
      "26544\n",
      "26545\n",
      "26546\n",
      "26547\n",
      "26548\n",
      "26549\n",
      "26550\n",
      "26551\n",
      "26552\n",
      "26553\n",
      "26554\n",
      "26555\n",
      "26556\n",
      "26557\n",
      "26558\n",
      "26559\n",
      "26560\n",
      "26561\n",
      "26562\n",
      "26563\n",
      "26564\n",
      "26565\n",
      "26566\n",
      "26567\n",
      "26568\n",
      "26569\n",
      "26570\n",
      "26571\n",
      "26572\n",
      "26573\n",
      "26574\n",
      "26575\n",
      "26576\n",
      "26577\n",
      "26578\n",
      "26579\n",
      "26580\n",
      "26581\n",
      "26582\n",
      "26583\n",
      "26584\n",
      "26585\n",
      "26586\n",
      "26587\n",
      "26588\n",
      "26589\n",
      "26590\n",
      "26591\n",
      "26592\n",
      "26593\n",
      "26594\n",
      "26595\n",
      "26596\n",
      "26597\n",
      "26598\n",
      "26599\n",
      "26600\n",
      "26601\n",
      "26602\n",
      "26603\n",
      "26604\n",
      "26605\n",
      "26606\n",
      "26607\n",
      "26608\n",
      "26609\n",
      "26610\n",
      "26611\n",
      "26612\n",
      "26613\n",
      "26614\n",
      "26615\n",
      "26616\n",
      "26617\n",
      "26618\n",
      "26619\n",
      "26620\n",
      "26621\n",
      "26622\n",
      "26623\n",
      "26624\n",
      "26625\n",
      "26626\n",
      "26627\n",
      "26628\n",
      "26629\n",
      "26630\n",
      "26631\n",
      "26632\n",
      "26633\n",
      "26634\n",
      "26635\n",
      "26636\n",
      "26637\n",
      "26638\n",
      "26639\n",
      "26640\n",
      "26641\n",
      "26642\n",
      "26643\n",
      "26644\n",
      "26645\n",
      "26646\n",
      "26647\n",
      "26648\n",
      "26649\n",
      "26650\n",
      "26651\n",
      "26652\n",
      "26653\n",
      "26654\n",
      "26655\n",
      "26656\n",
      "26657\n",
      "26658\n",
      "26659\n",
      "26660\n",
      "26661\n",
      "26662\n",
      "26663\n",
      "26664\n",
      "26665\n",
      "26666\n",
      "26667\n",
      "26668\n",
      "26669\n",
      "26670\n",
      "26671\n",
      "26672\n",
      "26673\n",
      "26674\n",
      "26675\n",
      "26676\n",
      "26677\n",
      "26678\n",
      "26679\n",
      "26680\n",
      "26681\n",
      "26682\n",
      "26683\n",
      "26684\n",
      "26685\n",
      "26686\n",
      "26687\n",
      "26688\n",
      "26689\n",
      "26690\n",
      "26691\n",
      "26692\n",
      "26693\n",
      "26694\n",
      "26695\n",
      "26696\n",
      "26697\n",
      "26698\n",
      "26699\n",
      "26700\n",
      "26701\n",
      "26702\n",
      "26703\n",
      "26704\n",
      "26705\n",
      "26706\n",
      "26707\n",
      "26708\n",
      "26709\n",
      "26710\n",
      "26711\n",
      "26712\n",
      "26713\n",
      "26714\n",
      "26715\n",
      "26716\n",
      "26717\n",
      "26718\n",
      "26719\n",
      "26720\n",
      "26721\n",
      "26722\n",
      "26723\n",
      "26724\n",
      "26725\n",
      "26726\n",
      "26727\n",
      "26728\n",
      "26729\n",
      "26730\n",
      "26731\n",
      "26732\n",
      "26733\n",
      "26734\n",
      "26735\n",
      "26736\n",
      "26737\n",
      "26738\n",
      "26739\n",
      "26740\n",
      "26741\n",
      "26742\n",
      "26743\n",
      "26744\n",
      "26745\n",
      "26746\n",
      "26747\n",
      "26748\n",
      "26749\n",
      "26750\n",
      "26751\n",
      "26752\n",
      "26753\n",
      "26754\n",
      "26755\n",
      "26756\n",
      "26757\n",
      "26758\n",
      "26759\n",
      "26760\n",
      "26761\n",
      "26762\n",
      "26763\n",
      "26764\n",
      "26765\n",
      "26766\n",
      "26767\n",
      "26768\n",
      "26769\n",
      "26770\n",
      "26771\n",
      "26772\n",
      "26773\n",
      "26774\n",
      "26775\n",
      "26776\n",
      "26777\n",
      "26778\n",
      "26779\n",
      "26780\n",
      "26781\n",
      "26782\n",
      "26783\n",
      "26784\n",
      "26785\n",
      "26786\n",
      "26787\n",
      "26788\n",
      "26789\n",
      "26790\n",
      "26791\n",
      "26792\n",
      "26793\n",
      "26794\n",
      "26795\n",
      "26796\n",
      "26797\n",
      "26798\n",
      "26799\n",
      "26800\n",
      "26801\n",
      "26802\n",
      "26803\n",
      "26804\n",
      "26805\n",
      "26806\n",
      "26807\n",
      "26808\n",
      "26809\n",
      "26810\n",
      "26811\n",
      "26812\n",
      "26813\n",
      "26814\n",
      "26815\n",
      "26816\n",
      "26817\n",
      "26818\n",
      "26819\n",
      "26820\n",
      "26821\n",
      "26822\n",
      "26823\n",
      "26824\n",
      "26825\n",
      "26826\n",
      "26827\n",
      "26828\n",
      "26829\n",
      "26830\n",
      "26831\n",
      "26832\n",
      "26833\n",
      "26834\n",
      "26835\n",
      "26836\n",
      "26837\n",
      "26838\n",
      "26839\n",
      "26840\n",
      "26841\n",
      "26842\n",
      "26843\n",
      "26844\n",
      "26845\n",
      "26846\n",
      "26847\n",
      "26848\n",
      "26849\n",
      "26850\n",
      "26851\n",
      "26852\n",
      "26853\n",
      "26854\n",
      "26855\n",
      "26856\n",
      "26857\n",
      "26858\n",
      "26859\n",
      "26860\n",
      "26861\n",
      "26862\n",
      "26863\n",
      "26864\n",
      "26865\n",
      "26866\n",
      "26867\n",
      "26868\n",
      "26869\n",
      "26870\n",
      "26871\n",
      "26872\n",
      "26873\n",
      "26874\n",
      "26875\n",
      "26876\n",
      "26877\n",
      "26878\n",
      "26879\n",
      "26880\n",
      "26881\n",
      "26882\n",
      "26883\n",
      "26884\n",
      "26885\n",
      "26886\n",
      "26887\n",
      "26888\n",
      "26889\n",
      "26890\n",
      "26891\n",
      "26892\n",
      "26893\n",
      "26894\n",
      "26895\n",
      "26896\n",
      "26897\n",
      "26898\n",
      "26899\n",
      "26900\n",
      "26901\n",
      "26902\n",
      "26903\n",
      "26904\n",
      "26905\n",
      "26906\n",
      "26907\n",
      "26908\n",
      "26909\n",
      "26910\n",
      "26911\n",
      "26912\n",
      "26913\n",
      "26914\n",
      "26915\n",
      "26916\n",
      "26917\n",
      "26918\n",
      "26919\n",
      "26920\n",
      "26921\n",
      "26922\n",
      "26923\n",
      "26924\n",
      "26925\n",
      "26926\n",
      "26927\n",
      "26928\n",
      "26929\n",
      "26930\n",
      "26931\n",
      "26932\n",
      "26933\n",
      "26934\n",
      "26935\n",
      "26936\n",
      "26937\n",
      "26938\n",
      "26939\n",
      "26940\n",
      "26941\n",
      "26942\n",
      "26943\n",
      "26944\n",
      "26945\n",
      "26946\n",
      "26947\n",
      "26948\n",
      "26949\n",
      "26950\n",
      "26951\n",
      "26952\n",
      "26953\n",
      "26954\n",
      "26955\n",
      "26956\n",
      "26957\n",
      "26958\n",
      "26959\n",
      "26960\n",
      "26961\n",
      "26962\n",
      "26963\n",
      "26964\n",
      "26965\n",
      "26966\n",
      "26967\n",
      "26968\n",
      "26969\n",
      "26970\n",
      "26971\n",
      "26972\n",
      "26973\n",
      "26974\n",
      "26975\n",
      "26976\n",
      "26977\n",
      "26978\n",
      "26979\n",
      "26980\n",
      "26981\n",
      "26982\n",
      "26983\n",
      "26984\n",
      "26985\n",
      "26986\n",
      "26987\n",
      "26988\n",
      "26989\n",
      "26990\n",
      "26991\n",
      "26992\n",
      "26993\n",
      "26994\n",
      "26995\n",
      "26996\n",
      "26997\n",
      "26998\n",
      "26999\n",
      "27000\n",
      "27001\n",
      "27002\n",
      "27003\n",
      "27004\n",
      "27005\n",
      "27006\n",
      "27007\n",
      "27008\n",
      "27009\n",
      "27010\n",
      "27011\n",
      "27012\n",
      "27013\n",
      "27014\n",
      "27015\n",
      "27016\n",
      "27017\n",
      "27018\n",
      "27019\n",
      "27020\n",
      "27021\n",
      "27022\n",
      "27023\n",
      "27024\n",
      "27025\n",
      "27026\n",
      "27027\n",
      "27028\n",
      "27029\n",
      "27030\n",
      "27031\n",
      "27032\n",
      "27033\n",
      "27034\n",
      "27035\n",
      "27036\n",
      "27037\n",
      "27038\n",
      "27039\n",
      "27040\n",
      "27041\n",
      "27042\n",
      "27043\n",
      "27044\n",
      "27045\n",
      "27046\n",
      "27047\n",
      "27048\n",
      "27049\n",
      "27050\n",
      "27051\n",
      "27052\n",
      "27053\n",
      "27054\n",
      "27055\n",
      "27056\n",
      "27057\n",
      "27058\n",
      "27059\n",
      "27060\n",
      "27061\n",
      "27062\n",
      "27063\n",
      "27064\n",
      "27065\n",
      "27066\n",
      "27067\n",
      "27068\n",
      "27069\n",
      "27070\n",
      "27071\n",
      "27072\n",
      "27073\n",
      "27074\n",
      "27075\n",
      "27076\n",
      "27077\n",
      "27078\n",
      "27079\n",
      "27080\n",
      "27081\n",
      "27082\n",
      "27083\n",
      "27084\n",
      "27085\n",
      "27086\n",
      "27087\n",
      "27088\n",
      "27089\n",
      "27090\n",
      "27091\n",
      "27092\n",
      "27093\n",
      "27094\n",
      "27095\n",
      "27096\n",
      "27097\n",
      "27098\n",
      "27099\n",
      "27100\n",
      "27101\n",
      "27102\n",
      "27103\n",
      "27104\n",
      "27105\n",
      "27106\n",
      "27107\n",
      "27108\n",
      "27109\n",
      "27110\n",
      "27111\n",
      "27112\n",
      "27113\n",
      "27114\n",
      "27115\n",
      "27116\n",
      "27117\n",
      "27118\n",
      "27119\n",
      "27120\n",
      "27121\n",
      "27122\n",
      "27123\n",
      "27124\n",
      "27125\n",
      "27126\n",
      "27127\n",
      "27128\n",
      "27129\n",
      "27130\n",
      "27131\n",
      "27132\n",
      "27133\n",
      "27134\n",
      "27135\n",
      "27136\n",
      "27137\n",
      "27138\n",
      "27139\n",
      "27140\n",
      "27141\n",
      "27142\n",
      "27143\n",
      "27144\n",
      "27145\n",
      "27146\n",
      "27147\n",
      "27148\n",
      "27149\n",
      "27150\n",
      "27151\n",
      "27152\n",
      "27153\n",
      "27154\n",
      "27155\n",
      "27156\n",
      "27157\n",
      "27158\n",
      "27159\n",
      "27160\n",
      "27161\n",
      "27162\n",
      "27163\n",
      "27164\n",
      "27165\n",
      "27166\n",
      "27167\n",
      "27168\n",
      "27169\n",
      "27170\n",
      "27171\n",
      "27172\n",
      "27173\n",
      "27174\n",
      "27175\n",
      "27176\n",
      "27177\n",
      "27178\n",
      "27179\n",
      "27180\n",
      "27181\n",
      "27182\n",
      "27183\n",
      "27184\n",
      "27185\n",
      "27186\n",
      "27187\n",
      "27188\n",
      "27189\n",
      "27190\n",
      "27191\n",
      "27192\n",
      "27193\n",
      "27194\n",
      "27195\n",
      "27196\n",
      "27197\n",
      "27198\n",
      "27199\n",
      "27200\n",
      "27201\n",
      "27202\n",
      "27203\n",
      "27204\n",
      "27205\n",
      "27206\n",
      "27207\n",
      "27208\n",
      "27209\n",
      "27210\n",
      "27211\n",
      "27212\n",
      "27213\n",
      "27214\n",
      "27215\n",
      "27216\n",
      "27217\n",
      "27218\n",
      "27219\n",
      "27220\n",
      "27221\n",
      "27222\n",
      "27223\n",
      "27224\n",
      "27225\n",
      "27226\n",
      "27227\n",
      "27228\n",
      "27229\n",
      "27230\n",
      "27231\n",
      "27232\n",
      "27233\n",
      "27234\n",
      "27235\n",
      "27236\n",
      "27237\n",
      "27238\n",
      "27239\n",
      "27240\n",
      "27241\n",
      "27242\n",
      "27243\n",
      "27244\n",
      "27245\n",
      "27246\n",
      "27247\n",
      "27248\n",
      "27249\n",
      "27250\n",
      "27251\n",
      "27252\n",
      "27253\n",
      "27254\n",
      "27255\n",
      "27256\n",
      "27257\n",
      "27258\n",
      "27259\n",
      "27260\n",
      "27261\n",
      "27262\n",
      "27263\n",
      "27264\n",
      "27265\n",
      "27266\n",
      "27267\n",
      "27268\n",
      "27269\n",
      "27270\n",
      "27271\n",
      "27272\n",
      "27273\n",
      "27274\n",
      "27275\n",
      "27276\n",
      "27277\n",
      "27278\n",
      "27279\n",
      "27280\n",
      "27281\n",
      "27282\n",
      "27283\n",
      "27284\n",
      "27285\n",
      "27286\n",
      "27287\n",
      "27288\n",
      "27289\n",
      "27290\n",
      "27291\n",
      "27292\n",
      "27293\n",
      "27294\n",
      "27295\n",
      "27296\n",
      "27297\n",
      "27298\n",
      "27299\n",
      "27300\n",
      "27301\n",
      "27302\n",
      "27303\n",
      "27304\n",
      "27305\n",
      "27306\n",
      "27307\n",
      "27308\n",
      "27309\n",
      "27310\n",
      "27311\n",
      "27312\n",
      "27313\n",
      "27314\n",
      "27315\n",
      "27316\n",
      "27317\n",
      "27318\n",
      "27319\n",
      "27320\n",
      "27321\n",
      "27322\n",
      "27323\n",
      "27324\n",
      "27325\n",
      "27326\n",
      "27327\n",
      "27328\n",
      "27329\n",
      "27330\n",
      "27331\n",
      "27332\n",
      "27333\n",
      "27334\n",
      "27335\n",
      "27336\n",
      "27337\n",
      "27338\n",
      "27339\n",
      "27340\n",
      "27341\n",
      "27342\n",
      "27343\n",
      "27344\n",
      "27345\n",
      "27346\n",
      "27347\n",
      "27348\n",
      "27349\n",
      "27350\n",
      "27351\n",
      "27352\n",
      "27353\n",
      "27354\n",
      "27355\n",
      "27356\n",
      "27357\n",
      "27358\n",
      "27359\n",
      "27360\n",
      "27361\n",
      "27362\n",
      "27363\n",
      "27364\n",
      "27365\n",
      "27366\n",
      "27367\n",
      "27368\n",
      "27369\n",
      "27370\n",
      "27371\n",
      "27372\n",
      "27373\n",
      "27374\n",
      "27375\n",
      "27376\n",
      "27377\n",
      "27378\n",
      "27379\n",
      "27380\n",
      "27381\n",
      "27382\n",
      "27383\n",
      "27384\n",
      "27385\n",
      "27386\n",
      "27387\n",
      "27388\n",
      "27389\n",
      "27390\n",
      "27391\n",
      "27392\n",
      "27393\n",
      "27394\n",
      "27395\n",
      "27396\n",
      "27397\n",
      "27398\n",
      "27399\n",
      "27400\n",
      "27401\n",
      "27402\n",
      "27403\n",
      "27404\n",
      "27405\n",
      "27406\n",
      "27407\n",
      "27408\n",
      "27409\n",
      "27410\n",
      "27411\n",
      "27412\n",
      "27413\n",
      "27414\n",
      "27415\n",
      "27416\n",
      "27417\n",
      "27418\n",
      "27419\n",
      "27420\n",
      "27421\n",
      "27422\n",
      "27423\n",
      "27424\n",
      "27425\n",
      "27426\n",
      "27427\n",
      "27428\n",
      "27429\n",
      "27430\n",
      "27431\n",
      "27432\n",
      "27433\n",
      "27434\n",
      "27435\n",
      "27436\n",
      "27437\n",
      "27438\n",
      "27439\n",
      "27440\n",
      "27441\n",
      "27442\n",
      "27443\n",
      "27444\n",
      "27445\n",
      "27446\n",
      "27447\n",
      "27448\n",
      "27449\n",
      "27450\n",
      "27451\n",
      "27452\n",
      "27453\n",
      "27454\n",
      "27455\n",
      "27456\n",
      "27457\n",
      "27458\n",
      "27459\n",
      "27460\n",
      "27461\n",
      "27462\n",
      "27463\n",
      "27464\n",
      "27465\n",
      "27466\n",
      "27467\n",
      "27468\n",
      "27469\n",
      "27470\n",
      "27471\n",
      "27472\n",
      "27473\n",
      "27474\n",
      "27475\n",
      "27476\n",
      "27477\n",
      "27478\n",
      "27479\n",
      "27480\n",
      "27481\n",
      "27482\n",
      "27483\n",
      "27484\n",
      "27485\n",
      "27486\n",
      "27487\n",
      "27488\n",
      "27489\n",
      "27490\n",
      "27491\n",
      "27492\n",
      "27493\n",
      "27494\n",
      "27495\n",
      "27496\n",
      "27497\n",
      "27498\n",
      "27499\n",
      "27500\n",
      "27501\n",
      "27502\n",
      "27503\n",
      "27504\n",
      "27505\n",
      "27506\n",
      "27507\n",
      "27508\n",
      "27509\n",
      "27510\n",
      "27511\n",
      "27512\n",
      "27513\n",
      "27514\n",
      "27515\n",
      "27516\n",
      "27517\n",
      "27518\n",
      "27519\n",
      "27520\n",
      "27521\n",
      "27522\n",
      "27523\n",
      "27524\n",
      "27525\n",
      "27526\n",
      "27527\n",
      "27528\n",
      "27529\n",
      "27530\n",
      "27531\n",
      "27532\n",
      "27533\n",
      "27534\n",
      "27535\n",
      "27536\n",
      "27537\n",
      "27538\n",
      "27539\n",
      "27540\n",
      "27541\n",
      "27542\n",
      "27543\n",
      "27544\n",
      "27545\n",
      "27546\n",
      "27547\n",
      "27548\n",
      "27549\n",
      "27550\n",
      "27551\n",
      "27552\n",
      "27553\n",
      "27554\n",
      "27555\n",
      "27556\n",
      "27557\n",
      "27558\n",
      "27559\n",
      "27560\n",
      "27561\n",
      "27562\n",
      "27563\n",
      "27564\n",
      "27565\n",
      "27566\n",
      "27567\n",
      "27568\n",
      "27569\n",
      "27570\n",
      "27571\n",
      "27572\n",
      "27573\n",
      "27574\n",
      "27575\n",
      "27576\n",
      "27577\n",
      "27578\n",
      "27579\n",
      "27580\n",
      "27581\n",
      "27582\n",
      "27583\n",
      "27584\n",
      "27585\n",
      "27586\n",
      "27587\n",
      "27588\n",
      "27589\n",
      "27590\n",
      "27591\n",
      "27592\n",
      "27593\n",
      "27594\n",
      "27595\n",
      "27596\n",
      "27597\n",
      "27598\n",
      "27599\n",
      "27600\n",
      "27601\n",
      "27602\n",
      "27603\n",
      "27604\n",
      "27605\n",
      "27606\n",
      "27607\n",
      "27608\n",
      "27609\n",
      "27610\n",
      "27611\n",
      "27612\n",
      "27613\n",
      "27614\n",
      "27615\n",
      "27616\n",
      "27617\n",
      "27618\n",
      "27619\n",
      "27620\n",
      "27621\n",
      "27622\n",
      "27623\n",
      "27624\n",
      "27625\n",
      "27626\n",
      "27627\n",
      "27628\n",
      "27629\n",
      "27630\n",
      "27631\n",
      "27632\n",
      "27633\n",
      "27634\n",
      "27635\n",
      "27636\n",
      "27637\n",
      "27638\n",
      "27639\n",
      "27640\n",
      "27641\n",
      "27642\n",
      "27643\n",
      "27644\n",
      "27645\n",
      "27646\n",
      "27647\n",
      "27648\n",
      "27649\n",
      "27650\n",
      "27651\n",
      "27652\n",
      "27653\n",
      "27654\n",
      "27655\n",
      "27656\n",
      "27657\n",
      "27658\n",
      "27659\n",
      "27660\n",
      "27661\n",
      "27662\n",
      "27663\n",
      "27664\n",
      "27665\n",
      "27666\n",
      "27667\n",
      "27668\n",
      "27669\n",
      "27670\n",
      "27671\n",
      "27672\n",
      "27673\n",
      "27674\n",
      "27675\n",
      "27676\n",
      "27677\n",
      "27678\n",
      "27679\n",
      "27680\n",
      "27681\n",
      "27682\n",
      "27683\n",
      "27684\n",
      "27685\n",
      "27686\n",
      "27687\n",
      "27688\n",
      "27689\n",
      "27690\n",
      "27691\n",
      "27692\n",
      "27693\n",
      "27694\n",
      "27695\n",
      "27696\n",
      "27697\n",
      "27698\n",
      "27699\n",
      "27700\n",
      "27701\n",
      "27702\n",
      "27703\n",
      "27704\n",
      "27705\n",
      "27706\n",
      "27707\n",
      "27708\n",
      "27709\n",
      "27710\n",
      "27711\n",
      "27712\n",
      "27713\n",
      "27714\n",
      "27715\n",
      "27716\n",
      "27717\n",
      "27718\n",
      "27719\n",
      "27720\n",
      "27721\n",
      "27722\n",
      "27723\n",
      "27724\n",
      "27725\n",
      "27726\n",
      "27727\n",
      "27728\n",
      "27729\n",
      "27730\n",
      "27731\n",
      "27732\n",
      "27733\n",
      "27734\n",
      "27735\n",
      "27736\n",
      "27737\n",
      "27738\n",
      "27739\n",
      "27740\n",
      "27741\n",
      "27742\n",
      "27743\n",
      "27744\n",
      "27745\n",
      "27746\n",
      "27747\n",
      "27748\n",
      "27749\n",
      "27750\n",
      "27751\n",
      "27752\n",
      "27753\n",
      "27754\n",
      "27755\n",
      "27756\n",
      "27757\n",
      "27758\n",
      "27759\n",
      "27760\n",
      "27761\n",
      "27762\n",
      "27763\n",
      "27764\n",
      "27765\n",
      "27766\n",
      "27767\n",
      "27768\n",
      "27769\n",
      "27770\n",
      "27771\n",
      "27772\n",
      "27773\n",
      "27774\n",
      "27775\n",
      "27776\n",
      "27777\n",
      "27778\n",
      "27779\n",
      "27780\n",
      "27781\n",
      "27782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-602-7624e725b0b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcorr4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_final99\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mcorr5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_final99\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mcorr6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_final99\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcorr1\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(self, method, min_periods)\u001b[0m\n\u001b[0;32m   7464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7465\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"pearson\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7466\u001b[1;33m             \u001b[0mcorrel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_float64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"spearman\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7468\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnancorr_spearman\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_float64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "#correlacoes = []\n",
    "lista_colunas_para_sorteio = df_final99.columns.tolist()[8:72] + ['score']\n",
    "\n",
    "for i in range(1000000):\n",
    "    \n",
    "    print(i)  \n",
    "    \n",
    "    ## Definição dos pesos\n",
    "    fator_mult = random.randint(1, 3)\n",
    "    pesos_aleatorios = np.random.random(3).tolist()\n",
    "    p1 = pesos_aleatorios[0] * fator_mult\n",
    "    p2 = pesos_aleatorios[1] * fator_mult\n",
    "    p3 = pesos_aleatorios[2] * fator_mult\n",
    "    \n",
    "    ## Definição das colunas:\n",
    "    amostras = sample(range(0,64,1), 3)\n",
    "    \n",
    "    var1 = lista_colunas_para_sorteio[amostras[0]]\n",
    "    var2 = lista_colunas_para_sorteio[amostras[1]]\n",
    "    var3 = lista_colunas_para_sorteio[amostras[2]]\n",
    "    \n",
    "    ## Calculando correlação da var sorteada\n",
    "    corr_var1 = df_final99.corr()[var1][3]\n",
    "    corr_var2 = df_final99.corr()[var2][3]\n",
    "    corr_var3 = df_final99.corr()[var3][3]\n",
    "    \n",
    "    max_corr_var_sorteadas = max(corr_var1,corr_var2,corr_var3)\n",
    "    \n",
    "    df_final99['comp1'] = p1 * df_final99[var1] + p2 * df_final99[var2] + p3 * df_final99[var3]\n",
    "    df_final99['comp2'] = p1 * df_final99[var1] + p3 * df_final99[var2] + p2 * df_final99[var3]\n",
    "    df_final99['comp3'] = p2 * df_final99[var1] + p1 * df_final99[var2] + p3 * df_final99[var3]\n",
    "    df_final99['comp4'] = p2 * df_final99[var1] + p3 * df_final99[var2] + p1 * df_final99[var3]\n",
    "    df_final99['comp5'] = p3 * df_final99[var1] + p1 * df_final99[var2] + p2 * df_final99[var3]\n",
    "    df_final99['comp6'] = p3 * df_final99[var1] + p2 * df_final99[var2] + p3 * df_final99[var3]\n",
    "\n",
    "    \n",
    "    \n",
    "    #df_final99['pos_teste'] = p1 * df_final99['positividade_vad'] + p2 * df_final99['pos_rob'] + p3 * df_final99['pos_finbert']\n",
    "    #df_final99['neg_teste'] = p1 * df_final99['negatividade_vad'] + p2 * df_final99['neg_rob'] + p3 * df_final99['neg_finbert']\n",
    "    #df_final99['neu_teste'] = p1 * df_final99['neutralidade_vad'] + p2 * df_final99['neu_rob'] + p3 * df_final99['neu_finbert']\n",
    "\n",
    "    corr1 = df_final99.corr().iloc[69:, 3][0]\n",
    "    corr2 = df_final99.corr().iloc[69:, 3][1]\n",
    "    corr3 = df_final99.corr().iloc[69:, 3][2]\n",
    "    corr4 = df_final99.corr().iloc[69:, 3][3]\n",
    "    corr5 = df_final99.corr().iloc[69:, 3][4]\n",
    "    corr6 = df_final99.corr().iloc[69:, 3][5]\n",
    "\n",
    "    if corr1<0:\n",
    "        corr1 = -1 * corr1\n",
    "    if corr2<0:\n",
    "        corr2 = -1 * corr2    \n",
    "    if corr3<0:\n",
    "        corr3 = -1 * corr3\n",
    "    if corr4<0:\n",
    "        corr4 = -1 * corr4        \n",
    "    if corr5<0:\n",
    "        corr5 = -1 * corr5        \n",
    "    if corr6<0:\n",
    "        corr6 = -1 * corr6\n",
    "        \n",
    "    melhor_corr = max(corr1,corr2,corr3,corr4,corr5,corr6)\n",
    "    \n",
    "    ## Sò armazena os resultados se a melhor correlação das combinações testadas for maior das variaveis individuais sorteadas\n",
    "    if melhor_corr > max_corr_var_sorteadas:\n",
    "        correlacoes.append(np.array([melhor_corr,var1,var2,var3,p1,p2,p3,corr1,corr2,corr3,corr4,corr5,corr6]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados_correlacoes_df = pd.DataFrame(np.array(correlacoes), columns=['melhor_corr','var1','var2','var3','p1','p2','p3','comb1','comb2','comb3','comb4','comb5','comb6'])\n",
    "#resultados_correlacoes_df.sort_values(by = 'melhor_corr', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Var%</th>\n",
       "      <th>Fechamento</th>\n",
       "      <th>score</th>\n",
       "      <th>polaridade_vad</th>\n",
       "      <th>subjetividade_vad</th>\n",
       "      <th>negatividade_vad</th>\n",
       "      <th>neutralidade_vad</th>\n",
       "      <th>positividade_vad</th>\n",
       "      <th>...</th>\n",
       "      <th>neu_finbertd1</th>\n",
       "      <th>neu_finbertd2</th>\n",
       "      <th>neu_finbertd3</th>\n",
       "      <th>neu_finbertd4</th>\n",
       "      <th>combinacao1</th>\n",
       "      <th>combinacao2</th>\n",
       "      <th>combinacao3</th>\n",
       "      <th>combinacao4</th>\n",
       "      <th>combinacao5</th>\n",
       "      <th>combinacao6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combinacao1</th>\n",
       "      <td>0.040042</td>\n",
       "      <td>-0.074160</td>\n",
       "      <td>0.080235</td>\n",
       "      <td>0.099911</td>\n",
       "      <td>0.061082</td>\n",
       "      <td>0.196160</td>\n",
       "      <td>0.407762</td>\n",
       "      <td>-0.923455</td>\n",
       "      <td>0.406005</td>\n",
       "      <td>0.327922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.027769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.238930</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.305285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinacao2</th>\n",
       "      <td>0.033718</td>\n",
       "      <td>-0.053562</td>\n",
       "      <td>0.089051</td>\n",
       "      <td>0.179119</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.097146</td>\n",
       "      <td>-0.088113</td>\n",
       "      <td>0.033702</td>\n",
       "      <td>0.037438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480969</td>\n",
       "      <td>0.331552</td>\n",
       "      <td>0.039726</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720726</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.806194</td>\n",
       "      <td>0.670136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinacao3</th>\n",
       "      <td>0.030262</td>\n",
       "      <td>-0.060402</td>\n",
       "      <td>0.138359</td>\n",
       "      <td>0.174304</td>\n",
       "      <td>0.043217</td>\n",
       "      <td>-0.022929</td>\n",
       "      <td>0.064495</td>\n",
       "      <td>-0.244921</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069982</td>\n",
       "      <td>0.519258</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.120232</td>\n",
       "      <td>0.238930</td>\n",
       "      <td>0.720726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846404</td>\n",
       "      <td>0.680431</td>\n",
       "      <td>0.585138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinacao4</th>\n",
       "      <td>0.055799</td>\n",
       "      <td>-0.039450</td>\n",
       "      <td>0.121846</td>\n",
       "      <td>0.172871</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.065916</td>\n",
       "      <td>0.282825</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.053926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057401</td>\n",
       "      <td>0.464179</td>\n",
       "      <td>0.040821</td>\n",
       "      <td>0.216752</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.859532</td>\n",
       "      <td>0.846404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842810</td>\n",
       "      <td>0.494142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinacao5</th>\n",
       "      <td>0.033594</td>\n",
       "      <td>-0.092227</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>0.159589</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.022488</td>\n",
       "      <td>0.088184</td>\n",
       "      <td>-0.066563</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.056771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.537002</td>\n",
       "      <td>0.054778</td>\n",
       "      <td>0.282549</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>0.806194</td>\n",
       "      <td>0.680431</td>\n",
       "      <td>0.842810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combinacao6</th>\n",
       "      <td>0.004419</td>\n",
       "      <td>-0.050825</td>\n",
       "      <td>0.053015</td>\n",
       "      <td>0.151405</td>\n",
       "      <td>0.103995</td>\n",
       "      <td>0.039415</td>\n",
       "      <td>0.064276</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>0.185948</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328869</td>\n",
       "      <td>0.042525</td>\n",
       "      <td>0.033859</td>\n",
       "      <td>0.258597</td>\n",
       "      <td>0.305285</td>\n",
       "      <td>0.670136</td>\n",
       "      <td>0.585138</td>\n",
       "      <td>0.494142</td>\n",
       "      <td>0.569995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close    Volume      Var%  Fechamento     score  \\\n",
       "combinacao1   0.040042 -0.074160  0.080235    0.099911  0.061082   \n",
       "combinacao2   0.033718 -0.053562  0.089051    0.179119  0.030880   \n",
       "combinacao3   0.030262 -0.060402  0.138359    0.174304  0.043217   \n",
       "combinacao4   0.055799 -0.039450  0.121846    0.172871  0.010433   \n",
       "combinacao5   0.033594 -0.092227  0.089290    0.159589  0.002727   \n",
       "combinacao6   0.004419 -0.050825  0.053015    0.151405  0.103995   \n",
       "\n",
       "             polaridade_vad  subjetividade_vad  negatividade_vad  \\\n",
       "combinacao1        0.196160           0.407762         -0.923455   \n",
       "combinacao2        0.018616           0.097146         -0.088113   \n",
       "combinacao3       -0.022929           0.064495         -0.244921   \n",
       "combinacao4        0.065916           0.282825         -0.075511   \n",
       "combinacao5        0.022488           0.088184         -0.066563   \n",
       "combinacao6        0.039415           0.064276         -0.312889   \n",
       "\n",
       "             neutralidade_vad  positividade_vad  ...  neu_finbertd1  \\\n",
       "combinacao1          0.406005          0.327922  ...       0.062053   \n",
       "combinacao2          0.033702          0.037438  ...       0.480969   \n",
       "combinacao3          0.172920          0.006999  ...       0.069982   \n",
       "combinacao4          0.010870          0.053926  ...       0.057401   \n",
       "combinacao5          0.002087          0.056771  ...       0.030056   \n",
       "combinacao6          0.185948          0.052016  ...       0.328869   \n",
       "\n",
       "             neu_finbertd2  neu_finbertd3  neu_finbertd4  combinacao1  \\\n",
       "combinacao1       0.037800       0.037146       0.027769     1.000000   \n",
       "combinacao2       0.331552       0.039726       0.269010     0.116300   \n",
       "combinacao3       0.519258       0.074077       0.120232     0.238930   \n",
       "combinacao4       0.464179       0.040821       0.216752     0.171200   \n",
       "combinacao5       0.537002       0.054778       0.282549     0.096805   \n",
       "combinacao6       0.042525       0.033859       0.258597     0.305285   \n",
       "\n",
       "             combinacao2  combinacao3  combinacao4  combinacao5  combinacao6  \n",
       "combinacao1     0.116300     0.238930     0.171200     0.096805     0.305285  \n",
       "combinacao2     1.000000     0.720726     0.859532     0.806194     0.670136  \n",
       "combinacao3     0.720726     1.000000     0.846404     0.680431     0.585138  \n",
       "combinacao4     0.859532     0.846404     1.000000     0.842810     0.494142  \n",
       "combinacao5     0.806194     0.680431     0.842810     1.000000     0.569995  \n",
       "combinacao6     0.670136     0.585138     0.494142     0.569995     1.000000  \n",
       "\n",
       "[6 rows x 75 columns]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Os seguintes resultados compõe as melhores combinações de features:\n",
    "\n",
    "# corr = 0.099\n",
    "df_final99['combinacao1'] = 0.060719118247568815 * df_final99['subjetividade_vad'] + 0.6259242968314084 * df_final99['neutralidade_vad'] + 0.7141001777794133 * df_final99['positividade_vad']\n",
    "# corr = 0.179\n",
    "df_final99['combinacao2'] = 0.1975138370186572 * df_final99['neu_finbertd1'] +  0.26367223378473537 * df_final99['neg_finbertd2'] + 0.7954443769308506 * df_final99['neu_robd4']\n",
    "# corr = 0.174\n",
    "df_final99['combinacao3'] = 1.264131299137323 * df_final99['neu_rob'] + 1.4796992822690314 * df_final99['neu_robd4'] + 1.264131299137323 * df_final99['neg_finbertd2']\n",
    "# corr = 0.172\n",
    "df_final99['combinacao4'] = 2.8498404816391836 * df_final99['neu_robd4'] + 1.5544953783606055 * df_final99['neg_finbertd2'] + 0.6276230669224906 * df_final99['subjetividade_vad']\n",
    "# corr = 0.1595\n",
    "df_final99['combinacao5'] = 0.4764943969243103 * df_final99['neu_finbertd2'] + 1.6455811654511971 * df_final99['neu_robd4'] + 1.2818211500203125 * df_final99['positividade_vadd2']\n",
    "# corr = 0.1514\n",
    "df_final99['combinacao6'] = 0.239031592216275 * df_final99['neu_rob'] + 0.12697822481213494 * df_final99['neg_finbertd1'] + 0.30078124336283985 * df_final99['neu_robd4']\n",
    "\n",
    "df_final99.corr().tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atualizando o dicionário com as novas features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "dict_dados_variacoes_sentilex = {}\n",
    "\n",
    "correlacoes = []\n",
    "\n",
    "for versao in versoes_sentilex:\n",
    "    \n",
    "    #print(versao)\n",
    "    ## Atualizando Score Sentilex (Etapa 5.1)\n",
    "    dic_palavra_polaridade  = montar_dicionario(versao)\n",
    "\n",
    "    ### Copia o df atualiza o score do dicionário recém-lido\n",
    "    df_final99 = df_final.copy()\n",
    "    \n",
    "    df_final99['score'] = df_final99['Noticias'].apply(lambda x: Score_sentimento(str(x)))\n",
    "    \n",
    "    ### Criação de novas features combinadas\n",
    "    #df_final99['pos_combinada'] = (df_final99['positividade_vad'] * df_final99['pos_rob'] * df_final99['pos_finbert'])**1/2\n",
    "    #df_final99['neg_combinada'] = (df_final99['negatividade_vad'] * df_final99['neg_rob'] * df_final99['neg_finbert'])**1/2\n",
    "    #df_final99['neu_combinada'] = (df_final99['neutralidade_vad'] * df_final99['neu_rob'] * df_final99['neu_finbert'])**1/2\n",
    "    \n",
    "    \n",
    "    #pesos_aleatorios = np.random.random(3).tolist()\n",
    "    #pesos_aleatorios\n",
    "    \n",
    "    #df_final99['pos_teste'] = 3* df_final99['positividade_vad'] + 2* df_final99['pos_rob'] + 1*df_final99['pos_finbert']\n",
    "    #df_final99['neg_teste'] = 2* df_final99['negatividade_vad'] + 3* df_final99['neg_rob'] + 1*df_final99['neg_finbert']\n",
    "    #df_final99['neu_teste'] = 1* df_final99['neutralidade_vad'] + 3* df_final99['neu_rob'] + 2* df_final99['neu_finbert']\n",
    "        \n",
    "    #corr_pos = df_final99.corr().iloc[20, 3]\n",
    "    #corr_neg = df_final99.corr().iloc[21, 3]\n",
    "    #corr_neu = df_final99.corr().iloc[22, 3]\n",
    "    \n",
    "    #correlacoes.append(np.array([corr_pos,corr_neg,corr_neu,pesos_aleatorios[0],pesos_aleatorios[1],pesos_aleatorios[2]]))\n",
    "    \n",
    "    #df_final99['pos_teste'] = 3* df_final99['positividade_vad'] + 2* df_final99['pos_rob'] + 1*df_final99['pos_finbert']\n",
    "    #df_final99['neg_teste'] = 2* df_final99['negatividade_vad'] + 3* df_final99['neg_rob'] + 1*df_final99['neg_finbert']\n",
    "    #df_final99['neu_teste'] = 1* df_final99['neutralidade_vad'] + 3* df_final99['neu_rob'] + 2* df_final99['neu_finbert']\n",
    "    \n",
    "    \n",
    "    features = ['polaridade_vad', 'subjetividade_vad', 'negatividade_vad', 'neutralidade_vad', 'positividade_vad',\n",
    "    'composicao_vad','score', 'neg_rob','neu_rob','pos_rob','pos_finbert', 'neg_finbert', 'neu_finbert']\n",
    "    \n",
    "    #features = ['polaridade_vad', 'subjetividade_vad', 'negatividade_vad', 'neutralidade_vad', 'positividade_vad', 'composicao_vad','score', 'neg_rob','neu_rob','pos_rob','pos_finbert', 'neg_finbert', 'neu_finbert','pos_combinada','neg_combinada','neu_combinada']\n",
    "    \n",
    "    featuresd1 = [i + \"d1\" for i in features]\n",
    "    featuresd2 = [i + \"d2\" for i in features]\n",
    "    featuresd3 = [i + \"d3\" for i in features]\n",
    "    featuresd4 = [i + \"d4\" for i in features]\n",
    "\n",
    "\n",
    "    #Criando as colunas de features para d-1, d-2, d-3, d-4 e inicializando com valores zeros:\n",
    "    for i in features:\n",
    "        df_final99[i+\"d1\"] = 0\n",
    "        df_final99[i+\"d2\"] = 0\n",
    "        df_final99[i+\"d3\"] = 0\n",
    "        df_final99[i+\"d4\"] = 0\n",
    "\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    #atualiza as features de d-1\n",
    "    for a,b in itertools.zip_longest(features,featuresd1):\n",
    "        df_final99[b] = df_final99.shift(periods=1)[a]\n",
    "\n",
    "    #atualiza as features de d-2\n",
    "    for a,b in itertools.zip_longest(features,featuresd2):\n",
    "        df_final99[b] = df_final99.shift(periods=2)[a]\n",
    "\n",
    "    #atualiza as features de d-3\n",
    "    for a,b in itertools.zip_longest(features,featuresd3):\n",
    "        df_final99[b] = df_final99.shift(periods=3)[a]\n",
    "\n",
    "    #atualiza as features de d-4\n",
    "    for a,b in itertools.zip_longest(features,featuresd4):\n",
    "        df_final99[b] = df_final99.shift(periods=4)[a]\n",
    "\n",
    "\n",
    "    df_final99 = df_final99.dropna()\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Adição das features recém criadas (combinações)\n",
    "    # corr = 0.099\n",
    "    df_final99['combinacao1'] = 0.060719118247568815 * df_final99['subjetividade_vad'] + 0.6259242968314084 * df_final99['neutralidade_vad'] + 0.7141001777794133 * df_final99['positividade_vad']\n",
    "    # corr = 0.179\n",
    "    df_final99['combinacao2'] = 0.1975138370186572 * df_final99['neu_finbertd1'] +  0.26367223378473537 * df_final99['neg_finbertd2'] + 0.7954443769308506 * df_final99['neu_robd4']\n",
    "    # corr = 0.174\n",
    "    df_final99['combinacao3'] = 1.264131299137323 * df_final99['neu_rob'] + 1.4796992822690314 * df_final99['neu_robd4'] + 1.264131299137323 * df_final99['neg_finbertd2']\n",
    "    # corr = 0.172\n",
    "    df_final99['combinacao4'] = 2.8498404816391836 * df_final99['neu_robd4'] + 1.5544953783606055 * df_final99['neg_finbertd2'] + 0.6276230669224906 * df_final99['subjetividade_vad']\n",
    "    # corr = 0.1595\n",
    "    df_final99['combinacao5'] = 0.4764943969243103 * df_final99['neu_finbertd2'] + 1.6455811654511971 * df_final99['neu_robd4'] + 1.2818211500203125 * df_final99['positividade_vadd2']\n",
    "    # corr = 0.1514\n",
    "    df_final99['combinacao6'] = 0.239031592216275 * df_final99['neu_rob'] + 0.12697822481213494 * df_final99['neg_finbertd1'] + 0.30078124336283985 * df_final99['neu_robd4']\n",
    "\n",
    "\n",
    "\n",
    "    ## Aplicando mesma reamostragem\n",
    "\n",
    "    from dateutil import parser\n",
    "    df_treino_valid = df_final99[(df_final99['Date'] <= parser.parse('2021-12-31'))]\n",
    "    df_test = df_final99[(df_final99['Date'] > parser.parse('2021-12-31'))]\n",
    "  \n",
    "    \n",
    "    #df_treino_valid = df_final99[(df_final99['Date'] <= parser.parse('2022-03-31'))] \n",
    "    #df_test = df_final99[(df_final99['Date'] > parser.parse('2021-12-31')) & (df_final99['Date'] <= parser.parse('2022-03-31'))]\n",
    "    #df_test = df_final99[(df_final99['Date'] > parser.parse('2022-03-31'))]\n",
    "\n",
    "    \n",
    "    indices_validacao = np.arange(0,len(df_treino_valid),3)\n",
    "    indices_validacao_lista = indices_validacao.tolist()\n",
    "\n",
    "    #cria array com todos os indexes\n",
    "    indices_train = np.arange(0,len(df_treino_valid),1)\n",
    "    indices_train_lista = indices_train.tolist()\n",
    "\n",
    "    # seleciona os indexes que nao estejam na validacao para compor o treino\n",
    "    indices_train_lista = [ i for i in indices_train_lista if i not in indices_validacao_lista]\n",
    "    \n",
    "    #transforma para array\n",
    "    indices_train = np.array(indices_train_lista)\n",
    "\n",
    "    # Redefinindo os datasets\n",
    "    df_train =  df_treino_valid.iloc[indices_train]                 \n",
    "                   \n",
    "    df_valid = df_treino_valid.iloc[indices_validacao]\n",
    "                      \n",
    "    \n",
    "    dict_dados_variacoes_sentilex[versao] = [df_train,df_valid,df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os dados de validação correspondem a 33% dos dados de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Prototipação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos treinar modelos ingenuos com dados de treino e verificar quais deles performam melhor em:\n",
    "\n",
    "- Dados de validação (2020 e 2021): Para avaliar a capacidade de generalização dos algoritmos\n",
    "- Dados de teste (2022): Para avaliar a performance em dados de produção.\n",
    "\n",
    "A ideia inicial é analisar o potencial de generalização de cada algorítmo assim como a performance em produção, para isso o experimento será repetido 10x treinando o modelo com um conjunto distinto composto por 80% dos dados de treino a cada repetição.\n",
    "\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "-> Seleção da versao do sentilex (20 versões) -> Holdout aleatório de 80% dos dados de treino -> Aplicação de PCA / Normalização / Dados brutos (3 técnicas de pré-processamento) -> Treino -> Avaliação sobre dados de validação / Avaliação sobre dados de teste -> Repete 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00,  9.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:03<00:00,  7.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:03<00:00,  9.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:04<00:00,  6.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:03<00:00,  8.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:04<00:00,  6.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:03<00:00,  7.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:05<00:00,  5.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 10.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 12.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 15.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 11.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:03<00:00,  8.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:05<00:00,  5.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_1 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_2 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_3 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_4 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_5 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 13.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_1 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_2 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_3 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_4 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_5 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_1 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_2 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:02<00:00, 14.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 14.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 19.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_3 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_4 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_5 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_1 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 24.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 16.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 18.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_2 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_3 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_4 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_5 - Repetição = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 40.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 20.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 22.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "df_models_valid = pd.DataFrame()\n",
    "df_models_test = pd.DataFrame()\n",
    "\n",
    "#Loop numero de repetições do experimento\n",
    "for rep in range(2):\n",
    "    \n",
    "   ##Loop do dicionário Sentilex Escolhido: \n",
    "    for versao in dict_dados_variacoes_sentilex.keys():\n",
    "        \n",
    "        print(\"Iterando versão do sentilex = {} - Repetição = {}\".format(versao,rep))\n",
    "\n",
    "        df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "        df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "        df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "        #Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "        X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_test2 = df_test['Fechamento']\n",
    "\n",
    "        X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_train2 = df_train['Fechamento']\n",
    "\n",
    "        X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "        #Definindo dados de treino (aprendendo com 70% da amostra de treino)\n",
    "        X_train4, X_descarte, y_train4, y_descarte = train_test_split(X_train2, y_train2, test_size=0.8, random_state=rep, stratify = y_train2)\n",
    "            \n",
    "        #X_train4 = X_train2\n",
    "        #y_train4 = y_train2 \n",
    "        \n",
    "\n",
    "        # Normalizando\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train4)\n",
    "        X_train_norm = scaler.transform(X_train4)\n",
    "        \n",
    "        scaler.fit(X_test2)\n",
    "        X_test_norm = scaler.transform(X_test2)\n",
    "        \n",
    "        scaler.fit(X_valid2)\n",
    "        X_valid_norm = scaler.transform(X_valid2)\n",
    "        \n",
    "        \n",
    "        ########################### Previsao dados validação ###########################\n",
    "        #Treinando e avaliando dados nao normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train4, X_valid2, y_train4, y_valid2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"NAO\"\n",
    "        df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        #Treinando e avaliando dados normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train_norm, X_valid_norm, y_train4, y_valid2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"SIM\"\n",
    "        df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        ########################### Previsao dados teste ###########################\n",
    "                #Treinando e avaliando dados nao normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train4, X_test2, y_train4, y_test2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"NAO\"\n",
    "        df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        #Treinando e avaliando dados normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train_norm, X_test_norm, y_train4, y_test2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"SIM\"\n",
    "        df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        \n",
    "         ## iterar sobre a quantidade de reduções de dimensionalidade das features (PCA) de 2 a 10 reduções\n",
    "        for i in range(2,10,1): \n",
    "\n",
    "            #Aplicando PCA\n",
    "            pca = PCA(n_components=i)\n",
    "            X_train_pca = pca.fit_transform(X_train4)\n",
    "            X_test_pca = pca.fit_transform(X_test2)\n",
    "            X_valid_pca = pca.fit_transform(X_valid2)\n",
    "\n",
    "            #Aplicando Normalização\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            scaler.fit(X_train_pca)\n",
    "            X_train_pca_normalized = scaler.transform(X_train_pca)\n",
    "            \n",
    "            scaler.fit(X_test_pca)\n",
    "            X_test_pca_normalized = scaler.transform(X_test_pca)\n",
    "            \n",
    "            scaler.fit(X_valid_pca)\n",
    "            X_valid_pca_normalized = scaler.transform(X_valid_pca)\n",
    "\n",
    "\n",
    "            ########################### Previsao dados validação ###########################\n",
    "            \n",
    "            #Testando PCA + normalizado \n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca_normalized, X_valid_pca_normalized, y_train4, y_valid2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i\n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"SIM\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "\n",
    "            #Testando PCA\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca, X_valid_pca, y_train4, y_valid2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i \n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"NAO\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True) \n",
    "            \n",
    "            ########################### Previsao dados teste ###########################\n",
    "            \n",
    "            #Testando PCA + normalizado\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca_normalized, X_test_pca_normalized, y_train4, y_test2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i\n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"SIM\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "\n",
    "            #Testando PCA\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca, X_test_pca, y_train4, y_test2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i \n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"NAO\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('^display.',silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy_valid</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>Acuracia_balanc_test_valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>n_PCA</th>\n",
       "      <th>versao_sentilex</th>\n",
       "      <th>Normalizacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.644172</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.630597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.625767</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.621394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.619632</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.618327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>6</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.625897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/A</th>\n",
       "      <th>70_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>6</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.644107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CalibratedClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.633468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.609124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.609124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.616695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>8</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.616695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.624266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.613627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.613627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTreeClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.634904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.634904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.610560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.610560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>9</th>\n",
       "      <th>70_1</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.625702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <th>9</th>\n",
       "      <th>70_1</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Accuracy_valid  \\\n",
       "Model                       n_PCA versao_sentilex Normalizacao                   \n",
       "DecisionTreeClassifier      5     75_5            SIM                 0.644172   \n",
       "LinearSVC                   7     75_5            SIM                 0.625767   \n",
       "LogisticRegression          N/A   70_2            SIM                 0.619632   \n",
       "BaggingClassifier           6     75_5            SIM                 0.613497   \n",
       "LogisticRegression          N/A   70_4            SIM                 0.613497   \n",
       "LinearSVC                   7     75_4            SIM                 0.613497   \n",
       "LogisticRegression          7     75_5            NAO                 0.613497   \n",
       "                            N/A   70_3            SIM                 0.613497   \n",
       "BaggingClassifier           6     75_5            NAO                 0.607362   \n",
       "CalibratedClassifierCV      7     75_5            NAO                 0.607362   \n",
       "                            6     75_4            NAO                 0.601227   \n",
       "NearestCentroid             9     70_2            SIM                 0.601227   \n",
       "RidgeClassifier             9     70_2            SIM                 0.595092   \n",
       "CalibratedClassifierCV      7     75_4            NAO                 0.595092   \n",
       "LGBMClassifier              8     75_3            SIM                 0.595092   \n",
       "RidgeClassifierCV           9     70_2            SIM                 0.595092   \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                 0.595092   \n",
       "Perceptron                  8     75_4            SIM                 0.595092   \n",
       "SGDClassifier               N/A   70_2            SIM                 0.595092   \n",
       "BaggingClassifier           5     75_4            NAO                 0.588957   \n",
       "LinearSVC                   7     75_5            NAO                 0.588957   \n",
       "RidgeClassifierCV           7     75_3            NAO                 0.588957   \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                 0.588957   \n",
       "LogisticRegression          7     75_4            NAO                 0.588957   \n",
       "DecisionTreeClassifier      5     75_5            NAO                 0.588957   \n",
       "                            7     75_3            SIM                 0.588957   \n",
       "LogisticRegression          6     75_3            NAO                 0.588957   \n",
       "BaggingClassifier           7     75_5            NAO                 0.582822   \n",
       "XGBClassifier               8     75_5            SIM                 0.582822   \n",
       "DecisionTreeClassifier      8     75_5            SIM                 0.582822   \n",
       "LinearSVC                   7     75_4            NAO                 0.582822   \n",
       "CalibratedClassifierCV      6     75_3            NAO                 0.582822   \n",
       "LGBMClassifier              8     75_5            NAO                 0.576687   \n",
       "XGBClassifier               8     75_3            SIM                 0.576687   \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                 0.576687   \n",
       "LinearSVC                   6     75_3            NAO                 0.576687   \n",
       "RidgeClassifierCV           9     70_1            SIM                 0.576687   \n",
       "RandomForestClassifier      9     75_4            NAO                 0.576687   \n",
       "LGBMClassifier              8     75_3            NAO                 0.576687   \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                 0.576687   \n",
       "AdaBoostClassifier          9     75_5            SIM                 0.576687   \n",
       "BaggingClassifier           5     75_5            NAO                 0.576687   \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                 0.570552   \n",
       "RidgeClassifier             N/A   70_2            SIM                 0.570552   \n",
       "RidgeClassifierCV           N/A   70_2            SIM                 0.570552   \n",
       "LogisticRegression          7     75_3            NAO                 0.570552   \n",
       "AdaBoostClassifier          8     75_5            SIM                 0.570552   \n",
       "XGBClassifier               7     75_5            NAO                 0.570552   \n",
       "NearestCentroid             9     70_1            SIM                 0.570552   \n",
       "AdaBoostClassifier          8     75_4            SIM                 0.570552   \n",
       "\n",
       "                                                                Accuracy_test  \\\n",
       "Model                       n_PCA versao_sentilex Normalizacao                  \n",
       "DecisionTreeClassifier      5     75_5            SIM                0.617021   \n",
       "LinearSVC                   7     75_5            SIM                0.617021   \n",
       "LogisticRegression          N/A   70_2            SIM                0.617021   \n",
       "BaggingClassifier           6     75_5            SIM                0.617021   \n",
       "LogisticRegression          N/A   70_4            SIM                0.617021   \n",
       "LinearSVC                   7     75_4            SIM                0.617021   \n",
       "LogisticRegression          7     75_5            NAO                0.638298   \n",
       "                            N/A   70_3            SIM                0.617021   \n",
       "BaggingClassifier           6     75_5            NAO                0.680851   \n",
       "CalibratedClassifierCV      7     75_5            NAO                0.659574   \n",
       "                            6     75_4            NAO                0.617021   \n",
       "NearestCentroid             9     70_2            SIM                0.617021   \n",
       "RidgeClassifier             9     70_2            SIM                0.617021   \n",
       "CalibratedClassifierCV      7     75_4            NAO                0.638298   \n",
       "LGBMClassifier              8     75_3            SIM                0.617021   \n",
       "RidgeClassifierCV           9     70_2            SIM                0.617021   \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                0.617021   \n",
       "Perceptron                  8     75_4            SIM                0.617021   \n",
       "SGDClassifier               N/A   70_2            SIM                0.638298   \n",
       "BaggingClassifier           5     75_4            NAO                0.617021   \n",
       "LinearSVC                   7     75_5            NAO                0.659574   \n",
       "RidgeClassifierCV           7     75_3            NAO                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                0.638298   \n",
       "LogisticRegression          7     75_4            NAO                0.638298   \n",
       "DecisionTreeClassifier      5     75_5            NAO                0.680851   \n",
       "                            7     75_3            SIM                0.680851   \n",
       "LogisticRegression          6     75_3            NAO                0.617021   \n",
       "BaggingClassifier           7     75_5            NAO                0.617021   \n",
       "XGBClassifier               8     75_5            SIM                0.638298   \n",
       "DecisionTreeClassifier      8     75_5            SIM                0.617021   \n",
       "LinearSVC                   7     75_4            NAO                0.638298   \n",
       "CalibratedClassifierCV      6     75_3            NAO                0.617021   \n",
       "LGBMClassifier              8     75_5            NAO                0.617021   \n",
       "XGBClassifier               8     75_3            SIM                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                0.617021   \n",
       "LinearSVC                   6     75_3            NAO                0.617021   \n",
       "RidgeClassifierCV           9     70_1            SIM                0.617021   \n",
       "RandomForestClassifier      9     75_4            NAO                0.617021   \n",
       "LGBMClassifier              8     75_3            NAO                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                0.638298   \n",
       "AdaBoostClassifier          9     75_5            SIM                0.638298   \n",
       "BaggingClassifier           5     75_5            NAO                0.638298   \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                0.617021   \n",
       "RidgeClassifier             N/A   70_2            SIM                0.638298   \n",
       "RidgeClassifierCV           N/A   70_2            SIM                0.638298   \n",
       "LogisticRegression          7     75_3            NAO                0.638298   \n",
       "AdaBoostClassifier          8     75_5            SIM                0.680851   \n",
       "XGBClassifier               7     75_5            NAO                0.617021   \n",
       "NearestCentroid             9     70_1            SIM                0.617021   \n",
       "AdaBoostClassifier          8     75_4            SIM                0.617021   \n",
       "\n",
       "                                                                Acuracia_balanc_test_valid  \n",
       "Model                       n_PCA versao_sentilex Normalizacao                              \n",
       "DecisionTreeClassifier      5     75_5            SIM                             0.630597  \n",
       "LinearSVC                   7     75_5            SIM                             0.621394  \n",
       "LogisticRegression          N/A   70_2            SIM                             0.618327  \n",
       "BaggingClassifier           6     75_5            SIM                             0.615259  \n",
       "LogisticRegression          N/A   70_4            SIM                             0.615259  \n",
       "LinearSVC                   7     75_4            SIM                             0.615259  \n",
       "LogisticRegression          7     75_5            NAO                             0.625897  \n",
       "                            N/A   70_3            SIM                             0.615259  \n",
       "BaggingClassifier           6     75_5            NAO                             0.644107  \n",
       "CalibratedClassifierCV      7     75_5            NAO                             0.633468  \n",
       "                            6     75_4            NAO                             0.609124  \n",
       "NearestCentroid             9     70_2            SIM                             0.609124  \n",
       "RidgeClassifier             9     70_2            SIM                             0.606057  \n",
       "CalibratedClassifierCV      7     75_4            NAO                             0.616695  \n",
       "LGBMClassifier              8     75_3            SIM                             0.606057  \n",
       "RidgeClassifierCV           9     70_2            SIM                             0.606057  \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                             0.606057  \n",
       "Perceptron                  8     75_4            SIM                             0.606057  \n",
       "SGDClassifier               N/A   70_2            SIM                             0.616695  \n",
       "BaggingClassifier           5     75_4            NAO                             0.602989  \n",
       "LinearSVC                   7     75_5            NAO                             0.624266  \n",
       "RidgeClassifierCV           7     75_3            NAO                             0.602989  \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                             0.613627  \n",
       "LogisticRegression          7     75_4            NAO                             0.613627  \n",
       "DecisionTreeClassifier      5     75_5            NAO                             0.634904  \n",
       "                            7     75_3            SIM                             0.634904  \n",
       "LogisticRegression          6     75_3            NAO                             0.602989  \n",
       "BaggingClassifier           7     75_5            NAO                             0.599922  \n",
       "XGBClassifier               8     75_5            SIM                             0.610560  \n",
       "DecisionTreeClassifier      8     75_5            SIM                             0.599922  \n",
       "LinearSVC                   7     75_4            NAO                             0.610560  \n",
       "CalibratedClassifierCV      6     75_3            NAO                             0.599922  \n",
       "LGBMClassifier              8     75_5            NAO                             0.596854  \n",
       "XGBClassifier               8     75_3            SIM                             0.596854  \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                             0.596854  \n",
       "LinearSVC                   6     75_3            NAO                             0.596854  \n",
       "RidgeClassifierCV           9     70_1            SIM                             0.596854  \n",
       "RandomForestClassifier      9     75_4            NAO                             0.596854  \n",
       "LGBMClassifier              8     75_3            NAO                             0.596854  \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                             0.607492  \n",
       "AdaBoostClassifier          9     75_5            SIM                             0.607492  \n",
       "BaggingClassifier           5     75_5            NAO                             0.607492  \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                             0.593787  \n",
       "RidgeClassifier             N/A   70_2            SIM                             0.604425  \n",
       "RidgeClassifierCV           N/A   70_2            SIM                             0.604425  \n",
       "LogisticRegression          7     75_3            NAO                             0.604425  \n",
       "AdaBoostClassifier          8     75_5            SIM                             0.625702  \n",
       "XGBClassifier               7     75_5            NAO                             0.593787  \n",
       "NearestCentroid             9     70_1            SIM                             0.593787  \n",
       "AdaBoostClassifier          8     75_4            SIM                             0.593787  "
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prototipacao = pd.merge(left = df_models_valid, right = df_models_test, how = 'left', on = ['Model','n_PCA','versao_sentilex','Normalizacao'], suffixes=('_valid', '_test'))\n",
    "\n",
    "##Media acuracia teste e valid\n",
    "df_prototipacao['Acuracia_balanc_test_valid'] = (df_prototipacao['Accuracy_valid'] + df_prototipacao['Accuracy_test'])/2\n",
    "\n",
    "#df_prototipacao.groupby(['Model','n_PCA','versao_sentilex','Normalizacao']).agg({'Accuracy_valid':np.mean, 'Balanced Accuracy_valid':np.mean, 'ROC AUC_valid':np.mean, 'F1 Score_valid':np.mean, 'Accuracy_test':np.mean, 'Balanced Accuracy_test':np.mean, 'ROC AUC_test':np.mean, 'F1 Score_test':np.mean}).sort_values(by='ROC AUC_valid', ascending=False).head(50)\n",
    "df_prototipacao.groupby(['Model','n_PCA','versao_sentilex','Normalizacao']).agg({'Accuracy_valid':np.mean, 'Accuracy_test':np.mean, 'Acuracia_balanc_test_valid': np.mean}).sort_values(by='Acuracia_balanc_test_valid', ascending=False).head(50)\n",
    "\n",
    "## Agrupa os resultados e retorna acuracy_teste > 60 e ordena por acuracy_valid\n",
    "df_agrupado = df_prototipacao.groupby(['Model','n_PCA','versao_sentilex','Normalizacao']).agg({'Accuracy_valid':np.mean, 'Accuracy_test':np.mean, 'Acuracia_balanc_test_valid': np.mean}).sort_values(by='Acuracia_balanc_test_valid', ascending=False)\n",
    "df_filtrado = df_agrupado[(df_agrupado['Accuracy_test']>0.6)].sort_values(by='Accuracy_valid', ascending=False)\n",
    "df_filtrado.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototipação com features de maior correlação com fechamento\n",
    "\n",
    "- Treinamento realizado até 03/2022, avaliação sobre dados de teste de 03/2022 á 06/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 65_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 70_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 75_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_1 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.92it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_2 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 23.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 38.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 39.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_3 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 21.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_4 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 34.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando versão do sentilex = 80_5 - Repetição = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 26.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 27.08it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 29.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 25.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 32.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 31.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 33.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 30.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 28.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 37.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 36.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "df_models_valid = pd.DataFrame()\n",
    "df_models_test = pd.DataFrame()\n",
    "feat = ['combinacao1','combinacao2','combinacao3','combinacao4','combinacao5','combinacao6','neu_robd4','neg_finbertd2','neu_finbertd2','neg_robd4','negatividade_vad','score']\n",
    "\n",
    "\n",
    "#Loop numero de repetições do experimento\n",
    "for rep in range(1):\n",
    "    \n",
    "   ##Loop do dicionário Sentilex Escolhido: \n",
    "    for versao in dict_dados_variacoes_sentilex.keys():\n",
    "        \n",
    "        print(\"Iterando versão do sentilex = {} - Repetição = {}\".format(versao,rep))\n",
    "\n",
    "        df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "        df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "        df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "        #Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "        X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        X_test2 = X_test2[feat]\n",
    "        y_test2 = df_test['Fechamento']\n",
    "\n",
    "        X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        X_train2 = X_train2[feat]\n",
    "        y_train2 = df_train['Fechamento']\n",
    "\n",
    "        X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        X_valid2 = X_valid2[feat]\n",
    "        y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "        #Definindo dados de treino (aprendendo com 70% da amostra de treino)\n",
    "        X_train4, X_descarte, y_train4, y_descarte = train_test_split(X_train2, y_train2, test_size=0.8, random_state=rep, stratify = y_train2)\n",
    "            \n",
    "        #X_train4 = X_train2\n",
    "        #y_train4 = y_train2 \n",
    "        \n",
    "\n",
    "        # Normalizando\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train4)\n",
    "        X_train_norm = scaler.transform(X_train4)\n",
    "        \n",
    "        scaler.fit(X_test2)\n",
    "        X_test_norm = scaler.transform(X_test2)\n",
    "        \n",
    "        scaler.fit(X_valid2)\n",
    "        X_valid_norm = scaler.transform(X_valid2)\n",
    "        \n",
    "        \n",
    "        ########################### Previsao dados validação ###########################\n",
    "        #Treinando e avaliando dados nao normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train4, X_valid2, y_train4, y_valid2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"NAO\"\n",
    "        df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        #Treinando e avaliando dados normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train_norm, X_valid_norm, y_train4, y_valid2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"SIM\"\n",
    "        df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        ########################### Previsao dados teste ###########################\n",
    "                #Treinando e avaliando dados nao normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train4, X_test2, y_train4, y_test2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"NAO\"\n",
    "        df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        #Treinando e avaliando dados normalizados\n",
    "        clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "        models,predictions = clf.fit(X_train_norm, X_test_norm, y_train4, y_test2)\n",
    "        models['n_PCA'] = \"N/A\"\n",
    "        models['versao_sentilex'] = versao\n",
    "        models['Normalizacao'] = \"SIM\"\n",
    "        df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "        \n",
    "        \n",
    "         ## iterar sobre a quantidade de reduções de dimensionalidade das features (PCA) de 2 a 10 reduções\n",
    "        for i in range(2,10,1): \n",
    "\n",
    "            #Aplicando PCA\n",
    "            pca = PCA(n_components=i)\n",
    "            X_train_pca = pca.fit_transform(X_train4)\n",
    "            X_test_pca = pca.fit_transform(X_test2)\n",
    "            X_valid_pca = pca.fit_transform(X_valid2)\n",
    "\n",
    "            #Aplicando Normalização\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            scaler.fit(X_train_pca)\n",
    "            X_train_pca_normalized = scaler.transform(X_train_pca)\n",
    "            \n",
    "            scaler.fit(X_test_pca)\n",
    "            X_test_pca_normalized = scaler.transform(X_test_pca)\n",
    "            \n",
    "            scaler.fit(X_valid_pca)\n",
    "            X_valid_pca_normalized = scaler.transform(X_valid_pca)\n",
    "\n",
    "\n",
    "            ########################### Previsao dados validação ###########################\n",
    "            \n",
    "            #Testando PCA + normalizado \n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca_normalized, X_valid_pca_normalized, y_train4, y_valid2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i\n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"SIM\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True)\n",
    "\n",
    "            #Testando PCA\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca, X_valid_pca, y_train4, y_valid2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i \n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"NAO\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_valid = df_models_valid.append(models.reset_index(), ignore_index=True) \n",
    "            \n",
    "            ########################### Previsao dados teste ###########################\n",
    "            \n",
    "            #Testando PCA + normalizado\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca_normalized, X_test_pca_normalized, y_train4, y_test2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i\n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"SIM\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)\n",
    "\n",
    "            #Testando PCA\n",
    "            reg = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "            models, predictions = reg.fit(X_train_pca, X_test_pca, y_train4, y_test2)\n",
    "            #models['conjunto_features'] = k\n",
    "            models['n_PCA'] = i \n",
    "            models['versao_sentilex'] = versao\n",
    "            models['Normalizacao'] = \"NAO\"\n",
    "            # Armazenando os modelos\n",
    "            df_models_test = df_models_test.append(models.reset_index(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy_valid</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>Acuracia_balanc_test_valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>n_PCA</th>\n",
       "      <th>versao_sentilex</th>\n",
       "      <th>Normalizacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.644172</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.630597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.625767</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.621394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.619632</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.618327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>6</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.625897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N/A</th>\n",
       "      <th>70_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.613497</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.615259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>6</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.644107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CalibratedClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.633468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.609124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.609124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.616695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <th>9</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <th>8</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.606057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.595092</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.616695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.624266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.613627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.613627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTreeClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.634904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.634904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.588957</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.602989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.610560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>7</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.610560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.599922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>6</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>9</th>\n",
       "      <th>70_1</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.596854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <th>4</th>\n",
       "      <th>75_4</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>9</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>5</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.607492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>N/A</th>\n",
       "      <th>70_2</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>7</th>\n",
       "      <th>75_3</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.604425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_5</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.625702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <th>7</th>\n",
       "      <th>75_5</th>\n",
       "      <th>NAO</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <th>9</th>\n",
       "      <th>70_1</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>8</th>\n",
       "      <th>75_4</th>\n",
       "      <th>SIM</th>\n",
       "      <td>0.570552</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Accuracy_valid  \\\n",
       "Model                       n_PCA versao_sentilex Normalizacao                   \n",
       "DecisionTreeClassifier      5     75_5            SIM                 0.644172   \n",
       "LinearSVC                   7     75_5            SIM                 0.625767   \n",
       "LogisticRegression          N/A   70_2            SIM                 0.619632   \n",
       "BaggingClassifier           6     75_5            SIM                 0.613497   \n",
       "LogisticRegression          N/A   70_4            SIM                 0.613497   \n",
       "LinearSVC                   7     75_4            SIM                 0.613497   \n",
       "LogisticRegression          7     75_5            NAO                 0.613497   \n",
       "                            N/A   70_3            SIM                 0.613497   \n",
       "BaggingClassifier           6     75_5            NAO                 0.607362   \n",
       "CalibratedClassifierCV      7     75_5            NAO                 0.607362   \n",
       "                            6     75_4            NAO                 0.601227   \n",
       "NearestCentroid             9     70_2            SIM                 0.601227   \n",
       "RidgeClassifier             9     70_2            SIM                 0.595092   \n",
       "CalibratedClassifierCV      7     75_4            NAO                 0.595092   \n",
       "LGBMClassifier              8     75_3            SIM                 0.595092   \n",
       "RidgeClassifierCV           9     70_2            SIM                 0.595092   \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                 0.595092   \n",
       "Perceptron                  8     75_4            SIM                 0.595092   \n",
       "SGDClassifier               N/A   70_2            SIM                 0.595092   \n",
       "BaggingClassifier           5     75_4            NAO                 0.588957   \n",
       "LinearSVC                   7     75_5            NAO                 0.588957   \n",
       "RidgeClassifierCV           7     75_3            NAO                 0.588957   \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                 0.588957   \n",
       "LogisticRegression          7     75_4            NAO                 0.588957   \n",
       "DecisionTreeClassifier      5     75_5            NAO                 0.588957   \n",
       "                            7     75_3            SIM                 0.588957   \n",
       "LogisticRegression          6     75_3            NAO                 0.588957   \n",
       "BaggingClassifier           7     75_5            NAO                 0.582822   \n",
       "XGBClassifier               8     75_5            SIM                 0.582822   \n",
       "DecisionTreeClassifier      8     75_5            SIM                 0.582822   \n",
       "LinearSVC                   7     75_4            NAO                 0.582822   \n",
       "CalibratedClassifierCV      6     75_3            NAO                 0.582822   \n",
       "LGBMClassifier              8     75_5            NAO                 0.576687   \n",
       "XGBClassifier               8     75_3            SIM                 0.576687   \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                 0.576687   \n",
       "LinearSVC                   6     75_3            NAO                 0.576687   \n",
       "RidgeClassifierCV           9     70_1            SIM                 0.576687   \n",
       "RandomForestClassifier      9     75_4            NAO                 0.576687   \n",
       "LGBMClassifier              8     75_3            NAO                 0.576687   \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                 0.576687   \n",
       "AdaBoostClassifier          9     75_5            SIM                 0.576687   \n",
       "BaggingClassifier           5     75_5            NAO                 0.576687   \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                 0.570552   \n",
       "RidgeClassifier             N/A   70_2            SIM                 0.570552   \n",
       "RidgeClassifierCV           N/A   70_2            SIM                 0.570552   \n",
       "LogisticRegression          7     75_3            NAO                 0.570552   \n",
       "AdaBoostClassifier          8     75_5            SIM                 0.570552   \n",
       "XGBClassifier               7     75_5            NAO                 0.570552   \n",
       "NearestCentroid             9     70_1            SIM                 0.570552   \n",
       "AdaBoostClassifier          8     75_4            SIM                 0.570552   \n",
       "\n",
       "                                                                Accuracy_test  \\\n",
       "Model                       n_PCA versao_sentilex Normalizacao                  \n",
       "DecisionTreeClassifier      5     75_5            SIM                0.617021   \n",
       "LinearSVC                   7     75_5            SIM                0.617021   \n",
       "LogisticRegression          N/A   70_2            SIM                0.617021   \n",
       "BaggingClassifier           6     75_5            SIM                0.617021   \n",
       "LogisticRegression          N/A   70_4            SIM                0.617021   \n",
       "LinearSVC                   7     75_4            SIM                0.617021   \n",
       "LogisticRegression          7     75_5            NAO                0.638298   \n",
       "                            N/A   70_3            SIM                0.617021   \n",
       "BaggingClassifier           6     75_5            NAO                0.680851   \n",
       "CalibratedClassifierCV      7     75_5            NAO                0.659574   \n",
       "                            6     75_4            NAO                0.617021   \n",
       "NearestCentroid             9     70_2            SIM                0.617021   \n",
       "RidgeClassifier             9     70_2            SIM                0.617021   \n",
       "CalibratedClassifierCV      7     75_4            NAO                0.638298   \n",
       "LGBMClassifier              8     75_3            SIM                0.617021   \n",
       "RidgeClassifierCV           9     70_2            SIM                0.617021   \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                0.617021   \n",
       "Perceptron                  8     75_4            SIM                0.617021   \n",
       "SGDClassifier               N/A   70_2            SIM                0.638298   \n",
       "BaggingClassifier           5     75_4            NAO                0.617021   \n",
       "LinearSVC                   7     75_5            NAO                0.659574   \n",
       "RidgeClassifierCV           7     75_3            NAO                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                0.638298   \n",
       "LogisticRegression          7     75_4            NAO                0.638298   \n",
       "DecisionTreeClassifier      5     75_5            NAO                0.680851   \n",
       "                            7     75_3            SIM                0.680851   \n",
       "LogisticRegression          6     75_3            NAO                0.617021   \n",
       "BaggingClassifier           7     75_5            NAO                0.617021   \n",
       "XGBClassifier               8     75_5            SIM                0.638298   \n",
       "DecisionTreeClassifier      8     75_5            SIM                0.617021   \n",
       "LinearSVC                   7     75_4            NAO                0.638298   \n",
       "CalibratedClassifierCV      6     75_3            NAO                0.617021   \n",
       "LGBMClassifier              8     75_5            NAO                0.617021   \n",
       "XGBClassifier               8     75_3            SIM                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                0.617021   \n",
       "LinearSVC                   6     75_3            NAO                0.617021   \n",
       "RidgeClassifierCV           9     70_1            SIM                0.617021   \n",
       "RandomForestClassifier      9     75_4            NAO                0.617021   \n",
       "LGBMClassifier              8     75_3            NAO                0.617021   \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                0.638298   \n",
       "AdaBoostClassifier          9     75_5            SIM                0.638298   \n",
       "BaggingClassifier           5     75_5            NAO                0.638298   \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                0.617021   \n",
       "RidgeClassifier             N/A   70_2            SIM                0.638298   \n",
       "RidgeClassifierCV           N/A   70_2            SIM                0.638298   \n",
       "LogisticRegression          7     75_3            NAO                0.638298   \n",
       "AdaBoostClassifier          8     75_5            SIM                0.680851   \n",
       "XGBClassifier               7     75_5            NAO                0.617021   \n",
       "NearestCentroid             9     70_1            SIM                0.617021   \n",
       "AdaBoostClassifier          8     75_4            SIM                0.617021   \n",
       "\n",
       "                                                                Acuracia_balanc_test_valid  \n",
       "Model                       n_PCA versao_sentilex Normalizacao                              \n",
       "DecisionTreeClassifier      5     75_5            SIM                             0.630597  \n",
       "LinearSVC                   7     75_5            SIM                             0.621394  \n",
       "LogisticRegression          N/A   70_2            SIM                             0.618327  \n",
       "BaggingClassifier           6     75_5            SIM                             0.615259  \n",
       "LogisticRegression          N/A   70_4            SIM                             0.615259  \n",
       "LinearSVC                   7     75_4            SIM                             0.615259  \n",
       "LogisticRegression          7     75_5            NAO                             0.625897  \n",
       "                            N/A   70_3            SIM                             0.615259  \n",
       "BaggingClassifier           6     75_5            NAO                             0.644107  \n",
       "CalibratedClassifierCV      7     75_5            NAO                             0.633468  \n",
       "                            6     75_4            NAO                             0.609124  \n",
       "NearestCentroid             9     70_2            SIM                             0.609124  \n",
       "RidgeClassifier             9     70_2            SIM                             0.606057  \n",
       "CalibratedClassifierCV      7     75_4            NAO                             0.616695  \n",
       "LGBMClassifier              8     75_3            SIM                             0.606057  \n",
       "RidgeClassifierCV           9     70_2            SIM                             0.606057  \n",
       "LinearDiscriminantAnalysis  9     70_2            SIM                             0.606057  \n",
       "Perceptron                  8     75_4            SIM                             0.606057  \n",
       "SGDClassifier               N/A   70_2            SIM                             0.616695  \n",
       "BaggingClassifier           5     75_4            NAO                             0.602989  \n",
       "LinearSVC                   7     75_5            NAO                             0.624266  \n",
       "RidgeClassifierCV           7     75_3            NAO                             0.602989  \n",
       "PassiveAggressiveClassifier 4     75_5            NAO                             0.613627  \n",
       "LogisticRegression          7     75_4            NAO                             0.613627  \n",
       "DecisionTreeClassifier      5     75_5            NAO                             0.634904  \n",
       "                            7     75_3            SIM                             0.634904  \n",
       "LogisticRegression          6     75_3            NAO                             0.602989  \n",
       "BaggingClassifier           7     75_5            NAO                             0.599922  \n",
       "XGBClassifier               8     75_5            SIM                             0.610560  \n",
       "DecisionTreeClassifier      8     75_5            SIM                             0.599922  \n",
       "LinearSVC                   7     75_4            NAO                             0.610560  \n",
       "CalibratedClassifierCV      6     75_3            NAO                             0.599922  \n",
       "LGBMClassifier              8     75_5            NAO                             0.596854  \n",
       "XGBClassifier               8     75_3            SIM                             0.596854  \n",
       "PassiveAggressiveClassifier 4     75_4            SIM                             0.596854  \n",
       "LinearSVC                   6     75_3            NAO                             0.596854  \n",
       "RidgeClassifierCV           9     70_1            SIM                             0.596854  \n",
       "RandomForestClassifier      9     75_4            NAO                             0.596854  \n",
       "LGBMClassifier              8     75_3            NAO                             0.596854  \n",
       "PassiveAggressiveClassifier 4     75_4            NAO                             0.607492  \n",
       "AdaBoostClassifier          9     75_5            SIM                             0.607492  \n",
       "BaggingClassifier           5     75_5            NAO                             0.607492  \n",
       "LinearDiscriminantAnalysis  N/A   70_2            SIM                             0.593787  \n",
       "RidgeClassifier             N/A   70_2            SIM                             0.604425  \n",
       "RidgeClassifierCV           N/A   70_2            SIM                             0.604425  \n",
       "LogisticRegression          7     75_3            NAO                             0.604425  \n",
       "AdaBoostClassifier          8     75_5            SIM                             0.625702  \n",
       "XGBClassifier               7     75_5            NAO                             0.593787  \n",
       "NearestCentroid             9     70_1            SIM                             0.593787  \n",
       "AdaBoostClassifier          8     75_4            SIM                             0.593787  "
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge resultados sobre dados de teste e valid\n",
    "df_prototipacao = pd.merge(left = df_models_valid, right = df_models_test, how = 'left', on = ['Model','n_PCA','versao_sentilex','Normalizacao'], suffixes=('_valid', '_test'))\n",
    "\n",
    "## Calculo da Media acuracia entre teste e valid\n",
    "df_prototipacao['Acuracia_balanc_test_valid'] = (df_prototipacao['Accuracy_valid'] + df_prototipacao['Accuracy_test'])/2\n",
    "\n",
    "\n",
    "## Agrupa os resultados e retorna acuracy_teste > 60 e ordena por acuracy_valid\n",
    "df_agrupado = df_prototipacao.groupby(['Model','n_PCA','versao_sentilex','Normalizacao']).agg({'Accuracy_valid':np.mean, 'Accuracy_test':np.mean, 'Acuracia_balanc_test_valid': np.mean}).sort_values(by='Acuracia_balanc_test_valid', ascending=False)\n",
    "df_filtrado = df_agrupado[(df_agrupado['Accuracy_test']>0.6)].sort_values(by='Accuracy_valid', ascending=False)\n",
    "df_filtrado.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Pré-Candidatos:\n",
    "- LGBM\n",
    "- RandomForestClassifier\n",
    "- LinearSVC\n",
    "- LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O codigo abaixo é responsável por selecionar:\n",
    "\n",
    "    - Melhor dicionário Sentilex\n",
    "    - Melhor conjunto de hiperparâmetros\n",
    "    - Melhor Quantidade de features\n",
    "    - Melhor conjunto de features\n",
    "    - Pipelines com seleção aleatória de features e com SelectFromModel do scikit-learn\n",
    "    - Pipelines com seleção de features por SelectFromModel do scikit-learn\n",
    "    \n",
    "Metodologia:\n",
    "\n",
    "    - Treino -> Dados de teste (2020 e 2021);\n",
    "    - Tuning -> Sobre dados de validação (2020 e 2021);\n",
    "    - Metricas acurácia, recall, precisão -> Sobre dados de validação (2020 e 2021) - (Potencial de generalização)\n",
    "    - Métricas -> Sobre os dados de teste (2022) - (Orientar a escolha do melhor algorítmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 0 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.505781683626272 - AUC Valid = 0.6410256410256411 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 3 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = score,positividade_vadd4,pos_robd2\n",
      "     DADOS TESTE - Recall 0 = 0.46808510638297873 - Recall 1 = 0.5434782608695652 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.5164199814986123 - AUC Valid = 0.632943143812709 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 2 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 3 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = score,positividade_vadd4,pos_robd2\n",
      "     DADOS TESTE - Recall 0 = 0.48936170212765956 - Recall 1 = 0.5434782608695652 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.5596669750231268 - AUC Valid = 0.5334448160535117 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 4 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 3 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neu_robd4,positividade_vad,score\n",
      "     DADOS TESTE - Recall 0 = 0.5106382978723404 - Recall 1 = 0.6086956521739131 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.5709990749306197 - AUC Valid = 0.6819955406911928 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 2 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 5 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = score,positividade_vadd4,neg_robd1,pos_robd2,combinacao1\n",
      "     DADOS TESTE - Recall 0 = 0.46808510638297873 - Recall 1 = 0.6739130434782609 \n",
      "============================================================================================================================\n",
      "Iterando seed = 1 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.5811748381128585 - AUC Valid = 0.5863991081382386 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 4 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 6 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neu_rob,positividade_vad,neu_robd4,scored4,pos_finbertd4,score\n",
      "     DADOS TESTE - Recall 0 = 0.5319148936170213 - Recall 1 = 0.6304347826086957 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6022201665124884 - AUC Valid = 0.6226309921962095 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 10 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = pos_robd2,neg_robd4,positividade_vad,combinacao2,neu_rob,scored4,neg_rob,neu_robd4,neu_robd1,score\n",
      "     DADOS TESTE - Recall 0 = 0.5957446808510638 - Recall 1 = 0.6086956521739131 \n",
      "============================================================================================================================\n",
      "Iterando seed = 2 - Versao sentilex = 70_1\n",
      "Iterando seed = 3 - Versao sentilex = 70_1\n",
      "Iterando seed = 4 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6241905642923219 - AUC Valid = 0.5493311036789297 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 4 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 8 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neu_robd1,neu_rob,scored4,neg_robd4,neutralidade_vadd2,combinacao2,neg_rob,score\n",
      "     DADOS TESTE - Recall 0 = 0.574468085106383 - Recall 1 = 0.6739130434782609 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6345975948196115 - AUC Valid = 0.5629877369007803 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 10 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neu_robd1,scored4,neutralidade_vadd2,pos_robd2,positividade_vad,neg_rob,combinacao2,pos_finbertd4,neg_robd4,score\n",
      "     DADOS TESTE - Recall 0 = 0.6170212765957447 - Recall 1 = 0.6521739130434783 \n",
      "============================================================================================================================\n",
      "Iterando seed = 5 - Versao sentilex = 70_1\n",
      "Iterando seed = 6 - Versao sentilex = 70_1\n",
      "Iterando seed = 7 - Versao sentilex = 70_1\n",
      "Iterando seed = 8 - Versao sentilex = 70_1\n",
      "Iterando seed = 9 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6352913968547642 - AUC Valid = 0.5944816053511706 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 5 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = combinacao2,neutralidade_vadd2,neu_robd4,neu_robd1,score\n",
      "     DADOS TESTE - Recall 0 = 0.5531914893617021 - Recall 1 = 0.717391304347826 \n",
      "============================================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 10 - Versao sentilex = 70_1\n",
      "Iterando seed = 11 - Versao sentilex = 70_1\n",
      "Iterando seed = 12 - Versao sentilex = 70_1\n",
      "Iterando seed = 13 - Versao sentilex = 70_1\n",
      "Iterando seed = 14 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6452358926919519 - AUC Valid = 0.548494983277592 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 5 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = pos_finbertd4,neg_finbertd4,positividade_vad,neg_rob,score\n",
      "     DADOS TESTE - Recall 0 = 0.6382978723404256 - Recall 1 = 0.6521739130434783 \n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6454671600370028 - AUC Valid = 0.5228539576365663 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 6 - tipo_scaler = Sem Scaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 5 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = pos_finbertd4,neg_finbertd4,positividade_vad,neg_rob,score\n",
      "     DADOS TESTE - Recall 0 = 0.6170212765957447 - Recall 1 = 0.6739130434782609 \n",
      "============================================================================================================================\n",
      "Iterando seed = 15 - Versao sentilex = 70_1\n",
      "Iterando seed = 16 - Versao sentilex = 70_1\n",
      "Iterando seed = 17 - Versao sentilex = 70_1\n",
      "Iterando seed = 18 - Versao sentilex = 70_1\n",
      "Iterando seed = 19 - Versao sentilex = 70_1\n",
      "Iterando seed = 20 - Versao sentilex = 70_1\n",
      "Iterando seed = 21 - Versao sentilex = 70_1\n",
      "Iterando seed = 22 - Versao sentilex = 70_1\n",
      "Iterando seed = 23 - Versao sentilex = 70_1\n",
      "Iterando seed = 24 - Versao sentilex = 70_1\n",
      "Iterando seed = 25 - Versao sentilex = 70_1\n",
      "Iterando seed = 26 - Versao sentilex = 70_1\n",
      "Iterando seed = 27 - Versao sentilex = 70_1\n",
      "Iterando seed = 28 - Versao sentilex = 70_1\n",
      "Iterando seed = 29 - Versao sentilex = 70_1\n",
      "Iterando seed = 30 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6558741905642923 - AUC Valid = 0.548494983277592 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neg_finbertd4,neg_rob,positividade_vad,score\n",
      "     DADOS TESTE - Recall 0 = 0.6595744680851063 - Recall 1 = 0.6521739130434783 \n",
      "============================================================================================================================\n",
      "Iterando seed = 31 - Versao sentilex = 70_1\n",
      "Iterando seed = 32 - Versao sentilex = 70_1\n",
      "Iterando seed = 33 - Versao sentilex = 70_1\n",
      "Iterando seed = 34 - Versao sentilex = 70_1\n",
      "Iterando seed = 35 - Versao sentilex = 70_1\n",
      "Iterando seed = 36 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6561054579093432 - AUC Valid = 0.5493311036789297 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 3 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neg_rob,positividade_vad,score\n",
      "     DADOS TESTE - Recall 0 = 0.6382978723404256 - Recall 1 = 0.6739130434782609 \n",
      "============================================================================================================================\n",
      "Iterando seed = 37 - Versao sentilex = 70_1\n",
      "Iterando seed = 38 - Versao sentilex = 70_1\n",
      "Iterando seed = 39 - Versao sentilex = 70_1\n",
      "Iterando seed = 40 - Versao sentilex = 70_1\n",
      "Iterando seed = 41 - Versao sentilex = 70_1\n",
      "Iterando seed = 42 - Versao sentilex = 70_1\n",
      "Iterando seed = 43 - Versao sentilex = 70_1\n",
      "Iterando seed = 44 - Versao sentilex = 70_1\n",
      "Iterando seed = 45 - Versao sentilex = 70_1\n",
      "Iterando seed = 46 - Versao sentilex = 70_1\n",
      "Iterando seed = 47 - Versao sentilex = 70_1\n",
      "Iterando seed = 48 - Versao sentilex = 70_1\n",
      "Iterando seed = 49 - Versao sentilex = 70_1\n",
      "Iterando seed = 50 - Versao sentilex = 70_1\n",
      "Iterando seed = 51 - Versao sentilex = 70_1\n",
      "Iterando seed = 52 - Versao sentilex = 70_1\n",
      "Iterando seed = 53 - Versao sentilex = 70_1\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  LGBM - AUC teste = 0.6785383903792785 - AUC Valid = 0.5702341137123746 -  versão sentilex = 70_1\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 10}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neu_rob,pos_finbertd4,neg_rob,score\n",
      "     DADOS TESTE - Recall 0 = 0.574468085106383 - Recall 1 = 0.782608695652174 \n",
      "============================================================================================================================\n",
      "Iterando seed = 54 - Versao sentilex = 70_1\n",
      "Iterando seed = 55 - Versao sentilex = 70_1\n",
      "Iterando seed = 56 - Versao sentilex = 70_1\n",
      "Iterando seed = 57 - Versao sentilex = 70_1\n",
      "Iterando seed = 58 - Versao sentilex = 70_1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-785-ca527e405131>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m#Fit dados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m#melhores hyperparametros:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "#Classweights testadas no algoritmo\n",
    "#weights = np.linspace(0.2,0.5,10) \n",
    "#weights = np.linspace(0.1,0.9,11)\n",
    "weights = np.linspace(0.1,0.9,5)\n",
    "\n",
    "\n",
    "list_class_weights = []\n",
    "for i in weights:\n",
    "    class_weight = {0: i, 1:1.0-i}\n",
    "    list_class_weights.append(class_weight)\n",
    "list_class_weights\n",
    "\n",
    "## Definição da função de refit no gridsearch acurácia balanceada:\n",
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "roc_score = make_scorer(roc_auc_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados, \"roc\": roc_score }\n",
    "\n",
    "\n",
    "maximo_auc = 0\n",
    "maximo_auc_model1 = 0\n",
    "maximo_auc_model2 = 0\n",
    "\n",
    "\n",
    "#Reset na lista de resultados dos modelos iterados e experimentos rodados.\n",
    "resultados_model1 = []\n",
    "resultados_model2 = []\n",
    "contagem_experimentos_unicos = 0\n",
    "\n",
    "\n",
    "#versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "versoes_sentilex = ['70_1']\n",
    "\n",
    "num_holdouts = 5\n",
    "\n",
    "#Loop de seed aleatória\n",
    "for seed in range(1000):\n",
    "    \n",
    "    #print(\"Iterando seed = {}\".format(seed))  \n",
    "        \n",
    "    ##Loop do dicionário Sentilex Escolhido: \n",
    "    for versao in versoes_sentilex:\n",
    "        print(\"Iterando seed = {} - Versao sentilex = {}\".format(seed,versao))\n",
    "\n",
    "        df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "        df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "        df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "        #Separando os dados (é a mesma separação definida previamente na etapa 8 - independe da aleatoriedade da seed)\n",
    "        X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_test2 = df_test['Fechamento']\n",
    "\n",
    "        X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_train2 = df_train['Fechamento']\n",
    "\n",
    "        X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Alteração nome das variáveis (Aqui aplicaria-se um balanceamento mas não é necessário)\n",
    "        X_train3 = X_train2\n",
    "        y_train3 = y_train2\n",
    "        \n",
    "        \n",
    "        ## Renomeando as variáveis para ficar com mesmo índice de X_train\n",
    "        X_test3 = X_test2\n",
    "        y_test3 = y_test2\n",
    "        \n",
    "        X_valid3 = X_valid2\n",
    "        y_valid3 = y_valid2\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ################ Definição de modelos candidatos ################\n",
    "        #model1 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "        model2 = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "        #models = [model1,model2]\n",
    "        #nome_modelo = ['RandomForest', 'LGBM']\n",
    "\n",
    "        #models = [model1]\n",
    "        #nome_modelo = ['RandomForest']\n",
    "\n",
    "        models = [model2]\n",
    "        nome_modelo = ['LGBM']\n",
    "\n",
    "        \n",
    "        \n",
    "        ################ Definindo conjunto de treino + validacao para tunar o modelo avaliando nos dados de validação ################\n",
    "        ## Concatenando dados de treino e valid:\n",
    "        X_train_valid = pd.concat([X_train3, X_valid3], ignore_index = True )\n",
    "        y_train_valid = pd.concat([y_train3, y_valid3], ignore_index = True )\n",
    "\n",
    "\n",
    "        # The indices which have the value -1 will be kept in train.\n",
    "        train_indices = np.full((X_train3.shape[0],), -1, dtype=int)\n",
    "\n",
    "        # The indices which have zero or positive values, will be kept in valid\n",
    "        valid_indices = np.full((X_valid3.shape[0],), 0, dtype=int)\n",
    "        valid_fold = np.append(train_indices, valid_indices)\n",
    "\n",
    "        # definindo o conjunto de validação\n",
    "        ps = PredefinedSplit(valid_fold)\n",
    "\n",
    "\n",
    "        ############################# Paramgrid de modelos ###############################\n",
    "\n",
    "        ##Grid model 1 RandomForest\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2,3,5,8,12], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[3], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20,40], \"min_samples_split\":[2,3,5,10,20], \"min_samples_leaf\":[1,3,5,10], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2], \"min_samples_leaf\":[1], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "        \n",
    "        ##Grid model 2 LGBM\n",
    "        \n",
    "        param_grid2={\"max_depth\":[-1,10,20], \"learning_rate\":[0.1,0.01,0.001], \"n_estimators\":[100,50,200], \"num_leaves\":[31,5,10,50]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[250,300,400], \"num_leaves\":[2,5,8,12,16,20]}\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1,0.01], \"n_estimators\":[70,100,150,200], \"num_leaves\":[31,10,25,50,80,120]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'boosting_type': ['gbdt', 'dart', 'goss', 'rf'] }\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1], \"n_estimators\":[150,200], \"num_leaves\":[31,10,25], 'class_weight': list_class_weights}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'class_weight': list_class_weights }\n",
    "\n",
    "        #list_param_grids = [param_grid1, param_grid2]\n",
    "        #list_param_grids = [param_grid1]\n",
    "        list_param_grids = [param_grid2]\n",
    "        \n",
    "        dictionary_paramgrid = dict(zip(models, list_param_grids))\n",
    "\n",
    "       \n",
    "        #Loop modelos\n",
    "        for num_modelo, model in enumerate(models):\n",
    "\n",
    "            nome_modelo_testado = nome_modelo[num_modelo]\n",
    "\n",
    "            param_grid = dictionary_paramgrid[model]\n",
    "\n",
    "            ############################ GridSearch de modelos candidatos com todas features ###############################\n",
    "            gs = GridSearchCV(model , param_grid=param_grid, scoring=scoring,  refit=\"f1\", n_jobs=-1, cv = ps )\n",
    "                       \n",
    "            #Fit dados \n",
    "            gs.fit(X_train_valid,y_train_valid)\n",
    "        \n",
    "            #melhores hyperparametros:\n",
    "            hyperparametros = list(gs.best_params_.values())\n",
    "            nome_hyperparametros = list(gs.best_params_.keys())\n",
    "\n",
    "\n",
    "            #melhor modelo\n",
    "            # CUIDADO: O atributo best_estimator_ retorna o melhor modelo ja treinado com o conjunto de dados\n",
    "            # passado pelo metodo gs.fit(), ou seja ja vem treinado com X_train_valid,y_train_valid, sendo, portanto\n",
    "            # necessário mais uma etapa de fit() do modelo tunado apenas com dados de treino.\n",
    "            modelo_tunado = gs.best_estimator_\n",
    "\n",
    "            # Refit no modelo tunado com apenas dados de treino para evitar superestimar os scores ao avaliar sobre dados de valid\n",
    "            modelo_tunado.fit(X_train3,y_train3)\n",
    "\n",
    "\n",
    "\n",
    "            #Loop Seletor de features:\n",
    "            #for k in range(X_train3.shape[1], X_train3.shape[1]+1, 1):  ## Iterar sobre n total de features e n (n = max)\n",
    "            #for k in range(4,5, 1):  ## Iterar sobre 4 á 4 features\n",
    "            for k in range(3,11, 1):  ## Iterar sobre 3 á 10 features\n",
    "                \n",
    "                #############################  Seletor aleatório features  ############################\n",
    "                \n",
    "                #selected = np.random.choice(X_train3.columns, k, replace=False)\n",
    "                #selected = np.random.choice(X_train3.columns, k-1, replace=False)  ### Seleciona k-1 feature e adiciona a feature 'Score'\n",
    "                #selected = np.append(selected, 'score')\n",
    "                \n",
    "                pre_selected = ['neg_rob','neu_rob','pos_robd2','combinacao5','neg_robd4','scored4','neu_robd1','pos_finbertd4','combinacao2','neu_robd4','neg_finbertd4','positividade_vad','neutralidade_vadd2']\n",
    "                selected = np.random.choice(pre_selected, k-1, replace=False)\n",
    "                selected = np.append(selected, 'score')\n",
    "                \n",
    "                #selected = np.random.choice(X_train3.columns, k, replace=False)\n",
    "                #selected = ['pos_rob','neutralidade_vadd4','pos_robd1','score']\n",
    "                                                             \n",
    "                #lista_auc_valid = []\n",
    "                #lista_auc_teste = []\n",
    "                \n",
    "                #dict_scores_pipes = {}\n",
    "                #dict_scores_pipes[0] = [[],[]]\n",
    "                #dict_scores_pipes[1] = [[],[]]\n",
    "                #dict_scores_pipes[2] = [[],[]]\n",
    "                #dict_scores_pipes[3] = [[],[]]\n",
    "                #dict_scores_pipes[4] = [[],[]]\n",
    "                #dict_scores_pipes[5] = [[],[]]\n",
    "                \n",
    "                \n",
    "                #Loop Holdout selecionar aleatoriamente 80% dados de treino para alimentar o modelo e a pipe.\n",
    "                #for qtde_holdout in range(1,num_holdouts+1):\n",
    "                    \n",
    "                    #seed_holdout = random.randint(0,9999)\n",
    "                    #X_train4, X_descarte, y_train4, y_descarte = train_test_split(X_train3, y_train3, test_size=0.8, random_state=seed_holdout, stratify=y_train3)\n",
    "                    \n",
    "                    \n",
    "                ##Renomeando as variáveis para ficar com mesmo índice do X_train\n",
    "                X_train4 = X_train3\n",
    "                y_train4 = y_train3\n",
    "                \n",
    "                X_test4 = X_test3\n",
    "                y_test4 = y_test3\n",
    "\n",
    "                X_valid4 = X_valid3\n",
    "                y_valid4 = y_valid3\n",
    "\n",
    "\n",
    "                #Fit do modelo aos 80% dos dados de treino selecionados pelo holdout aleatório\n",
    "                modelo_tunado.fit(X_train4, y_train4)\n",
    "\n",
    "                #modelo_tunado_seletorK = modelo_tunado\n",
    "                #modelo_tunado_seletor_aleatorio = modelo_tunado\n",
    "                #modelo_tunado_seletorK.fit(X_train4,y_train4)   \n",
    "                #modelo_tunado_seletor_aleatorio.fit(X_train4,y_train4)\n",
    "\n",
    "                ################ Definição de Pipelines com modelo tunado ################\n",
    "\n",
    "                ##Com Seletor K\n",
    "                pipe1 = Pipeline([('scaler', StandardScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe2 = Pipeline([('scaler', MinMaxScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe3 = Pipeline([('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "\n",
    "                \n",
    "                ## Com seletor aleatorio\n",
    "                pipe4 = Pipeline([('scaler', StandardScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe5 = Pipeline([('scaler', MinMaxScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe6 = Pipeline([(nome_modelo_testado, modelo_tunado)])\n",
    "                \n",
    "                ## Com PCA\n",
    "                pipe7 = Pipeline([('PCA', PCA(n_components=k)),('scaler', StandardScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe8 = Pipeline([('PCA', PCA(n_components=k)),('scaler', MinMaxScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe9 = Pipeline([('PCA', PCA(n_components=k)),(nome_modelo_testado, modelo_tunado)])\n",
    "                \n",
    "\n",
    "\n",
    "                #pipelines = [pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,pipe8,pipe9]\n",
    "                pipelines = [pipe1,pipe2,pipe3,pipe4,pipe5,pipe6]\n",
    "\n",
    "\n",
    "                #Loop das pipelines testadas com seletor de features e outras etapas:\n",
    "                for num_pipe, pipe in enumerate(pipelines):\n",
    "\n",
    "                    # features aleatorias aplicado ao  PIPE4 á PIPE6\n",
    "                    if num_pipe in [3,4,5]:\n",
    "\n",
    "                        X_train5 = X_train4[selected]\n",
    "                        y_train5 = y_train4\n",
    "\n",
    "                        X_valid5 = X_valid4[selected]\n",
    "\n",
    "                        X_test5 = X_test4[selected]\n",
    "\n",
    "                        ## Nome das features selecionadas aleatoriamente\n",
    "                        features_selecionadas = ','.join(list(selected))\n",
    "\n",
    "\n",
    "                    if num_pipe in [0,1,2]:\n",
    "                    \n",
    "                        X_train5 = X_train4\n",
    "                        y_train5 = y_train4\n",
    "\n",
    "                        X_valid5 = X_valid4\n",
    "                        y_valid5 = y_valid4\n",
    "\n",
    "                        X_test5 = X_test4\n",
    "                        y_test5 = y_test4\n",
    "\n",
    "                        ## Nome das features selecionadas pelo SelectFromModel\n",
    "                        selector = SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)\n",
    "                        selector.fit(X_train5,y_train5)\n",
    "                        mask = selector.get_support()\n",
    "                        features_selecionadas = ','.join(list(X_train5.columns[mask]))\n",
    "\n",
    "                    if num_pipe in [6,7,8]:\n",
    "                        \n",
    "                        X_train5 = X_train4\n",
    "                        y_train5 = y_train4\n",
    "\n",
    "                        X_valid5 = X_valid4\n",
    "                        y_valid5 = y_valid4\n",
    "\n",
    "                        X_test5 = X_test4\n",
    "                        y_test5 = y_test4\n",
    "                        \n",
    "                        features_selecionadas = \"Aplicado PCA\"\n",
    "                        \n",
    "                    ############################ Fit Pipeline #################\n",
    "\n",
    "                    pipe.fit(X_train5,y_train5)\n",
    "\n",
    "\n",
    "                    #Armazenando propriedades das PIPES\n",
    "                    if num_pipe == 0:\n",
    "                        seletor_feature = \"SelectFromModel\"\n",
    "                        scaler = \"StandardScaler\"\n",
    "\n",
    "                    if num_pipe == 1:\n",
    "                        seletor_feature = \"SelectFromModel\"\n",
    "                        scaler = \"MinMax\"\n",
    "\n",
    "                    if num_pipe == 2:\n",
    "                        seletor_feature = 'SelectFromModel'\n",
    "                        scaler = \"Sem Scaler\"\n",
    "\n",
    "                    if num_pipe == 3:\n",
    "                    #if num_pipe == 0:\n",
    "                        seletor_feature = \"Aleatorio\"\n",
    "                        scaler = \"StandardScaler\"\n",
    "\n",
    "                    if num_pipe == 4:\n",
    "                        seletor_feature = \"Aleatorio\"\n",
    "                        scaler = \"MinMax\"\n",
    "\n",
    "                    if num_pipe == 5:\n",
    "                        seletor_feature = \"Aleatorio\"\n",
    "                        scaler = \"Sem Scaler\"\n",
    "                        \n",
    "                    if num_pipe == 6:\n",
    "                        seletor_feature = \"PCA\"\n",
    "                        scaler = \"StandardScaler\"\n",
    "                        \n",
    "                    if num_pipe == 7:\n",
    "                        seletor_feature = \"PCA\"\n",
    "                        scaler = \"MinMax\"\n",
    "                        \n",
    "                    if num_pipe == 8:\n",
    "                        seletor_feature = \"PCA\"\n",
    "                        scaler = \"Sem Scaler\"\n",
    "                        \n",
    "                    ################ Calculando métricas da pipe DADOS NÃO VISTOS - 2022 - TESTE ################\n",
    "                    ################ DADOS DE TESTE\n",
    "\n",
    "                    # Fazendo predição\n",
    "                    p = pipe.predict(X_test5)\n",
    "\n",
    "                    contagem_experimentos_unicos = contagem_experimentos_unicos + 1\n",
    "\n",
    "                    #Calculando o recall\n",
    "                    recall_0 = recall_score(y_test5, p, pos_label=0)\n",
    "                    recall_1 = recall_score(y_test5, p, pos_label=1)\n",
    "\n",
    "                    #Calculando Precision\n",
    "                    precision_0 = precision_score(y_test5, p, pos_label = 0)\n",
    "                    precision_1 = precision_score(y_test5, p, pos_label = 1)\n",
    "\n",
    "                    #Calculando acurácia\n",
    "                    accuracy = accuracy_score(y_test5, p)\n",
    "\n",
    "                    #Calculando AUC\n",
    "                    auc = roc_auc_score(y_test5, p)\n",
    "\n",
    "\n",
    "\n",
    "                    ################ Calculando métricas da pipe DADOS NÃO VISTOS, subamostragem dos dados de treino ################\n",
    "                    ################ 2020 e 2021 - DADOS DE VALIDACAO\n",
    "\n",
    "                    # Fazendo predição\n",
    "                    p = pipe.predict(X_valid5)\n",
    "\n",
    "                    #Calculando o recall\n",
    "                    recall_0_valid = recall_score(y_valid5, p, pos_label=0)\n",
    "                    recall_1_valid = recall_score(y_valid5, p, pos_label=1)\n",
    "\n",
    "                    #Calculando Precision\n",
    "                    precision_0_valid = precision_score(y_valid5, p, pos_label = 0)\n",
    "                    precision_1_valid = precision_score(y_valid5, p, pos_label = 1)\n",
    "\n",
    "                    #Calculando acurácia\n",
    "                    accuracy_valid = accuracy_score(y_valid5, p)\n",
    "\n",
    "                    #Calculando AUC\n",
    "                    auc_valid = roc_auc_score(y_valid5, p)\n",
    "\n",
    "\n",
    "                    ##Media AUC valid e AUC teste\n",
    "                    auc_valid_teste = (auc + auc_valid) / 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ################ Calculo AUC medio por pipe sobre a totalidade dos holdouts ################\n",
    "\n",
    "                    #resultados_parciais_teste = dict_scores_pipes[num_pipe][0]\n",
    "                    #resultados_parciais_valid = dict_scores_pipes[num_pipe][1]\n",
    "\n",
    "                    #resultados_parciais_teste.append(auc)\n",
    "                    #resultados_parciais_valid.append(auc_valid)\n",
    "\n",
    "                    #dict_scores_pipes[num_pipe] = [resultados_parciais_teste,resultados_parciais_valid]\n",
    "\n",
    "                    #metrica = 0\n",
    "                    auc_teste_medio = 0\n",
    "                    auc_valid_medio = 0\n",
    "\n",
    "                    ## Apenas quando a pipeline estiver rodado os 5 holdouts calcular os resultados das medias\n",
    "                    #if len(resultados_parciais_teste)==num_holdouts:\n",
    "\n",
    "                        #array_auc = np.array(resultados_parciais_teste)\n",
    "                        #array_auc_valid = np.array(resultados_parciais_valid)\n",
    "\n",
    "                        #auc_teste_medio = array_auc.mean()\n",
    "                        #auc_valid_medio = array_auc_valid.mean()\n",
    "\n",
    "                        #metrica = auc_teste_medio - auc_valid_medio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                   ################ Armazenando e imprimindo os resultados  ################\n",
    "\n",
    "                    dictionary_hyperparams = dict(zip(nome_hyperparametros, hyperparametros))\n",
    "\n",
    "                    if num_modelo ==0:\n",
    "\n",
    "                        #col_names_modelo1 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features','seed_holdout', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc','auc_valid']\n",
    "                        col_names_modelo1 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc','auc_valid','auc_valid_teste']                             \n",
    "                        resultados_model1.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, accuracy, recall_0, recall_1, precision_0, precision_1, auc, auc_valid ]))\n",
    "\n",
    "\n",
    "                        ## Imprime resultados do melhor modelo 1                                \n",
    "                        #if auc > maximo_auc_model1:\n",
    "                        #if auc > 0.6:\n",
    "\n",
    "\n",
    "                            #print(\"============================================================================================================================\")\n",
    "                            #print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC Valid = {} - AUC Teste - {} - num_seed_aleatoria = {} - versao_sentilex = {} - num_seed_holdout = {}\".format(nome_modelo_testado, auc_valid, auc, seed, versao,seed_holdout))\n",
    "                            #print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                \n",
    "                            #print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                            #print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                            #print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                            #print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                            #print(\"\")\n",
    "                            #print(\"============================================================================================================================\")\n",
    "\n",
    "                        #melhor_modelo1 = pipe\n",
    "                        #maximo_auc_model1 = auc\n",
    "\n",
    "                    #if num_modelo ==1:\n",
    "\n",
    "                        #col_names_modelo2 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                        #resultados_model2.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "\n",
    "                        ## Imprime resultados do melhor modelo 2\n",
    "                        #if auc > maximo_auc_model2:\n",
    "\n",
    "                            #print(\"============================================================================================================================\")\n",
    "                            #print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado, auc, seed, versao))\n",
    "                            #print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                        \n",
    "                            #print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                            #print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                            #print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                            #print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                            #print(\"\")\n",
    "                            #print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "                        #melhor_modelo2 = pipe\n",
    "                        #maximo_auc_model2 = auc\n",
    "\n",
    "\n",
    "\n",
    "                    ################ Imprime resultados do melhor modelo global até o momento. ################\n",
    "                        # Armazenar modelo que:\n",
    "                        # 1) generaliza bem (AUC_VALID alto) e\n",
    "                        # 2) Performa bem dados de producao (AUC_TESTE alto)\n",
    "                        # 3) Não há disparidade entre AUC's\n",
    "                       ## AUC teste pode ser inferior a AUC validação, contanto que seja alto\n",
    "                      ### mas nao pode ser MUITO maior que AUC validação (Limite máximo tolerado = +7%)\n",
    "\n",
    "                    #limite_maximo_tolerado = 0.07\n",
    "\n",
    "                    #if auc_teste_medio > maximo_auc:\n",
    "                    if auc > maximo_auc:\n",
    "\n",
    "                        #if metrica < 0 or metrica > limite_maximo_tolerado:\n",
    "                            print(\"============================================================================================================================\")\n",
    "                            print(\"MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  {} - AUC teste = {} - AUC Valid = {} -  versão sentilex = {}\".format(nome_modelo_testado, auc, auc_valid, versao))                   \n",
    "                            print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                            print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                            print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                            print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                            print(\"     DADOS TESTE - Recall 0 = {} - Recall 1 = {} \".format(recall_0,recall_1))\n",
    "                            print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "                            melhor_modelo = pipe\n",
    "                            maximo_auc = auc\n",
    "                            best_seed = seed\n",
    "\n",
    "                    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2784, 17), indices imply (2784, 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1653\u001b[0m                 blocks = [\n\u001b[1;32m-> 1654\u001b[1;33m                     \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m                 ]\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3053\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m   2600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2601\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 17, placement implies 18",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-787-3cf39fdeaadd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Transformando resultados em dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresultados_df_model1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultados_model1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_names_modelo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mresultados_df_model1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresultados_df_model1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1662\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1664\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1694\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2784, 17), indices imply (2784, 18)"
     ]
    }
   ],
   "source": [
    "####### Resultados Modelo 1: LGBM\n",
    "\n",
    "## Configurando Numero de caracteres para visualização do dataframe\n",
    "pd.set_option('display.precision',5)\n",
    "pd.reset_option('^display.',silent=True)\n",
    "\n",
    "# Transformando resultados em dataframe\n",
    "resultados_df_model1 = pd.DataFrame(np.array(resultados_model1), columns=col_names_modelo1)\n",
    "resultados_df_model1['auc'] = resultados_df_model1['auc'].astype(float, errors = 'raise')\n",
    "\n",
    "## Criando dicionário com os tipos de dados dos parâmetros e das métricas\n",
    "import itertools\n",
    "\n",
    "col_metricas = col_names_modelo1[10:]\n",
    "dict_metrics_types = dict.fromkeys(col_metricas , 'float')\n",
    "\n",
    "col_params = col_names_modelo1[:10]\n",
    "dict_params_types = dict.fromkeys(col_params , 'str')\n",
    "\n",
    "dict_data_types = itertools.chain(dict_params_types.items(),dict_metrics_types.items())\n",
    "dict_data_types = dict(dict_data_types)\n",
    "dict_data_types\n",
    "\n",
    "group_by_list = col_names_modelo1[2:10]\n",
    "\n",
    "## Agrupando por hiperparâmetros e ordenando pelas métricas\n",
    "df_agrupado = resultados_df_model1.astype(dict_data_types).groupby(group_by_list).agg({'contagem_exp': 'nunique', 'acuracia':np.mean, 'recall_0':np.mean, 'recall_1':np.mean, 'prec_0':np.mean, 'prec_1':np.mean, 'auc':np.mean, 'auc_valid': np.mean})\n",
    "df_agrupado['media_auc_valid_teste'] = (df_agrupado['auc'] + df_agrupado['auc_valid']) /2\n",
    "df_agrupado = df_agrupado.sort_values(by='media_auc_valid_teste', ascending=False)\n",
    "df_agrupado[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armazenamento candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Candidatos:\n",
    "#df_agrupado[51:52]\n",
    "#df_agrupado[76:77]\n",
    "#df_agrupado[127:128]\n",
    "#df_agrupado[139:140]\n",
    "#df_agrupado[199:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "      <th>media_auc_valid_teste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>70_3</td>\n",
       "      <td>5</td>\n",
       "      <td>score,neutralidade_vadd1,pos_robd2,combinacao5...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.622572</td>\n",
       "      <td>0.658027</td>\n",
       "      <td>0.640299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>70_1</td>\n",
       "      <td>6</td>\n",
       "      <td>neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.636302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>70_1</td>\n",
       "      <td>4</td>\n",
       "      <td>neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.633904</td>\n",
       "      <td>0.627369</td>\n",
       "      <td>0.630636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>70_1</td>\n",
       "      <td>5</td>\n",
       "      <td>neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.623728</td>\n",
       "      <td>0.632943</td>\n",
       "      <td>0.628336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>70_4</td>\n",
       "      <td>4</td>\n",
       "      <td>composicao_vadd4,negatividade_vad,neutralidade...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.611702</td>\n",
       "      <td>0.624303</td>\n",
       "      <td>0.618003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  learning_rate max_depth n_estimators num_leaves modelo Sentilex num_pipe  \\\n",
       "0         0.001        -1          100         10   LGBM     70_3        5   \n",
       "1           0.1        -1          200         10   LGBM     70_1        6   \n",
       "2           0.1        -1          200         10   LGBM     70_1        4   \n",
       "3           0.1        -1          200         10   LGBM     70_1        5   \n",
       "4          0.01        -1          100          5   LGBM     70_4        4   \n",
       "\n",
       "                                            features  contagem_exp  acuracia  \\\n",
       "0  score,neutralidade_vadd1,pos_robd2,combinacao5...             1  0.623656   \n",
       "1  neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...             1  0.645161   \n",
       "2  neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...             1  0.634409   \n",
       "3  neg_rob,neu_robd1,pos_finbertd4,combinacao2,sc...             1  0.623656   \n",
       "4  composicao_vadd4,negatividade_vad,neutralidade...             1  0.612903   \n",
       "\n",
       "   recall_0  recall_1    prec_0    prec_1       auc  auc_valid  \\\n",
       "0  0.723404  0.521739  0.607143  0.648649  0.622572   0.658027   \n",
       "1  0.638298  0.652174  0.652174  0.638298  0.645236   0.627369   \n",
       "2  0.680851  0.586957  0.627451  0.642857  0.633904   0.627369   \n",
       "3  0.617021  0.630435  0.630435  0.617021  0.623728   0.632943   \n",
       "4  0.723404  0.500000  0.596491  0.638889  0.611702   0.624303   \n",
       "\n",
       "   media_auc_valid_teste  \n",
       "0               0.640299  \n",
       "1               0.636302  \n",
       "2               0.630636  \n",
       "3               0.628336  \n",
       "4               0.618003  "
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_lgbm_candidatos = pd.DataFrame()\n",
    "#df_lgbm_candidatos = df_lgbm_candidatos.append(df_agrupado[51:52].reset_index(), ignore_index=True)\n",
    "#df_lgbm_candidatos = df_lgbm_candidatos.append(df_agrupado[76:77].reset_index(), ignore_index=True)\n",
    "#df_lgbm_candidatos = df_lgbm_candidatos.append(df_agrupado[127:128].reset_index(), ignore_index=True)\n",
    "#df_lgbm_candidatos = df_lgbm_candidatos.append(df_agrupado[139:140].reset_index(), ignore_index=True)\n",
    "#df_lgbm_candidatos = df_lgbm_candidatos.append(df_agrupado[199:200].reset_index(), ignore_index=True)\n",
    "df_lgbm_candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg_rob,neu_robd1,pos_finbertd4,combinacao2,score,neu_robd4,neg_finbertd4,neu_rob,positividade_vad,neutralidade_vadd2'"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgbm_candidatos.features[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['score','neg_rob','neu_rob','pos_robd2','combinacao5','neg_robd4','scored4','neu_robd1','pos_finbertd4','combinacao2','','neu_robd4','neg_finbertd4','positividade_vad','neutralidade_vadd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm_candidatos.to_csv('candidatos_lgbm',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.0 Experimentos RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O codigo abaixo é responsável por selecionar:\n",
    "    - Fator de balanceamento nos dados de treino\n",
    "    - Tecnica de balanceamento nos dados de treino\n",
    "    - Melhor Quantidade de features\n",
    "    - Melhor conjunto de features\n",
    "    - Pipelines com normalização\n",
    "    - Pipelines sem normalização\n",
    "    - Pipelines com seleção aleatória de features e com SelectFromModel do scikit-learn\n",
    "    - Melhor conjunto de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 0 - Versao sentilex = 80_2\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.5897993311036789 - AUC Teste medio 5 repeticoes = 0.460777058279371 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = subjetividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd2,negatividade_vadd3,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neu_robd1,neu_robd3,pos_robd2,pos_robd3,pos_robd4,pos_finbertd1,neu_finbertd2\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.5910813823857302 - AUC Teste medio 5 repeticoes = 0.4651248843663275 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 2 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = subjetividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd2,negatividade_vadd3,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neu_robd1,neu_robd3,pos_robd2,pos_robd3,pos_robd4,pos_finbertd1,neu_finbertd2\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.5928651059085841 - AUC Teste medio 5 repeticoes = 0.4785846438482886 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 4 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = pos_finbertd4,negatividade_vadd2,neutralidade_vadd4,scored4,pos_robd3,subjetividade_vad,negatividade_vadd1,neu_finbertd2,scored2,positividade_vadd1,subjetividade_vadd4,neu_robd1,polaridade_vadd4,neg_finbertd2,pos_robd2,pos_robd4,neutralidade_vadd1,negatividade_vad,neg_robd4,neg_finbertd3,positividade_vadd2,neg_robd3,polaridade_vadd3,score,neg_rob,neu_finbertd1,pos_robd1,score\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.5941471571906354 - AUC Teste medio 5 repeticoes = 0.48080481036077705 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = pos_finbertd4,negatividade_vadd2,neutralidade_vadd4,scored4,pos_robd3,subjetividade_vad,negatividade_vadd1,neu_finbertd2,scored2,positividade_vadd1,subjetividade_vadd4,neu_robd1,polaridade_vadd4,neg_finbertd2,pos_robd2,pos_robd4,neutralidade_vadd1,negatividade_vad,neg_robd4,neg_finbertd3,positividade_vadd2,neg_robd3,polaridade_vadd3,score,neg_rob,neu_finbertd1,pos_robd1,score\n",
      "\n",
      "============================================================================================================================\n",
      "Iterando seed = 1 - Versao sentilex = 80_2\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.612263099219621 - AUC Teste medio 5 repeticoes = 0.5195189639222941 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = polaridade_vad,subjetividade_vad,neutralidade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd3,polaridade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd1,composicao_vadd1,composicao_vadd2,composicao_vadd3,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd2,neu_finbertd3\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.6162764771460423 - AUC Teste medio 5 repeticoes = 0.5217391304347826 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 2 - tipo_scaler = MinMax\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.7000000000000001, 1: 0.29999999999999993}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = polaridade_vad,subjetividade_vad,neutralidade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd3,polaridade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd1,composicao_vadd1,composicao_vadd2,composicao_vadd3,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd2,neu_finbertd3\n",
      "\n",
      "============================================================================================================================\n",
      "Iterando seed = 2 - Versao sentilex = 80_2\n",
      "Iterando seed = 3 - Versao sentilex = 80_2\n",
      "Iterando seed = 4 - Versao sentilex = 80_2\n",
      "Iterando seed = 5 - Versao sentilex = 80_2\n",
      "Iterando seed = 6 - Versao sentilex = 80_2\n",
      "Iterando seed = 7 - Versao sentilex = 80_2\n",
      "Iterando seed = 8 - Versao sentilex = 80_2\n",
      "Iterando seed = 9 - Versao sentilex = 80_2\n",
      "Iterando seed = 10 - Versao sentilex = 80_2\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  RandomForest - AUC Valid medio 5 repeticoes = 0.6157748049052396 - AUC Teste medio 5 repeticoes = 0.531313598519889 -  versão sentilex = 80_2\n",
      "     Características pipeline: num_pipeline = 4 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.5, 1: 0.5}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 28 - metodo_selecao_features = Aleatorio\n",
      "     Features Selecionadas = neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score\n",
      "\n",
      "============================================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 11 - Versao sentilex = 80_2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-15edcb9d3091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                         \u001b[1;31m#pipe.fit(X_train4,y_train4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                         \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "#Classweights testadas no algoritmo\n",
    "#weights = np.linspace(0.2,0.5,10) \n",
    "#weights = np.linspace(0.1,0.9,11)\n",
    "weights = np.linspace(0.1,0.9,5)\n",
    "\n",
    "\n",
    "list_class_weights = []\n",
    "for i in weights:\n",
    "    class_weight = {0: i, 1:1.0-i}\n",
    "    list_class_weights.append(class_weight)\n",
    "list_class_weights\n",
    "\n",
    "## Definição da função de refit no gridsearch acurácia balanceada:\n",
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "roc_score = make_scorer(roc_auc_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados, \"roc\": roc_score }\n",
    "\n",
    "\n",
    "maximo_auc = 0\n",
    "maximo_auc_model1 = 0\n",
    "maximo_auc_model2 = 0\n",
    "\n",
    "\n",
    "#Reset na lista de resultados dos modelos iterados e experimentos rodados.\n",
    "resultados_model1 = []\n",
    "resultados_model2 = []\n",
    "contagem_experimentos_unicos = 0\n",
    "\n",
    "\n",
    "#versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "versoes_sentilex = ['80_2']\n",
    "\n",
    "num_holdouts = 5\n",
    "\n",
    "#Loop de seed aleatória\n",
    "for seed in range(1000):\n",
    "    \n",
    "    #print(\"Iterando seed = {}\".format(seed))  \n",
    "        \n",
    "    ##Loop do dicionário Sentilex Escolhido: \n",
    "    for versao in versoes_sentilex:\n",
    "        print(\"Iterando seed = {} - Versao sentilex = {}\".format(seed,versao))\n",
    "\n",
    "        df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "        df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "        df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "        #Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "        X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_test2 = df_test['Fechamento']\n",
    "\n",
    "        X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_train2 = df_train['Fechamento']\n",
    "\n",
    "        X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Na há balanceamento, portanto, para evitar mudar X_train3 para X_train2 em todo código iremos usar as variáveis:\n",
    "        X_test3 = X_test2\n",
    "        y_test3 = y_test2\n",
    "\n",
    "        X_train3 = X_train2\n",
    "        y_train3 = y_train2\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ################ Definição de modelos candidatos ################\n",
    "        model1 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "        #model2 = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "        #models = [model1,model2]\n",
    "        #nome_modelo = ['RandomForest', 'LGBM']\n",
    "\n",
    "        models = [model1]\n",
    "        nome_modelo = ['RandomForest']\n",
    "\n",
    "        #models = [model2]\n",
    "        #nome_modelo = ['LGBM']\n",
    "\n",
    "        \n",
    "        \n",
    "        ################ Definindo conjunto de treino + validacao para avaliar gridsearch nos dados de avaliação ################\n",
    "        ## Concatenando dados de treino e valid:\n",
    "        X_train_valid = pd.concat([X_train3, X_valid2], ignore_index = True )\n",
    "        y_train_valid = pd.concat([y_train3, y_valid2], ignore_index = True )\n",
    "\n",
    "\n",
    "        # The indices which have the value -1 will be kept in train.\n",
    "        train_indices = np.full((X_train3.shape[0],), -1, dtype=int)\n",
    "\n",
    "        # The indices which have zero or positive values, will be kept in valid\n",
    "        valid_indices = np.full((X_valid2.shape[0],), 0, dtype=int)\n",
    "        valid_fold = np.append(train_indices, valid_indices)\n",
    "\n",
    "        # definindo o conjunto de validação\n",
    "        ps = PredefinedSplit(valid_fold)\n",
    "\n",
    "\n",
    "        ############# Paramgrid de modelos ################\n",
    "\n",
    "        ##Grid model 1 RandomForest\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2,3,5,8,12], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[3], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20,40], \"min_samples_split\":[2,3,5,10,20], \"min_samples_leaf\":[1,3,5,10], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "        param_grid1={\"max_depth\":[None], \"min_samples_split\":[2], \"min_samples_leaf\":[1], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "        \n",
    "        ##Grid model 2 LGBM\n",
    "        #param_grid2={\"max_depth\":[-1,10,20], \"learning_rate\":[0.1,0.01,0.001], \"n_estimators\":[100,50,200], \"num_leaves\":[31,5,10,50]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[250,300,400], \"num_leaves\":[2,5,8,12,16,20]}\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1,0.01], \"n_estimators\":[70,100,150,200], \"num_leaves\":[31,10,25,50,80,120]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'boosting_type': ['gbdt', 'dart', 'goss', 'rf'] }\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1], \"n_estimators\":[150,200], \"num_leaves\":[31,10,25], 'class_weight': list_class_weights}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'class_weight': list_class_weights }\n",
    "\n",
    "        #list_param_grids = [param_grid1, param_grid2]\n",
    "        list_param_grids = [param_grid1]\n",
    "\n",
    "        #list_param_grids = [param_grid2]\n",
    "        dictionary_paramgrid = dict(zip(models, list_param_grids))\n",
    "\n",
    "\n",
    "        \n",
    "        #Loop modelos\n",
    "        for num_modelo, model in enumerate(models):\n",
    "\n",
    "            nome_modelo_testado = nome_modelo[num_modelo]\n",
    "\n",
    "            param_grid = dictionary_paramgrid[model]\n",
    "\n",
    "            ############# GridSearch de modelos candidatos com todas features ################\n",
    "            #gs = GridSearchCV(model , param_grid=param_grid, scoring=scoring,  refit=\"f1\", n_jobs=-1, cv = ps )\n",
    "            \n",
    "            gs = GridSearchCV(model , param_grid=param_grid, scoring=scoring,  refit=\"f1\", n_jobs=-1, cv = 10 )\n",
    "            \n",
    "            #Fit dados \n",
    "            gs.fit(X_train_valid,y_train_valid)\n",
    "            \n",
    "            #gs.fit(X_train3,y_train3)\n",
    "\n",
    "            #melhores hyperparametros:\n",
    "            hyperparametros = list(gs.best_params_.values())\n",
    "            nome_hyperparametros = list(gs.best_params_.keys())\n",
    "\n",
    "\n",
    "            #melhor modelo\n",
    "            # CUIDADO: O atributo best_estimator_ retorna o melhor modelo ja treinado com o conjunto de dados\n",
    "            # passado pelo metodo gs.fit(), ou seja ja vem treinado com X_train_valid,y_train_valid, sendo, portanto\n",
    "            # necessário mais uma etapa de fit() do modelo tunado apenas com dados de treino.\n",
    "            modelo_tunado = gs.best_estimator_\n",
    "\n",
    "            # Refit no modelo tunado com apenas dados de treino para evitar overtting ao avaliar sobre dados de valid\n",
    "            modelo_tunado.fit(X_train3,y_train3)\n",
    "\n",
    "\n",
    "\n",
    "            #Loop Seletor de features:\n",
    "            #for k in range(X_train3.shape[1]-2, X_train3.shape[1], 1):   #Iterar sobre n-1 total de features e n-3.\n",
    "            #for k in range(X_train3.shape[1]-1, X_train3.shape[1]+1, 1): #Iterar sobre n total de features e n-2\n",
    "\n",
    "            #for k in range(X_train3.shape[1], X_train3.shape[1]+1, 1):  ## Iterar sobre n total de features e n (n = max)\n",
    "\n",
    "            #for k in range(4,5, 1):  ## Iterar sobre 4 á 4 features\n",
    "            for k in range(28,29, 1):  ## Iterar sobre 28 á 28 features\n",
    "                \n",
    "                #Seletor aleatório features\n",
    "                \n",
    "                \n",
    "                #pre_selected = ['pos_robd1','pos_rob','neutralidade_vadd4','neutralidade_vad','negatividade_vadd1','subjetividade_vadd2','subjetividade_vadd1','subjetividade_vadd3']\n",
    "                #selected = np.random.choice(pre_selected, k, replace=False)\n",
    "                #selected = np.append(selected, 'score')\n",
    "                \n",
    "                #selected = np.random.choice(X_train3.columns, k, replace=False)\n",
    "                selected = np.random.choice(X_train3.columns, k-1, replace=False)\n",
    "                selected = np.append(selected, 'score')\n",
    "                #selected = ['pos_rob','neutralidade_vadd4','pos_robd1','score']\n",
    "                             \n",
    "                \n",
    "                 #Loop Holdout selecionar aleatoriamente 70% dados de treino para alimentar o modelo e a pipe.\n",
    "                \n",
    "                lista_auc_valid = []\n",
    "                lista_auc_teste = []\n",
    "                \n",
    "                dict_scores_pipes = {}\n",
    "                dict_scores_pipes[0] = [[],[]]\n",
    "                dict_scores_pipes[1] = [[],[]]\n",
    "                dict_scores_pipes[2] = [[],[]]\n",
    "                dict_scores_pipes[3] = [[],[]]\n",
    "                dict_scores_pipes[4] = [[],[]]\n",
    "                dict_scores_pipes[5] = [[],[]]\n",
    "                \n",
    "                \n",
    "                for qtde_holdout in range(1,num_holdouts+1):\n",
    "                    \n",
    "                    seed_holdout = random.randint(0,9999)\n",
    "                    X_train4, X_descarte, y_train4, y_descarte = train_test_split(X_train3, y_train3, test_size=0.8, random_state=seed_holdout, stratify=y_train3)\n",
    "\n",
    "                    modelo_tunado_seletorK = modelo_tunado\n",
    "                    modelo_tunado_seletor_aleatorio = modelo_tunado\n",
    "                    \n",
    "                    #Fit do modelo aos dados do holdout\n",
    "                    modelo_tunado_seletorK.fit(X_train4,y_train4)   \n",
    "                    modelo_tunado_seletor_aleatorio.fit(X_train4[selected],y_train4)\n",
    "                    \n",
    "                    ################ Definição de Pipelines com modelo tunado ################\n",
    "                    \n",
    "                    ##Com Seletor K\n",
    "                    pipe1 = Pipeline([('scaler', StandardScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado_seletorK)])\n",
    "                    pipe2 = Pipeline([('scaler', MinMaxScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado_seletorK)])\n",
    "                    pipe3 = Pipeline([('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado_seletorK)])\n",
    "                    \n",
    "                    ## Com seletor aleatorio\n",
    "                    pipe4 = Pipeline([('scaler', StandardScaler()), (nome_modelo_testado, modelo_tunado_seletor_aleatorio)])\n",
    "                    pipe5 = Pipeline([('scaler', MinMaxScaler()), (nome_modelo_testado, modelo_tunado_seletor_aleatorio)])\n",
    "                    pipe6 = Pipeline([(nome_modelo_testado, modelo_tunado_seletor_aleatorio)])\n",
    "                    \n",
    "\n",
    "                    pipelines = [pipe1,pipe2,pipe3,pipe4,pipe5,pipe6]\n",
    "                    #pipelines = [pipe4,pipe5,pipe6]\n",
    "\n",
    "\n",
    "                    #Loop das pipelines testadas com seletor de features e outras etapas:\n",
    "                    for num_pipe, pipe in enumerate(pipelines):\n",
    "\n",
    "                        # features aleatorias aplicado ao  PIPE4 á PIPE5\n",
    "                        if num_pipe >= 3:\n",
    "\n",
    "                            X_train5 = X_train4[selected]\n",
    "                            y_train5 = y_train4\n",
    "\n",
    "                            X_valid3 = X_valid2[selected]\n",
    "\n",
    "                            X_test3 = X_test2[selected]\n",
    "                            \n",
    "                            ##Nome das features sorteadas\n",
    "                            features_selecionadas = ','.join(list(selected))\n",
    "                            \n",
    "                            \n",
    "                        else:\n",
    "                            X_train5 = X_train4\n",
    "                            y_train5 = y_train4\n",
    "\n",
    "                            X_valid3 = X_valid2\n",
    "\n",
    "                            X_test3 = X_test2\n",
    "                            \n",
    "                            #Nome das features selecionadas pelo SelectFromModel\n",
    "                            selector = SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)\n",
    "                            selector.fit(X_train5,y_train5)\n",
    "                            mask = selector.get_support()\n",
    "                            features_selecionadas = ','.join(list(X_train5.columns[mask]))\n",
    "                            \n",
    "\n",
    "\n",
    "                        #Fit Pipe e model\n",
    "\n",
    "                        #pipe.fit(X_train4,y_train4)\n",
    "                        pipe.fit(X_train5,y_train5)\n",
    "                              \n",
    "\n",
    "                        #Armazenando propriedades das PIPES\n",
    "                        if num_pipe == 0:\n",
    "                            seletor_feature = \"SelectFromModel\"\n",
    "                            scaler = \"StandardScaler\"\n",
    "\n",
    "                        if num_pipe == 1:\n",
    "                            seletor_feature = \"SelectFromModel\"\n",
    "                            scaler = \"MinMax\"\n",
    "\n",
    "                        if num_pipe == 2:\n",
    "                            seletor_feature = 'SelectFromModel'\n",
    "                            scaler = \"Sem Scaler\"\n",
    "\n",
    "                        if num_pipe == 3:\n",
    "                        #if num_pipe == 0:\n",
    "                            seletor_feature = \"Aleatorio\"\n",
    "                            scaler = \"StandardScaler\"\n",
    "                            \n",
    "                        if num_pipe == 4:\n",
    "                        #if num_pipe == 1:\n",
    "                            seletor_feature = \"Aleatorio\"\n",
    "                            scaler = \"MinMax\"\n",
    "                            \n",
    "                        if num_pipe == 5:\n",
    "                        #if num_pipe == 2:\n",
    "                            seletor_feature = \"Aleatorio\"\n",
    "                            scaler = \"Sem Scaler\"\n",
    "\n",
    "                        ################ Calculando métricas da pipe DADOS NAO UTILIZADOS E NÃO VISTOS - TESTE ################\n",
    "                        # Fazendo predição\n",
    "                        p = pipe.predict(X_test3)\n",
    "                        \n",
    "                        contagem_experimentos_unicos = contagem_experimentos_unicos + 1\n",
    "                        \n",
    "                        #Calculando o recall\n",
    "                        recall_0 = recall_score(y_test3, p, pos_label=0)\n",
    "                        recall_1 = recall_score(y_test3, p, pos_label=1)\n",
    "\n",
    "                        #Calculando Precision\n",
    "                        precision_0 = precision_score(y_test3, p, pos_label = 0)\n",
    "                        precision_1 = precision_score(y_test3, p, pos_label = 1)\n",
    "\n",
    "                        #Calculando acurácia\n",
    "                        accuracy = accuracy_score(y_test3, p)\n",
    "\n",
    "                        #Calculando AUC\n",
    "                        auc = roc_auc_score(y_test3, p)\n",
    "\n",
    "\n",
    "\n",
    "                       ################ Calculando métricas da pipe amostra representativa dos dados de teste - VALID ################\n",
    "                        # Fazendo predição\n",
    "                        p = pipe.predict(X_valid3)\n",
    "                        \n",
    "                        #Calculando o recall\n",
    "                        recall_0_valid = recall_score(y_valid2, p, pos_label=0)\n",
    "                        recall_1_valid = recall_score(y_valid2, p, pos_label=1)\n",
    "\n",
    "                        #Calculando Precision\n",
    "                        precision_0_valid = precision_score(y_valid2, p, pos_label = 0)\n",
    "                        precision_1_valid = precision_score(y_valid2, p, pos_label = 1)\n",
    "\n",
    "                        #Calculando acurácia\n",
    "                        accuracy_valid = accuracy_score(y_valid2, p)\n",
    "\n",
    "                        #Calculando AUC\n",
    "                        auc_valid = roc_auc_score(y_valid2, p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        ########## Calculo AUC medio sobre a totalidade dos holdouts: #############\n",
    "                        \n",
    "                        resultados_parciais_teste = dict_scores_pipes[num_pipe][0]\n",
    "                        resultados_parciais_valid = dict_scores_pipes[num_pipe][1]\n",
    "                        \n",
    "                        resultados_parciais_teste.append(auc)\n",
    "                        resultados_parciais_valid.append(auc_valid)\n",
    "                        \n",
    "                        dict_scores_pipes[num_pipe] = [resultados_parciais_teste,resultados_parciais_valid]\n",
    "                        \n",
    "                        metrica = 0\n",
    "                        auc_teste_medio = 0\n",
    "                        auc_valid_medio = 0\n",
    "                        \n",
    "                        ## quando a pipeline estiver rodado os 5 holdouts calcular os resultados das medias\n",
    "                        if len(resultados_parciais_teste)==num_holdouts:\n",
    "                        \n",
    "                            array_auc = np.array(resultados_parciais_teste)\n",
    "                            array_auc_valid = np.array(resultados_parciais_valid)\n",
    "                            \n",
    "                            auc_teste_medio = array_auc.mean()\n",
    "                            auc_valid_medio = array_auc_valid.mean()\n",
    "                            \n",
    "                            metrica = auc_teste_medio - auc_valid_medio\n",
    "                    \n",
    "                        ################# Armazenando e imprimindo os resultados  ################\n",
    "\n",
    "                        dictionary_hyperparams = dict(zip(nome_hyperparametros, hyperparametros))\n",
    "\n",
    "                        if num_modelo ==0:\n",
    "                            \n",
    "                            #col_names_modelo1 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                            #resultados_model1.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                            col_names_modelo1 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features','seed_holdout', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc','auc_valid']\n",
    "                            resultados_model1.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, seed_holdout, accuracy, recall_0, recall_1, precision_0, precision_1, auc, auc_valid ]))\n",
    "\n",
    "                            \n",
    "                            ## Imprime resultados do melhor modelo 1                                \n",
    "                            #if auc > maximo_auc_model1:\n",
    "                            #if auc > 0.6:\n",
    "                            \n",
    "                                \n",
    "                                #print(\"============================================================================================================================\")\n",
    "                                #print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC Valid = {} - AUC Teste - {} - num_seed_aleatoria = {} - versao_sentilex = {} - num_seed_holdout = {}\".format(nome_modelo_testado, auc_valid, auc, seed, versao,seed_holdout))\n",
    "                                #print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                \n",
    "                                #print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                                #print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                                #print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                                #print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                                #print(\"\")\n",
    "                                #print(\"============================================================================================================================\")\n",
    "\n",
    "                            melhor_modelo1 = pipe\n",
    "                            maximo_auc_model1 = auc\n",
    "\n",
    "                        if num_modelo ==1:\n",
    "\n",
    "                            #col_names_modelo2 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                            #resultados_model2.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                            col_names_modelo2 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                            resultados_model2.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "\n",
    "                            ## Imprime resultados do melhor modelo 2\n",
    "                            #if auc > maximo_auc_model2:\n",
    "\n",
    "                                #print(\"============================================================================================================================\")\n",
    "                                #print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado, auc, seed, versao))\n",
    "                                #print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                        \n",
    "                                #print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                                #print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                                #print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                                #print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                                #print(\"\")\n",
    "                                #print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "                            melhor_modelo2 = pipe\n",
    "                            maximo_auc_model2 = auc\n",
    "\n",
    "\n",
    "\n",
    "                        # Imprime resultados do melhor modelo global até o momento.                         \n",
    "                        if auc_teste_medio > maximo_auc:\n",
    "                            #print(\"Novo melhor modelo encontrado:  modelo = {} - AUC = {} - fator_balanceamento_classes = {} - num_pipeline = {}, tipo_encoding = {} - tipo_scaler = {} - num_seed_aleatoria = {} - num_features = {} - metodo_selecao_features = {} - features_selecionadas = {} - hyperparâmetros_selecionados = {}\".format(\"RF\", fator, auc,num_pipe+1, encode, scaler, seed, k, seletor_feature, features_selecionadas, dictionary_hyperparams))\n",
    "\n",
    "                            #Armazenar modelo que:\n",
    "                            # 1) generaliza bem (AUC_VALID alto) e\n",
    "                            # 2) Performa bem dados de producao (AUC_TESTE alto)\n",
    "                            # 3) Não há disparidade entre AUC's\n",
    "                           ## AUC teste pode ser inferior a AUC validação, contanto que seja alto\n",
    "                          ### mas nao pode ser MUITO maior que AUC validação (Limite máximo tolerado = +7%)\n",
    "                            \n",
    "                            limite_maximo_tolerado = 0.07\n",
    "                            \n",
    "                            if metrica < 0 or metrica > limite_maximo_tolerado:\n",
    "                                print(\"============================================================================================================================\")\n",
    "                                print(\"MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  {} - AUC Valid medio 5 repeticoes = {} - AUC Teste medio 5 repeticoes = {} -  versão sentilex = {}\".format(nome_modelo_testado, auc_valid_medio, auc_teste_medio, versao))                   \n",
    "                                print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                                print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                                print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                                print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                                print(\"\")\n",
    "                                print(\"============================================================================================================================\")\n",
    "\n",
    "                                \n",
    "                                \n",
    "                                melhor_modelo = pipe\n",
    "                                maximo_auc = auc_teste_medio\n",
    "                                best_seed = seed\n",
    "\n",
    "                        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">80_2</th>\n",
       "      <th>1</th>\n",
       "      <th>subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd2,subjetividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd1,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neu_robd1,neu_robd2,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd2,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.591119</td>\n",
       "      <td>0.591137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd4,positividade_vadd4,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,scored1,neg_robd2,neg_robd3,neg_robd4,neu_robd3,neu_robd4,pos_robd2,pos_robd3,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.587793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd4,positividade_vadd4,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,scored1,neg_robd2,neg_robd3,neg_robd4,neu_robd3,neu_robd4,pos_robd2,pos_robd3,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.581382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">80_2</th>\n",
       "      <th>3</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd2,neutralidade_vadd2,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.643255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd2,neutralidade_vadd2,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.643255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd2,neutralidade_vadd2,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.558048</td>\n",
       "      <td>0.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>neutralidade_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,polaridade_vadd4,subjetividade_vadd2,subjetividade_vadd3,negatividade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>neutralidade_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,polaridade_vadd4,subjetividade_vadd2,subjetividade_vadd3,negatividade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>neutralidade_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,polaridade_vadd4,subjetividade_vadd2,subjetividade_vadd3,negatividade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd2,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">80_2</th>\n",
       "      <th>1</th>\n",
       "      <th>score,subjetividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,subjetividade_vadd1,subjetividade_vadd2,subjetividade_vadd3,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd1,positividade_vadd4,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd3,neg_robd4,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.602285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,subjetividade_vadd1,negatividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,subjetividade_vadd1,negatividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>subjetividade_vad,negatividade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,polaridade_vadd2,subjetividade_vadd1,negatividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">80_2</th>\n",
       "      <th>2</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd1,composicao_vadd4,scored3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,pos_robd1,pos_robd2,pos_robd3,pos_finbertd1,neu_finbertd2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd1,composicao_vadd4,scored3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,pos_robd1,pos_robd2,pos_robd3,pos_finbertd1,neu_finbertd2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd1,composicao_vadd4,scored3,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,pos_robd1,pos_robd2,pos_robd3,pos_finbertd1,neu_finbertd2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polaridade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,polaridade_vadd3,subjetividade_vadd3,negatividade_vadd3,negatividade_vadd4,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd3,neg_robd4,neu_robd3,pos_robd1,pos_robd2,pos_robd3,neg_finbertd3,neu_finbertd1,neu_finbertd2,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.613434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">80_2</th>\n",
       "      <th>1</th>\n",
       "      <th>polaridade_vad,subjetividade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd3,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.556577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>polaridade_vad,subjetividade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd3,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.556577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>polaridade_vad,subjetividade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd3,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.563824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd2,subjetividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd1,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neu_robd1,neu_robd2,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd2,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536772</td>\n",
       "      <td>0.583055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">80_2</th>\n",
       "      <th>1</th>\n",
       "      <th>score,subjetividade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neg_robd3,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.536309</td>\n",
       "      <td>0.636845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>score,subjetividade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neg_robd3,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.536309</td>\n",
       "      <td>0.636845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>score,subjetividade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,neu_rob,pos_rob,neu_finbert,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd2,neg_robd3,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,neu_finbertd1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.536309</td>\n",
       "      <td>0.636845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>polaridade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd3,polaridade_vadd4,negatividade_vadd1,negatividade_vadd4,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd2,scored2,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd4,pos_robd2,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.536078</td>\n",
       "      <td>0.531773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.531183</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.547552</td>\n",
       "      <td>0.519533</td>\n",
       "      <td>0.531314</td>\n",
       "      <td>0.615775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.544404</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>0.529186</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">80_2</th>\n",
       "      <th>1</th>\n",
       "      <th>subjetividade_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,polaridade_vadd3,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd4,positividade_vadd2,positividade_vadd3,composicao_vadd2,composicao_vadd4,neg_robd1,neg_robd2,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.527058</td>\n",
       "      <td>0.559643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>subjetividade_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,polaridade_vadd3,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd4,positividade_vadd2,positividade_vadd3,composicao_vadd2,composicao_vadd4,neg_robd1,neg_robd2,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.527058</td>\n",
       "      <td>0.553233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>subjetividade_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,polaridade_vadd3,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd4,positividade_vadd2,positividade_vadd3,composicao_vadd2,composicao_vadd4,neg_robd1,neg_robd2,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.527058</td>\n",
       "      <td>0.553233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd1,subjetividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd4,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>0.589465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd1,subjetividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd4,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>0.589465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,composicao_vad,neg_rob,neu_rob,polaridade_vadd3,polaridade_vadd4,subjetividade_vadd1,subjetividade_vadd2,neutralidade_vadd1,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd3,composicao_vadd1,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd4,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>0.589465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.5, 1: 0.5}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>3</th>\n",
       "      <th>subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_finbert,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd2,subjetividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd1,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neu_robd1,neu_robd2,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd2,neu_finbertd3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.583055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">80_2</th>\n",
       "      <th>3</th>\n",
       "      <th>subjetividade_vad,neutralidade_vad,pos_rob,polaridade_vadd2,polaridade_vadd3,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.534002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>subjetividade_vad,neutralidade_vad,pos_rob,polaridade_vadd2,polaridade_vadd3,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.540412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>subjetividade_vad,neutralidade_vad,pos_rob,polaridade_vadd2,polaridade_vadd3,subjetividade_vadd2,subjetividade_vadd4,negatividade_vadd2,negatividade_vadd3,neutralidade_vadd1,neutralidade_vadd3,positividade_vadd3,positividade_vadd4,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd1,pos_robd3,pos_robd4,neu_finbertd1,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.534002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>polaridade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd3,polaridade_vadd4,negatividade_vadd1,negatividade_vadd4,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd2,scored2,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd4,pos_robd2,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.525439</td>\n",
       "      <td>0.531773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>polaridade_vad,negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,pos_rob,neu_finbert,polaridade_vadd3,polaridade_vadd4,negatividade_vadd1,negatividade_vadd4,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd2,scored2,neg_robd1,neg_robd2,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd4,pos_robd2,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.525208</td>\n",
       "      <td>0.546265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.5, 1: 0.5}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>5</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.524731</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.534783</td>\n",
       "      <td>0.537197</td>\n",
       "      <td>0.514471</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.612876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">80_2</th>\n",
       "      <th>2</th>\n",
       "      <th>polaridade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,polaridade_vadd3,subjetividade_vadd3,negatividade_vadd3,negatividade_vadd4,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd3,neg_robd4,neu_robd3,pos_robd1,pos_robd2,pos_robd3,neg_finbertd3,neu_finbertd1,neu_finbertd2,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.613434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>polaridade_vad,neutralidade_vad,positividade_vad,composicao_vad,neu_rob,polaridade_vadd3,subjetividade_vadd3,negatividade_vadd3,negatividade_vadd4,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd1,positividade_vadd3,composicao_vadd2,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd3,neg_robd4,neu_robd3,pos_robd1,pos_robd2,pos_robd3,neg_finbertd3,neu_finbertd1,neu_finbertd2,neu_finbertd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.517114</td>\n",
       "      <td>0.613434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>polaridade_vad,negatividade_vad,composicao_vad,neu_rob,pos_rob,polaridade_vadd3,subjetividade_vadd1,subjetividade_vadd4,negatividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd1,composicao_vadd2,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.632943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>negatividade_vad,neutralidade_vad,positividade_vad,composicao_vad,pos_rob,polaridade_vadd1,polaridade_vadd2,subjetividade_vadd1,subjetividade_vadd3,negatividade_vadd1,negatividade_vadd3,neutralidade_vadd2,neutralidade_vadd3,positividade_vadd2,composicao_vadd2,composicao_vadd3,composicao_vadd4,scored3,scored4,neg_robd1,neg_robd3,neu_robd1,neu_robd2,neu_robd4,pos_robd1,pos_robd2,pos_robd3,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.583891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polaridade_vad,negatividade_vad,composicao_vad,neu_rob,pos_rob,polaridade_vadd3,subjetividade_vadd1,subjetividade_vadd4,negatividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd1,composicao_vadd2,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.632943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>6</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.595095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.595095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>3</th>\n",
       "      <th>polaridade_vad,negatividade_vad,composicao_vad,neu_rob,pos_rob,polaridade_vadd3,subjetividade_vadd1,subjetividade_vadd4,negatividade_vadd2,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd2,positividade_vadd4,composicao_vadd1,composicao_vadd2,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd2,neu_robd3,neu_robd4,pos_robd2,pos_robd3,neu_finbertd1,neu_finbertd2,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.632943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>3</th>\n",
       "      <th>polaridade_vad,neutralidade_vad,positividade_vad,composicao_vad,neg_rob,pos_rob,polaridade_vadd1,subjetividade_vadd2,subjetividade_vadd3,subjetividade_vadd4,neutralidade_vadd2,neutralidade_vadd3,neutralidade_vadd4,positividade_vadd3,composicao_vadd1,composicao_vadd3,composicao_vadd4,neg_robd1,neg_robd3,neg_robd4,neu_robd1,neu_robd3,neu_robd4,pos_robd1,pos_robd2,pos_robd3,pos_robd4,neu_finbertd4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.605630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.596544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                          contagem_exp  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                           \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...             1   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...             1   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...             1   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...             1   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...             1   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...             1   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...             1   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...             1   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...             1   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...             1   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...             1   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...             1   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...             1   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...             1   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...             1   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...             1   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...             1   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...             1   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...             1   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...             1   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...             1   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...             1   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...             1   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...             1   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...             1   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...             1   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...             1   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...             1   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...             1   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...             1   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...             1   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...             1   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...             1   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "\n",
       "                                                                                                                                                                                          acuracia  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.591398   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.569892   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.569892   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.559140   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.559140   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.559140   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.559140   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.559140   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.559140   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.548387   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.548387   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.548387   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.548387   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.548387   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.548387   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.548387   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.537634   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.537634   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.537634   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.537634   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.537634   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.537634   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.537634   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.537634   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.537634   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.531183   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.529032   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.526882   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.526882   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.526882   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.526882   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.526882   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.526882   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.526882   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526882   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526882   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526882   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.526882   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.526882   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.524731   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.516129   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.516129   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.516129   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.516129   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.516129   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.516129   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.516129   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "\n",
       "                                                                                                                                                                                          recall_0  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.617021   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.531915   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.531915   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.638298   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.638298   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.659574   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.680851   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.680851   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.680851   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.489362   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.702128   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.702128   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.702128   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.425532   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.595745   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.595745   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.595745   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.617021   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.659574   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.659574   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.659574   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.680851   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.519149   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514894   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.510638   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.510638   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.510638   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.595745   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.595745   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.595745   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.617021   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.617021   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.617021   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.617021   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.659574   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.680851   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514894   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.425532   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.425532   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.574468   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.574468   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.574468   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.574468   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.574468   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "\n",
       "                                                                                                                                                                                          recall_1  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.565217   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.608696   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.608696   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.478261   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.478261   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.456522   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.434783   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.434783   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.434783   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.608696   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.391304   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.391304   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.391304   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.652174   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.478261   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.478261   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.478261   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.456522   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.413043   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.413043   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.413043   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.391304   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.543478   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.543478   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.543478   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.543478   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.543478   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.456522   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.456522   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.456522   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.434783   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.434783   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.434783   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.434783   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.391304   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.369565   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.534783   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.608696   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.608696   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.456522   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.456522   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.456522   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.456522   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.456522   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "\n",
       "                                                                                                                                                                                            prec_0  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.591837   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.581395   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.581395   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.555556   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.555556   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.553571   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.551724   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.551724   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.551724   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.560976   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.553191   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.540984   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.540984   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.540984   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.555556   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.538462   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.538462   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.538462   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.537037   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.534483   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.534483   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.534483   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.533333   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.547552   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.544404   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.533333   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.533333   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.533333   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.528302   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.528302   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.528302   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.527273   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.527273   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.527273   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.527273   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.525424   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.524590   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.537197   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.526316   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.526316   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.519231   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.519231   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.519231   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.519231   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.519231   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "\n",
       "                                                                                                                                                                                            prec_1  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.590909   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.560000   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.560000   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.564103   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.564103   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.567568   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.571429   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.571429   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.571429   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.538462   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.543478   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.562500   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.562500   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.562500   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.526316   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.536585   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.536585   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.536585   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.538462   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.542857   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.542857   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.542857   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.545455   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.519533   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.517512   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.520833   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.520833   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.520833   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.525000   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.525000   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.525000   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.526316   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526316   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526316   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.526316   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.529412   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.531250   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514471   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.509091   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.509091   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.512195   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.512195   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.512195   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.512195   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.512195   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "\n",
       "                                                                                                                                                                                               auc  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.591119   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.570305   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...  0.570305   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...  0.558279   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...  0.558279   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...  0.558048   \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.557817   \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.557817   \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...  0.557817   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...  0.549029   \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...  0.548335   \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...  0.548335   \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...  0.548335   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...  0.546716   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.546716   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...  0.546716   \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...  0.538853   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...  0.537003   \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...  0.537003   \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...  0.537003   \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.536772   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...  0.536309   \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...  0.536309   \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...  0.536309   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...  0.536078   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.531314   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.529186   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.527058   \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.527058   \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...  0.527058   \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...  0.526133   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...  0.526133   \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...  0.526133   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...  0.525902   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.525902   \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.525902   \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...  0.525902   \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...  0.525439   \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...  0.525208   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.524838   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...  0.517114   \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...  0.517114   \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...  0.515495   \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...  0.515495   \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...  0.515495   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...  0.515495   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...  0.515495   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "\n",
       "                                                                                                                                                                                          auc_valid  \n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...   0.591137  \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...   0.587793  \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,positividade_...   0.581382  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,negatividade_vad,neutralidade...   0.643255  \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,neutralidade...   0.643255  \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,neutralidade...   0.630435  \n",
       "                                                                                                                             2        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...   0.585284  \n",
       "                                                                                                                             1        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...   0.585284  \n",
       "                                                                                                                             3        neutralidade_vad,neg_rob,neu_rob,pos_rob,polari...   0.585284  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,composicao_vad,neu_rob,...   0.602285  \n",
       "                                                                                                                             3        subjetividade_vad,negatividade_vad,positividade...   0.529264  \n",
       "                                                                                                                             1        subjetividade_vad,negatividade_vad,positividade...   0.529264  \n",
       "                                                                                                                             2        subjetividade_vad,negatividade_vad,positividade...   0.529264  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        negatividade_vad,neutralidade_vad,positividade_...   0.592531  \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...   0.592531  \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,positividade_...   0.592531  \n",
       "                                                                                                                                      polaridade_vad,neutralidade_vad,positividade_va...   0.613434  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     1        polaridade_vad,subjetividade_vad,positividade_v...   0.556577  \n",
       "                                                                                                                             2        polaridade_vad,subjetividade_vad,positividade_v...   0.556577  \n",
       "                                                                                                                             3        polaridade_vad,subjetividade_vad,positividade_v...   0.563824  \n",
       "                                                                                                                             2        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...   0.583055  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        score,subjetividade_vad,negatividade_vad,neutra...   0.636845  \n",
       "                                                                                                                             2        score,subjetividade_vad,negatividade_vad,neutra...   0.636845  \n",
       "                                                                                                                             3        score,subjetividade_vad,negatividade_vad,neutra...   0.636845  \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,neutralidade_va...   0.531773  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.615775  \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.613043  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     1        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...   0.559643  \n",
       "                                                                                                                             3        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...   0.553233  \n",
       "                                                                                                                             2        subjetividade_vad,neu_rob,pos_rob,neu_finbert,p...   0.553233  \n",
       "                                                                                                                             3        negatividade_vad,neutralidade_vad,composicao_va...   0.589465  \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,composicao_va...   0.589465  \n",
       "                                                                                                                             2        negatividade_vad,neutralidade_vad,composicao_va...   0.589465  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_f...   0.583055  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        subjetividade_vad,neutralidade_vad,pos_rob,pola...   0.534002  \n",
       "                                                                                                                             2        subjetividade_vad,neutralidade_vad,pos_rob,pola...   0.540412  \n",
       "                                                                                                                             1        subjetividade_vad,neutralidade_vad,pos_rob,pola...   0.534002  \n",
       "                                                                                                                             3        polaridade_vad,negatividade_vad,neutralidade_va...   0.531773  \n",
       "                                                                                                                             1        polaridade_vad,negatividade_vad,neutralidade_va...   0.546265  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.612876  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     2        polaridade_vad,neutralidade_vad,positividade_va...   0.613434  \n",
       "                                                                                                                             1        polaridade_vad,neutralidade_vad,positividade_va...   0.613434  \n",
       "                                                                                                                             2        polaridade_vad,negatividade_vad,composicao_vad,...   0.632943  \n",
       "                                                                                                                             1        negatividade_vad,neutralidade_vad,positividade_...   0.583891  \n",
       "                                                                                                                                      polaridade_vad,negatividade_vad,composicao_vad,...   0.632943  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.595095  \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.595095  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,negatividade_vad,composicao_vad,...   0.632943  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     3        polaridade_vad,neutralidade_vad,positividade_va...   0.605630  \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.596544  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Resultados Modelo 1: RF\n",
    "\n",
    "## Configurando Numero de caracteres para visualização do dataframe\n",
    "pd.set_option('display.precision',5)\n",
    "pd.reset_option('^display.',silent=True)\n",
    "\n",
    "# Transformando resultados em dataframe\n",
    "resultados_df_model1 = pd.DataFrame(np.array(resultados_model1), columns=col_names_modelo1)\n",
    "resultados_df_model1['auc'] = resultados_df_model1['auc'].astype(float, errors = 'raise')\n",
    "\n",
    "## Criando dicionário com os tipos de dados dos parâmetros e das métricas\n",
    "import itertools\n",
    "\n",
    "col_metricas = col_names_modelo1[12:]\n",
    "dict_metrics_types = dict.fromkeys(col_metricas , 'float')\n",
    "\n",
    "col_params = col_names_modelo1[:12]\n",
    "dict_params_types = dict.fromkeys(col_params , 'str')\n",
    "\n",
    "dict_data_types = itertools.chain(dict_params_types.items(),dict_metrics_types.items())\n",
    "dict_data_types = dict(dict_data_types)\n",
    "dict_data_types\n",
    "\n",
    "group_by_list = col_names_modelo1[2:11]\n",
    "\n",
    "## Agrupando por hiperparâmetros e ordenando pelas métricas\n",
    "df_agrupado = resultados_df_model1.astype(dict_data_types).groupby(group_by_list).agg({'contagem_exp': 'nunique', 'acuracia':np.mean, 'recall_0':np.mean, 'recall_1':np.mean, 'prec_0':np.mean, 'prec_1':np.mean, 'auc':np.mean, 'auc_valid': np.mean}).sort_values(by='auc', ascending=False)\n",
    "df_agrupado.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos mais consistentes: que foram selecionados mais de 1x nos experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.531183</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.547552</td>\n",
       "      <td>0.519533</td>\n",
       "      <td>0.531314</td>\n",
       "      <td>0.615775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.544404</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>0.529186</td>\n",
       "      <td>0.613043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>neg_robd4,pos_finbertd1,neu_robd1,polaridade_vadd2,polaridade_vadd4,neg_rob,pos_rob,polaridade_vadd1,negatividade_vad,negatividade_vadd2,pos_robd4,scored2,pos_robd3,polaridade_vadd3,pos_robd2,subjetividade_vadd2,neutralidade_vadd4,scored4,neg_finbertd1,neu_robd2,polaridade_vad,pos_finbertd2,neu_finbertd4,neutralidade_vadd1,composicao_vad,pos_finbertd4,scored3,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.524731</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.534783</td>\n",
       "      <td>0.537197</td>\n",
       "      <td>0.514471</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.612876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.595095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.595095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>negatividade_vadd4,pos_finbertd4,neutralidade_vadd4,neu_finbert,neu_finbertd2,neu_finbertd4,neg_rob,subjetividade_vadd2,scored1,neg_finbertd2,neu_rob,composicao_vadd4,positividade_vadd4,positividade_vadd3,polaridade_vadd1,neg_robd1,neu_robd4,composicao_vad,subjetividade_vad,negatividade_vad,score,negatividade_vadd2,composicao_vadd1,positividade_vad,neg_finbertd3,subjetividade_vadd1,polaridade_vadd4,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.505612</td>\n",
       "      <td>0.515495</td>\n",
       "      <td>0.596544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>5</th>\n",
       "      <th>scored2,neu_robd3,neu_rob,neutralidade_vadd1,pos_robd3,pos_robd4,neg_robd1,pos_finbertd4,pos_rob,neg_finbertd4,subjetividade_vad,polaridade_vadd1,polaridade_vadd4,neu_finbertd1,subjetividade_vadd4,positividade_vad,composicao_vadd4,subjetividade_vadd2,pos_finbertd1,neutralidade_vadd2,neutralidade_vadd3,subjetividade_vadd1,neutralidade_vadd4,neg_robd2,scored3,positividade_vadd3,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.511828</td>\n",
       "      <td>0.557447</td>\n",
       "      <td>0.465217</td>\n",
       "      <td>0.506457</td>\n",
       "      <td>0.517122</td>\n",
       "      <td>0.511332</td>\n",
       "      <td>0.608027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>scored2,neu_robd3,neu_rob,neutralidade_vadd1,pos_robd3,pos_robd4,neg_robd1,pos_finbertd4,pos_rob,neg_finbertd4,subjetividade_vad,polaridade_vadd1,polaridade_vadd4,neu_finbertd1,subjetividade_vadd4,positividade_vad,composicao_vadd4,subjetividade_vadd2,pos_finbertd1,neutralidade_vadd2,neutralidade_vadd3,subjetividade_vadd1,neutralidade_vadd4,neg_robd2,scored3,positividade_vadd3,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.557447</td>\n",
       "      <td>0.460870</td>\n",
       "      <td>0.504581</td>\n",
       "      <td>0.514582</td>\n",
       "      <td>0.509158</td>\n",
       "      <td>0.606745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.9, 1: 0.09999999999999998}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>5</th>\n",
       "      <th>neutralidade_vadd4,subjetividade_vad,composicao_vad,neu_robd1,scored2,pos_robd1,neg_rob,neu_finbert,neg_finbertd1,neu_robd4,pos_robd2,pos_robd4,positividade_vadd1,negatividade_vadd4,neutralidade_vad,subjetividade_vadd1,pos_rob,positividade_vad,neu_finbertd2,negatividade_vad,pos_finbert,scored1,neg_finbert,pos_robd3,subjetividade_vadd3,neg_robd1,score,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.507527</td>\n",
       "      <td>0.608511</td>\n",
       "      <td>0.404348</td>\n",
       "      <td>0.507874</td>\n",
       "      <td>0.510761</td>\n",
       "      <td>0.506429</td>\n",
       "      <td>0.605463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neutralidade_vadd4,subjetividade_vad,composicao_vad,neu_robd1,scored2,pos_robd1,neg_rob,neu_finbert,neg_finbertd1,neu_robd4,pos_robd2,pos_robd4,positividade_vadd1,negatividade_vadd4,neutralidade_vad,subjetividade_vadd1,pos_rob,positividade_vad,neu_finbertd2,negatividade_vad,pos_finbert,scored1,neg_finbert,pos_robd3,subjetividade_vadd3,neg_robd1,score,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.507527</td>\n",
       "      <td>0.608511</td>\n",
       "      <td>0.404348</td>\n",
       "      <td>0.507874</td>\n",
       "      <td>0.510761</td>\n",
       "      <td>0.506429</td>\n",
       "      <td>0.601115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>scored2,neu_robd3,neu_rob,neutralidade_vadd1,pos_robd3,pos_robd4,neg_robd1,pos_finbertd4,pos_rob,neg_finbertd4,subjetividade_vad,polaridade_vadd1,polaridade_vadd4,neu_finbertd1,subjetividade_vadd4,positividade_vad,composicao_vadd4,subjetividade_vadd2,pos_finbertd1,neutralidade_vadd2,neutralidade_vadd3,subjetividade_vadd1,neutralidade_vadd4,neg_robd2,scored3,positividade_vadd3,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.500574</td>\n",
       "      <td>0.509921</td>\n",
       "      <td>0.504857</td>\n",
       "      <td>0.609476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>pos_finbert,negatividade_vadd3,neutralidade_vadd4,neu_robd1,neutralidade_vadd3,positividade_vad,subjetividade_vad,positividade_vadd2,neg_robd3,neutralidade_vad,neu_rob,neu_finbertd3,composicao_vad,neutralidade_vadd1,neu_finbertd1,polaridade_vadd2,neg_robd1,negatividade_vadd1,composicao_vadd1,pos_finbertd4,positividade_vadd1,neu_robd4,scored2,neg_finbertd1,scored4,scored1,composicao_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.561702</td>\n",
       "      <td>0.447826</td>\n",
       "      <td>0.510418</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.504764</td>\n",
       "      <td>0.593032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>subjetividade_vadd1,scored1,pos_finbertd2,neutralidade_vadd3,negatividade_vadd1,positividade_vadd1,scored2,subjetividade_vadd4,negatividade_vadd3,positividade_vadd3,pos_robd2,subjetividade_vadd2,pos_robd1,neg_robd1,polaridade_vadd1,neg_finbertd4,neg_finbert,neu_robd1,positividade_vadd2,neu_robd4,composicao_vadd1,neutralidade_vad,negatividade_vad,neg_robd2,neu_finbert,pos_robd4,negatividade_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.540426</td>\n",
       "      <td>0.465217</td>\n",
       "      <td>0.505567</td>\n",
       "      <td>0.499566</td>\n",
       "      <td>0.502821</td>\n",
       "      <td>0.612096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>pos_finbert,negatividade_vadd3,neutralidade_vadd4,neu_robd1,neutralidade_vadd3,positividade_vad,subjetividade_vad,positividade_vadd2,neg_robd3,neutralidade_vad,neu_rob,neu_finbertd3,composicao_vad,neutralidade_vadd1,neu_finbertd1,polaridade_vadd2,neg_robd1,negatividade_vadd1,composicao_vadd1,pos_finbertd4,positividade_vadd1,neu_robd4,scored2,neg_finbertd1,scored4,scored1,composicao_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.508780</td>\n",
       "      <td>0.495879</td>\n",
       "      <td>0.502683</td>\n",
       "      <td>0.593032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neg_finbert,positividade_vad,scored4,neu_robd4,score,subjetividade_vadd1,neg_robd2,negatividade_vadd4,positividade_vadd2,neu_rob,negatividade_vadd2,pos_rob,subjetividade_vad,neg_finbertd4,negatividade_vadd1,composicao_vadd2,neu_robd3,scored2,positividade_vadd4,neutralidade_vadd1,neg_robd1,neu_finbertd1,scored3,pos_finbertd2,neg_finbertd1,composicao_vadd4,neu_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.421277</td>\n",
       "      <td>0.582609</td>\n",
       "      <td>0.497038</td>\n",
       "      <td>0.503629</td>\n",
       "      <td>0.501943</td>\n",
       "      <td>0.597380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>subjetividade_vadd1,scored1,pos_finbertd2,neutralidade_vadd3,negatividade_vadd1,positividade_vadd1,scored2,subjetividade_vadd4,negatividade_vadd3,positividade_vadd3,pos_robd2,subjetividade_vadd2,pos_robd1,neg_robd1,polaridade_vadd1,neg_finbertd4,neg_finbert,neu_robd1,positividade_vadd2,neu_robd4,composicao_vadd1,neutralidade_vad,negatividade_vad,neg_robd2,neu_finbert,pos_robd4,negatividade_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.465217</td>\n",
       "      <td>0.502358</td>\n",
       "      <td>0.497984</td>\n",
       "      <td>0.500694</td>\n",
       "      <td>0.610814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>pos_finbert,negatividade_vadd3,neutralidade_vadd4,neu_robd1,neutralidade_vadd3,positividade_vad,subjetividade_vad,positividade_vadd2,neg_robd3,neutralidade_vad,neu_rob,neu_finbertd3,composicao_vad,neutralidade_vadd1,neu_finbertd1,polaridade_vadd2,neg_robd1,negatividade_vadd1,composicao_vadd1,pos_finbertd4,positividade_vadd1,neu_robd4,scored2,neg_finbertd1,scored4,scored1,composicao_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.505996</td>\n",
       "      <td>0.494955</td>\n",
       "      <td>0.500555</td>\n",
       "      <td>0.591583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.9, 1: 0.09999999999999998}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>neutralidade_vadd4,subjetividade_vad,composicao_vad,neu_robd1,scored2,pos_robd1,neg_rob,neu_finbert,neg_finbertd1,neu_robd4,pos_robd2,pos_robd4,positividade_vadd1,negatividade_vadd4,neutralidade_vad,subjetividade_vadd1,pos_rob,positividade_vad,neu_finbertd2,negatividade_vad,pos_finbert,scored1,neg_finbert,pos_robd3,subjetividade_vadd3,neg_robd1,score,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.404348</td>\n",
       "      <td>0.501805</td>\n",
       "      <td>0.502766</td>\n",
       "      <td>0.500046</td>\n",
       "      <td>0.609309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>5</th>\n",
       "      <th>neg_finbert,positividade_vad,scored4,neu_robd4,score,subjetividade_vadd1,neg_robd2,negatividade_vadd4,positividade_vadd2,neu_rob,negatividade_vadd2,pos_rob,subjetividade_vad,neg_finbertd4,negatividade_vadd1,composicao_vadd2,neu_robd3,scored2,positividade_vadd4,neutralidade_vadd1,neg_robd1,neu_finbertd1,scored3,pos_finbertd2,neg_finbertd1,composicao_vadd4,neu_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.417021</td>\n",
       "      <td>0.578261</td>\n",
       "      <td>0.493137</td>\n",
       "      <td>0.498660</td>\n",
       "      <td>0.497641</td>\n",
       "      <td>0.597380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.5, 1: 0.5}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>6</th>\n",
       "      <th>neutralidade_vadd4,positividade_vadd2,scored2,scored4,polaridade_vadd4,negatividade_vadd4,composicao_vad,neg_finbert,subjetividade_vadd4,subjetividade_vadd3,neu_finbert,pos_robd1,scored1,subjetividade_vadd2,composicao_vadd4,neg_robd1,neg_finbertd4,neg_rob,neu_robd4,neutralidade_vadd3,neg_finbertd2,neu_finbertd4,scored3,neutralidade_vadd1,negatividade_vadd3,pos_robd3,neutralidade_vadd2,score</th>\n",
       "      <td>3</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.503145</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.599405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>subjetividade_vadd1,scored1,pos_finbertd2,neutralidade_vadd3,negatividade_vadd1,positividade_vadd1,scored2,subjetividade_vadd4,negatividade_vadd3,positividade_vadd3,pos_robd2,subjetividade_vadd2,pos_robd1,neg_robd1,polaridade_vadd1,neg_finbertd4,neg_finbert,neu_robd1,positividade_vadd2,neu_robd4,composicao_vadd1,neutralidade_vad,negatividade_vad,neg_robd2,neu_finbert,pos_robd4,negatividade_vadd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.460870</td>\n",
       "      <td>0.499142</td>\n",
       "      <td>0.492678</td>\n",
       "      <td>0.496392</td>\n",
       "      <td>0.609532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">{0: 0.5, 1: 0.5}</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>neutralidade_vadd4,positividade_vadd2,scored2,scored4,polaridade_vadd4,negatividade_vadd4,composicao_vad,neg_finbert,subjetividade_vadd4,subjetividade_vadd3,neu_finbert,pos_robd1,scored1,subjetividade_vadd2,composicao_vadd4,neg_robd1,neg_finbertd4,neg_rob,neu_robd4,neutralidade_vadd3,neg_finbertd2,neu_finbertd4,scored3,neutralidade_vadd1,negatividade_vadd3,pos_robd3,neutralidade_vadd2,score</th>\n",
       "      <td>3</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.487393</td>\n",
       "      <td>0.493833</td>\n",
       "      <td>0.599405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>neutralidade_vadd4,positividade_vadd2,scored2,scored4,polaridade_vadd4,negatividade_vadd4,composicao_vad,neg_finbert,subjetividade_vadd4,subjetividade_vadd3,neu_finbert,pos_robd1,scored1,subjetividade_vadd2,composicao_vadd4,neg_robd1,neg_finbertd4,neg_rob,neu_robd4,neutralidade_vadd3,neg_finbertd2,neu_finbertd4,scored3,neutralidade_vadd1,negatividade_vadd3,pos_robd3,neutralidade_vadd2,score</th>\n",
       "      <td>3</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.567376</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.487393</td>\n",
       "      <td>0.493833</td>\n",
       "      <td>0.596990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">{0: 0.7000000000000001, 1: 0.29999999999999993}</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">gini</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">None</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">RandomForest</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">80_2</th>\n",
       "      <th>4</th>\n",
       "      <th>neg_finbert,positividade_vad,scored4,neu_robd4,score,subjetividade_vadd1,neg_robd2,negatividade_vadd4,positividade_vadd2,neu_rob,negatividade_vadd2,pos_rob,subjetividade_vad,neg_finbertd4,negatividade_vadd1,composicao_vadd2,neu_robd3,scored2,positividade_vadd4,neutralidade_vadd1,neg_robd1,neu_finbertd1,scored3,pos_finbertd2,neg_finbertd1,composicao_vadd4,neu_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.578261</td>\n",
       "      <td>0.483332</td>\n",
       "      <td>0.493882</td>\n",
       "      <td>0.491258</td>\n",
       "      <td>0.597380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>neutralidade_vadd2,scored3,neg_rob,scored1,positividade_vadd4,pos_robd4,positividade_vadd1,neu_robd3,scored2,neu_finbertd4,negatividade_vadd1,pos_finbertd4,pos_robd3,pos_finbertd1,positividade_vadd2,neg_robd3,polaridade_vadd2,composicao_vadd3,neu_rob,neu_robd1,polaridade_vadd1,neu_finbert,composicao_vadd2,neu_robd2,positividade_vadd3,neu_finbertd3,negatividade_vad,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.536170</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.487852</td>\n",
       "      <td>0.474166</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0.593311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_finbertd4,negatividade_vadd2,neutralidade_vadd4,scored4,pos_robd3,subjetividade_vad,negatividade_vadd1,neu_finbertd2,scored2,positividade_vadd1,subjetividade_vadd4,neu_robd1,polaridade_vadd4,neg_finbertd2,pos_robd2,pos_robd4,neutralidade_vadd1,negatividade_vad,neg_robd4,neg_finbertd3,positividade_vadd2,neg_robd3,polaridade_vadd3,score,neg_rob,neu_finbertd1,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>0.489541</td>\n",
       "      <td>0.470090</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>0.594147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>pos_finbertd4,negatividade_vadd2,neutralidade_vadd4,scored4,pos_robd3,subjetividade_vad,negatividade_vadd1,neu_finbertd2,scored2,positividade_vadd1,subjetividade_vadd4,neu_robd1,polaridade_vadd4,neg_finbertd2,pos_robd2,pos_robd4,neutralidade_vadd1,negatividade_vad,neg_robd4,neg_finbertd3,positividade_vadd2,neg_robd3,polaridade_vadd3,score,neg_rob,neu_finbertd1,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>0.489695</td>\n",
       "      <td>0.469920</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>0.592865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>neutralidade_vadd2,scored3,neg_rob,scored1,positividade_vadd4,pos_robd4,positividade_vadd1,neu_robd3,scored2,neu_finbertd4,negatividade_vadd1,pos_finbertd4,pos_robd3,pos_finbertd1,positividade_vadd2,neg_robd3,polaridade_vadd2,composicao_vadd3,neu_rob,neu_robd1,polaridade_vadd1,neu_finbert,composicao_vadd2,neu_robd2,positividade_vadd3,neu_finbertd3,negatividade_vad,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.479570</td>\n",
       "      <td>0.527660</td>\n",
       "      <td>0.430435</td>\n",
       "      <td>0.485574</td>\n",
       "      <td>0.472373</td>\n",
       "      <td>0.479047</td>\n",
       "      <td>0.592029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neutralidade_vadd2,scored3,neg_rob,scored1,positividade_vadd4,pos_robd4,positividade_vadd1,neu_robd3,scored2,neu_finbertd4,negatividade_vadd1,pos_finbertd4,pos_robd3,pos_finbertd1,positividade_vadd2,neg_robd3,polaridade_vadd2,composicao_vadd3,neu_rob,neu_robd1,polaridade_vadd1,neu_finbert,composicao_vadd2,neu_robd2,positividade_vadd3,neu_finbertd3,negatividade_vad,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.479570</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.426087</td>\n",
       "      <td>0.485891</td>\n",
       "      <td>0.471843</td>\n",
       "      <td>0.479001</td>\n",
       "      <td>0.593311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>pos_finbertd4,negatividade_vadd2,neutralidade_vadd4,scored4,pos_robd3,subjetividade_vad,negatividade_vadd1,neu_finbertd2,scored2,positividade_vadd1,subjetividade_vadd4,neu_robd1,polaridade_vadd4,neg_finbertd2,pos_robd2,pos_robd4,neutralidade_vadd1,negatividade_vad,neg_robd4,neg_finbertd3,positividade_vadd2,neg_robd3,polaridade_vadd3,score,neg_rob,neu_finbertd1,pos_robd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.479570</td>\n",
       "      <td>0.570213</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.488118</td>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.478585</td>\n",
       "      <td>0.592865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_finbertd1,neu_robd2,score,neg_robd3,neu_finbertd3,neu_rob,subjetividade_vad,neu_robd4,negatividade_vadd4,composicao_vadd3,neu_finbertd2,neutralidade_vadd1,neg_rob,positividade_vadd3,pos_finbertd4,neg_robd2,composicao_vadd2,positividade_vadd4,neutralidade_vadd3,positividade_vad,pos_finbert,neg_finbertd3,scored1,pos_robd2,subjetividade_vadd1,pos_robd1,pos_finbertd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.468817</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.360870</td>\n",
       "      <td>0.478920</td>\n",
       "      <td>0.449447</td>\n",
       "      <td>0.467669</td>\n",
       "      <td>0.581828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>neu_finbertd1,neu_robd2,score,neg_robd3,neu_finbertd3,neu_rob,subjetividade_vad,neu_robd4,negatividade_vadd4,composicao_vadd3,neu_finbertd2,neutralidade_vadd1,neg_rob,positividade_vadd3,pos_finbertd4,neg_robd2,composicao_vadd2,positividade_vadd4,neutralidade_vadd3,positividade_vad,pos_finbert,neg_finbertd3,scored1,pos_robd2,subjetividade_vadd1,pos_robd1,pos_finbertd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.578723</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.476043</td>\n",
       "      <td>0.442233</td>\n",
       "      <td>0.463275</td>\n",
       "      <td>0.580881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>neu_finbertd1,neu_robd2,score,neg_robd3,neu_finbertd3,neu_rob,subjetividade_vad,neu_robd4,negatividade_vadd4,composicao_vadd3,neu_finbertd2,neutralidade_vadd1,neg_rob,positividade_vadd3,pos_finbertd4,neg_robd2,composicao_vadd2,positividade_vadd4,neutralidade_vadd3,positividade_vad,pos_finbert,neg_finbertd3,scored1,pos_robd2,subjetividade_vadd1,pos_robd1,pos_finbertd1,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.462366</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.473592</td>\n",
       "      <td>0.439986</td>\n",
       "      <td>0.461147</td>\n",
       "      <td>0.581996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>positividade_vadd2,polaridade_vadd3,neg_finbertd1,scored2,neutralidade_vadd2,negatividade_vadd1,scored3,neu_finbertd3,composicao_vadd2,pos_robd1,neu_finbertd2,neg_finbertd4,subjetividade_vad,neutralidade_vadd3,neutralidade_vad,subjetividade_vadd4,neu_robd4,polaridade_vadd2,pos_rob,negatividade_vad,neg_finbertd2,neg_robd4,polaridade_vadd4,neu_finbert,pos_finbertd4,neg_finbert,pos_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.453763</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.464987</td>\n",
       "      <td>0.439070</td>\n",
       "      <td>0.453284</td>\n",
       "      <td>0.610033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>positividade_vadd2,polaridade_vadd3,neg_finbertd1,scored2,neutralidade_vadd2,negatividade_vadd1,scored3,neu_finbertd3,composicao_vadd2,pos_robd1,neu_finbertd2,neg_finbertd4,subjetividade_vad,neutralidade_vadd3,neutralidade_vad,subjetividade_vadd4,neu_robd4,polaridade_vadd2,pos_rob,negatividade_vad,neg_finbertd2,neg_robd4,polaridade_vadd4,neu_finbert,pos_finbertd4,neg_finbert,pos_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.453763</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.465044</td>\n",
       "      <td>0.438896</td>\n",
       "      <td>0.453284</td>\n",
       "      <td>0.610201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>positividade_vadd2,polaridade_vadd3,neg_finbertd1,scored2,neutralidade_vadd2,negatividade_vadd1,scored3,neu_finbertd3,composicao_vadd2,pos_robd1,neu_finbertd2,neg_finbertd4,subjetividade_vad,neutralidade_vadd3,neutralidade_vad,subjetividade_vadd4,neu_robd4,polaridade_vadd2,pos_rob,negatividade_vad,neg_finbertd2,neg_robd4,polaridade_vadd4,neu_finbert,pos_finbertd4,neg_finbert,pos_finbertd2,score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.404348</td>\n",
       "      <td>0.463429</td>\n",
       "      <td>0.435798</td>\n",
       "      <td>0.451110</td>\n",
       "      <td>0.610033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                          contagem_exp  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                           \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...             5   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...             5   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...             5   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...             5   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...             5   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...             5   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...             5   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...             5   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...             5   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...             5   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...             5   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...             5   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...             5   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...             3   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...             5   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...             3   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...             3   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...             5   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...             5   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...             5   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...             5   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...             5   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...             5   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...             5   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...             5   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...             5   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...             5   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...             5   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...             5   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...             5   \n",
       "\n",
       "                                                                                                                                                                                          acuracia  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.531183   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.529032   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.524731   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.516129   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.511828   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.509677   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.507527   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.507527   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.505376   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.505376   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.503226   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.503226   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.501075   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.501075   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.501075   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.501075   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.496774   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.498208   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.496774   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.494624   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.494624   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.490323   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.481720   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.481720   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.481720   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.479570   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.479570   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.479570   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.468817   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.464516   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.462366   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.453763   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.453763   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.451613   \n",
       "\n",
       "                                                                                                                                                                                          recall_0  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.519149   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514894   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514894   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.574468   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.557447   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.557447   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.608511   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.608511   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.553191   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.561702   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.540426   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.553191   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.421277   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.536170   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.548936   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.595745   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.417021   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.574468   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.531915   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.567376   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.567376   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.404255   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.536170   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.565957   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.565957   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.527660   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.531915   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.570213   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.574468   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.578723   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.574468   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.497872   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.497872   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.497872   \n",
       "\n",
       "                                                                                                                                                                                          recall_1  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.543478   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.543478   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.534783   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.456522   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.465217   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.460870   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.404348   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.404348   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.456522   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.447826   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.465217   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.452174   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.582609   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.465217   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.452174   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.404348   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.578261   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.420290   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.460870   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.420290   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.420290   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.578261   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.426087   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.395652   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.395652   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.430435   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.426087   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.386957   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.360870   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.347826   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.347826   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.408696   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.408696   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.404348   \n",
       "\n",
       "                                                                                                                                                                                            prec_0  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.547552   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.544404   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.537197   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.523422   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.506457   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.504581   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.507874   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.507874   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.500574   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.510418   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.505567   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.508780   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.497038   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.502358   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.505996   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.501805   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.493137   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.503145   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.499142   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.500000   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.500000   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.483332   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.487852   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.489541   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.489695   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.485574   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.485891   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.488118   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.478920   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.476043   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.473592   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.464987   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.465044   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.463429   \n",
       "\n",
       "                                                                                                                                                                                            prec_1  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.519533   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.517512   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.514471   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.505612   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.517122   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.514582   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.510761   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.510761   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.509921   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.498889   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.499566   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.495879   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.503629   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.497984   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.494955   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.502766   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.498660   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.491453   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.492678   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.487393   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.487393   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.493882   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.474166   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.470090   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.469920   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.472373   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.471843   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.466400   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.449447   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.442233   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.439986   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.439070   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.438896   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.435798   \n",
       "\n",
       "                                                                                                                                                                                               auc  \\\n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.531314   \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.529186   \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...  0.524838   \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...  0.515495   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.511332   \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.509158   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...  0.506429   \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...  0.506429   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...  0.504857   \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.504764   \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.502821   \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.502683   \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.501943   \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.500694   \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...  0.500555   \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...  0.500046   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.497641   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.497379   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...  0.496392   \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.493833   \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...  0.493833   \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...  0.491258   \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.481129   \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.480805   \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.480805   \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.479047   \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...  0.479001   \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...  0.478585   \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.467669   \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.463275   \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...  0.461147   \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.453284   \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.453284   \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...  0.451110   \n",
       "\n",
       "                                                                                                                                                                                          auc_valid  \n",
       "class_weight                                    criterion max_depth min_samples_leaf min_samples_split modelo       Sentilex num_pipe features                                                       \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.615775  \n",
       "                                                                                                                             6        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.613043  \n",
       "                                                                                                                             5        neg_robd4,pos_finbertd1,neu_robd1,polaridade_va...   0.612876  \n",
       "                                                                                                                             6        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.595095  \n",
       "                                                                                                                             5        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.595095  \n",
       "                                                                                                                             4        negatividade_vadd4,pos_finbertd4,neutralidade_v...   0.596544  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...   0.608027  \n",
       "                                                                                                                             6        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...   0.606745  \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     5        neutralidade_vadd4,subjetividade_vad,composicao...   0.605463  \n",
       "                                                                                                                             6        neutralidade_vadd4,subjetividade_vad,composicao...   0.601115  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        scored2,neu_robd3,neu_rob,neutralidade_vadd1,po...   0.609476  \n",
       "                                                                                                                             5        pos_finbert,negatividade_vadd3,neutralidade_vad...   0.593032  \n",
       "                                                                                                                             6        subjetividade_vadd1,scored1,pos_finbertd2,neutr...   0.612096  \n",
       "                                                                                                                             4        pos_finbert,negatividade_vadd3,neutralidade_vad...   0.593032  \n",
       "                                                                                                                             6        neg_finbert,positividade_vad,scored4,neu_robd4,...   0.597380  \n",
       "                                                                                                                             5        subjetividade_vadd1,scored1,pos_finbertd2,neutr...   0.610814  \n",
       "                                                                                                                             6        pos_finbert,negatividade_vadd3,neutralidade_vad...   0.591583  \n",
       "{0: 0.9, 1: 0.09999999999999998}                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,subjetividade_vad,composicao...   0.609309  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     5        neg_finbert,positividade_vad,scored4,neu_robd4,...   0.597380  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     6        neutralidade_vadd4,positividade_vadd2,scored2,s...   0.599405  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        subjetividade_vadd1,scored1,pos_finbertd2,neutr...   0.609532  \n",
       "{0: 0.5, 1: 0.5}                                gini      None      1                2                 RandomForest 80_2     4        neutralidade_vadd4,positividade_vadd2,scored2,s...   0.599405  \n",
       "                                                                                                                             5        neutralidade_vadd4,positividade_vadd2,scored2,s...   0.596990  \n",
       "{0: 0.7000000000000001, 1: 0.29999999999999993} gini      None      1                2                 RandomForest 80_2     4        neg_finbert,positividade_vad,scored4,neu_robd4,...   0.597380  \n",
       "                                                                                                                             5        neutralidade_vadd2,scored3,neg_rob,scored1,posi...   0.593311  \n",
       "                                                                                                                                      pos_finbertd4,negatividade_vadd2,neutralidade_v...   0.594147  \n",
       "                                                                                                                             6        pos_finbertd4,negatividade_vadd2,neutralidade_v...   0.592865  \n",
       "                                                                                                                             4        neutralidade_vadd2,scored3,neg_rob,scored1,posi...   0.592029  \n",
       "                                                                                                                             6        neutralidade_vadd2,scored3,neg_rob,scored1,posi...   0.593311  \n",
       "                                                                                                                             4        pos_finbertd4,negatividade_vadd2,neutralidade_v...   0.592865  \n",
       "                                                                                                                                      neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...   0.581828  \n",
       "                                                                                                                             5        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...   0.580881  \n",
       "                                                                                                                             6        neu_finbertd1,neu_robd2,score,neg_robd3,neu_fin...   0.581996  \n",
       "                                                                                                                             5        positividade_vadd2,polaridade_vadd3,neg_finbert...   0.610033  \n",
       "                                                                                                                             6        positividade_vadd2,polaridade_vadd3,neg_finbert...   0.610201  \n",
       "                                                                                                                             4        positividade_vadd2,polaridade_vadd3,neg_finbert...   0.610033  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agrupado[(df_agrupado['contagem_exp']>1)].sort_values(by='auc', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos que performaram melhor, independente do número de vezes que foram selecionados nos experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>seed</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th>seed_holdout</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>324</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...</td>\n",
       "      <td>4830</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.603145</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...</td>\n",
       "      <td>4830</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.592276</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>322</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...</td>\n",
       "      <td>4830</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.592276</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>325</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_...</td>\n",
       "      <td>9787</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.591119</td>\n",
       "      <td>0.591137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>neg_finbert,positividade_vad,scored4,neu_robd4...</td>\n",
       "      <td>8915</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.579787</td>\n",
       "      <td>0.580825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>338</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>negatividade_vad,neutralidade_vad,positividade...</td>\n",
       "      <td>3394</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.581382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>339</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>negatividade_vad,neutralidade_vad,positividade...</td>\n",
       "      <td>3394</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.570305</td>\n",
       "      <td>0.587793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>268</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>neg_finbert,positividade_vad,scored4,neu_robd4...</td>\n",
       "      <td>8915</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.587235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>269</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>neg_finbert,positividade_vad,scored4,neu_robd4...</td>\n",
       "      <td>8915</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.569149</td>\n",
       "      <td>0.587235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...</td>\n",
       "      <td>1780</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.568686</td>\n",
       "      <td>0.642419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...</td>\n",
       "      <td>1780</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.568686</td>\n",
       "      <td>0.642419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...</td>\n",
       "      <td>1780</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.568686</td>\n",
       "      <td>0.642419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>274</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5563</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55814</td>\n",
       "      <td>0.558742</td>\n",
       "      <td>0.595039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>276</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5563</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55814</td>\n",
       "      <td>0.558742</td>\n",
       "      <td>0.601449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5563</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55814</td>\n",
       "      <td>0.558742</td>\n",
       "      <td>0.601449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,neutralidad...</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.643255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,neutralidad...</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.558279</td>\n",
       "      <td>0.643255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,neutralidad...</td>\n",
       "      <td>2193</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.558048</td>\n",
       "      <td>0.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...</td>\n",
       "      <td>1755</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...</td>\n",
       "      <td>1755</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...</td>\n",
       "      <td>1755</td>\n",
       "      <td>0.55914</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.557817</td>\n",
       "      <td>0.585284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>289</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>score,subjetividade_vad,composicao_vad,neu_rob...</td>\n",
       "      <td>5761</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.602285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5761</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.537068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5761</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.537068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>292</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>5761</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.537068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>343</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,positividad...</td>\n",
       "      <td>720</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>344</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,positividad...</td>\n",
       "      <td>720</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>345</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>subjetividade_vad,negatividade_vad,positividad...</td>\n",
       "      <td>720</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.548335</td>\n",
       "      <td>0.529264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>208</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...</td>\n",
       "      <td>9322</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.54386</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.547179</td>\n",
       "      <td>0.653567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>6</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...</td>\n",
       "      <td>9322</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.54386</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.547179</td>\n",
       "      <td>0.659978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>219</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>negatividade_vad,neutralidade_vad,positividade...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>218</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>negatividade_vad,neutralidade_vad,positividade...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>217</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>negatividade_vad,neutralidade_vad,positividade...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.546716</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>161</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 0.9, 1: 0.09999999999999998}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>neutralidade_vadd4,subjetividade_vad,composica...</td>\n",
       "      <td>6763</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.546022</td>\n",
       "      <td>0.612598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 0.9, 1: 0.09999999999999998}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>neutralidade_vadd4,subjetividade_vad,composica...</td>\n",
       "      <td>6763</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.546022</td>\n",
       "      <td>0.605351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>304</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...</td>\n",
       "      <td>7098</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.607023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>225</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>polaridade_vad,neutralidade_vad,positividade_v...</td>\n",
       "      <td>9535</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.613434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>neg_finbert,positividade_vad,scored4,neu_robd4...</td>\n",
       "      <td>6177</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.618172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>neg_finbert,positividade_vad,scored4,neu_robd4...</td>\n",
       "      <td>6177</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.611761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>positividade_vadd2,polaridade_vadd3,neg_finber...</td>\n",
       "      <td>5179</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.60563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>positividade_vadd2,polaridade_vadd3,neg_finber...</td>\n",
       "      <td>5179</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.60563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>positividade_vadd2,polaridade_vadd3,neg_finber...</td>\n",
       "      <td>5179</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.538159</td>\n",
       "      <td>0.60563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>316</td>\n",
       "      <td>10</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...</td>\n",
       "      <td>1533</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.537928</td>\n",
       "      <td>0.632664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>222</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>6</td>\n",
       "      <td>subjetividade_vadd1,scored1,pos_finbertd2,neut...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.537234</td>\n",
       "      <td>0.598941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>220</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>subjetividade_vadd1,scored1,pos_finbertd2,neut...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.537234</td>\n",
       "      <td>0.598941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>221</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.7000000000000001, 1: 0.29999999999999993}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>5</td>\n",
       "      <td>subjetividade_vadd1,scored1,pos_finbertd2,neut...</td>\n",
       "      <td>2347</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.537234</td>\n",
       "      <td>0.592531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>277</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>1</td>\n",
       "      <td>polaridade_vad,subjetividade_vad,positividade_...</td>\n",
       "      <td>7242</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.556577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>279</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>3</td>\n",
       "      <td>polaridade_vad,subjetividade_vad,positividade_...</td>\n",
       "      <td>7242</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.563824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>280</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>4</td>\n",
       "      <td>negatividade_vadd4,pos_finbertd4,neutralidade_...</td>\n",
       "      <td>7242</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.579989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 0.5, 1: 0.5}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>80_2</td>\n",
       "      <td>2</td>\n",
       "      <td>polaridade_vad,subjetividade_vad,positividade_...</td>\n",
       "      <td>7242</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>0.556577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contagem_exp seed                                     class_weight  \\\n",
       "323          324   10                                 {0: 0.5, 1: 0.5}   \n",
       "322          323   10                                 {0: 0.5, 1: 0.5}   \n",
       "321          322   10                                 {0: 0.5, 1: 0.5}   \n",
       "324          325   10                                 {0: 0.5, 1: 0.5}   \n",
       "269          270    8  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "337          338   11                                 {0: 0.5, 1: 0.5}   \n",
       "338          339   11                                 {0: 0.5, 1: 0.5}   \n",
       "267          268    8  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "268          269    8  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "189          190    6  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "190          191    6  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "191          192    6  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "273          274    9                                 {0: 0.5, 1: 0.5}   \n",
       "275          276    9                                 {0: 0.5, 1: 0.5}   \n",
       "274          275    9                                 {0: 0.5, 1: 0.5}   \n",
       "37            38    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "38            39    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "36            37    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "50            51    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "48            49    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "49            50    1  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "288          289    9                                 {0: 0.5, 1: 0.5}   \n",
       "293          294    9                                 {0: 0.5, 1: 0.5}   \n",
       "292          293    9                                 {0: 0.5, 1: 0.5}   \n",
       "291          292    9                                 {0: 0.5, 1: 0.5}   \n",
       "342          343   11                                 {0: 0.5, 1: 0.5}   \n",
       "343          344   11                                 {0: 0.5, 1: 0.5}   \n",
       "344          345   11                                 {0: 0.5, 1: 0.5}   \n",
       "207          208    6  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "208          209    6  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "218          219    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "217          218    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "216          217    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "160          161    5                 {0: 0.9, 1: 0.09999999999999998}   \n",
       "161          162    5                 {0: 0.9, 1: 0.09999999999999998}   \n",
       "303          304   10                                 {0: 0.5, 1: 0.5}   \n",
       "224          225    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "251          252    8  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "250          251    8  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "101          102    3  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "100          101    3  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "99           100    3  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "315          316   10                                 {0: 0.5, 1: 0.5}   \n",
       "221          222    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "219          220    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "220          221    7  {0: 0.7000000000000001, 1: 0.29999999999999993}   \n",
       "276          277    9                                 {0: 0.5, 1: 0.5}   \n",
       "278          279    9                                 {0: 0.5, 1: 0.5}   \n",
       "279          280    9                                 {0: 0.5, 1: 0.5}   \n",
       "277          278    9                                 {0: 0.5, 1: 0.5}   \n",
       "\n",
       "    criterion max_depth min_samples_leaf min_samples_split        modelo  \\\n",
       "323      gini      None                1                 2  RandomForest   \n",
       "322      gini      None                1                 2  RandomForest   \n",
       "321      gini      None                1                 2  RandomForest   \n",
       "324      gini      None                1                 2  RandomForest   \n",
       "269      gini      None                1                 2  RandomForest   \n",
       "337      gini      None                1                 2  RandomForest   \n",
       "338      gini      None                1                 2  RandomForest   \n",
       "267      gini      None                1                 2  RandomForest   \n",
       "268      gini      None                1                 2  RandomForest   \n",
       "189      gini      None                1                 2  RandomForest   \n",
       "190      gini      None                1                 2  RandomForest   \n",
       "191      gini      None                1                 2  RandomForest   \n",
       "273      gini      None                1                 2  RandomForest   \n",
       "275      gini      None                1                 2  RandomForest   \n",
       "274      gini      None                1                 2  RandomForest   \n",
       "37       gini      None                1                 2  RandomForest   \n",
       "38       gini      None                1                 2  RandomForest   \n",
       "36       gini      None                1                 2  RandomForest   \n",
       "50       gini      None                1                 2  RandomForest   \n",
       "48       gini      None                1                 2  RandomForest   \n",
       "49       gini      None                1                 2  RandomForest   \n",
       "288      gini      None                1                 2  RandomForest   \n",
       "293      gini      None                1                 2  RandomForest   \n",
       "292      gini      None                1                 2  RandomForest   \n",
       "291      gini      None                1                 2  RandomForest   \n",
       "342      gini      None                1                 2  RandomForest   \n",
       "343      gini      None                1                 2  RandomForest   \n",
       "344      gini      None                1                 2  RandomForest   \n",
       "207      gini      None                1                 2  RandomForest   \n",
       "208      gini      None                1                 2  RandomForest   \n",
       "218      gini      None                1                 2  RandomForest   \n",
       "217      gini      None                1                 2  RandomForest   \n",
       "216      gini      None                1                 2  RandomForest   \n",
       "160      gini      None                1                 2  RandomForest   \n",
       "161      gini      None                1                 2  RandomForest   \n",
       "303      gini      None                1                 2  RandomForest   \n",
       "224      gini      None                1                 2  RandomForest   \n",
       "251      gini      None                1                 2  RandomForest   \n",
       "250      gini      None                1                 2  RandomForest   \n",
       "101      gini      None                1                 2  RandomForest   \n",
       "100      gini      None                1                 2  RandomForest   \n",
       "99       gini      None                1                 2  RandomForest   \n",
       "315      gini      None                1                 2  RandomForest   \n",
       "221      gini      None                1                 2  RandomForest   \n",
       "219      gini      None                1                 2  RandomForest   \n",
       "220      gini      None                1                 2  RandomForest   \n",
       "276      gini      None                1                 2  RandomForest   \n",
       "278      gini      None                1                 2  RandomForest   \n",
       "279      gini      None                1                 2  RandomForest   \n",
       "277      gini      None                1                 2  RandomForest   \n",
       "\n",
       "    Sentilex num_pipe                                           features  \\\n",
       "323     80_2        6  neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...   \n",
       "322     80_2        5  neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...   \n",
       "321     80_2        4  neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...   \n",
       "324     80_2        1  subjetividade_vad,neg_rob,neu_rob,pos_rob,neu_...   \n",
       "269     80_2        6  neg_finbert,positividade_vad,scored4,neu_robd4...   \n",
       "337     80_2        2  negatividade_vad,neutralidade_vad,positividade...   \n",
       "338     80_2        3  negatividade_vad,neutralidade_vad,positividade...   \n",
       "267     80_2        4  neg_finbert,positividade_vad,scored4,neu_robd4...   \n",
       "268     80_2        5  neg_finbert,positividade_vad,scored4,neu_robd4...   \n",
       "189     80_2        4  scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...   \n",
       "190     80_2        5  scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...   \n",
       "191     80_2        6  scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...   \n",
       "273     80_2        4  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "275     80_2        6  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "274     80_2        5  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "37      80_2        2  subjetividade_vad,negatividade_vad,neutralidad...   \n",
       "38      80_2        3  subjetividade_vad,negatividade_vad,neutralidad...   \n",
       "36      80_2        1  subjetividade_vad,negatividade_vad,neutralidad...   \n",
       "50      80_2        3  neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...   \n",
       "48      80_2        1  neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...   \n",
       "49      80_2        2  neutralidade_vad,neg_rob,neu_rob,pos_rob,polar...   \n",
       "288     80_2        1  score,subjetividade_vad,composicao_vad,neu_rob...   \n",
       "293     80_2        6  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "292     80_2        5  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "291     80_2        4  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "342     80_2        1  subjetividade_vad,negatividade_vad,positividad...   \n",
       "343     80_2        2  subjetividade_vad,negatividade_vad,positividad...   \n",
       "344     80_2        3  subjetividade_vad,negatividade_vad,positividad...   \n",
       "207     80_2        4  scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...   \n",
       "208     80_2        5  scored2,neu_robd3,neu_rob,neutralidade_vadd1,p...   \n",
       "218     80_2        3  negatividade_vad,neutralidade_vad,positividade...   \n",
       "217     80_2        2  negatividade_vad,neutralidade_vad,positividade...   \n",
       "216     80_2        1  negatividade_vad,neutralidade_vad,positividade...   \n",
       "160     80_2        5  neutralidade_vadd4,subjetividade_vad,composica...   \n",
       "161     80_2        6  neutralidade_vadd4,subjetividade_vad,composica...   \n",
       "303     80_2        4  neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...   \n",
       "224     80_2        3  polaridade_vad,neutralidade_vad,positividade_v...   \n",
       "251     80_2        6  neg_finbert,positividade_vad,scored4,neu_robd4...   \n",
       "250     80_2        5  neg_finbert,positividade_vad,scored4,neu_robd4...   \n",
       "101     80_2        6  positividade_vadd2,polaridade_vadd3,neg_finber...   \n",
       "100     80_2        5  positividade_vadd2,polaridade_vadd3,neg_finber...   \n",
       "99      80_2        4  positividade_vadd2,polaridade_vadd3,neg_finber...   \n",
       "315     80_2        4  neg_robd4,pos_finbertd1,neu_robd1,polaridade_v...   \n",
       "221     80_2        6  subjetividade_vadd1,scored1,pos_finbertd2,neut...   \n",
       "219     80_2        4  subjetividade_vadd1,scored1,pos_finbertd2,neut...   \n",
       "220     80_2        5  subjetividade_vadd1,scored1,pos_finbertd2,neut...   \n",
       "276     80_2        1  polaridade_vad,subjetividade_vad,positividade_...   \n",
       "278     80_2        3  polaridade_vad,subjetividade_vad,positividade_...   \n",
       "279     80_2        4  negatividade_vadd4,pos_finbertd4,neutralidade_...   \n",
       "277     80_2        2  polaridade_vad,subjetividade_vad,positividade_...   \n",
       "\n",
       "    seed_holdout  acuracia  recall_0  recall_1    prec_0    prec_1       auc  \\\n",
       "323         4830  0.602151  0.510638  0.695652  0.631579  0.581818  0.603145   \n",
       "322         4830  0.591398  0.510638  0.673913  0.615385  0.574074  0.592276   \n",
       "321         4830  0.591398  0.510638  0.673913  0.615385  0.574074  0.592276   \n",
       "324         9787  0.591398  0.617021  0.565217  0.591837  0.590909  0.591119   \n",
       "269         8915  0.580645  0.659574       0.5  0.574074  0.589744  0.579787   \n",
       "337         3394  0.569892  0.531915  0.608696  0.581395      0.56  0.570305   \n",
       "338         3394  0.569892  0.531915  0.608696  0.581395      0.56  0.570305   \n",
       "267         8915  0.569892  0.638298       0.5  0.566038     0.575  0.569149   \n",
       "268         8915  0.569892  0.638298       0.5  0.566038     0.575  0.569149   \n",
       "189         1780  0.569892  0.680851  0.456522  0.561404  0.583333  0.568686   \n",
       "190         1780  0.569892  0.680851  0.456522  0.561404  0.583333  0.568686   \n",
       "191         1780  0.569892  0.680851  0.456522  0.561404  0.583333  0.568686   \n",
       "273         5563   0.55914  0.595745  0.521739      0.56   0.55814  0.558742   \n",
       "275         5563   0.55914  0.595745  0.521739      0.56   0.55814  0.558742   \n",
       "274         5563   0.55914  0.595745  0.521739      0.56   0.55814  0.558742   \n",
       "37          2193   0.55914  0.638298  0.478261  0.555556  0.564103  0.558279   \n",
       "38          2193   0.55914  0.638298  0.478261  0.555556  0.564103  0.558279   \n",
       "36          2193   0.55914  0.659574  0.456522  0.553571  0.567568  0.558048   \n",
       "50          1755   0.55914  0.680851  0.434783  0.551724  0.571429  0.557817   \n",
       "48          1755   0.55914  0.680851  0.434783  0.551724  0.571429  0.557817   \n",
       "49          1755   0.55914  0.680851  0.434783  0.551724  0.571429  0.557817   \n",
       "288         5761  0.548387  0.489362  0.608696  0.560976  0.538462  0.549029   \n",
       "293         5761  0.548387  0.489362  0.608696  0.560976  0.538462  0.549029   \n",
       "292         5761  0.548387  0.489362  0.608696  0.560976  0.538462  0.549029   \n",
       "291         5761  0.548387  0.489362  0.608696  0.560976  0.538462  0.549029   \n",
       "342          720  0.548387  0.553191  0.543478  0.553191  0.543478  0.548335   \n",
       "343          720  0.548387  0.553191  0.543478  0.553191  0.543478  0.548335   \n",
       "344          720  0.548387  0.553191  0.543478  0.553191  0.543478  0.548335   \n",
       "207         9322  0.548387  0.659574  0.434783   0.54386  0.555556  0.547179   \n",
       "208         9322  0.548387  0.659574  0.434783   0.54386  0.555556  0.547179   \n",
       "218         2347  0.548387  0.702128  0.391304  0.540984    0.5625  0.546716   \n",
       "217         2347  0.548387  0.702128  0.391304  0.540984    0.5625  0.546716   \n",
       "216         2347  0.548387  0.702128  0.391304  0.540984    0.5625  0.546716   \n",
       "160         6763  0.548387  0.765957  0.326087  0.537313  0.576923  0.546022   \n",
       "161         6763  0.548387  0.765957  0.326087  0.537313  0.576923  0.546022   \n",
       "303         7098  0.537634  0.319149   0.76087  0.576923  0.522388  0.540009   \n",
       "224         9535  0.537634  0.425532  0.652174  0.555556  0.526316  0.538853   \n",
       "251         6177  0.537634  0.489362  0.586957  0.547619  0.529412  0.538159   \n",
       "250         6177  0.537634  0.489362  0.586957  0.547619  0.529412  0.538159   \n",
       "101         5179  0.537634  0.489362  0.586957  0.547619  0.529412  0.538159   \n",
       "100         5179  0.537634  0.489362  0.586957  0.547619  0.529412  0.538159   \n",
       "99          5179  0.537634  0.489362  0.586957  0.547619  0.529412  0.538159   \n",
       "315         1533  0.537634  0.510638  0.565217  0.545455  0.530612  0.537928   \n",
       "221         2347  0.537634  0.574468       0.5      0.54  0.534884  0.537234   \n",
       "219         2347  0.537634  0.574468       0.5      0.54  0.534884  0.537234   \n",
       "220         2347  0.537634  0.574468       0.5      0.54  0.534884  0.537234   \n",
       "276         7242  0.537634  0.595745  0.478261  0.538462  0.536585  0.537003   \n",
       "278         7242  0.537634  0.595745  0.478261  0.538462  0.536585  0.537003   \n",
       "279         7242  0.537634  0.595745  0.478261  0.538462  0.536585  0.537003   \n",
       "277         7242  0.537634  0.595745  0.478261  0.538462  0.536585  0.537003   \n",
       "\n",
       "    auc_valid  \n",
       "323  0.641583  \n",
       "322  0.641583  \n",
       "321  0.641583  \n",
       "324  0.591137  \n",
       "269  0.580825  \n",
       "337  0.581382  \n",
       "338  0.587793  \n",
       "267  0.587235  \n",
       "268  0.587235  \n",
       "189  0.642419  \n",
       "190  0.642419  \n",
       "191  0.642419  \n",
       "273  0.595039  \n",
       "275  0.601449  \n",
       "274  0.601449  \n",
       "37   0.643255  \n",
       "38   0.643255  \n",
       "36   0.630435  \n",
       "50   0.585284  \n",
       "48   0.585284  \n",
       "49   0.585284  \n",
       "288  0.602285  \n",
       "293  0.537068  \n",
       "292  0.537068  \n",
       "291  0.537068  \n",
       "342  0.529264  \n",
       "343  0.529264  \n",
       "344  0.529264  \n",
       "207  0.653567  \n",
       "208  0.659978  \n",
       "218  0.592531  \n",
       "217  0.592531  \n",
       "216  0.592531  \n",
       "160  0.612598  \n",
       "161  0.605351  \n",
       "303  0.607023  \n",
       "224  0.613434  \n",
       "251  0.618172  \n",
       "250  0.611761  \n",
       "101   0.60563  \n",
       "100   0.60563  \n",
       "99    0.60563  \n",
       "315  0.632664  \n",
       "221  0.598941  \n",
       "219  0.598941  \n",
       "220  0.592531  \n",
       "276  0.556577  \n",
       "278  0.563824  \n",
       "279  0.579989  \n",
       "277  0.556577  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_df_model1.sort_values(by='auc', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armazenamento do melhor modelo RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('RandomForest',\n",
       "                 RandomForestClassifier(class_weight={0: 0.1, 1: 0.9},\n",
       "                                        n_jobs=-1, random_state=73))])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhor_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVO MÍNIMO LOCAL ENCONTRADO:  RandomForest - AUC = 0.731036077705828 - num_seed_aleatoria = 3 - versao_sentilex = 80_2\n",
    "     Experimento número = 17\n",
    "     Características pipeline: num_pipeline = 2 - tipo_scaler = Sem Scaler\n",
    "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
    "     Features Selecionadas = pos_rob,neutralidade_vadd4,pos_robd1,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo-RF.pkl']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import joblib\n",
    "#joblib.dump(melhor_modelo, 'modelo-RF.pkl',compress=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Importance RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('seletor',\n",
       "                 SelectFromModel(estimator=RandomForestClassifier(class_weight={0: 0.1,\n",
       "                                                                                1: 0.9},\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=3),\n",
       "                                 max_features=4, threshold=-inf)),\n",
       "                ('RandomForest',\n",
       "                 RandomForestClassifier(class_weight={0: 0.1, 1: 0.9},\n",
       "                                        n_jobs=-1, random_state=3))])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "melhor_modelo_rf = joblib.load(open(os.path.join('modelo-RF.pkl'),\"rb\"))\n",
    "melhor_modelo_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = melhor_modelo_rf['RandomForest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.1, 1: 0.9}, n_jobs=-1, random_state=3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versao_sentilex = '80_2'\n",
    "#features_selecionadas =  ['pos_robd1','pos_rob','neutralidade_vadd4','score']\n",
    "#features_selecionadas = ['subjetividade_vadd1','subjetividade_vadd2','negatividade_vadd1','neutralidade_vad','score']\n",
    "features_selecionadas = ['pos_rob','neutralidade_vadd4','pos_robd1','score']\n",
    "seed = 73\n",
    "\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "#X_test4 = df_test[.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)]\n",
    "X_test4 = df_test[features_selecionadas]\n",
    "y_test4 = df_test['Fechamento']\n",
    "\n",
    "#X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_train4 = df_train[features_selecionadas]\n",
    "y_train4 = df_train['Fechamento']\n",
    "\n",
    "#X_valid4 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_valid4 = df_valid[features_selecionadas]\n",
    "y_valid4 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "rf.fit(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validacao:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74        47\n",
      "           1       0.73      0.72      0.73        46\n",
      "\n",
      "    accuracy                           0.73        93\n",
      "   macro avg       0.73      0.73      0.73        93\n",
      "weighted avg       0.73      0.73      0.73        93\n",
      "\n",
      "\n",
      "Confusion Matrix Dados - Validacao:\n",
      " [[35 12]\n",
      " [13 33]]\n",
      "\n",
      "Recall_0: 0.7446808510638298\n",
      "Recall_1: 0.717391304347826\n",
      "Precision_0: 0.7291666666666666\n",
      "Precision_1: 0.7333333333333333\n",
      "Acuracia: 0.7311827956989247\n",
      "Acuracia Balanceada: 0.7310360777058279\n",
      "AUC: 0.731036077705828\n"
     ]
    }
   ],
   "source": [
    "#predict validacao\n",
    "p = rf.predict(X_test4)\n",
    "\n",
    "############ Métricas #################\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report - Validacao:\\n\",classification_report(y_test4, p))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados - Validacao:\\n\",confusion_matrix(y_test4, p))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test4, p, pos_label=0)\n",
    "recall_1 = recall_score(y_test4, p, pos_label=1)\n",
    "\n",
    "#Calculando Precision\n",
    "precision_0 = precision_score(y_test4, p, pos_label = 0)\n",
    "precision_1 = precision_score(y_test4, p, pos_label = 1)\n",
    "\n",
    "#Calculando acurácia\n",
    "accuracy = accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test4, p)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Precision_0: %s\" % (precision_0))\n",
    "print(\"Precision_1: %s\" % (precision_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lista de features\n",
    "features_names = X_train4.columns.tolist()\n",
    "class_names = ['Queda','Subida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_robd1             0.320396\n",
       "pos_rob               0.313004\n",
       "neutralidade_vadd4    0.259611\n",
       "score                 0.106989\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(rf.feature_importances_,index=features_names).sort_values(ascending=False)\n",
    "feature_imp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualiza_features_importantes(features_lista):\n",
    "    %matplotlib inline\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    sns.barplot(x=features_lista, y=features_lista.index)\n",
    "\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(\"Visualizing Important Features\")\n",
    "    plt.show()\n",
    "    \n",
    "visualiza_features_importantes(feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0 Experimentos - ExtraTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 0\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.6133209990749307 - num_seed_aleatoria = 0 - versao_sentilex = 70_4\n",
      "     Experimento número = 1\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = positividade_vad,pos_finbert,neutralidade_vadd2,score\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  ExtraTree - AUC = 0.6133209990749307 - num_seed_aleatoria = 0 - versão sentilex = 70_4\n",
      "============================================================================================================================\n",
      "Iterando seed = 1\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.6787696577243294 - num_seed_aleatoria = 1 - versao_sentilex = 70_4\n",
      "     Experimento número = 2\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = positividade_vad,pos_finbert,neutralidade_vadd2,score\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  ExtraTree - AUC = 0.6787696577243294 - num_seed_aleatoria = 1 - versão sentilex = 70_4\n",
      "============================================================================================================================\n",
      "Iterando seed = 2\n",
      "Iterando seed = 3\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.688945420906568 - num_seed_aleatoria = 3 - versao_sentilex = 70_4\n",
      "     Experimento número = 4\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = positividade_vad,pos_finbert,neutralidade_vadd2,score\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  ExtraTree - AUC = 0.688945420906568 - num_seed_aleatoria = 3 - versão sentilex = 70_4\n",
      "============================================================================================================================\n",
      "Iterando seed = 4\n",
      "Iterando seed = 5\n",
      "Iterando seed = 6\n",
      "Iterando seed = 7\n",
      "Iterando seed = 8\n",
      "Iterando seed = 9\n",
      "Iterando seed = 10\n",
      "Iterando seed = 11\n",
      "Iterando seed = 12\n",
      "Iterando seed = 13\n",
      "Iterando seed = 14\n",
      "Iterando seed = 15\n",
      "Iterando seed = 16\n",
      "Iterando seed = 17\n",
      "Iterando seed = 18\n",
      "Iterando seed = 19\n",
      "Iterando seed = 20\n",
      "Iterando seed = 21\n",
      "Iterando seed = 22\n",
      "Iterando seed = 23\n",
      "Iterando seed = 24\n",
      "Iterando seed = 25\n",
      "Iterando seed = 26\n",
      "Iterando seed = 27\n",
      "Iterando seed = 28\n",
      "Iterando seed = 29\n",
      "Iterando seed = 30\n",
      "Iterando seed = 31\n",
      "Iterando seed = 32\n",
      "Iterando seed = 33\n",
      "Iterando seed = 34\n",
      "Iterando seed = 35\n",
      "Iterando seed = 36\n",
      "Iterando seed = 37\n",
      "Iterando seed = 38\n",
      "Iterando seed = 39\n",
      "Iterando seed = 40\n",
      "Iterando seed = 41\n",
      "Iterando seed = 42\n",
      "Iterando seed = 43\n",
      "Iterando seed = 44\n",
      "Iterando seed = 45\n",
      "Iterando seed = 46\n",
      "Iterando seed = 47\n",
      "Iterando seed = 48\n",
      "Iterando seed = 49\n",
      "Iterando seed = 50\n",
      "Iterando seed = 51\n",
      "Iterando seed = 52\n",
      "Iterando seed = 53\n",
      "Iterando seed = 54\n",
      "Iterando seed = 55\n",
      "Iterando seed = 56\n",
      "Iterando seed = 57\n",
      "Iterando seed = 58\n",
      "Iterando seed = 59\n",
      "Iterando seed = 60\n",
      "Iterando seed = 61\n",
      "Iterando seed = 62\n",
      "Iterando seed = 63\n",
      "Iterando seed = 64\n",
      "Iterando seed = 65\n",
      "Iterando seed = 66\n",
      "Iterando seed = 67\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.6995837187789085 - num_seed_aleatoria = 67 - versao_sentilex = 70_4\n",
      "     Experimento número = 68\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
      "     Features Selecionadas = positividade_vad,pos_finbert,neutralidade_vadd2,score\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  ExtraTree - AUC = 0.6995837187789085 - num_seed_aleatoria = 67 - versão sentilex = 70_4\n",
      "============================================================================================================================\n",
      "Iterando seed = 68\n",
      "Iterando seed = 69\n",
      "Iterando seed = 70\n",
      "Iterando seed = 71\n",
      "Iterando seed = 72\n",
      "Iterando seed = 73\n",
      "Iterando seed = 74\n",
      "Iterando seed = 75\n",
      "Iterando seed = 76\n",
      "Iterando seed = 77\n",
      "Iterando seed = 78\n",
      "Iterando seed = 79\n",
      "Iterando seed = 80\n",
      "Iterando seed = 81\n",
      "Iterando seed = 82\n",
      "Iterando seed = 83\n",
      "Iterando seed = 84\n",
      "Iterando seed = 85\n",
      "Iterando seed = 86\n",
      "Iterando seed = 87\n",
      "Iterando seed = 88\n",
      "Iterando seed = 89\n",
      "Iterando seed = 90\n",
      "Iterando seed = 91\n",
      "Iterando seed = 92\n",
      "Iterando seed = 93\n",
      "Iterando seed = 94\n",
      "Iterando seed = 95\n",
      "Iterando seed = 96\n",
      "Iterando seed = 97\n",
      "Iterando seed = 98\n",
      "Iterando seed = 99\n",
      "Iterando seed = 100\n",
      "Iterando seed = 101\n",
      "Iterando seed = 102\n",
      "Iterando seed = 103\n",
      "Iterando seed = 104\n",
      "Iterando seed = 105\n",
      "Iterando seed = 106\n",
      "Iterando seed = 107\n",
      "Iterando seed = 108\n",
      "Iterando seed = 109\n",
      "Iterando seed = 110\n",
      "Iterando seed = 111\n",
      "Iterando seed = 112\n",
      "Iterando seed = 113\n",
      "Iterando seed = 114\n",
      "Iterando seed = 115\n",
      "Iterando seed = 116\n",
      "Iterando seed = 117\n",
      "Iterando seed = 118\n",
      "Iterando seed = 119\n",
      "Iterando seed = 120\n",
      "Iterando seed = 121\n",
      "Iterando seed = 122\n",
      "Iterando seed = 123\n",
      "Iterando seed = 124\n",
      "Iterando seed = 125\n",
      "Iterando seed = 126\n",
      "Iterando seed = 127\n",
      "Iterando seed = 128\n",
      "Iterando seed = 129\n",
      "Iterando seed = 130\n",
      "Iterando seed = 131\n",
      "Iterando seed = 132\n",
      "Iterando seed = 133\n",
      "Iterando seed = 134\n",
      "Iterando seed = 135\n",
      "Iterando seed = 136\n",
      "Iterando seed = 137\n",
      "Iterando seed = 138\n",
      "Iterando seed = 139\n",
      "Iterando seed = 140\n",
      "Iterando seed = 141\n",
      "Iterando seed = 142\n",
      "Iterando seed = 143\n",
      "Iterando seed = 144\n",
      "Iterando seed = 145\n",
      "Iterando seed = 146\n",
      "Iterando seed = 147\n",
      "Iterando seed = 148\n",
      "Iterando seed = 149\n",
      "Iterando seed = 150\n",
      "Iterando seed = 151\n",
      "Iterando seed = 152\n",
      "Iterando seed = 153\n",
      "Iterando seed = 154\n",
      "Iterando seed = 155\n",
      "Iterando seed = 156\n",
      "Iterando seed = 157\n",
      "Iterando seed = 158\n",
      "Iterando seed = 159\n",
      "Iterando seed = 160\n",
      "Iterando seed = 161\n",
      "Iterando seed = 162\n",
      "Iterando seed = 163\n",
      "Iterando seed = 164\n",
      "Iterando seed = 165\n",
      "Iterando seed = 166\n",
      "Iterando seed = 167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando seed = 168\n",
      "Iterando seed = 169\n",
      "Iterando seed = 170\n",
      "Iterando seed = 171\n",
      "Iterando seed = 172\n",
      "Iterando seed = 173\n",
      "Iterando seed = 174\n",
      "Iterando seed = 175\n",
      "Iterando seed = 176\n",
      "Iterando seed = 177\n",
      "Iterando seed = 178\n",
      "Iterando seed = 179\n",
      "Iterando seed = 180\n",
      "Iterando seed = 181\n",
      "Iterando seed = 182\n",
      "Iterando seed = 183\n",
      "Iterando seed = 184\n",
      "Iterando seed = 185\n",
      "Iterando seed = 186\n",
      "Iterando seed = 187\n",
      "Iterando seed = 188\n",
      "Iterando seed = 189\n",
      "Iterando seed = 190\n",
      "Iterando seed = 191\n",
      "Iterando seed = 192\n",
      "Iterando seed = 193\n",
      "Iterando seed = 194\n",
      "Iterando seed = 195\n",
      "Iterando seed = 196\n",
      "Iterando seed = 197\n",
      "Iterando seed = 198\n",
      "Iterando seed = 199\n",
      "Iterando seed = 200\n",
      "Iterando seed = 201\n",
      "Iterando seed = 202\n",
      "Iterando seed = 203\n",
      "Iterando seed = 204\n",
      "Iterando seed = 205\n",
      "Iterando seed = 206\n",
      "Iterando seed = 207\n",
      "Iterando seed = 208\n",
      "Iterando seed = 209\n",
      "Iterando seed = 210\n",
      "Iterando seed = 211\n",
      "Iterando seed = 212\n",
      "Iterando seed = 213\n",
      "Iterando seed = 214\n",
      "Iterando seed = 215\n",
      "Iterando seed = 216\n",
      "Iterando seed = 217\n",
      "Iterando seed = 218\n",
      "Iterando seed = 219\n",
      "Iterando seed = 220\n",
      "Iterando seed = 221\n",
      "Iterando seed = 222\n",
      "Iterando seed = 223\n",
      "Iterando seed = 224\n",
      "Iterando seed = 225\n",
      "Iterando seed = 226\n",
      "Iterando seed = 227\n",
      "Iterando seed = 228\n",
      "Iterando seed = 229\n",
      "Iterando seed = 230\n",
      "Iterando seed = 231\n",
      "Iterando seed = 232\n",
      "Iterando seed = 233\n",
      "Iterando seed = 234\n",
      "Iterando seed = 235\n",
      "Iterando seed = 236\n",
      "Iterando seed = 237\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-4a11f6b225bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;31m#Fit dados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;31m#melhores hyperparametros:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "#Classweights testadas no algoritmo\n",
    "#weights = np.linspace(0.2,0.5,10) \n",
    "#weights = np.linspace(0.1,0.9,11)\n",
    "weights = np.linspace(0.1,0.9,5)\n",
    "\n",
    "\n",
    "list_class_weights = []\n",
    "for i in weights:\n",
    "    class_weight = {0: i, 1:1.0-i}\n",
    "    list_class_weights.append(class_weight)\n",
    "list_class_weights\n",
    "\n",
    "## Definição da função de refit no gridsearch acurácia balanceada:\n",
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "roc_score = make_scorer(roc_auc_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados, \"roc\": roc_score }\n",
    "\n",
    "\n",
    "maximo_auc = 0\n",
    "maximo_auc_model1 = 0\n",
    "maximo_auc_model2 = 0\n",
    "\n",
    "\n",
    "#Reset na lista de resultados dos modelos iterados e experimentos rodados.\n",
    "resultados_model1 = []\n",
    "resultados_model2 = []\n",
    "contagem_experimentos_unicos = 0\n",
    "\n",
    "\n",
    "#versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "versoes_sentilex = ['70_4']\n",
    "\n",
    "#Loop de seed aleatória\n",
    "for seed in range(30000):\n",
    "    \n",
    "    print(\"Iterando seed = {}\".format(seed))  \n",
    "        \n",
    "    ##Loop do dicionário Sentilex Escolhido: \n",
    "    for versao in versoes_sentilex:\n",
    "\n",
    "        df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "        df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "        df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "        #Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "        X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_test2 = df_test['Fechamento']\n",
    "\n",
    "        X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_train2 = df_train['Fechamento']\n",
    "\n",
    "        X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "        y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Na há balanceamento, portanto, para evitar mudar X_train3 para X_train2 em todo código iremos usar as variáveis:\n",
    "        X_test3 = X_test2\n",
    "        y_test3 = y_test2\n",
    "\n",
    "        X_train3 = X_train2\n",
    "        y_train3 = y_train2\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        ################ Definição de modelos candidatos ################\n",
    "        #model1 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "        #model2 = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "        model3 = ExtraTreeClassifier(random_state=seed)\n",
    "\n",
    "        #models = [model1,model2]\n",
    "        #nome_modelo = ['RandomForest', 'LGBM']\n",
    "\n",
    "        #models = [model1]\n",
    "        #nome_modelo = ['ExtraTree']\n",
    "\n",
    "        #models = [model2]\n",
    "        #nome_modelo = ['LGBM']\n",
    "        \n",
    "        models = [model3]\n",
    "        nome_modelo = ['ExtraTree']\n",
    "\n",
    "        \n",
    "        \n",
    "        ################ Definindo conjunto de treino + validacao para avaliar gridsearch nos dados de avaliação ################\n",
    "        ## Concatenando dados de treino e valid:\n",
    "        X_train_valid = pd.concat([X_train3, X_valid2], ignore_index = True )\n",
    "        y_train_valid = pd.concat([y_train3, y_valid2], ignore_index = True )\n",
    "\n",
    "\n",
    "        # The indices which have the value -1 will be kept in train.\n",
    "        train_indices = np.full((X_train3.shape[0],), -1, dtype=int)\n",
    "\n",
    "        # The indices which have zero or positive values, will be kept in valid\n",
    "        valid_indices = np.full((X_valid2.shape[0],), 0, dtype=int)\n",
    "        valid_fold = np.append(train_indices, valid_indices)\n",
    "\n",
    "        # definindo o conjunto de validação\n",
    "        ps = PredefinedSplit(valid_fold)\n",
    "\n",
    "\n",
    "        ############# Paramgrid de modelos ################\n",
    "\n",
    "        ##Grid model 1 RandomForest\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2,3,5,8,12], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None], \"min_samples_split\":[3], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20,40], \"min_samples_split\":[2,3,5,10,20], \"min_samples_leaf\":[1,3,5,10], \"criterion\":['gini','entropy']}\n",
    "        #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "\n",
    "        ##Grid model 2 LGBM\n",
    "        #param_grid2={\"max_depth\":[-1,10,20], \"learning_rate\":[0.1,0.01,0.001], \"n_estimators\":[100,50,200], \"num_leaves\":[31,5,10,50]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[250,300,400], \"num_leaves\":[2,5,8,12,16,20]}\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1,0.01], \"n_estimators\":[70,100,150,200], \"num_leaves\":[31,10,25,50,80,120]}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'boosting_type': ['gbdt', 'dart', 'goss', 'rf'] }\n",
    "        #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1], \"n_estimators\":[150,200], \"num_leaves\":[31,10,25], 'class_weight': list_class_weights}\n",
    "        #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'class_weight': list_class_weights }\n",
    "\n",
    "        \n",
    "        ##Grid model  ExtraTree\n",
    "        param_grid3={\"max_depth\":[None,10,20], \"criterion\":['gini', 'entropy', 'log_loss'], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3,5], 'class_weight': list_class_weights }\n",
    "\n",
    "        \n",
    "        #list_param_grids = [param_grid1, param_grid2]\n",
    "        #list_param_grids = [param_grid1]\n",
    "        list_param_grids = [param_grid3]\n",
    "\n",
    "        #list_param_grids = [param_grid2]\n",
    "        dictionary_paramgrid = dict(zip(models, list_param_grids))\n",
    "\n",
    "\n",
    "        \n",
    "        #Loop modelos\n",
    "        for num_modelo, model in enumerate(models):\n",
    "\n",
    "            nome_modelo_testado = nome_modelo[num_modelo]\n",
    "\n",
    "            param_grid = dictionary_paramgrid[model]\n",
    "\n",
    "            ############# GridSearch de modelos candidatos com todas features ################\n",
    "            gs = GridSearchCV(model , param_grid=param_grid, scoring=scoring,  refit=\"f1\", n_jobs=-1, cv = ps )\n",
    "\n",
    "            #Fit dados \n",
    "            gs.fit(X_train_valid,y_train_valid)\n",
    "\n",
    "            #melhores hyperparametros:\n",
    "            hyperparametros = list(gs.best_params_.values())\n",
    "            nome_hyperparametros = list(gs.best_params_.keys())\n",
    "\n",
    "\n",
    "            #melhor modelo\n",
    "            # CUIDADO: O atributo best_estimator_ retorna o melhor modelo ja treinado com o conjunto de dados\n",
    "            # passado pelo metodo gs.fit(), ou seja ja vem treinado com X_train_valid,y_train_valid, sendo, portanto\n",
    "            # necessário mais uma etapa de fit() do modelo tunado apenas com dados de treino.\n",
    "            modelo_tunado = gs.best_estimator_\n",
    "\n",
    "            # Refit no modelo tunado com apenas dados de treino para evitar overtting ao avaliar sobre dados de valid\n",
    "            modelo_tunado.fit(X_train3,y_train3)\n",
    "            \n",
    "\n",
    "            #Loop Seletor de features:\n",
    "            #for k in range(X_train3.shape[1]-2, X_train3.shape[1], 1):   #Iterar sobre n-1 total de features e n-3.\n",
    "            #for k in range(X_train3.shape[1]-1, X_train3.shape[1]+1, 1): #Iterar sobre n total de features e n-2\n",
    "\n",
    "            #for k in range(X_train3.shape[1], X_train3.shape[1]+1, 1):  ## Iterar sobre n total de features e n (n = max)\n",
    "\n",
    "            for k in range(4, 5, 1):  ## Iterar sobre 4 a 5 features\n",
    "\n",
    "                ## O seletor de features varia conforme a pipe de aleatório á SelectFromModel:\n",
    "\n",
    "                ################ Definição de Pipelines com modelo tunado ################\n",
    "                pipe1 = Pipeline([('scaler', StandardScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe2 = Pipeline([('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "                pipe3 = Pipeline([(nome_modelo_testado, modelo_tunado)])\n",
    "                pipe4 = Pipeline([('scaler', MinMaxScaler()), ('seletor',  SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)), (nome_modelo_testado, modelo_tunado)])\n",
    "                \n",
    "                pipe3 = BaggingClassifier(modelo_tunado, random_state=seed)\n",
    "                \n",
    "                #pipelines = [pipe1,pipe2,pipe3,pipe4]\n",
    "                pipelines = [pipe3]\n",
    "\n",
    "                #Loop das pipelines testadas com seletor de features e outras etapas:\n",
    "                for num_pipe, pipe in enumerate(pipelines):\n",
    "\n",
    "\n",
    "                    # features aleatorias aplicado ao  PIPE3 \n",
    "                    if num_pipe == 2:\n",
    "\n",
    "                        selected = np.random.choice(X_train3.columns, k, replace=False)\n",
    "                        \n",
    "                        #selected = np.append(selected, 'score')\n",
    "                        \n",
    "                        #selected = ['pos_rob','neutralidade_vadd4','pos_robd1','score'] ### Remover\n",
    "                        #pre_selected = ['neutralidade_vad','neutralidade_vadd3','composicao_vadd1','neu_finbertd1','neg_finbertd1','subjetividade_vadd2','neutralidade_vad','polaridade_vadd3']\n",
    "                        #selected = np.random.choice(pre_selected, k-1, replace=False)\n",
    "                        #selected = np.append(selected, 'score')\n",
    "                        #selected = ['neg_finbertd1','subjetividade_vadd2','neutralidade_vad','score']\n",
    "                        \n",
    "                        #selected = np.random.choice(X_train3.columns, k-1, replace=False)\n",
    "                        #selected = np.append(selected, 'score')\n",
    "                        \n",
    "                        ##selected = ['positividade_vad','pos_finbert','neutralidade_vadd2','score'] ## 70_4 #### mean 62,6% max 68,89 ********** candidato1\n",
    "                        ##selected = ['pos_finbert','positividade_vadd4','negatividade_vadd1','score'] ## 80_2 ### mean 60,7% max 71,94 ******** candidato2\n",
    "                        \n",
    "                        selected = ['positividade_vad','pos_finbert','neutralidade_vadd2','score']\n",
    "                        \n",
    "                        X_train4 = X_train3[selected]\n",
    "                        y_train4 = y_train3\n",
    "\n",
    "                        X_valid3 = X_valid2[selected]\n",
    "\n",
    "                        X_test3 = X_test2[selected]\n",
    "\n",
    "                    else:\n",
    "                        X_train4 = X_train3\n",
    "                        y_train4 = y_train3\n",
    "\n",
    "                        X_valid3 = X_valid2\n",
    "\n",
    "                        X_test3 = X_test2\n",
    "\n",
    "                        \n",
    "                        #selected = ['pos_rob','neutralidade_vadd4','pos_robd1','score'] ### Remover\n",
    "                        #selected = np.random.choice(X_train3.columns, k, replace=False) ### Remover\n",
    "                        #selected = np.append(selected, 'score')\n",
    "                        \n",
    "                        #pre_selected = ['neutralidade_vad','neutralidade_vadd3','composicao_vadd1','neu_finbertd1','neg_finbertd1','subjetividade_vadd2','neutralidade_vad','polaridade_vadd3']\n",
    "                        #selected = np.random.choice(pre_selected, k-1, replace=False)\n",
    "                        #selected = np.append(selected, 'score')\n",
    "                        \n",
    "                        selected = np.random.choice(X_train3.columns, k-1, replace=False)\n",
    "                        selected = np.append(selected, 'score')\n",
    "                        \n",
    "                        \n",
    "                        ##selected = ['positividade_vad','pos_finbert','neutralidade_vadd2','score'] ## 70_4 #### mean 62,6% max 68,89 ********** candidato1\n",
    "                        ##selected = ['pos_finbert','positividade_vadd4','negatividade_vadd1','score'] ## 80_2 ### mean 60,7% max 71,94 ******** candidato2\n",
    "                        \n",
    "                        selected = ['positividade_vad','pos_finbert','neutralidade_vadd2','score']\n",
    "\n",
    "                        X_train4 = X_train3[selected] ### Remover\n",
    "                        y_train4 = y_train3 ### Remover\n",
    "\n",
    "                        X_valid3 = X_valid2[selected] ### Remover\n",
    "\n",
    "                        X_test3 = X_test2[selected] ### Remover\n",
    "\n",
    "                    #Fit Pipe\n",
    "                    pipe.fit(X_train4,y_train4)\n",
    "\n",
    "\n",
    "                   # Nome das features selecionadas para PIPE1 , PIPE2 e PIPE3\n",
    "                    if num_pipe == 2:\n",
    "\n",
    "                        features_selecionadas = ','.join(list(selected))\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        selector = SelectFromModel(modelo_tunado, max_features=k, threshold=-np.inf)\n",
    "                        selector.fit(X_train4,y_train4)\n",
    "                        mask = selector.get_support()\n",
    "                        features_selecionadas = ','.join(list(X_train4.columns[mask]))\n",
    "\n",
    "\n",
    "                    #Armazenando propriedades das PIPES\n",
    "                    if num_pipe == 0:\n",
    "                        seletor_feature = \"SelectFromModel\"\n",
    "                        scaler = \"StandardScaler\"\n",
    "\n",
    "                    if num_pipe == 1:\n",
    "                        seletor_feature = \"SelectFromModel\"\n",
    "                        scaler = \"Sem Scaler\"\n",
    "\n",
    "                    if num_pipe == 2:\n",
    "                        seletor_feature = 'Aleatorio'\n",
    "                        scaler = \"StandardScaler\"\n",
    "\n",
    "                    if num_pipe == 3:\n",
    "                        seletor_feature = 'Aleatorio'\n",
    "                        seletor_feature = \"SelectFromModel\"\n",
    "                        scaler = \"MinMaxScaler\"\n",
    "\n",
    "                    ################ Calculando métricas da pipe DADOS NAO UTILIZADOS E NÃO VISTOS - TESTE ################\n",
    "                    # Fazendo predição\n",
    "                    p = pipe.predict(X_test3)\n",
    "                    contagem_experimentos_unicos = contagem_experimentos_unicos + 1\n",
    "\n",
    "                    #Calculando o recall\n",
    "                    recall_0 = recall_score(y_test3, p, pos_label=0)\n",
    "                    recall_1 = recall_score(y_test3, p, pos_label=1)\n",
    "\n",
    "                    #Calculando Precision\n",
    "                    precision_0 = precision_score(y_test3, p, pos_label = 0)\n",
    "                    precision_1 = precision_score(y_test3, p, pos_label = 1)\n",
    "\n",
    "                    #Calculando acurácia\n",
    "                    accuracy = accuracy_score(y_test3, p)\n",
    "\n",
    "                    #Calculando AUC\n",
    "                    auc = roc_auc_score(y_test3, p)\n",
    "\n",
    "\n",
    "\n",
    "                    ################# Armazenando e imprimindo os resultados  ################\n",
    "\n",
    "                    dictionary_hyperparams = dict(zip(nome_hyperparametros, hyperparametros))\n",
    "\n",
    "                    if num_modelo ==0:\n",
    "\n",
    "                        #col_names_modelo1 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                        #resultados_model1.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                        col_names_modelo1 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                        resultados_model1.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "\n",
    "                        ## Imprime resultados do melhor modelo 1                                \n",
    "                        if auc > maximo_auc_model1:\n",
    "\n",
    "                            print(\"============================================================================================================================\")\n",
    "                            print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado, auc, seed, versao))\n",
    "                            print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                \n",
    "                            print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                            print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                            print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                            print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                            print(\"\")\n",
    "                            print(\"============================================================================================================================\")\n",
    "\n",
    "                            melhor_modelo1 = pipe\n",
    "                            maximo_auc_model1 = auc\n",
    "\n",
    "                    if num_modelo ==1:\n",
    "\n",
    "                        #col_names_modelo2 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                        #resultados_model2.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                        col_names_modelo2 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'features', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                        resultados_model2.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1,features_selecionadas, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "\n",
    "                        ## Imprime resultados do melhor modelo 2\n",
    "                        if auc > maximo_auc_model2:\n",
    "\n",
    "                            print(\"============================================================================================================================\")\n",
    "                            print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado, auc, seed, versao))\n",
    "                            print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                        \n",
    "                            print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                            print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                            print(\"     Características das features selecionadas: num_features = {} - metodo_selecao_features = {}\".format(k, seletor_feature))\n",
    "                            print(\"     Features Selecionadas = {}\".format(features_selecionadas))\n",
    "                            print(\"\")\n",
    "                            print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "                            melhor_modelo2 = pipe\n",
    "                            maximo_auc_model2 = auc\n",
    "\n",
    "\n",
    "\n",
    "                    # Imprime resultados do melhor modelo global até o momento.                         \n",
    "                    if auc > maximo_auc:\n",
    "                        #print(\"Novo melhor modelo encontrado:  modelo = {} - AUC = {} - fator_balanceamento_classes = {} - num_pipeline = {}, tipo_encoding = {} - tipo_scaler = {} - num_seed_aleatoria = {} - num_features = {} - metodo_selecao_features = {} - features_selecionadas = {} - hyperparâmetros_selecionados = {}\".format(\"RF\", fator, auc,num_pipe+1, encode, scaler, seed, k, seletor_feature, features_selecionadas, dictionary_hyperparams))\n",
    "\n",
    "                        print(\"============================================================================================================================\")\n",
    "                        print(\"MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  {} - AUC = {} - num_seed_aleatoria = {} - versão sentilex = {}\".format(nome_modelo_testado, auc, seed, versao))\n",
    "                        print(\"============================================================================================================================\")\n",
    "\n",
    "                        melhor_modelo = pipe\n",
    "                        maximo_auc = auc\n",
    "                        best_seed = seed\n",
    "\n",
    "                    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{0: 0.1, 1: 0.9}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>ExtraTree</th>\n",
       "      <th>70_4</th>\n",
       "      <th>1</th>\n",
       "      <th>positividade_vad,pos_finbert,neutralidade_vadd2,score</th>\n",
       "      <td>237</td>\n",
       "      <td>0.620208</td>\n",
       "      <td>0.572583</td>\n",
       "      <td>0.668868</td>\n",
       "      <td>0.639732</td>\n",
       "      <td>0.605412</td>\n",
       "      <td>0.620725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        contagem_exp  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                           \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...           237   \n",
       "\n",
       "                                                                                                                                                        acuracia  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.620208   \n",
       "\n",
       "                                                                                                                                                        recall_0  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.572583   \n",
       "\n",
       "                                                                                                                                                        recall_1  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.668868   \n",
       "\n",
       "                                                                                                                                                          prec_0  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.639732   \n",
       "\n",
       "                                                                                                                                                          prec_1  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.605412   \n",
       "\n",
       "                                                                                                                                                             auc  \n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                      \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.620725  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Resultados Modelo 1: RF\n",
    "\n",
    "## Configurando Numero de caracteres para visualização do dataframe\n",
    "pd.set_option('display.precision',5)\n",
    "pd.reset_option('^display.',silent=True)\n",
    "\n",
    "# Transformando resultados em dataframe\n",
    "resultados_df_model1 = pd.DataFrame(np.array(resultados_model1), columns=col_names_modelo1)\n",
    "resultados_df_model1['auc'] = resultados_df_model1['auc'].astype(float, errors = 'raise')\n",
    "\n",
    "## Criando dicionário com os tipos de dados dos parâmetros e das métricas\n",
    "import itertools\n",
    "\n",
    "col_metricas = col_names_modelo1[11:]\n",
    "dict_metrics_types = dict.fromkeys(col_metricas , 'float')\n",
    "\n",
    "col_params = col_names_modelo1[:11]\n",
    "dict_params_types = dict.fromkeys(col_params , 'str')\n",
    "\n",
    "dict_data_types = itertools.chain(dict_params_types.items(),dict_metrics_types.items())\n",
    "dict_data_types = dict(dict_data_types)\n",
    "dict_data_types\n",
    "\n",
    "group_by_list = col_names_modelo1[2:11]\n",
    "\n",
    "## Agrupando por hiperparâmetros e ordenando pelas métricas\n",
    "df_agrupado = resultados_df_model1.astype(dict_data_types).groupby(group_by_list).agg({'contagem_exp': 'nunique', 'acuracia':np.mean, 'recall_0':np.mean, 'recall_1':np.mean, 'prec_0':np.mean, 'prec_1':np.mean, 'auc':np.mean, }).sort_values(by='auc', ascending=False)\n",
    "df_agrupado.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{0: 0.1, 1: 0.9}</th>\n",
       "      <th>gini</th>\n",
       "      <th>None</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>ExtraTree</th>\n",
       "      <th>70_4</th>\n",
       "      <th>1</th>\n",
       "      <th>positividade_vad,pos_finbert,neutralidade_vadd2,score</th>\n",
       "      <td>237</td>\n",
       "      <td>0.620208</td>\n",
       "      <td>0.572583</td>\n",
       "      <td>0.668868</td>\n",
       "      <td>0.639732</td>\n",
       "      <td>0.605412</td>\n",
       "      <td>0.620725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        contagem_exp  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                           \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...           237   \n",
       "\n",
       "                                                                                                                                                        acuracia  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.620208   \n",
       "\n",
       "                                                                                                                                                        recall_0  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.572583   \n",
       "\n",
       "                                                                                                                                                        recall_1  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.668868   \n",
       "\n",
       "                                                                                                                                                          prec_0  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.639732   \n",
       "\n",
       "                                                                                                                                                          prec_1  \\\n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                       \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.605412   \n",
       "\n",
       "                                                                                                                                                             auc  \n",
       "class_weight     criterion max_depth min_samples_leaf min_samples_split modelo    Sentilex num_pipe features                                                      \n",
       "{0: 0.1, 1: 0.9} gini      None      1                2                 ExtraTree 70_4     1        positividade_vad,pos_finbert,neutralidade_vadd2...  0.620725  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agrupado[(df_agrupado['contagem_exp']>1)].sort_values(by='auc', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>seed</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>features</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.699584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.688945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.688714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.688483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>136</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.688483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.688252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.688252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.678770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.72973</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.678076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.678076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>236</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>189</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.677382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.677151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.667669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>223</td>\n",
       "      <td>222</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.667669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>226</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.667438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168</td>\n",
       "      <td>167</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.667438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>161</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.667438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.667206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.667206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.666975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.666975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.76087</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.657031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.656799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>205</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.656799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>193</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.656799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.656799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.656568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>166</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.656568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.656568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.656337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>117</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.656337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.656337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152</td>\n",
       "      <td>151</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.656337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.656105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.656105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>111</td>\n",
       "      <td>110</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.656105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.655874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.655874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.655643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>120</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.646855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.646623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.646161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.645930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.645930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>{0: 0.1, 1: 0.9}</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ExtraTree</td>\n",
       "      <td>70_4</td>\n",
       "      <td>1</td>\n",
       "      <td>positividade_vad,pos_finbert,neutralidade_vadd...</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.645930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contagem_exp seed      class_weight criterion max_depth min_samples_leaf  \\\n",
       "67            68   67  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "3              4    3  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "61            62   61  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "224          225  224  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "136          137  136  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "36            37   36  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "112          113  112  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "1              2    1  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "30            31   30  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "7              8    7  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "111          112  111  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "236          237  236  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "51            52   51  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "189          190  189  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "68            69   68  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "204          205  204  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "8              9    8  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "78            79   78  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "222          223  222  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "226          227  226  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "167          168  167  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "161          162  161  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "33            34   33  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "152          153  152  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "185          186  185  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "39            40   39  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "93            94   93  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "66            67   66  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "205          206  205  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "193          194  193  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "208          209  208  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "142          143  142  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "166          167  166  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "210          211  210  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "53            54   53  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "117          118  117  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "40            41   40  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "151          152  151  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "235          236  235  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "76            77   76  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "110          111  110  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "113          114  113  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "199          200  199  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "200          201  200  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "120          121  120  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "29            30   29  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "101          102  101  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "100          101  100  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "123          124  123  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "150          151  150  {0: 0.1, 1: 0.9}      gini      None                1   \n",
       "\n",
       "    min_samples_split     modelo Sentilex num_pipe  \\\n",
       "67                  2  ExtraTree     70_4        1   \n",
       "3                   2  ExtraTree     70_4        1   \n",
       "61                  2  ExtraTree     70_4        1   \n",
       "224                 2  ExtraTree     70_4        1   \n",
       "136                 2  ExtraTree     70_4        1   \n",
       "36                  2  ExtraTree     70_4        1   \n",
       "112                 2  ExtraTree     70_4        1   \n",
       "1                   2  ExtraTree     70_4        1   \n",
       "30                  2  ExtraTree     70_4        1   \n",
       "7                   2  ExtraTree     70_4        1   \n",
       "111                 2  ExtraTree     70_4        1   \n",
       "236                 2  ExtraTree     70_4        1   \n",
       "51                  2  ExtraTree     70_4        1   \n",
       "189                 2  ExtraTree     70_4        1   \n",
       "68                  2  ExtraTree     70_4        1   \n",
       "204                 2  ExtraTree     70_4        1   \n",
       "8                   2  ExtraTree     70_4        1   \n",
       "78                  2  ExtraTree     70_4        1   \n",
       "222                 2  ExtraTree     70_4        1   \n",
       "226                 2  ExtraTree     70_4        1   \n",
       "167                 2  ExtraTree     70_4        1   \n",
       "161                 2  ExtraTree     70_4        1   \n",
       "33                  2  ExtraTree     70_4        1   \n",
       "152                 2  ExtraTree     70_4        1   \n",
       "185                 2  ExtraTree     70_4        1   \n",
       "39                  2  ExtraTree     70_4        1   \n",
       "93                  2  ExtraTree     70_4        1   \n",
       "66                  2  ExtraTree     70_4        1   \n",
       "205                 2  ExtraTree     70_4        1   \n",
       "193                 2  ExtraTree     70_4        1   \n",
       "208                 2  ExtraTree     70_4        1   \n",
       "142                 2  ExtraTree     70_4        1   \n",
       "166                 2  ExtraTree     70_4        1   \n",
       "210                 2  ExtraTree     70_4        1   \n",
       "53                  2  ExtraTree     70_4        1   \n",
       "117                 2  ExtraTree     70_4        1   \n",
       "40                  2  ExtraTree     70_4        1   \n",
       "151                 2  ExtraTree     70_4        1   \n",
       "235                 2  ExtraTree     70_4        1   \n",
       "76                  2  ExtraTree     70_4        1   \n",
       "110                 2  ExtraTree     70_4        1   \n",
       "113                 2  ExtraTree     70_4        1   \n",
       "199                 2  ExtraTree     70_4        1   \n",
       "200                 2  ExtraTree     70_4        1   \n",
       "120                 2  ExtraTree     70_4        1   \n",
       "29                  2  ExtraTree     70_4        1   \n",
       "101                 2  ExtraTree     70_4        1   \n",
       "100                 2  ExtraTree     70_4        1   \n",
       "123                 2  ExtraTree     70_4        1   \n",
       "150                 2  ExtraTree     70_4        1   \n",
       "\n",
       "                                              features  acuracia  recall_0  \\\n",
       "67   positividade_vad,pos_finbert,neutralidade_vadd...  0.698925  0.638298   \n",
       "3    positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.617021   \n",
       "61   positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.638298   \n",
       "224  positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.659574   \n",
       "136  positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.659574   \n",
       "36   positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.680851   \n",
       "112  positividade_vad,pos_finbert,neutralidade_vadd...  0.688172  0.680851   \n",
       "1    positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.553191   \n",
       "30   positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.574468   \n",
       "7    positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.617021   \n",
       "111  positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.617021   \n",
       "236  positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.659574   \n",
       "51   positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.659574   \n",
       "189  positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.680851   \n",
       "68   positividade_vad,pos_finbert,neutralidade_vadd...  0.677419  0.702128   \n",
       "204  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.553191   \n",
       "8    positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.553191   \n",
       "78   positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.574468   \n",
       "222  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.574468   \n",
       "226  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.595745   \n",
       "167  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.595745   \n",
       "161  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.595745   \n",
       "33   positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.617021   \n",
       "152  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.617021   \n",
       "185  positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.638298   \n",
       "39   positividade_vad,pos_finbert,neutralidade_vadd...  0.666667  0.638298   \n",
       "93   positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.553191   \n",
       "66   positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.574468   \n",
       "205  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.574468   \n",
       "193  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.574468   \n",
       "208  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.574468   \n",
       "142  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.595745   \n",
       "166  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.595745   \n",
       "210  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.595745   \n",
       "53   positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.617021   \n",
       "117  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.617021   \n",
       "40   positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.617021   \n",
       "151  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.617021   \n",
       "235  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.638298   \n",
       "76   positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.638298   \n",
       "110  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.638298   \n",
       "113  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.659574   \n",
       "199  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.659574   \n",
       "200  positividade_vad,pos_finbert,neutralidade_vadd...  0.655914  0.680851   \n",
       "120  positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.489362   \n",
       "29   positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.510638   \n",
       "101  positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.553191   \n",
       "100  positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.574468   \n",
       "123  positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.574468   \n",
       "150  positividade_vad,pos_finbert,neutralidade_vadd...  0.645161  0.574468   \n",
       "\n",
       "     recall_1    prec_0    prec_1       auc  \n",
       "67    0.76087  0.731707  0.673077  0.699584  \n",
       "3     0.76087     0.725  0.660377  0.688945  \n",
       "61    0.73913  0.714286  0.666667  0.688714  \n",
       "224  0.717391  0.704545  0.673469  0.688483  \n",
       "136  0.717391  0.704545  0.673469  0.688483  \n",
       "36   0.695652  0.695652  0.680851  0.688252  \n",
       "112  0.695652  0.695652  0.680851  0.688252  \n",
       "1    0.804348  0.742857  0.637931  0.678770  \n",
       "30   0.782609   0.72973  0.642857  0.678538  \n",
       "7     0.73913  0.707317  0.653846  0.678076  \n",
       "111   0.73913  0.707317  0.653846  0.678076  \n",
       "236  0.695652  0.688889  0.666667  0.677613  \n",
       "51   0.695652  0.688889  0.666667  0.677613  \n",
       "189  0.673913  0.680851  0.673913  0.677382  \n",
       "68   0.652174  0.673469  0.681818  0.677151  \n",
       "204  0.782609  0.722222  0.631579  0.667900  \n",
       "8    0.782609  0.722222  0.631579  0.667900  \n",
       "78    0.76087  0.710526  0.636364  0.667669  \n",
       "222   0.76087  0.710526  0.636364  0.667669  \n",
       "226   0.73913       0.7  0.641509  0.667438  \n",
       "167   0.73913       0.7  0.641509  0.667438  \n",
       "161   0.73913       0.7  0.641509  0.667438  \n",
       "33   0.717391  0.690476  0.647059  0.667206  \n",
       "152  0.717391  0.690476  0.647059  0.667206  \n",
       "185  0.695652  0.681818  0.653061  0.666975  \n",
       "39   0.695652  0.681818  0.653061  0.666975  \n",
       "93    0.76087  0.702703     0.625  0.657031  \n",
       "66    0.73913  0.692308   0.62963  0.656799  \n",
       "205   0.73913  0.692308   0.62963  0.656799  \n",
       "193   0.73913  0.692308   0.62963  0.656799  \n",
       "208   0.73913  0.692308   0.62963  0.656799  \n",
       "142  0.717391  0.682927  0.634615  0.656568  \n",
       "166  0.717391  0.682927  0.634615  0.656568  \n",
       "210  0.717391  0.682927  0.634615  0.656568  \n",
       "53   0.695652  0.674419      0.64  0.656337  \n",
       "117  0.695652  0.674419      0.64  0.656337  \n",
       "40   0.695652  0.674419      0.64  0.656337  \n",
       "151  0.695652  0.674419      0.64  0.656337  \n",
       "235  0.673913  0.666667  0.645833  0.656105  \n",
       "76   0.673913  0.666667  0.645833  0.656105  \n",
       "110  0.673913  0.666667  0.645833  0.656105  \n",
       "113  0.652174  0.659574  0.652174  0.655874  \n",
       "199  0.652174  0.659574  0.652174  0.655874  \n",
       "200  0.630435  0.653061  0.659091  0.655643  \n",
       "120  0.804348   0.71875  0.606557  0.646855  \n",
       "29   0.782609  0.705882  0.610169  0.646623  \n",
       "101   0.73913  0.684211  0.618182  0.646161  \n",
       "100  0.717391     0.675  0.622642  0.645930  \n",
       "123  0.717391     0.675  0.622642  0.645930  \n",
       "150  0.717391     0.675  0.622642  0.645930  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_df_model1.sort_values(by='auc', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia em disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreeClassifier(class_weight={0: 0.1,\n",
       "                                                                   1: 0.9},\n",
       "                                                     random_state=36),\n",
       "                  random_state=36)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhor_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo-ExtraTree.pkl']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import joblib\n",
    "#joblib.dump(melhor_modelo, 'modelo-ExtraTree.pkl',compress=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#joblib.dump(melhor_modelo, 'modelo-ExtraTree2.pkl',compress=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas candidato 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.709990749306198 - num_seed_aleatoria = 56 - versao_sentilex = 80_3\n",
    "     Experimento número = 57\n",
    "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
    "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
    "     Features Selecionadas = pos_finbert,positividade_vadd4,negatividade_vadd1,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreeClassifier(class_weight={0: 0.1,\n",
       "                                                                   1: 0.9},\n",
       "                                                     random_state=56),\n",
       "                  random_state=56)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "melhor_modelo_extratree = joblib.load(open(os.path.join('modelo-ExtraTree.pkl'),\"rb\"))\n",
    "melhor_modelo_extratree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreeClassifier(class_weight={0: 0.1,\n",
       "                                                                   1: 0.9},\n",
       "                                                     random_state=56),\n",
       "                  random_state=56)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versao_sentilex = '80_3'\n",
    "#features_selecionadas = \n",
    "features_selecionadas = ['pos_finbert','positividade_vadd4','negatividade_vadd1','score']\n",
    "\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "#X_test4 = df_test[.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)]\n",
    "X_test4 = df_test[features_selecionadas]\n",
    "y_test4 = df_test['Fechamento']\n",
    "\n",
    "#X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_train4 = df_train[features_selecionadas]\n",
    "y_train4 = df_train['Fechamento']\n",
    "\n",
    "#X_valid4 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_valid4 = df_valid[features_selecionadas]\n",
    "y_valid4 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "melhor_modelo_extratree.fit(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validacao:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70        47\n",
      "           1       0.69      0.74      0.72        46\n",
      "\n",
      "    accuracy                           0.71        93\n",
      "   macro avg       0.71      0.71      0.71        93\n",
      "weighted avg       0.71      0.71      0.71        93\n",
      "\n",
      "\n",
      "Confusion Matrix Dados - Validacao:\n",
      " [[32 15]\n",
      " [12 34]]\n",
      "\n",
      "Recall_0: 0.6808510638297872\n",
      "Recall_1: 0.7391304347826086\n",
      "Precision_0: 0.7272727272727273\n",
      "Precision_1: 0.6938775510204082\n",
      "Acuracia: 0.7096774193548387\n",
      "Acuracia Balanceada: 0.7099907493061979\n",
      "AUC: 0.709990749306198\n"
     ]
    }
   ],
   "source": [
    "#predict validacao\n",
    "p = melhor_modelo_extratree.predict(X_test4)\n",
    "\n",
    "############ Métricas #################\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report - Validacao:\\n\",classification_report(y_test4, p))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados - Validacao:\\n\",confusion_matrix(y_test4, p))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test4, p, pos_label=0)\n",
    "recall_1 = recall_score(y_test4, p, pos_label=1)\n",
    "\n",
    "#Calculando Precision\n",
    "precision_0 = precision_score(y_test4, p, pos_label = 0)\n",
    "precision_1 = precision_score(y_test4, p, pos_label = 1)\n",
    "\n",
    "#Calculando acurácia\n",
    "accuracy = accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test4, p)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Precision_0: %s\" % (precision_0))\n",
    "print(\"Precision_1: %s\" % (precision_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas candidato 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVO MÍNIMO LOCAL ENCONTRADO:  ExtraTree - AUC = 0.6882 - num_seed_aleatoria = 36 - versao_sentilex = 70_4\n",
    "     Experimento número = 37\n",
    "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
    "     Características do modelo: hyperparâmetros_selecionados = {'class_weight': {0: 0.1, 1: 0.9}, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "     Características das features selecionadas: num_features = 4 - metodo_selecao_features = SelectFromModel\n",
    "     Features Selecionadas = positividade_vad,pos_finbert,neutralidade_vadd2,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreeClassifier(class_weight={0: 0.1,\n",
       "                                                                   1: 0.9},\n",
       "                                                     random_state=36),\n",
       "                  random_state=36)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "melhor_modelo_extratree2 = joblib.load(open(os.path.join('modelo-ExtraTree2.pkl'),\"rb\"))\n",
    "melhor_modelo_extratree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=ExtraTreeClassifier(class_weight={0: 0.1,\n",
       "                                                                   1: 0.9},\n",
       "                                                     random_state=36),\n",
       "                  random_state=36)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versao_sentilex = '70_4'\n",
    "#features_selecionadas = \n",
    "features_selecionadas = ['positividade_vad','pos_finbert','neutralidade_vadd2','score']\n",
    "\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "#X_test4 = df_test[.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)]\n",
    "X_test4 = df_test[features_selecionadas]\n",
    "y_test4 = df_test['Fechamento']\n",
    "\n",
    "#X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_train4 = df_train[features_selecionadas]\n",
    "y_train4 = df_train['Fechamento']\n",
    "\n",
    "#X_valid4 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_valid4 = df_valid[features_selecionadas]\n",
    "y_valid4 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "melhor_modelo_extratree2.fit(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validacao:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69        47\n",
      "           1       0.68      0.70      0.69        46\n",
      "\n",
      "    accuracy                           0.69        93\n",
      "   macro avg       0.69      0.69      0.69        93\n",
      "weighted avg       0.69      0.69      0.69        93\n",
      "\n",
      "\n",
      "Confusion Matrix Dados - Validacao:\n",
      " [[32 15]\n",
      " [14 32]]\n",
      "\n",
      "Recall_0: 0.6808510638297872\n",
      "Recall_1: 0.6956521739130435\n",
      "Precision_0: 0.6956521739130435\n",
      "Precision_1: 0.6808510638297872\n",
      "Acuracia: 0.6881720430107527\n",
      "Acuracia Balanceada: 0.6882516188714154\n",
      "AUC: 0.6882516188714154\n"
     ]
    }
   ],
   "source": [
    "#predict validacao\n",
    "p = melhor_modelo_extratree2.predict(X_test4)\n",
    "\n",
    "############ Métricas #################\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report - Validacao:\\n\",classification_report(y_test4, p))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados - Validacao:\\n\",confusion_matrix(y_test4, p))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test4, p, pos_label=0)\n",
    "recall_1 = recall_score(y_test4, p, pos_label=1)\n",
    "\n",
    "#Calculando Precision\n",
    "precision_0 = precision_score(y_test4, p, pos_label = 0)\n",
    "precision_1 = precision_score(y_test4, p, pos_label = 1)\n",
    "\n",
    "#Calculando acurácia\n",
    "accuracy = accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test4, p)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Precision_0: %s\" % (precision_0))\n",
    "print(\"Precision_1: %s\" % (precision_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.0 Experimentos - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterando array_num = 21\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  kNN - AUC valid = 0.6744704570791527 - - AUC teste = 0.6341350601295097 - num_seed_aleatoria = 0 - versao_sentilex = 80_2\n",
      "     Experimento número = 1\n",
      "     Características pipeline: num_pipeline = 1 - tipo_scaler = StandardScaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'algorithm': 'auto', 'leaf_size': 1, 'metric': 'wminkowski', 'metric_params': {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}, 'n_neighbors': 5, 'p': 2}\n",
      "     Características das features selecionadas: num_PCA = 22\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  kNN - AUC valid = 0.6744704570791527 - AUC teste = 0.6341350601295097 - num_seed_aleatoria = 0 - versão sentilex = 80_2\n",
      "0.6595744680851063\n",
      "0.6086956521739131\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  kNN - AUC valid = 0.641583054626533 - AUC teste = 0.6017576318223867 - num_seed_aleatoria = 0 - versão sentilex = 80_2\n",
      "0.6382978723404256\n",
      "0.5652173913043478\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  kNN - AUC valid = 0.641583054626533 - AUC teste = 0.6017576318223867 - num_seed_aleatoria = 0 - versão sentilex = 80_2\n",
      "0.6382978723404256\n",
      "0.5652173913043478\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  kNN - AUC valid = 0.641583054626533 - AUC teste = 0.6017576318223867 - num_seed_aleatoria = 0 - versão sentilex = 80_2\n",
      "0.6382978723404256\n",
      "0.5652173913043478\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "NOVO MÍNIMO LOCAL ENCONTRADO:  kNN - AUC valid = 0.7171125975473802 - - AUC teste = 0.7097594819611471 - num_seed_aleatoria = 0 - versao_sentilex = 80_2\n",
      "     Experimento número = 5\n",
      "     Características pipeline: num_pipeline = 5 - tipo_scaler = Sem Scaler\n",
      "     Características do modelo: hyperparâmetros_selecionados = {'algorithm': 'auto', 'leaf_size': 1, 'metric': 'wminkowski', 'metric_params': {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}, 'n_neighbors': 5, 'p': 2}\n",
      "     Características das features selecionadas: num_PCA = 22\n",
      "\n",
      "============================================================================================================================\n",
      "============================================================================================================================\n",
      "MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  kNN - AUC valid = 0.7171125975473802 - AUC teste = 0.7097594819611471 - num_seed_aleatoria = 0 - versão sentilex = 80_2\n",
      "0.7021276595744681\n",
      "0.717391304347826\n",
      "============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Classweights testadas no algoritmo\n",
    "#weights = np.linspace(0.2,0.5,10) \n",
    "#weights = np.linspace(0.1,0.9,11)\n",
    "weights = np.linspace(0.1,0.9,5)\n",
    "\n",
    "\n",
    "\n",
    "## Definição da função de refit no gridsearch acurácia balanceada:\n",
    "acuracia_dados = make_scorer(accuracy_score)\n",
    "f1_dados = make_scorer(f1_score)\n",
    "balanced_acc_dados = make_scorer(balanced_accuracy_score)\n",
    "roc_score = make_scorer(roc_auc_score)\n",
    "scoring = {\"accuracy\": acuracia_dados, \"f1\":f1_dados, \"bacuracy\":balanced_acc_dados, \"roc\": roc_score }\n",
    "\n",
    "\n",
    "maximo_auc = 0\n",
    "maximo_auc_model1 = 0\n",
    "maximo_auc_model2 = 0\n",
    "\n",
    "\n",
    "#Reset na lista de resultados dos modelos iterados e experimentos rodados.\n",
    "resultados_model1 = []\n",
    "resultados_model2 = []\n",
    "contagem_experimentos_unicos = 0\n",
    "\n",
    "\n",
    "#versoes_sentilex = ['65_1','65_2','65_3','65_4','65_5','70_1','70_2','70_3','70_4','70_5','75_1','75_2','75_3','75_4','75_5','80_1','80_2','80_3','80_4','80_5']\n",
    "versoes_sentilex = ['80_2']\n",
    "\n",
    "#peso_inicial = [0.27686713, 0.01928838, 0.087757, 0.00451469, 0.14060713, 0.04357977, 0.04226601, 0.000130912651, 0.05421824, 0.10130499, 0.26512252, 0.03000374, 0.38915364, 0.26911481, 0.10984078, 0.25851415, 0.31254619, 0.18041496, 0.03987287, 0.37023451, 0.10583821, 0.15432689]\n",
    "\n",
    "\n",
    "\n",
    "melhores_pesos = []\n",
    "\n",
    "pesos_iniciais = [0.8093233,\n",
    " 0.1981739,\n",
    " 0.130479,\n",
    " 0.31633728,\n",
    " 0.93040947,\n",
    " 0.15634982,\n",
    " 0.12300895,\n",
    " 0.1711896,\n",
    " 0.09953253,\n",
    " 0.40637464,\n",
    " 0.03798309,\n",
    " 0.19449661,\n",
    " 0.99009024,\n",
    " 0.30795755,\n",
    " 0.27682479,\n",
    " 0.97880038,\n",
    " 0.98200391,\n",
    " 0.82488358,\n",
    " 0.1406156,\n",
    " 0.53879264,\n",
    " 0.64082789,\n",
    " 0.51055045]\n",
    "\n",
    "fator_iterador_pesos = 4\n",
    "lista_array_pesos = []\n",
    "for numero in range(22):\n",
    "      \n",
    "    pesos_editados = [i for i in pesos_iniciais]\n",
    "    \n",
    "    \n",
    "    ## Atualização randomica peso_pase\n",
    "    #numsorteado = random.randint(0, 22)\n",
    "    pesos_editados[numero] = pesos_editados[numero] * fator_iterador_pesos\n",
    "\n",
    "    peso_testado = np.array(pesos_editados)\n",
    "    lista_array_pesos.append(peso_testado)\n",
    "    \n",
    "    \n",
    "    \n",
    "#for num_array, array_testado in enumerate(lista_array_pesos):\n",
    "for i in range(1):\n",
    "    #peso_minkowski = array_testado\n",
    "    peso_minkowski = np.array(pesos_iniciais)\n",
    "    \n",
    "\n",
    "    print(\"Iterando array_num = {}\".format(num_array))\n",
    "   \n",
    "    \n",
    "\n",
    "    #Loop de seed aleatória\n",
    "    for seed in range(1):\n",
    "\n",
    "        #print(\"Iterando seed = {}\".format(seed))  \n",
    "\n",
    "        ##Loop do dicionário Sentilex Escolhido: \n",
    "        for versao in versoes_sentilex:\n",
    "\n",
    "            df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "            df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "            df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "            #Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "            X_test2 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "            y_test2 = df_test['Fechamento']\n",
    "\n",
    "            X_train2 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "            y_train2 = df_train['Fechamento']\n",
    "\n",
    "            X_valid2 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "            y_valid2 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "\n",
    "            ## Na há balanceamento, portanto, para evitar mudar X_train3 para X_train2 em todo código iremos usar as variáveis:\n",
    "            X_test3 = X_test2\n",
    "            y_test3 = y_test2\n",
    "\n",
    "            X_train3 = X_train2\n",
    "            y_train3 = y_train2\n",
    "\n",
    "\n",
    "\n",
    "            ################ Definição de modelos candidatos ################\n",
    "            #model1 = RandomForestClassifier(random_state=seed, n_jobs=-1)\n",
    "            #model2 = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "            model3 = KNeighborsClassifier()\n",
    "\n",
    "            #models = [model1,model2]\n",
    "            #nome_modelo = ['RandomForest', 'LGBM']\n",
    "\n",
    "            #models = [model1]\n",
    "            #nome_modelo = ['RandomForest']\n",
    "\n",
    "            #models = [model2]\n",
    "            #nome_modelo = ['LGBM']\n",
    "\n",
    "            models = [model3]\n",
    "            nome_modelo = ['kNN']\n",
    "\n",
    "\n",
    "            ################ Definindo conjunto de treino + validacao para avaliar gridsearch nos dados de avaliação ################\n",
    "            ## Concatenando dados de treino e valid:\n",
    "            X_train_valid = pd.concat([X_train3, X_valid2], ignore_index = True )\n",
    "            y_train_valid = pd.concat([y_train3, y_valid2], ignore_index = True )\n",
    "\n",
    "\n",
    "            # The indices which have the value -1 will be kept in train.\n",
    "            train_indices = np.full((X_train3.shape[0],), -1, dtype=int)\n",
    "\n",
    "            # The indices which have zero or positive values, will be kept in valid\n",
    "            valid_indices = np.full((X_valid2.shape[0],), 0, dtype=int)\n",
    "            valid_fold = np.append(train_indices, valid_indices)\n",
    "\n",
    "            # definindo o conjunto de validação\n",
    "            ps = PredefinedSplit(valid_fold)\n",
    "\n",
    "\n",
    "            ############# Paramgrid de modelos ################\n",
    "\n",
    "            ##Grid model 1 RandomForest\n",
    "            #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini','entropy']}\n",
    "            #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2,3,5,8,12], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "            #param_grid1={\"max_depth\":[None], \"min_samples_split\":[3], \"min_samples_leaf\":[1], \"criterion\":['gini']}\n",
    "            #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini']}\n",
    "            #param_grid1={\"max_depth\":[None,10,20,40], \"min_samples_split\":[2,3,5,10,20], \"min_samples_leaf\":[1,3,5,10], \"criterion\":['gini','entropy']}\n",
    "            #param_grid1={\"max_depth\":[None,10,20], \"min_samples_split\":[2,3,5], \"min_samples_leaf\":[1,3], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "            #param_grid1={\"max_depth\":[None], \"min_samples_split\":[2], \"min_samples_leaf\":[1], \"criterion\":['gini'], 'class_weight': list_class_weights}\n",
    "\n",
    "            ##Grid model 2 LGBM\n",
    "            #param_grid2={\"max_depth\":[-1,10,20], \"learning_rate\":[0.1,0.01,0.001], \"n_estimators\":[100,50,200], \"num_leaves\":[31,5,10,50]}\n",
    "            #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[250,300,400], \"num_leaves\":[2,5,8,12,16,20]}\n",
    "            #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1,0.01], \"n_estimators\":[70,100,150,200], \"num_leaves\":[31,10,25,50,80,120]}\n",
    "            #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'boosting_type': ['gbdt', 'dart', 'goss', 'rf'] }\n",
    "            #param_grid2={\"max_depth\":[-1,50,100,150,200], \"learning_rate\":[0.1], \"n_estimators\":[150,200], \"num_leaves\":[31,10,25], 'class_weight': list_class_weights}\n",
    "            #param_grid2={\"max_depth\":[-1], \"learning_rate\":[0.1], \"n_estimators\":[200], \"num_leaves\":[31,10], 'class_weight': list_class_weights }\n",
    "\n",
    "            ## Itera sobre numero de k vizinhos\n",
    "\n",
    "            #for neighbor in range(2,12,1):\n",
    "            #for neighbor in range(4,9,1): \n",
    "            for neighbor in range(5,6,1): \n",
    "\n",
    "                #param_grid3={\"n_neighbors\":[neighbor], \"weights\":['uniform','distance'], \"algorithm\":['auto','ball_tree','kd_tree','brute'], 'p': [1,2], 'leaf_size':[5,10,20,30,50,80]}\n",
    "                #param_grid3={\"n_neighbors\":[neighbor], \"weights\":['uniform','distance'], \"algorithm\":['auto','ball_tree','kd_tree','brute'], 'p': [1,2], 'leaf_size':[5,10,20,30,50,80], 'metric': ['euclidean','manhattan','chebyshev','minkowski','seuclidean','mahalanobis'] }\n",
    "           #### #param_grid3={\"n_neighbors\":[neighbor], \"weights\":['uniform','distance'], \"algorithm\":['auto','ball_tree','kd_tree','brute'], 'p': [1,2], 'leaf_size':[1,2,3,4,5,6,7,8,9]}\n",
    "                param_grid3={\"n_neighbors\":[neighbor], \"algorithm\":['auto','ball_tree','kd_tree','brute'], 'p': [2], 'leaf_size':[1,2,3,4,5,6,7,8,9], 'metric': ['wminkowski'], 'metric_params': [{ 'w': np.array([1 for numero in range(0,X_train3.shape[1])]) }] }\n",
    "                #param_grid3={\"n_neighbors\":[neighbor], \"weights\":['uniform','distance'], \"algorithm\":['auto','ball_tree','kd_tree','brute'], 'p': [1,2], 'leaf_size':[1,2,3,4,5,6,7,8,9], 'metric': ['minkowski']}\n",
    "\n",
    "\n",
    "                #list_param_grids = [param_grid1, param_grid2]\n",
    "                #list_param_grids = [param_grid1]\n",
    "                list_param_grids = [param_grid3]\n",
    "\n",
    "                #list_param_grids = [param_grid2]\n",
    "                dictionary_paramgrid = dict(zip(models, list_param_grids))\n",
    "\n",
    "\n",
    "\n",
    "                #Loop modelos\n",
    "                for num_modelo, model in enumerate(models):\n",
    "\n",
    "                    nome_modelo_testado = nome_modelo[num_modelo]\n",
    "\n",
    "                    param_grid = dictionary_paramgrid[model]\n",
    "\n",
    "                    ############# GridSearch de modelos candidatos com todas features ################\n",
    "                    gs = GridSearchCV(model , param_grid=param_grid, scoring=scoring,  refit=\"f1\", n_jobs=-1, cv = ps )\n",
    "\n",
    "                    #Fit dados \n",
    "                    gs.fit(X_train_valid,y_train_valid)\n",
    "\n",
    "                    #melhores hyperparametros:\n",
    "                    hyperparametros = list(gs.best_params_.values())\n",
    "                    nome_hyperparametros = list(gs.best_params_.keys())\n",
    "\n",
    "\n",
    "                    #melhor modelo\n",
    "                    # CUIDADO: O atributo best_estimator_ retorna o melhor modelo ja treinado com o conjunto de dados\n",
    "                    # passado pelo metodo gs.fit(), ou seja ja vem treinado com X_train_valid,y_train_valid, sendo, portanto\n",
    "                    # necessário mais uma etapa de fit() do modelo tunado apenas com dados de treino.\n",
    "                    modelo_tunado = gs.best_estimator_\n",
    "\n",
    "                    # Refit no modelo tunado com apenas dados de treino para evitar overtting ao avaliar sobre dados de valid\n",
    "                    modelo_tunado.fit(X_train3,y_train3)\n",
    "\n",
    "\n",
    "\n",
    "                    #Loop PCA:\n",
    "                    #for k in range(2,X_train3.shape[1]-1,1):  ## Iterar sobre 2 á n features - 1 -  PCA\n",
    "                    #for k in range(2,26,1):  ## Iterar sobre 2 á 25 features  PCA\n",
    "                    for k in range(22,23,1):  ## Iterar sobre 22 á 22 features  PCA\n",
    "\n",
    "                        ## Alterando os pesos de wminkowski para ter a mesma dimensão do X_Train definido pelo PCA\n",
    "                        pesos_aleatorios = np.random.random(k)\n",
    "                        #modelo_tunado.set_params(metric_params = {'w': pesos_aleatorios} )\n",
    "\n",
    "\n",
    "\n",
    "                        #for num in range(22):\n",
    "\n",
    "                            #Atualiza pesos de minkowski\n",
    "                            #if len(melhores_pesos)==0:\n",
    "                                #peso_minkowski = [pes for pes in peso_inicial]\n",
    "                                #peso_minkowski[num] = peso_minkowski[num]*2\n",
    "                                #peso_minkowski = np.array(peso_minkowski)\n",
    "\n",
    "                            #else:\n",
    "                                #peso_minkowski = [pes for pes in melhores_pesos.tolist()] \n",
    "                                #peso_minkowski[num] = peso_minkowski[num]*2\n",
    "                                #peso_minkowski = np.array(peso_minkowski)\n",
    "\n",
    "\n",
    "                        modelo_tunado.set_params(metric_params = {'w': peso_minkowski} )\n",
    "\n",
    "\n",
    "                        ## O seletor de features varia conforme a pipe de aleatório á SelectFromModel:\n",
    "\n",
    "                        ################ Definição de Pipelines com modelo tunado ################\n",
    "                        pipe1 = Pipeline([('PCA', PCA(n_components=k)), ('scaler', StandardScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                        pipe2 = Pipeline([('PCA', PCA(n_components=k)), (nome_modelo_testado, modelo_tunado)])\n",
    "                        #pipe3 = Pipeline([('scaler', StandardScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                        #pipe4 = Pipeline([(nome_modelo_testado, modelo_tunado)])\n",
    "                        pipe5 = Pipeline([('PCA', PCA(n_components=k)), ('scaler', MinMaxScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "                        #pipe6 = Pipeline([('scaler', MinMaxScaler()), (nome_modelo_testado, modelo_tunado)])\n",
    "\n",
    "                        pipe3 = Pipeline([('PCA', PCA(n_components=k)), (nome_modelo_testado, modelo_tunado)])\n",
    "                        pipe4 = Pipeline([('PCA', PCA(n_components=k)), (nome_modelo_testado, modelo_tunado)])\n",
    "                        pipe6 = Pipeline([('PCA', PCA(n_components=k)), (nome_modelo_testado, modelo_tunado)])\n",
    "\n",
    "                        pipelines = [pipe1,pipe2,pipe3,pipe4,pipe5,pipe6]\n",
    "\n",
    "\n",
    "                        #Loop das pipelines testadas com seletor de features e outras etapas:\n",
    "                        for num_pipe, pipe in enumerate(pipelines):\n",
    "\n",
    "                            #Fit Pipe\n",
    "                            pipe.fit(X_train3,y_train3)\n",
    "\n",
    "\n",
    "                            #Armazenando propriedades das PIPES\n",
    "                            if num_pipe == 0:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"StandardScaler\"\n",
    "\n",
    "                                #pca = PCA(n_components=k)\n",
    "\n",
    "                                #X_test4 = pca.fit_transform(X_test3)\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "\n",
    "                            if num_pipe == 1:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"Sem Scaler\"\n",
    "\n",
    "                                #pca = PCA(n_components = k)\n",
    "                                #X_test4 = pca.fit_transform(X_test3)\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "                            if num_pipe == 2:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"MinMaxScaler\"\n",
    "\n",
    "                                #X_test4 = X_test3\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "                            if num_pipe == 3:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"Sem Scaler\"\n",
    "\n",
    "                                #X_test4 = X_test3\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "                            if num_pipe == 4:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"Sem Scaler\"\n",
    "\n",
    "                                #pca = PCA(n_components = k)\n",
    "                                #X_test4 = pca.fit_transform(X_test3)\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "                            if num_pipe == 5:\n",
    "                                pca_bol = k\n",
    "                                scaler = \"Sem Scaler\"\n",
    "\n",
    "                                #X_test4 = X_test3\n",
    "                                #y_test4 = y_test3\n",
    "\n",
    "                            X_test4 = X_test3\n",
    "                            y_test4 = y_test3\n",
    "\n",
    "                            ################ Calculando métricas da pipe DADOS NAO UTILIZADOS E NÃO VISTOS - TESTE ################\n",
    "                            # Fazendo predição\n",
    "\n",
    "                            X_test4 = pd.DataFrame(X_test4)\n",
    "\n",
    "                            p = pipe.predict(X_test4)\n",
    "                            contagem_experimentos_unicos = contagem_experimentos_unicos + 1\n",
    "\n",
    "                            #Calculando o recall\n",
    "                            recall_0 = recall_score(y_test4, p, pos_label=0)\n",
    "                            recall_1 = recall_score(y_test4, p, pos_label=1)\n",
    "\n",
    "                            #Calculando Precision\n",
    "                            precision_0 = precision_score(y_test4, p, pos_label = 0)\n",
    "                            precision_1 = precision_score(y_test4, p, pos_label = 1)\n",
    "\n",
    "                            #Calculando acurácia\n",
    "                            accuracy = accuracy_score(y_test4, p)\n",
    "                        \n",
    "\n",
    "                            #Calculando AUC\n",
    "                            auc = roc_auc_score(y_test4, p)\n",
    "                            \n",
    "                            ################ Calculando métricas da pipe DADOS validação - avaliar se generaliza bem ################\n",
    "                            # Fazendo predição\n",
    "\n",
    "                            p = pipe.predict(X_valid2)\n",
    "                            #contagem_experimentos_unicos = contagem_experimentos_unicos + 1\n",
    "\n",
    "                            #Calculando o recall\n",
    "                            recall_0_valid = recall_score(y_valid2, p, pos_label=0)\n",
    "                            recall_1_valid = recall_score(y_valid2, p, pos_label=1)\n",
    "\n",
    "                            #Calculando Precision\n",
    "                            precision_0_valid = precision_score(y_valid2, p, pos_label = 0)\n",
    "                            precision_1_valid = precision_score(y_valid2, p, pos_label = 1)\n",
    "\n",
    "                            #Calculando acurácia\n",
    "                            accuracy_valid = accuracy_score(y_valid2, p)\n",
    "                        \n",
    "\n",
    "                            #Calculando AUC\n",
    "                            auc_valid = roc_auc_score(y_valid2, p)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "                            ################# Armazenando e imprimindo os resultados  ################\n",
    "\n",
    "                            dictionary_hyperparams = dict(zip(nome_hyperparametros, hyperparametros))\n",
    "\n",
    "                            if num_modelo ==0:\n",
    "\n",
    "                                #col_names_modelo1 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                                #resultados_model1.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                                col_names_modelo1 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','pesos','num_pipe', 'PCA', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc','auc_valid']\n",
    "                                resultados_model1.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, pesos_aleatorios, num_pipe+1, pca_bol, accuracy, recall_0, recall_1, precision_0, precision_1, auc, auc_valid ]))\n",
    "\n",
    "\n",
    "                                ## Imprime resultados do melhor modelo 1                                \n",
    "                                if auc_valid > maximo_auc_model1:\n",
    "\n",
    "                                    print(\"============================================================================================================================\")\n",
    "                                    print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC valid = {} - - AUC teste = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado,auc_valid, auc, seed, versao))\n",
    "                                    print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                \n",
    "                                    print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                                    print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                                    print(\"     Características das features selecionadas: num_PCA = {}\".format(pca_bol))\n",
    "                                    print(\"\")\n",
    "                                    print(\"============================================================================================================================\")\n",
    "\n",
    "                                    melhor_modelo1 = pipe\n",
    "                                    maximo_auc_model1 = auc_valid\n",
    "\n",
    "                            if num_modelo ==1:\n",
    "\n",
    "                                #col_names_modelo2 = nome_hyperparametros + ['modelo','features', 'num_pipe','fator_balanceamento','seed', 'tipo_encode', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                                #resultados_model2.append(np.array( hyperparametros +  [nome_modelo_testado, features_selecionadas, num_pipe+1, fator, seed, encode, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "                                col_names_modelo2 = ['contagem_exp', 'seed'] + nome_hyperparametros + ['modelo','Sentilex','num_pipe', 'PCA', 'acuracia', 'recall_0','recall_1','prec_0','prec_1','auc']\n",
    "                                resultados_model2.append(np.array( [contagem_experimentos_unicos, seed] + hyperparametros +  [nome_modelo_testado,versao, num_pipe+1, PCA, accuracy, recall_0, recall_1, precision_0, precision_1, auc ]))\n",
    "\n",
    "\n",
    "                                ## Imprime resultados do melhor modelo 2\n",
    "                                if auc_valid > maximo_auc_model2:\n",
    "\n",
    "                                    print(\"============================================================================================================================\")\n",
    "                                    print(\"NOVO MÍNIMO LOCAL ENCONTRADO:  {} - AUC valid = {} - - AUC teste = {} - num_seed_aleatoria = {} - versao_sentilex = {}\".format(nome_modelo_testado,auc_valid, auc, seed, versao))\n",
    "                                    print(\"     Experimento número = {}\".format(contagem_experimentos_unicos))                \n",
    "                                    print(\"     Características pipeline: num_pipeline = {} - tipo_scaler = {}\".format(num_pipe+1, scaler))\n",
    "                                    print(\"     Características do modelo: hyperparâmetros_selecionados = {}\".format(dictionary_hyperparams))\n",
    "                                    print(\"     Características das features selecionadas: num_PCA = {}\".format(pca_bol))\n",
    "                                    print(\"\")\n",
    "                                    print(\"============================================================================================================================\")\n",
    "\n",
    "\n",
    "                                    melhor_modelo2 = pipe\n",
    "                                    maximo_auc_model2 = auc_valid\n",
    "\n",
    "\n",
    "\n",
    "                            # Imprime resultados do melhor modelo global até o momento.                         \n",
    "                            if auc_valid > maximo_auc:\n",
    "                                #print(\"Novo melhor modelo encontrado:  modelo = {} - AUC = {} - fator_balanceamento_classes = {} - num_pipeline = {}, tipo_encoding = {} - tipo_scaler = {} - num_seed_aleatoria = {} - num_features = {} - metodo_selecao_features = {} - features_selecionadas = {} - hyperparâmetros_selecionados = {}\".format(\"RF\", fator, auc,num_pipe+1, encode, scaler, seed, k, seletor_feature, features_selecionadas, dictionary_hyperparams))\n",
    "\n",
    "                               # diferenca para teste:\n",
    "                                metrica = auc_valid - auc\n",
    "                                \n",
    "                                if metrica < 10 and metrica > -10:\n",
    "                                \n",
    "                                    print(\"============================================================================================================================\")\n",
    "                                    print(\"MÍNIMO GLOBAL: NOVO MELHOR MODELO ENCONTRADO:  {} - AUC valid = {} - AUC teste = {} - num_seed_aleatoria = {} - versão sentilex = {}\".format(nome_modelo_testado, auc_valid, auc, seed, versao))\n",
    "                                    print(recall_0),print(recall_1)\n",
    "                                    print(\"============================================================================================================================\")\n",
    "\n",
    "                                    melhor_modelo = pipe\n",
    "                                    maximo_auc = auc\n",
    "                                    best_seed = seed\n",
    "                                    #melhores_pesos = peso_minkowski\n",
    "                                    melhores_pesos = pesos_aleatorios\n",
    "\n",
    "                            #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia Euclidiana:\n",
    "- Best: AUC 67,76, knn = 3, PCA = 23\n",
    "\n",
    "### Distancia de Minkowski com Pesos por features\n",
    "\n",
    "- Baseline: AUC 0.591 knn = 5, PCA = 22 wminkowski pesos 1\n",
    "\n",
    "- AUC Valid = 71,71 AUC teste = 70,97 knn = 5, PCA = 22 pesos:\n",
    "\n",
    "[0.8093233,\n",
    " 0.1981739,\n",
    " 0.130479,\n",
    " 0.31633728,\n",
    " 0.93040947,\n",
    " 0.15634982,\n",
    " 0.12300895,\n",
    " 0.1711896,\n",
    " 0.09953253,\n",
    " 0.40637464,\n",
    " 0.03798309,\n",
    " 0.19449661,\n",
    " 0.99009024,\n",
    " 0.30795755,\n",
    " 0.27682479,\n",
    " 0.97880038,\n",
    " 0.98200391,\n",
    " 0.82488358,\n",
    " 0.1406156,\n",
    " 0.53879264,\n",
    " 0.64082789,\n",
    " 0.51055045]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th>leaf_size</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_params</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>pesos</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>PCA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">auto</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">wminkowski</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">kNN</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">80_2</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">[0.45139425 0.79545848 0.42583587 0.98595407 0.56233469 0.42485045\\n 0.08955203 0.91642262 0.28665458 0.11055712 0.91840288 0.76765131\\n 0.80285197 0.53542985 0.23132605 0.07380404 0.17605895 0.30379726\\n 0.64047738 0.34541613 0.64365549 0.19252769]</th>\n",
       "      <th>5</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.709759</td>\n",
       "      <td>0.717113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.634135</td>\n",
       "      <td>0.674470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.601758</td>\n",
       "      <td>0.641583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                 contagem_exp  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA                 \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22              1   \n",
       "                                                                                                                                                                   1        22              1   \n",
       "                                                                                                                                                                   2        22              1   \n",
       "                                                                                                                                                                   3        22              1   \n",
       "                                                                                                                                                                   4        22              1   \n",
       "                                                                                                                                                                   6        22              1   \n",
       "\n",
       "                                                                                                                                                                                 acuracia  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.709677   \n",
       "                                                                                                                                                                   1        22   0.634409   \n",
       "                                                                                                                                                                   2        22   0.602151   \n",
       "                                                                                                                                                                   3        22   0.602151   \n",
       "                                                                                                                                                                   4        22   0.602151   \n",
       "                                                                                                                                                                   6        22   0.602151   \n",
       "\n",
       "                                                                                                                                                                                 recall_0  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.702128   \n",
       "                                                                                                                                                                   1        22   0.659574   \n",
       "                                                                                                                                                                   2        22   0.638298   \n",
       "                                                                                                                                                                   3        22   0.638298   \n",
       "                                                                                                                                                                   4        22   0.638298   \n",
       "                                                                                                                                                                   6        22   0.638298   \n",
       "\n",
       "                                                                                                                                                                                 recall_1  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.717391   \n",
       "                                                                                                                                                                   1        22   0.608696   \n",
       "                                                                                                                                                                   2        22   0.565217   \n",
       "                                                                                                                                                                   3        22   0.565217   \n",
       "                                                                                                                                                                   4        22   0.565217   \n",
       "                                                                                                                                                                   6        22   0.565217   \n",
       "\n",
       "                                                                                                                                                                                   prec_0  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.717391   \n",
       "                                                                                                                                                                   1        22   0.632653   \n",
       "                                                                                                                                                                   2        22   0.600000   \n",
       "                                                                                                                                                                   3        22   0.600000   \n",
       "                                                                                                                                                                   4        22   0.600000   \n",
       "                                                                                                                                                                   6        22   0.600000   \n",
       "\n",
       "                                                                                                                                                                                   prec_1  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.702128   \n",
       "                                                                                                                                                                   1        22   0.636364   \n",
       "                                                                                                                                                                   2        22   0.604651   \n",
       "                                                                                                                                                                   3        22   0.604651   \n",
       "                                                                                                                                                                   4        22   0.604651   \n",
       "                                                                                                                                                                   6        22   0.604651   \n",
       "\n",
       "                                                                                                                                                                                      auc  \\\n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22   0.709759   \n",
       "                                                                                                                                                                   1        22   0.634135   \n",
       "                                                                                                                                                                   2        22   0.601758   \n",
       "                                                                                                                                                                   3        22   0.601758   \n",
       "                                                                                                                                                                   4        22   0.601758   \n",
       "                                                                                                                                                                   6        22   0.601758   \n",
       "\n",
       "                                                                                                                                                                                 auc_valid  \n",
       "algorithm leaf_size metric     metric_params                                      n_neighbors p modelo Sentilex pesos                                              num_pipe PCA             \n",
       "auto      1         wminkowski {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... 5           2 kNN    80_2     [0.45139425 0.79545848 0.42583587 0.98595407 0.... 5        22    0.717113  \n",
       "                                                                                                                                                                   1        22    0.674470  \n",
       "                                                                                                                                                                   2        22    0.641583  \n",
       "                                                                                                                                                                   3        22    0.641583  \n",
       "                                                                                                                                                                   4        22    0.641583  \n",
       "                                                                                                                                                                   6        22    0.641583  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Resultados Modelo 1: KNN\n",
    "\n",
    "## Configurando Numero de caracteres para visualização do dataframe\n",
    "pd.set_option('display.precision',5)\n",
    "pd.reset_option('^display.',silent=True)\n",
    "\n",
    "# Transformando resultados em dataframe\n",
    "resultados_df_model1 = pd.DataFrame(np.array(resultados_model1), columns=col_names_modelo1)\n",
    "resultados_df_model1['auc'] = resultados_df_model1['auc'].astype(float, errors = 'raise')\n",
    "\n",
    "## Criando dicionário com os tipos de dados dos parâmetros e das métricas\n",
    "import itertools\n",
    "\n",
    "col_metricas = col_names_modelo1[13:]\n",
    "dict_metrics_types = dict.fromkeys(col_metricas , 'float')\n",
    "\n",
    "col_params = col_names_modelo1[:13]\n",
    "dict_params_types = dict.fromkeys(col_params , 'str')\n",
    "\n",
    "dict_data_types = itertools.chain(dict_params_types.items(),dict_metrics_types.items())\n",
    "dict_data_types = dict(dict_data_types)\n",
    "dict_data_types\n",
    "\n",
    "group_by_list = col_names_modelo1[2:13]\n",
    "\n",
    "## Agrupando por hiperparâmetros e ordenando pelas métricas\n",
    "df_agrupado = resultados_df_model1.astype(dict_data_types).groupby(group_by_list).agg({'contagem_exp': 'nunique', 'acuracia':np.mean, 'recall_0':np.mean, 'recall_1':np.mean, 'prec_0':np.mean, 'prec_1':np.mean, 'auc':np.mean, 'auc_valid': np.mean }).sort_values(by='auc_valid', ascending=False)\n",
    "df_agrupado.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>seed</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>leaf_size</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_params</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>pesos</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>PCA</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.45139424990395394, 0.7954584762282572, 0.42...</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.709759</td>\n",
       "      <td>0.717113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  contagem_exp seed algorithm leaf_size      metric  \\\n",
       "4            5    0      auto         1  wminkowski   \n",
       "\n",
       "                                       metric_params n_neighbors  p modelo  \\\n",
       "4  {'w': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...           5  2    kNN   \n",
       "\n",
       "  Sentilex                                              pesos num_pipe PCA  \\\n",
       "4     80_2  [0.45139424990395394, 0.7954584762282572, 0.42...        5  22   \n",
       "\n",
       "   acuracia  recall_0  recall_1    prec_0    prec_1       auc auc_valid  \n",
       "4  0.709677  0.702128  0.717391  0.717391  0.702128  0.709759  0.717113  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_filtrados = resultados_df_model1[(resultados_df_model1['auc']>=0.70)]\n",
    "resultados_filtrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise para incialização de pesos de Weighted Minkowski\n",
    "\n",
    "- Foi rodado 231 mil experimentos com diversas combinações de PCA, n-neightboors com inicialização aleatória de pesos a fim de avaliar qual melhor numero de vizinhos e numero de PCA. (Dados disponíveis no csv kNN best features.csv) Nº Vizinhos = 5, PCA = 2.  \n",
    "\n",
    "  \n",
    "- Foi rodado 51 mil experimentos com nº Vizinhos = 5 e PCA = 22 com inicialização aleatória de pesos. Iremos selecionar os conjuntos de pesos que performaram bem nos dados de validação e nos dados de testes.  \n",
    "  \n",
    "  \n",
    "- Em seguida iremos comparar os resultados por weighted minkowski VS distância Euclidiana.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados_df_model1.to_csv('kNN best features2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_df_model1 = pd.read_csv('kNN best features2.csv', sep=',')\n",
    "len(resultados_df_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    7\n",
       "Name: PCA, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_filtrados = resultados_df_model1[(resultados_df_model1['auc']>=0.70)]\n",
    "resultados_filtrados.PCA.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Há 7 registros com AUC nos dados de teste > 0.7, vamos avaliar qual deles também performaram bem nos dados de validação uma vez que desejamos um algorítmo que, além de performar bem nos dados de produção também seja capaz de generalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contagem_exp</th>\n",
       "      <th>seed</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>leaf_size</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_params</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>modelo</th>\n",
       "      <th>Sentilex</th>\n",
       "      <th>pesos</th>\n",
       "      <th>num_pipe</th>\n",
       "      <th>PCA</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>prec_0</th>\n",
       "      <th>prec_1</th>\n",
       "      <th>auc</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40488</th>\n",
       "      <td>40489</td>\n",
       "      <td>6748</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.78385762 0.31939701 0.56434666 0.05833802 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.720860</td>\n",
       "      <td>0.664994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17665</th>\n",
       "      <td>17666</td>\n",
       "      <td>2944</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.86302124 0.00769531 0.24891148 0.6233247  0...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.643813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17666</th>\n",
       "      <td>17667</td>\n",
       "      <td>2944</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.86302124 0.00769531 0.24891148 0.6233247  0...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.643813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17667</th>\n",
       "      <td>17668</td>\n",
       "      <td>2944</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.86302124 0.00769531 0.24891148 0.6233247  0...</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.643813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17669</th>\n",
       "      <td>17670</td>\n",
       "      <td>2944</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.86302124 0.00769531 0.24891148 0.6233247  0...</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.643813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>3263</td>\n",
       "      <td>543</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.56597903 0.27513643 0.50498585 0.42344289 0...</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.710453</td>\n",
       "      <td>0.702620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200</th>\n",
       "      <td>11201</td>\n",
       "      <td>1866</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>wminkowski</td>\n",
       "      <td>{'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>80_2</td>\n",
       "      <td>[0.8093233  0.1981739  0.130479   0.31633728 0...</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.709759</td>\n",
       "      <td>0.717113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contagem_exp  seed algorithm  leaf_size      metric  \\\n",
       "40488         40489  6748      auto          1  wminkowski   \n",
       "17665         17666  2944      auto          1  wminkowski   \n",
       "17666         17667  2944      auto          1  wminkowski   \n",
       "17667         17668  2944      auto          1  wminkowski   \n",
       "17669         17670  2944      auto          1  wminkowski   \n",
       "3262           3263   543      auto          1  wminkowski   \n",
       "11200         11201  1866      auto          1  wminkowski   \n",
       "\n",
       "                                           metric_params  n_neighbors  p  \\\n",
       "40488  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "17665  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "17666  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "17667  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "17669  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "3262   {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "11200  {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            5  2   \n",
       "\n",
       "      modelo Sentilex                                              pesos  \\\n",
       "40488    kNN     80_2  [0.78385762 0.31939701 0.56434666 0.05833802 0...   \n",
       "17665    kNN     80_2  [0.86302124 0.00769531 0.24891148 0.6233247  0...   \n",
       "17666    kNN     80_2  [0.86302124 0.00769531 0.24891148 0.6233247  0...   \n",
       "17667    kNN     80_2  [0.86302124 0.00769531 0.24891148 0.6233247  0...   \n",
       "17669    kNN     80_2  [0.86302124 0.00769531 0.24891148 0.6233247  0...   \n",
       "3262     kNN     80_2  [0.56597903 0.27513643 0.50498585 0.42344289 0...   \n",
       "11200    kNN     80_2  [0.8093233  0.1981739  0.130479   0.31633728 0...   \n",
       "\n",
       "       num_pipe  PCA  acuracia  recall_0  recall_1    prec_0    prec_1  \\\n",
       "40488         1   22  0.720430  0.680851  0.760870  0.744186  0.700000   \n",
       "17665         2   22  0.720430  0.702128  0.739130  0.733333  0.708333   \n",
       "17666         3   22  0.720430  0.702128  0.739130  0.733333  0.708333   \n",
       "17667         4   22  0.720430  0.702128  0.739130  0.733333  0.708333   \n",
       "17669         6   22  0.720430  0.702128  0.739130  0.733333  0.708333   \n",
       "3262          5   22  0.709677  0.638298  0.782609  0.750000  0.679245   \n",
       "11200         5   22  0.709677  0.702128  0.717391  0.717391  0.702128   \n",
       "\n",
       "            auc  auc_valid  \n",
       "40488  0.720860   0.664994  \n",
       "17665  0.720629   0.643813  \n",
       "17666  0.720629   0.643813  \n",
       "17667  0.720629   0.643813  \n",
       "17669  0.720629   0.643813  \n",
       "3262   0.710453   0.702620  \n",
       "11200  0.709759   0.717113  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_filtrados[(resultados_filtrados['PCA']==22)].sort_values(by='auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os experimentos 3263 e 11201 trouxeram os resultados mais promissores ambos com cerca de 70% de AUC nos dados de teste e validação.\n",
    "\n",
    "        \n",
    "\n",
    "- Testaremos algumas combinações de pesos provindas desses 2 resultados:\n",
    "\n",
    "    - Minimo,\n",
    "    - Média,\n",
    "    - Máximo \n",
    "    - Combinação aleatória de pesos entre os 2 candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>acuracia</th>\n",
       "      <th>recall0</th>\n",
       "      <th>recall1</th>\n",
       "      <th>auc_teste</th>\n",
       "      <th>auc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565979</td>\n",
       "      <td>0.275136</td>\n",
       "      <td>0.504986</td>\n",
       "      <td>0.423443</td>\n",
       "      <td>0.614964</td>\n",
       "      <td>0.849806</td>\n",
       "      <td>0.586008</td>\n",
       "      <td>0.397275</td>\n",
       "      <td>0.866672</td>\n",
       "      <td>0.152407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.082530</td>\n",
       "      <td>0.849863</td>\n",
       "      <td>0.736292</td>\n",
       "      <td>0.679899</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.702620</td>\n",
       "      <td>0.710453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.809323</td>\n",
       "      <td>0.198174</td>\n",
       "      <td>0.130479</td>\n",
       "      <td>0.316337</td>\n",
       "      <td>0.930409</td>\n",
       "      <td>0.156350</td>\n",
       "      <td>0.123009</td>\n",
       "      <td>0.171190</td>\n",
       "      <td>0.099533</td>\n",
       "      <td>0.406375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824884</td>\n",
       "      <td>0.140616</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.640828</td>\n",
       "      <td>0.510550</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.717113</td>\n",
       "      <td>0.709759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.565979  0.275136  0.504986  0.423443  0.614964  0.849806  0.586008   \n",
       "1  0.809323  0.198174  0.130479  0.316337  0.930409  0.156350  0.123009   \n",
       "\n",
       "         V8        V9       V10  ...       V18       V19       V20       V21  \\\n",
       "0  0.397275  0.866672  0.152407  ...  0.124124  0.082530  0.849863  0.736292   \n",
       "1  0.171190  0.099533  0.406375  ...  0.824884  0.140616  0.538793  0.640828   \n",
       "\n",
       "        V22  acuracia   recall0   recall1  auc_teste  auc_valid  \n",
       "0  0.679899  0.709677  0.638298  0.782609   0.702620   0.710453  \n",
       "1  0.510550  0.709677  0.702128  0.717391   0.717113   0.709759  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Capturando os pesos individuais que alcançaram 0,68 de auc ou mais para PCA = 22\n",
    "indexes = [0,1]\n",
    "\n",
    "resultados_knn = []\n",
    "\n",
    "for i in indexes:\n",
    "    \n",
    "    string = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][10]\n",
    "    string = string[1:-1]\n",
    "    string = string.replace('\\n','')\n",
    "    peso = np.fromstring(string, dtype=float, sep=' ')\n",
    "    \n",
    "    pesos = []\n",
    "    metricas = []\n",
    "    \n",
    "    for elemento in peso:\n",
    "        pesos.append(elemento)\n",
    "        \n",
    "    ac = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][13]\n",
    "    rec0 = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][14]\n",
    "    rec1 = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][15]\n",
    "    auc_teste = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][18]\n",
    "    auc_valid = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[i][19]\n",
    "\n",
    "    metricas.append(ac)\n",
    "    metricas.append(rec0)\n",
    "    metricas.append(rec1)\n",
    "    metricas.append(auc_valid)\n",
    "    metricas.append(auc_teste)\n",
    "    \n",
    "    resultados_knn.append(np.array( pesos + metricas))\n",
    "    \n",
    "resultados_knn = pd.DataFrame(np.array(resultados_knn), columns=['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','acuracia','recall0','recall1','auc_teste','auc_valid'])\n",
    "resultados_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.56597903,\n",
       " 0.27513643,\n",
       " 0.50498585,\n",
       " 0.42344289,\n",
       " 0.61496418,\n",
       " 0.8498061,\n",
       " 0.58600755,\n",
       " 0.39727532,\n",
       " 0.86667183,\n",
       " 0.15240741,\n",
       " 0.13431222,\n",
       " 0.13453222,\n",
       " 0.6551549,\n",
       " 0.66488951,\n",
       " 0.00154138,\n",
       " 0.50863837,\n",
       " 0.34494423,\n",
       " 0.12412385,\n",
       " 0.08253047,\n",
       " 0.84986266,\n",
       " 0.73629169,\n",
       " 0.67989901]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Peso testado\n",
    "string = resultados_filtrados[(resultados_filtrados['PCA']==22)].iloc[0][10]\n",
    "string = string[1:-1]\n",
    "string = string.replace('\\n','')\n",
    "lista = np.fromstring(string, dtype=float, sep=' ').tolist()\n",
    "    \n",
    "\n",
    "#Alterando valores\n",
    "var = resultados_knn.columns[:22]\n",
    "pesos = []\n",
    "for var in var:\n",
    "    #print(var)\n",
    "    #peso = resultados_knn[var].min()\n",
    "    #peso = resultados_knn[var].max()\n",
    "    #peso = resultados_knn[var].mean()\n",
    "    \n",
    "    peso = resultados_knn[var][0]\n",
    "    pesos.append(peso)\n",
    "    \n",
    "\n",
    "peso_testado = np.array(pesos)\n",
    "peso_testado.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia do melhor modelo em disco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WEIGHTED MINKOWSKI\n",
    "\n",
    "NOVO MÍNIMO LOCAL ENCONTRADO:  kNN - AUC valid = 0.7171125975473802 - - AUC teste = 0.7097594819611471 - num_seed_aleatoria = 0 - versao_sentilex = 80_2\n",
    "     Experimento número = 5\n",
    "     Características pipeline: num_pipeline = 5 - tipo_scaler = Sem Scaler\n",
    "     Características do modelo: hyperparâmetros_selecionados = {'algorithm': 'auto', 'leaf_size': 1, 'metric': 'wminkowski', 'metric_params': {'w': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}, 'n_neighbors': 5, 'p': 2}\n",
    "     Características das features selecionadas: num_PCA = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA(n_components=22)), ('scaler', MinMaxScaler()),\n",
       "                ('kNN',\n",
       "                 KNeighborsClassifier(leaf_size=1, metric='wminkowski',\n",
       "                                      metric_params={'w': array([0.8093233 , 0.1981739 , 0.130479  , 0.31633728, 0.93040947,\n",
       "       0.15634982, 0.12300895, 0.1711896 , 0.09953253, 0.40637464,\n",
       "       0.03798309, 0.19449661, 0.99009024, 0.30795755, 0.27682479,\n",
       "       0.97880038, 0.98200391, 0.82488358, 0.1406156 , 0.53879264,\n",
       "       0.64082789, 0.51055045])}))])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melhor_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo-kNN.pkl']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import joblib\n",
    "#joblib.dump(melhor_modelo, 'modelo-kNN.pkl',compress=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas do melhor modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PCA', PCA(n_components=22)), ('scaler', MinMaxScaler()),\n",
       "                ('kNN',\n",
       "                 KNeighborsClassifier(leaf_size=1, metric='wminkowski',\n",
       "                                      metric_params={'w': array([0.8093233 , 0.1981739 , 0.130479  , 0.31633728, 0.93040947,\n",
       "       0.15634982, 0.12300895, 0.1711896 , 0.09953253, 0.40637464,\n",
       "       0.03798309, 0.19449661, 0.99009024, 0.30795755, 0.27682479,\n",
       "       0.97880038, 0.98200391, 0.82488358, 0.1406156 , 0.53879264,\n",
       "       0.64082789, 0.51055045])}))])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "melhor_modelo_knn = joblib.load(open(os.path.join('modelo-kNN.pkl'),\"rb\"))\n",
    "melhor_modelo_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validacao:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50        26\n",
      "           1       0.44      0.52      0.48        21\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.49      0.49      0.49        47\n",
      "weighted avg       0.50      0.49      0.49        47\n",
      "\n",
      "\n",
      "Confusion Matrix Dados - Validacao:\n",
      " [[12 14]\n",
      " [10 11]]\n",
      "\n",
      "Recall_0: 0.46153846153846156\n",
      "Recall_1: 0.5238095238095238\n",
      "Precision_0: 0.5454545454545454\n",
      "Precision_1: 0.44\n",
      "Acuracia: 0.48936170212765956\n",
      "Acuracia Balanceada: 0.4926739926739927\n",
      "AUC: 0.4926739926739927\n"
     ]
    }
   ],
   "source": [
    "versao_sentilex = '80_2'\n",
    "#features_selecionadas = \n",
    "\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#df_test = df_test[(df_test['Date'] > parser.parse('2022-02-01'))]\n",
    "\n",
    "#Separando os dados (é a mesma separação de indexes independente da versao do sentilex, seed, etc)\n",
    "X_test4 = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_test4 = df_test['Fechamento']\n",
    "\n",
    "X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_train4 = df_train['Fechamento']\n",
    "\n",
    "X_valid4 = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_valid4 = df_valid['Fechamento']\n",
    "\n",
    "\n",
    "##Treinando\n",
    "melhor_modelo_knn.fit(X_train4,y_train4)\n",
    "\n",
    "\n",
    "##Avaliando\n",
    "#predict validacao\n",
    "p = melhor_modelo_knn.predict(X_test4)\n",
    "\n",
    "############ Métricas #################\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report - Validacao:\\n\",classification_report(y_test4, p))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados - Validacao:\\n\",confusion_matrix(y_test4, p))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test4, p, pos_label=0)\n",
    "recall_1 = recall_score(y_test4, p, pos_label=1)\n",
    "\n",
    "#Calculando Precision\n",
    "precision_0 = precision_score(y_test4, p, pos_label = 0)\n",
    "precision_1 = precision_score(y_test4, p, pos_label = 1)\n",
    "\n",
    "#Calculando acurácia\n",
    "accuracy = accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test4, p)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test4, p)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Precision_0: %s\" % (precision_0))\n",
    "print(\"Precision_1: %s\" % (precision_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.0 Validação estatística e comparação de performance dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "melhor_modelo_rf = joblib.load(open(os.path.join('modelo-RF.pkl'),\"rb\"))\n",
    "rf = melhor_modelo_rf['RandomForest']\n",
    "\n",
    "et1 = joblib.load(open(os.path.join('modelo-ExtraTree.pkl'),\"rb\"))\n",
    "                  \n",
    "et2 = joblib.load(open(os.path.join('modelo-ExtraTree2.pkl'),\"rb\"))\n",
    "\n",
    "knn = joblib.load(open(os.path.join('modelo-kNN.pkl'),\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados para cada modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "versao_sentilex_rf = '80_2'\n",
    "features_selecionadas = ['pos_rob','neutralidade_vadd4','pos_robd1','score']\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#iremos utilizar só os dados treino/validacao pois vamos rodar um crossvalidation com kfolds\n",
    "#df_train = pd.concat([df_train, df_valid])\n",
    "\n",
    "#X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_train_rf = df_train[features_selecionadas]\n",
    "y_train_rf = df_train['Fechamento']\n",
    "\n",
    "X_test_rf = df_test[features_selecionadas]\n",
    "y_test_rf = df_test['Fechamento']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTree 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "versao_sentilex = '80_3'\n",
    "features_selecionadas = ['pos_finbert','positividade_vadd4','negatividade_vadd1','score']\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#iremos utilizar só os dados treino/validacao pois vamos rodar um crossvalidation com kfolds\n",
    "#df_train = pd.concat([df_train, df_valid])\n",
    "\n",
    "\n",
    "#X_train4 = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "X_train_et1 = df_train[features_selecionadas]\n",
    "y_train_et1 = df_train['Fechamento']\n",
    "\n",
    "X_test_et1 = df_test[features_selecionadas]\n",
    "y_test_et1 = df_test['Fechamento']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "versao_sentilex = '70_4'\n",
    "features_selecionadas = ['positividade_vad','pos_finbert','neutralidade_vadd2','score']\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "\n",
    "#iremos utilizar só os dados treino/validacao pois vamos rodar um crossvalidation com kfolds\n",
    "#df_train = pd.concat([df_train, df_valid])\n",
    "\n",
    "#Separando os dados \n",
    "X_train_et2 = df_train[features_selecionadas]\n",
    "y_train_et2 = df_train['Fechamento']\n",
    "\n",
    "X_test_et2 = df_test[features_selecionadas]\n",
    "y_test_et2 = df_test['Fechamento']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "versao_sentilex = '80_2'\n",
    "\n",
    "df_train = dict_dados_variacoes_sentilex[versao_sentilex][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao_sentilex][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao_sentilex][2]\n",
    "\n",
    "#iremos utilizar só os dados treino/validacao pois vamos rodar um crossvalidation com kfolds\n",
    "#df_train = pd.concat([df_train, df_valid])\n",
    "\n",
    "#Separando os dados \n",
    "X_train_knn = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_train_knn = df_train['Fechamento']\n",
    "\n",
    "X_test_knn = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_test_knn = df_test['Fechamento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Validacao:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50        26\n",
      "           1       0.44      0.52      0.48        21\n",
      "\n",
      "    accuracy                           0.49        47\n",
      "   macro avg       0.49      0.49      0.49        47\n",
      "weighted avg       0.50      0.49      0.49        47\n",
      "\n",
      "\n",
      "Confusion Matrix Dados - Validacao:\n",
      " [[12 14]\n",
      " [10 11]]\n",
      "\n",
      "Recall_0: 0.46153846153846156\n",
      "Recall_1: 0.5238095238095238\n",
      "Precision_0: 0.5454545454545454\n",
      "Precision_1: 0.44\n",
      "Acuracia: 0.48936170212765956\n",
      "Acuracia Balanceada: 0.4926739926739927\n",
      "AUC: 0.4926739926739927\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_knn,y_train_knn)\n",
    "\n",
    "#Relatórios e matriz de confusao\n",
    "print(\"Classification Report - Validacao:\\n\",classification_report(y_test_knn, p))\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix Dados - Validacao:\\n\",confusion_matrix(y_test_knn, p))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#Calculando o recall\n",
    "recall_0 = recall_score(y_test_knn, p, pos_label=0)\n",
    "recall_1 = recall_score(y_test_knn, p, pos_label=1)\n",
    "\n",
    "#Calculando Precision\n",
    "precision_0 = precision_score(y_test_knn, p, pos_label = 0)\n",
    "precision_1 = precision_score(y_test_knn, p, pos_label = 1)\n",
    "\n",
    "#Calculando acurácia\n",
    "accuracy = accuracy_score(y_test_knn, p)\n",
    "\n",
    "#Calculando acurácia balanceada\n",
    "accuracy_balanced = balanced_accuracy_score(y_test_knn, p)\n",
    "\n",
    "#Calculando AUC\n",
    "auc = roc_auc_score(y_test_knn, p)\n",
    "\n",
    "print(\"Recall_0: %s\" % (recall_0))\n",
    "print(\"Recall_1: %s\" % (recall_1))\n",
    "print(\"Precision_0: %s\" % (precision_0))\n",
    "print(\"Precision_1: %s\" % (precision_1))\n",
    "print(\"Acuracia: %s\" % (accuracy))\n",
    "print(\"Acuracia Balanceada: %s\" % (accuracy_balanced))\n",
    "print(\"AUC: %s\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando dicionário com dados de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dados_modelos = {}\n",
    "dict_dados_modelos['rf'] = [rf, X_train_rf,y_train_rf,X_test_rf,y_test_rf]\n",
    "dict_dados_modelos['et1'] = [et1, X_train_et1,y_train_et1,X_test_et1,y_test_et1]\n",
    "dict_dados_modelos['et2'] = [et2, X_train_et2,y_train_et2,X_test_et2,y_test_et2]\n",
    "dict_dados_modelos['knn'] = [knn, X_train_knn,y_train_knn,X_test_knn,y_test_knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossvalidation com 10kfold - 30 Repetições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetição 1\n",
      "Repetição 2\n",
      "Repetição 3\n",
      "Repetição 4\n",
      "Repetição 5\n",
      "Repetição 6\n",
      "Repetição 7\n",
      "Repetição 8\n",
      "Repetição 9\n",
      "Repetição 10\n",
      "Repetição 11\n",
      "Repetição 12\n",
      "Repetição 13\n",
      "Repetição 14\n",
      "Repetição 15\n",
      "Repetição 16\n",
      "Repetição 17\n",
      "Repetição 18\n",
      "Repetição 19\n",
      "Repetição 20\n",
      "Repetição 21\n",
      "Repetição 22\n",
      "Repetição 23\n",
      "Repetição 24\n",
      "Repetição 25\n",
      "Repetição 26\n",
      "Repetição 27\n",
      "Repetição 28\n",
      "Repetição 29\n",
      "Repetição 30\n"
     ]
    }
   ],
   "source": [
    "resultados_rf = []\n",
    "resultados_et1 = []\n",
    "resultados_et2 = []\n",
    "resultados_knn = []\n",
    "\n",
    "for i in range(30):\n",
    "    print(\"Repetição %s\" % (i+1))\n",
    "    \n",
    "    #Loop mdelos:\n",
    "    for modelo in dict_dados_modelos.keys():\n",
    "        \n",
    "        \n",
    "        instancia_modelo = dict_dados_modelos[modelo][0] \n",
    "        #print(instancia_modelo)\n",
    "        X = dict_dados_modelos[modelo][1]\n",
    "        y = dict_dados_modelos[modelo][2]\n",
    "        X_test = dict_dados_modelos[modelo][3]\n",
    "        y_test = dict_dados_modelos[modelo][4]\n",
    "        \n",
    "        #Holdout para treinar com 70% dos dados de validação+teste\n",
    "        X_train, X_descarte, y_train, y_descarte = train_test_split(X, y, test_size=0.8, random_state=i, stratify=y)\n",
    "        \n",
    "        # 10 Kfolds\n",
    "        kfold = KFold(n_splits = 10, shuffle = True, random_state = i)\n",
    "     \n",
    "        instancia_modelo.fit(X_train,y_train)\n",
    "        score = instancia_modelo.score(X_test,y_test)\n",
    "        \n",
    "        #score = cross_val_score(instancia_modelo, X_train, y_train, cv = kfold, scoring = \"f1\")\n",
    "    \n",
    "        # Aplicação dos kfolds para avaliação estatística\n",
    "        if modelo == 'rf':\n",
    "            \n",
    "            resultados_rf.append(score)\n",
    "            \n",
    "        if modelo == 'et1':\n",
    "\n",
    "            resultados_et1.append(score)\n",
    "            \n",
    "        if modelo == 'et2':\n",
    "\n",
    "            resultados_et2.append(score) \n",
    "            \n",
    "        if modelo == 'knn':\n",
    "\n",
    "            resultados_knn.append(score)\n",
    "            \n",
    "# Transformando os resultados para numpy\n",
    "score_rf = np.array(resultados_rf)\n",
    "score_et1 = np.array(resultados_et1)\n",
    "score_et2 = np.array(resultados_et2)\n",
    "score_knn = np.array(resultados_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results rf: 0.5121 (0.0645) f1\n",
      "Results et1: 0.4993 (0.0626) f1\n",
      "Results et2: 0.5660 (0.0685) f1\n",
      "Results knn: 0.4730 (0.0591) f1\n"
     ]
    }
   ],
   "source": [
    "print(\"Results rf: %.4f (%.4f) f1\" % (score_rf.mean(), score_rf.std()))\n",
    "print(\"Results et1: %.4f (%.4f) f1\" % (score_et1.mean(), score_et1.std()))\n",
    "print(\"Results et2: %.4f (%.4f) f1\" % (score_et2.mean(), score_et2.std()))\n",
    "print(\"Results knn: %.4f (%.4f) f1\" % (score_knn.mean(), score_knn.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação pré-feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 65) (441, 2)\n",
      "k = 2 - Acuracia = 0.5268817204301075\n",
      "(441, 65) (441, 3)\n",
      "k = 3 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 4)\n",
      "k = 4 - Acuracia = 0.4946236559139785\n",
      "(441, 65) (441, 5)\n",
      "k = 5 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 6)\n",
      "k = 6 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 7)\n",
      "k = 7 - Acuracia = 0.5268817204301075\n",
      "(441, 65) (441, 8)\n",
      "k = 8 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 9)\n",
      "k = 9 - Acuracia = 0.4838709677419355\n",
      "(441, 65) (441, 10)\n",
      "k = 10 - Acuracia = 0.5698924731182796\n",
      "(441, 65) (441, 11)\n",
      "k = 11 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 12)\n",
      "k = 12 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 13)\n",
      "k = 13 - Acuracia = 0.5161290322580645\n",
      "(441, 65) (441, 14)\n",
      "k = 14 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 15)\n",
      "k = 15 - Acuracia = 0.5161290322580645\n",
      "(441, 65) (441, 16)\n",
      "k = 16 - Acuracia = 0.41935483870967744\n",
      "(441, 65) (441, 17)\n",
      "k = 17 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 18)\n",
      "k = 18 - Acuracia = 0.5698924731182796\n",
      "(441, 65) (441, 19)\n",
      "k = 19 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 20)\n",
      "k = 20 - Acuracia = 0.4838709677419355\n",
      "(441, 65) (441, 21)\n",
      "k = 21 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 22)\n",
      "k = 22 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 23)\n",
      "k = 23 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 24)\n",
      "k = 24 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 25)\n",
      "k = 25 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 26)\n",
      "k = 26 - Acuracia = 0.4946236559139785\n",
      "(441, 65) (441, 27)\n",
      "k = 27 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 28)\n",
      "k = 28 - Acuracia = 0.5913978494623656\n",
      "(441, 65) (441, 29)\n",
      "k = 29 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 30)\n",
      "k = 30 - Acuracia = 0.5698924731182796\n",
      "(441, 65) (441, 31)\n",
      "k = 31 - Acuracia = 0.5913978494623656\n",
      "(441, 65) (441, 32)\n",
      "k = 32 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 33)\n",
      "k = 33 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 34)\n",
      "k = 34 - Acuracia = 0.5268817204301075\n",
      "(441, 65) (441, 35)\n",
      "k = 35 - Acuracia = 0.46236559139784944\n",
      "(441, 65) (441, 36)\n",
      "k = 36 - Acuracia = 0.6129032258064516\n",
      "(441, 65) (441, 37)\n",
      "k = 37 - Acuracia = 0.5268817204301075\n",
      "(441, 65) (441, 38)\n",
      "k = 38 - Acuracia = 0.5161290322580645\n",
      "(441, 65) (441, 39)\n",
      "k = 39 - Acuracia = 0.4838709677419355\n",
      "(441, 65) (441, 40)\n",
      "k = 40 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 41)\n",
      "k = 41 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 42)\n",
      "k = 42 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 43)\n",
      "k = 43 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 44)\n",
      "k = 44 - Acuracia = 0.4731182795698925\n",
      "(441, 65) (441, 45)\n",
      "k = 45 - Acuracia = 0.4946236559139785\n",
      "(441, 65) (441, 46)\n",
      "k = 46 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 47)\n",
      "k = 47 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 48)\n",
      "k = 48 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 49)\n",
      "k = 49 - Acuracia = 0.4838709677419355\n",
      "(441, 65) (441, 50)\n",
      "k = 50 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 51)\n",
      "k = 51 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 52)\n",
      "k = 52 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 53)\n",
      "k = 53 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 54)\n",
      "k = 54 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 55)\n",
      "k = 55 - Acuracia = 0.5698924731182796\n",
      "(441, 65) (441, 56)\n",
      "k = 56 - Acuracia = 0.5053763440860215\n",
      "(441, 65) (441, 57)\n",
      "k = 57 - Acuracia = 0.46236559139784944\n",
      "(441, 65) (441, 58)\n",
      "k = 58 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 59)\n",
      "k = 59 - Acuracia = 0.5806451612903226\n",
      "(441, 65) (441, 60)\n",
      "k = 60 - Acuracia = 0.5483870967741935\n",
      "(441, 65) (441, 61)\n",
      "k = 61 - Acuracia = 0.5376344086021505\n",
      "(441, 65) (441, 62)\n",
      "k = 62 - Acuracia = 0.5268817204301075\n",
      "(441, 65) (441, 63)\n",
      "k = 63 - Acuracia = 0.4946236559139785\n",
      "(441, 65) (441, 64)\n",
      "k = 64 - Acuracia = 0.4946236559139785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "k_vs_score = []\n",
    "\n",
    "versao = '80_2'\n",
    "df_train = dict_dados_variacoes_sentilex[versao][0]\n",
    "df_valid = dict_dados_variacoes_sentilex[versao][1]\n",
    "df_test = dict_dados_variacoes_sentilex[versao][2]\n",
    "\n",
    "X_train = df_train.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_train = df_train['Fechamento']\n",
    "\n",
    "X_valid = df_valid.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_valid = df_valid['Fechamento']\n",
    "\n",
    "X_test = df_test.drop([\"Fechamento\",\"Adj Close\",\"Date\",\"Volume\",\"Var%\",\"Noticias\",\"Noticia_traduzida\"],axis=1)\n",
    "y_test = df_test['Fechamento']\n",
    "        \n",
    "        \n",
    "for k in range(2, X_train.shape[1], 1):\n",
    "    selector_model = RandomForestClassifier(random_state = 1, n_jobs=-1)\n",
    "    selector = SelectFromModel(selector_model, max_features=k, threshold=-np.inf)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    X_train2 = selector.transform(X_train)\n",
    "\n",
    "    X_test2 = selector.transform(X_test)\n",
    "\n",
    "    print(X_train.shape, X_train2.shape)\n",
    "\n",
    "    #Xtrain.columns[selector.get_support()]\n",
    "\n",
    "    #mdl = RandomForestRegressor(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "    #mdl = XGBRegressor(objective=\"reg:squarederror\", seed=0)\n",
    "    mdl = selector_model\n",
    "    mdl.fit(X_train2, y_train)\n",
    "\n",
    "    p = mdl.predict(X_test2)\n",
    "\n",
    "    score = accuracy_score(y_test, p)\n",
    "    print(\"k = {} - Acuracia = {}\".format(k, score))\n",
    "\n",
    "\n",
    "    mask = selector.get_support()\n",
    "    #print(Xtrain.columns[mask])\n",
    "\n",
    "    k_vs_score.append(score)\n",
    "    #break\n",
    "\n",
    "    # k =14 , mae = 100.5\n",
    "    # k = 6, mae = 96.07 - ['COMPLETION QUARTER', 'V-1', 'V-7', 'V-8', 'V-17.3', 'V-20.4']\n",
    "    # k = 4, mae 94.78\n",
    "    # rf - k=8 - Index(['V-1', 'V-5', 'V-7', 'V-8', 'V-11', 'V-14', 'V-14.1', 'V-11.2']\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAGbCAYAAABj1iyXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAACTL0lEQVR4nO39e5QkZ3nmiz5fXiKvlZl16e6q7q7uKpCQELp0g5BAsj3AGFvYjMDG9oAxIHnG7LmwsGdmew+ccwavweN9tvc5Zzyevdgzi8FIMsZgDMbItmwN2OCLEKCGLt0QEq3u6q7q7uruyq68Z0ZmZHznj4gvMiorLxGZEZERWe9vrV7qzsqqikpVRrzxvs/7PIxzDoIgCIIgCMI7QpM+AIIgCIIgiP0GFWAEQRAEQRAeQwUYQRAEQRCEx1ABRhAEQRAE4TFUgBEEQRAEQXhMZNIHYIeFhQW+srIy6cMgCIIgCIIYyne/+91tzvmBXh8LVAG2srKCU6dOTfowCIIgCIIghsIYO9/vYzSCJAiCIAiC8BgqwAiCIAiCIDyGCjCCIAiCIAiPoQKMIAiCIAjCY6gAIwiCIAiC8BgqwAiCIAiCIDyGCjCCIAiCIAiPoQKMIAiCIAjCY6gAIwiCIAiC8BgqwAiCIAiCIDyGCjCCIAiCIAiPoQKMIAiCIAjCY6gAIwiCIAiC8BgqwAiCIAiCIDyGCjCCIAiHKdZb4JxP+jAIgvAxVIARBEE4SL4i4/W/9TX87UvXJn0oBEH4GCrACIIgHCRfbaKpqNi4Xpv0oRAE4WOoACMIgnAQuaUCAMqyMuEjIQjCz1ABRhAE4SCy0gYAVBpUgBEE0R8qwAiCIBxEVrQOWJU6YARBDIAKMIIgCAcRHTAaQRIEMQgqwAiCIBxEaMBoBEkQxCCoACMIgnCQZlsvwKgDRhDEAKgAIwiCcBCjA0YFGEEQA6ACjCAIwkFoC5IgCCtQAUYQBOEgYguSRPgEQQyCCjCCIAgHIRsKgiCsQAUYQRCEg8gtbQRZa7bRVimQmyCI3lABRhAE4SCiAwaQEJ8giP5QAUYQBOEgVIARBGEFKsAIgiAcRGxBArQJSRBEf6gAIwiCcBDhAwYAFbk1wSMhCMLPUAFGEAThILtHkO0BzyQIYj9DBRhBEISDyIqKaJgBoBEkQRD9oQKMIAjCQWSljbmUBIBGkARB9IcKMIIgCAeRFRXzqRgAoEwdMIIg+mCpAGOM3ccYe5ExdoYx9pE+z/kFxtj3GWPPM8b+0PT4BxhjP9T/fMD0+OsYY8/qX/O/MsbY+D8OQRDEZJEV1dQBowKMIIjeDC3AGGNhAJ8A8DYAtwB4D2Pslq7n3AjgowDu5Zy/BsCv6Y/PAfgNAHcDuAvAbzDGZvVP+28AfgXAjfqf+xz4eQiCICaK3GojIYWRlMKkASMIoi9WOmB3ATjDOT/LOW8C+DyAd3Q951cAfIJzvgMAnPOr+uM/CeCrnPPr+se+CuA+xtgSgAzn/Fuccw7g9wG8c/wfhyAIYrI0FRWxSAjpWIQ6YARB9MVKAXYEwIbp35v6Y2ZeBeBVjLEnGGPfYozdN+Rzj+h/H/Q1AQCMsQ8yxk4xxk5du3bNwuESBEFMDllREYuEkY5TAUYQRH+cEuFHoI0R3wTgPQD+B2Ms58QX5px/knN+J+f8zgMHDjjxJQmCIFxDVtqIRUOYoQ4YQRADsFKAXQSwbPr3Uf0xM5sAHuWctzjn5wC8BK0g6/e5F/W/D/qaBEEQgUNu6SPIeIQ0YARB9MVKAfYUgBsZY6uMMQnAuwE82vWcP4XW/QJjbAHaSPIsgMcB/ARjbFYX3/8EgMc555cBlBhjb9C3H98P4CsO/DwEQRATxRhBUgeMIIgBRIY9gXOuMMY+BK2YCgP4NOf8ecbYxwGc4pw/ik6h9X0AbQC/zjnPAwBj7DehFXEA8HHO+XX97/8KwMMAEgD+Uv9DEAQRWFSVo9nWOmCpWIR8wAiC6MvQAgwAOOePAXis67GPmf7OAfxb/U/3534awKd7PH4KwK02j5cgCMK3NNtaDiRpwAiCGAY54RMEQTiECOKWwpoGrCor0O5PCYIgdkMFGEEQhEPIShsAEIuGkY5FoajcKMoIgiDMUAFGEAThEHJLH0HqW5AA5UESBNEbKsAIgiAcQnS7YhFNAwZQHiRBEL2xJMInCIIghmOMICNhREIMAMgLjCCInlABRhAE4RBGBywaQjwSBgCU5dYkD4kgCJ9CI0iCIAiHMGvAZnQNGHXACILoBRVgBEEQDmEeQaZ1DVi1SQUYQRB7oQKMIAhH+KvntvDwE+dc/R5f+u4mHnL5e4yDWYSfpg4YQRADoAKMIAhH+Oy3z+O//+1ZV7/HJ75xBv/vx36Aa2XZ1e8zKqIAi0dDRgesTFuQBEH0gAowgiAcYavYwNVyA0rbHePRYq2Fs9eqaLZVfPbb5135HuMitzojyFgkhGiYUQeMIIieUAFGEIQjbBUbUDlwreJOd+rpzQIAYCEdwx986wKaPnSYN7IgIyEwxpCiPEiCIPpABRhBEGNTkRVj1LZVbLjyPU5fKIAx4D/e/xpsV2T8xbOXXPk+4yC2IKWIdmpNxyLUASMIoidUgBEEMTbmosutAmxtYwc3Hkzjp25bxCsPpPDQE+u+C7ruiPA1D7A0dcAIgugDFWAEQYyNuei67EIBxjnH2kYBJ5ZzYIzhgXtX8cxmEd+7sOP49xoHYUMhOmAzcSrACILoDRVgBEGMzVapU3RdKTlfgJ3P17BTa+HE8iwA4GdPHsFMPIJPP7Hu+PcaB1lREQ0zhPUYIuqAEQTRDyrACIIYm61iHQCwmIm70gFb2ygAAE4eywEAUrEI3v36ZfzVc1u4rH9vPyC3VGP8CADpeJQ0YARB9IQKMIIgxuZysYHZZBTH5pOuaMBOX9hBUgrjVYdmjMfe/8YVcM7xmSf9Y0khK23EIp3TajoWIR8wgiB6QgUYQRBjs1VsYDGbwFI2jssl5ztSaxsF3HYka4z2AGB5Lom33nIIn/vOBTR0/61JIytqVwEWpg4YQRA9oQKMIIix2So1sJSNYzEbx5Wi7Oh2YqPVxvcvl3Dy2Oyejz1wzyp2ai386emLjn2/cZAVFbGoaQQZi6LeartmTksQRHChAowgiLHZKjZwKBPHYiaOZlvF9WrTsa/9/KUSWm2OE8u5PR97wyvmcPPiDB7+pj8sKeRW1wgyLgK5/dGhIwjCP1ABRhDEWMhKG/lqE0vZOJaycQDOWlF0C/DNMMbwy/eu4gdbZTx5Nu/Y9xyV7hHkjJ4HSZuQBEF0QwUYQRBjcbWkRQ8tZuNYzCYAOGtFcfrCDg5n4ziUiff8+P0nDmMuJeEhH1hSNJXuLUi9ACMdGEEQXVABRhDEWIhu16I+gjQ/5gRrGwWc6NH9EsSjYbznrmV87YUruJCvOfZ9R0FW2ohFd29BAkBFbk3qkAiC8ClUgBEEMRbCh2spG8eBmRjCIeaYFcW1sozNnTpOLu8V4Jt53xtWEGYMjzy57sj3HRVZUSGF92rAytQBIwiiCyrACIIYCzFuXMzGEQ4xHJyJ7XLGHweh/xrUARPf+223LeELT22gOkG9lbYF2asDRgUYQRC7oQKMIIixuFxsICWFMROPAtCKIac6YGsbOwiHGG49nB363AfvXUFZVvCl72068r1HQTNiNdtQ6FuQVIARBNFFZNIHQNjn8ee3cNuRLA7nEpM+FMIDZKWNT/39OdSa/S/iDAw/89ojeOWBtIdHpqGZsHYE8ouZOF66Unbka5++UMCrl2aQkMJDn3tyOYc7jmbx8BPr+KW7jyNkMm31Ci2KiEaQTvL481u49UgWRwJ+vvvy6U38o1cdxFxKmvShjExb5fi9fziLYn2wpvGnbzuMWw5nPDqq4EIFWMBotVX8yz/4Lv7lm16JX//Jmyd9OIQHfHd9B/+fx19EiAEh1ruoUFSOYr2F33znrR4fndYBW8p2Lo6L2Tj+/ofbY3/dtsrxzGYR7zx52NLzGWN41+uO4mNfeR6XS42JXLC7bShSEo0gx4Fzjn/92e/hgXtW8P96+y2TPpyR2bhew7/5o6fxG//kFjx47+qkD2dkXrhcwv/+2A+GnotevlrFf3/f6zw+uuBBBVjA2Kk2oXK6o95PiLvNx371R3HzYu+7yjf/f78x9K7ULa6UGnjlKxeMfy9l46jICsqNljGWHIWXr1VQkRWcGCLAN3MgHQMAlOqtCRVg7V1O+OEQQ0qiOKJRqTXbUFTuSsC7l5zdrgLAxN6jTlHTDYU/88/uxr03LPR8zj97+Cmc039eYjCkAQsY2xXNYbwqk7P2fqHU0E7ag4qZmXjEeJ6XKG0VV8uyYcAKwPDrGlcHdvrCDoDeBqz9EK9RaQIXOs75ng4YoI0hqQM2GuJ1E5u2QWVdL0hK9WD/HtT1zNV4tL8kYGUhhfV8Fao6+WQKv0MFWMDIVzXTy0F6IGK6ECftTLx/wzoTj06k6NiuNNFW+S4NmBhHjtu1WNsoIBOPYHU+ZflzMgntNSpNoOPUanNwjj0FWCoWQZkKsJEQBdgV3ew3qIiO0CRukpykrnfAEkMKMFlRHduEnmaoAAsY2xXtRER31PuHUqOFEOvoiXqRSUQmUnSIk+zSrgIsvutjo3L6QgEnjs3aEtNnJtgBkxXt4mTeggS0OCIaQY6GeN2ulBpoB7ijcj4vOmDBLsAaegds0FKMuGFaz9MYchhUgAWMvD6CrFG4776hVNe0VIMKkUl1wLb00ZA5JuhgJqZ/bPQCrCoreOlKuWcA9yAyCb0Am0CnoamoALDLBwzQRpBkQzEa4kZTUTnyleB2wdb1hIbAd8BaVjpgSQDA+vZkUymCABVgAaOjAaMT+n6h1FCM0Vo/MonoRE7uYsxo7oDFImHMp6SxRpDPbBahcs1awg4z+ph2ElobWRRg3RqwGGnARsW8bBRUIb7SVrFxXS/Agq4BszCCPJxNQIqEqANmAUsFGGPsPsbYi4yxM4yxj/T4+AOMsWuMsTX9zz/XH3+z6bE1xliDMfZO/WMPM8bOmT52wskfbFoRd4FV0oDtG8qNljFa60cmHkGjpRpdGK/YKjUghUN7vI0Ws/GxArlPb2gCfLsdsGg4hKQURnkCxWinANt9cUrHorS1PCLmwjWomqLNnToUlSMSYigHPBPUEOFL/UuHUIjh+FySNiEtMNSGgjEWBvAJAG8FsAngKcbYo5zz73c99Y845x8yP8A5/zqAE/rXmQNwBsD/ND3l1znnXxz98Pcf+ao+gqQtyH1Dqa4YnZ1+iO2/cqOFed2KwQu2ig0cysbAujyBFjNxXBqjY7F2oYCV+SRmRzCtnNRGqNCASV0dsBnaghyZiun/o1PpCl5zTu8E3bQ4g82dYG9zNlpthBh25Z32YmUhZWx+Ev2x0gG7C8AZzvlZznkTwOcBvGOE7/VzAP6Sc06D4TGgDtj+o2SlAzah7b/LxQaWMnv9trQ4otEuNpxznN4o2O5+CTQ93ARGkK3BI0jOgysinxSicA2HWGBHkKIQuf1oFuVGK9D2DPVmG4loeM8NVzerCymcv14L9M/qBVYKsCMANkz/3tQf6+ZdjLFnGGNfZIwt9/j4uwF8ruux39I/53cYYz1v2xljH2SMnWKMnbp27ZqFw51uhAas0VKhtL0dNxGToVRvGeLyfkxq++9KaXcMkWApG8dOrWVsTdnhUrGBa2UZJ49ZN2A1Myk9XL8RZCoWQVvlaLTo/WqXityGFAlhacyR9iRZ364iHYtgdSEFlQf75rnealuKBVuZT6GpqLgUcP82t3FKhP9nAFY457cD+CqAR8wfZIwtAbgNwOOmhz8K4GYArwcwB+Df9/rCnPNPcs7v5JzfeeDAAYcON5hwzrFdkRENa3cftREubkTwKDUUCx0w77f/ONccynsVYIu6F9goF821CwUA9vVfgsyER5C9tiABso4ZhYrcwkwsgqVsPLBmrOfyNawsJJE13qPB/T2ot9oDTVgFtAlpDSsF2EUA5o7WUf0xA855nnMudoQ/BaA7BOoXAHyZc94yfc5lriEDeAjaqJMYQLXZhqyoODqr/XKTDmz6aascFdnCFqTRAfPu5L5Ta6GpqFjM9CjA9MdGGRudvrADKRLCq5dGC/PNJCYjeu83gpyJUQE2KpWGgnQ8gkOZeGA1YOvbVazMpybqUecUjVZ74AakYHVB8wI7R5uQA7FSgD0F4EbG2CpjTII2SnzU/AS9wyW4H8ALXV/jPegaP4rPYdow+Z0AnrN15PsQof9antMKsCC3sglrCCPKYZmKokDzcvtPdCSWenbAtMdG6oBtFHDr4cweMbtVJuWJ1n8LUi/AAtz5mBQVWUFa74BtlRqB09E1FRWbOzWsLqSMLnWQN2LrzTaSFkaQh2biiEVCJMQfwtAtSM65whj7ELTxYRjApznnzzPGPg7gFOf8UQAfZozdD0ABcB3AA+LzGWMr0Dpof9v1pT/LGDsAgAFYA/Avxv5pphyh/zo2p413yAts+hGjtEExRIApA9HDAkwUV4cGFGB2O2CttopnLxbx3ruPj3xc2hakJnofJhZ2ko4Tfu8RZNAtCCZBuaEVYIvZBBotFcV6C7mk/c3YSbGxU4PKgePzKZNHXXB/D6yOIEMhhpV52oQcxtACDAA4548BeKzrsY+Z/v5RaJquXp+7jh6ifc75W+wcKNHpgB2f09q7FMg9/RT1k/UwEX5KCiPEvB1B9jJhFaRjEczEIrbHRj+4XIasqLYCuLvJJKJoqxy1ZhupmKVTnCPI/ZzwqQM2MhVZwWImvmukHaQCTBQgqwvJzggywG749WbbsjXMykISP7xacfmIgg054QcI4QEmRpAUyD39dDpggwswxpjn239bxQZCDDjQx3dscQTh9NqIBqxmJnWhaw4bQVLH2jZVWdOAiY5q0HRgwox0Zb4zggx6B8yKBgzQvMA2rtdoW38AVIAFCNEBO6YXYHRCn35ER2uYCB/wXvu0VWzgwEwMkT6mjIvZOLZK9vL7Tl8oYCEt4ejsXm8xqxieaB57gQ0bQdL71T5mDRgQPDf88/kaZuIRzKWkzggywJ1QOwXY6nwKrTYPrH+bF1ABFiC2K03jzQyMHsitqhwvbpWdPLTAcrlYx3W9s+hHyhY7YIBWeHgp8N0qNQy7iV4sZuybsa5tFHBieXYs7VbGlArgJYOMWAEqwEahrG9BHpiJgbHg5UGu56tYXUiBMeZJTNaLW2W0XTQ/rTdVxC2I8AGtAwaAIokGQAVYgNiuyFhIx5CMaW+AUUX4X3vhCu773b/D5g55tPyLz3wX/+Er/l3AFXfLlgqwuLcjSM0Ff6/+S7CUjeNaWbY8gijUmji7XR1L/wVMxhMN0DRg4RDb0xGMRUKIhhlpwGzSVFTIioqZWATRcAgH0rGR0xUmxTndgkIwE4+41pnduF7Dfb/7d/ir57Zc+fqAdRsKoGNFQaHc/aECLEDkK03MpyQko6IAG60DdqUsg/PRLAKmjUvFBn5wuTTpw+iLGCmmh2xBAu6e3HtxpY8Jq2Axm4DKgWsVa2PItY0CAODkGPovAKZtM+9HkL0y8hhjRhwRYR1xgyk6iEsjjLQniay0calQNzpBgLs3SS9dKYNzuGZYyzm3NYI8OBNDUgpTB2wAVIAFiHxVxnxaQiQcQjwaGlmEL+7Ed6rBFYM6AecchVoTG9frrrbtx6HU0JzAw6HhIzkvO2DlRgtlWRlYgC3ZtKJY2yiAMeC2o9mxjm1SInxZUfdsQArS8Qh1wGwiClaxyXpohJH2JNm4rllQrOqu8IC7MVmi0NmpuSOpaLU52iq3FEUEaDcex8mKYiBUgAWIfKWJeX3jLCVFRjZiFXeWhQBv4zhBrdlGq83RbKu4VPDnib1UV4ZaUAgyCe9E+KJ72suCQnAoY29z7fSFAm48mB5qOjuMSfktyS11j/5LkI5FUaYOmC3KhglxpwMWJA3YOT2GxzyCzLjYpRajvkLNnd/7uh59Z8UHTLC6kMR6nqQu/aACLCC0VY7rtSYWdAF+MhYeeQQp7iwLLt0pBQXznaJfdQrlRsu4AA0jE4+i2mx7sva9VdRGQYeGaMC05w6/aHLO8fRmASeXRwvgNhOPhhGLhDzfNpOV9h4LCkE6FqYOmE3EDWY6phXki9kEyg0lMAbUHQ8wUwHmYgfsvF7ouFWANfQCzOoIEtCKT7Ki6A8VYAFhp9YE58DCjKkDNuKJSNxZuvVGDQrmn9+vbfJSo2VJgA907Be80BoNiiES5JJRxCIhS9YB6/kaCrUWTowpwBdoeZATGEH27YCN3rHer4iCVegfF7PauS8oVhTn8lXkktFdxrGZuHs5pWIEWai7c2Nd17fuE5L1smFlIQVF5djc8eeEYdJQARYQtnUh83xKL8BikZFtKCp6JIpbb9SgUDSNqMS4wG9oI0hrHbAZDwO5RVdrUAeMMaabsQ6/YJ6+oBmwjrsBKfB6IQEYpgGLUgfMJuUuEf5iRrM8CYoZ63rXBiQgfi9bjmdaCsE/4P4I0k4HjEK5B0MFWEDI6zmQ82l9BCmFR+50iM/b2ecdMDGCjEVCvh1B2uqAGUaP7v9/vVxqYC4lDdWDLGbiuGLhgrm2UUBKCuPGgzOOHJ/XlhzAsBFkhDRgNqn00IABwfEC0wqw5K7HMokoFJUbxYxTCMF/LBLylQZMFKB+nTBMGirAAoLogC3oBVhKioy9BVnc5wWYOFHddiTr2xNEqd6yJcIXn+M2V4qNgd0vwVI2jsul4eOH0xcKuO1o1tK2pxW8XEgQNAeMIGdoC9I2olNvdMD0AiwI9jmNVhuXio1dFhSAaUPX4e6s6ODfdiTrmra30bTfAVtIS0jHIr49v04aKsACgtEBM40gxxXhu7WuHBTEierEcg4XfCgUVVWOsqwYna1heGm/cLnYGKj/EhzKxnGlKEMdYPPRaLXxwuUSTh4bX4AvyMQjExDhD9aA1VveLEhMC5WGAsa0bj+gdV5yyahrPldOIgTxq90FWMKdLrUocE4s51Btto1cUicRHbCkZD3gnjGGlYUkztEmZE+oAAsI+aqMcIghq3c5UrHw6B0wmUT4gPbzJ6UwXnVoBorKcdFnVhTVpgLOYaMD5p0BqRZDZKEDlomj2VZxfUCx//ylIhSVjxXA3c1ERPgtdeAIEhjdPHk/UpYVpKXIrlgqLd7K/x0wcwi3mU4HzNnfzXP5KmaTURzXR55u6HtrI4jwAe01oA5Yb6gACwjCBT+kj2iS0hgdsAbZUACaBi6XiPo2s6zUpYEZhlcRPI1WG9erTSxaGEGKrMhBF83TFwoAxnfAN6MFkyuOi50HISvt/iJ8vQAry/v7pscOVVnZkwChueH7vwA7r2tK94wgEyKn1NmbpPXtKo7Pp4yNSzdurkfRgAFaAba5U3OlKxd0qAALCNsmE1ZA8xVqtlXbv9RtlaPabCMaZq61qoNCsd5ELikZQlm/3aWJu2SrInytWwDXR29X9TgYKx2wRQteYKc3CjiSS+CghYLOKjPxCJptLUvQK2RF7RlFBHSsFKgDZp2KrBiFq2AxG4wO2Hq+irmUZEwsBDMuLcqsb2uh37mk9v3cKMBG8QEDtCJU5aDs4R5QARYQtCDujp+MmMPXbVpRCC+iwzmtM7GfrSh2ai3kklEcmIkhJYV959hsFGAWR5ChkJY56Lb43IoHmMDYXBvQtVi7UHB0/Ah4u5AgGGhDERMebdQBs0q5sbcDtphJYLvShKz4u5A912MDEnBnBGkI/udTyCW0a4Qb+t6OD5i9AkxEMfl103ySUAEWEPJVGfOpTgGWimlvgopNHZgYPy7Pam+K/bwJWag1MZuUjMwyv44grXbAxHPdHkGKEZCVEeRCOoZwiPW1orhabuBioe6Y/5fAS0sOgdwaYEOhH49bJpzTSK8OmCjor/o8lHt9u7Zn/AiYO2DO/R4Iwf/KQtLogLlxXjdGkH1+x/shdHB+9VqcJFSABYR81whSBNTWbHoLCQH+0VmtA7afvcAKtRay+glrdSFl6Db8ghCRWzVi1Z4bdV2EL0ZAVkaQ4RDDoZlYX++mNV3/5VYHrOihGeugLciZmHcpBdNCpbG3ADskRto+1oHVm21slRpYnd9bgBkxWQ52wM6ZIo9EAeZKB6zVRiwSMnTIVplLSZiJkxVFL6gACwC1poJas22YsAKaDxgAVG2OIMUFYHlO35bZp0J8zjkK9RZm9RPWykISGzt1tHxkEyBO0nbCqTX7BbdHkA2kYxHLx3UoG8dWHy+w0xsFREIMtx7JOnmIRtfQq01Ipa1CUfnQDhh5gVlnUAfMz2as630E+AKn8yDN3y8diyASYii4MHpvNNu2x4+AZkWxupCiEWQPqAALAMIDbMHUARPeOHbzIMUFQHTA9qsVRVlW0Fa5oZlYmU+h7bPMMrtbkICwX3D3In+l1MChTGz4E3WWBgin1y4U8OqljO3NqmFkE86PegbR1Av3fhqwFHXAbFPppQETZqx+LsB6hHCbcdqjbn27ivmUhEw8CsYYcsmoa1uQdgX4ghUfSjz8ABVgASBfFQWYWQMmtqrGG0HuVxG+0EjkTCNIwF+bkKW65lMW7bNZ1wuRNecmmglrwvLzFzMJXC429lhCtFWOZzadF+AD5lxMb24w5JZegPUZQYqONWnArME5R6WpGKNbwUwsgqQU9nUHTOQeHu8hwge0300nfy/X89Vd3bZcUnJlslFvqaMXYAspXCrUfb884TVUgAWAfFcQN2DSgNkdQeoXgIMzca1VvU87YAWjANM7YD70ArOTAynwRIRftGbCKljMxlBrtvdkIf7wahnVZttxAT7gbSoAYOqA9RlBhkMMKSls+4Zpv1JrtsE59nTARMB7v5G2H1jfrmIhLfUd0WsjSCc7YLVdhq+5hEsdsGZ75E716kISKtcyK4kOVIAFAJEDuVsDpm9B2jyhi4tgJh5FLintWxG+EKkKDdh8SsJMLOIrnUKprtgS4APayb0iKwOjf8ZBaau4Wm5Y2oAUCDPW7rGRWwJ8AIhHQ4iGmSepAMDwDhigFRM0grSGeJ3Ssb1FzFI27usOWHdB1E0mHkHZoQ6YIfhf6HTbtPO68x2wRms0DRhAm5D9oAIsAGx35UAC5g7YaBqwVEzLVSvu0xGkEKmKEaSWWeYvnUJZHqUDFgHn2NNtcortShMqt7YBKegnnD59oYBsItpXKzMOjDFPuoECMVrppwEDNC8wt/6/TBtiVNvdAQO0kbafNWDnukaC3Tgpwu8l+NfO6/7SgPlR4uEHqAALAPlKEykpvOvuQ7wR7DprV5sKEtEwIuEQcokodqr7swMmNBJiBAloJzG/dcDsCPABc9SJO/9f7ZiwCkS3rFuIv7ah6b/MWX9O4sVCgkA47vcbQQJAOh6lLUiLdDpge1/PxWwMV8oy2i51ecehIiu4VpYH3lSImCwnWO+ROTmbjLpmxDrqCDKXlJBLRg19HKFBBVgAyFflXR5ggOZ6nhxBU2J2l84lJVfWlYOA0EiYo0JW55O4uFP3TTxTqdGy7IIv6Dhtu3OhF0XUIRsjyIP6xqTZu6kiK3jpatmV8aMg48FCgsDogA0YQc7EaARpFVGo9hpBLmYTaKvckGb4iV4FUTciJktE+4zDuZ4dMAmNljNf38w4I0iAQrl7QQVYAMhXmrs2IAVJKTKSD5jYLNLWlffnCHKn1sRMLLJrw1Bkll3wiVC0VB9tBAm4Jz4XRZSdDlgsEsZCWto1gnxmowDO4YoAXzDj5QhS14BJAwqwVCxMHTCLiMimbh8wAFjq01H1A2ZX+n4YMVkO/G5qgv/YrtfJrTzIequN5Bh2MZrZtT/OrX6BCrAAsF3Z2wEDtPa8fQ1Yy9CPzbrkFxMEiiYXfMGKj3QKnHOUGqOJ8AH37Be2ig1I4RDmUntvCAZxKBPHVrGzuXZ6owDAHQG+IJPwsgNmQYQfi1IHzCIVXVrRawS/6GMzVkOTNUSEDzjTpV7fru0S4AMwvA2dthiqjWjEKliZT+FSse54Zy7IUAEWALYHdcBsasDM7tK5pIR6q70v3xA7taZxpygQ0SF+0IHVW220VT6SDQXgngHpZd2Cwq5uq3tz7fSFgh6dYq+Qs4MmwvdKAyZGkP0vUDO0BWmZSqN/B0wUYOaC3i+c267i4EzMuMnthZMdsHP56p5iT2x2O63vrbdG14ABWleQ+2jC4AeoAPM5qspxvSrv2oAUpGLjasBEXt7+64JpMUS7L/65ZBSZuD+sKMTdsZ0YIqCTG+laB6xkz4JCsJiN44o+vuScY22jgJMudr8AIcL3uAM2ZAuyIit7DGmJvYhCtVchM5eUIIVD2PJhIPf69uANSMCs0xzvd1MI/ru/X9Y4rzvXAWurHE1ldCNWoLMJ6adN80lDBZjPKdRbUPluDzBBKhaxP4I0a8D0VrUbGzN+p1Br7RLgA6bMMh941ZRGCOIGOh0Dt7b/7JqwCpayCezUWmi02rhYqGO7IuOEi/ovQBv1NFqqJ+7bVn3A2ipHo+WPJQ8/U5YVxCKhnpq6UIjhYCbmyw7Yer7aM4TbjIjJGvc92i/ySHSVnZSXiClJQhq9ZDg+7x+Jh1+gAsznGC74PTRgqRFE+FW50wGbdUmsGQQKteaeDhgA33iBibtjuyPISDiElBR2RXzOOcdWqWFLgC84ZBJOn9YNWE8uzzp5eHvoWHK4P/azMoI0imN5/73f7FJp7A3iNuNHM9Zyo4XtSnNoB2zGoZSGfnozYwTp4Hm9LgqwMTpg2UQUcynJFxMGv0AFmM/ZruzNgRTYtaHgnO/SgGWNAmx/dcBUlaNYb+3RgAH+EYp2OmD2CjDxOW6MIHdqLTQV1ZYFhUAUbVulBtY2CohFQrh5acbpQ9zFTNzdcawZqyNIALQJaYGKvDeI28xiNrHL1sQPiM55tyi+G6esYgzLi67vl4iGIYVDjorw6/qN/jgaMABYmU/64gbXL1AB5nPyVa0DttCrAxaL2CrAZEVFq81NHTDnW9VBoNxQoHL0FICvLqTAfZBZJk7OGZtGrNrnuGO/MIoJq6AjnG7g9IUd3HokaytkfBTcXkgwY20LUi/ASIg/lGEdsMVMDFs9At4nSSeEe3AHzIjJGvM9em67hkOZGJLS3rzMXDKKgoMi/M4IcswCzCcSD79ABZjPyRsxRL00YGE9tNbaSajjLr1bhL/fzFjFnWGuR3fJL6Hc5bE6YBFXjFiF79IoGjAh3N+4XsNzl0quC/AB9y05zIgCTBpQVIobHyrAhmPu1PdiMZuArKi+unm0YsIKmGKyxvy9PN9jA1KQS0ad7YA5MIIEtE3zrVLD6KjtdywVYIyx+xhjLzLGzjDGPtLj4w8wxq4xxtb0P//c9LG26fFHTY+vMsa+rX/NP2KMubePHmC2KzJCrHe3JilFoKjcOPkPo+MurZ3YEtEwpEho34nwhTZiNrW3uPGLFYXo2tiNIgLc7ICNXoClYhHMxCP4+otX0VRU1wX4QKcD5pUGLBYJDbTnoBGkdSry4Biufvmik2R9u4rFTNxSl0jLgxxzBJmv9o080gK5HdSANZ0pwAyvRdKBAbBQgDHGwgA+AeBtAG4B8B7G2C09nvpHnPMT+p9PmR6vmx6/3/T4bwP4Hc75DQB2APyz0X+M6WW70sRcSkI4tPfEnjYCua3dTXR3wBhjyCWiKProLtILhOYtm9hb1GaTUcwmozg34TZ5qd5CLBIaKOruh1sZiFdKDYQYcKDHONwKS9k4vicE+MfcFeADJksOD6wo5JY6cPwIdIpp6oANZ3gHTCvArvhIB6aFcA/Wfwky8chYFinDBP9On9dFByw+5giSQrl3Y6UDdheAM5zzs5zzJoDPA3jHON+UabeJbwHwRf2hRwC8c5yvOa3kK709wABNhA/Asg7MKMBMd5azSWnfdcDE2GK2hwgfEDqFSXfA7OdACmbiEdc6YAdn4oiMqN0S4v0DMzEcHqGLZpcZh/yWrCArKmJDugOkAbNOpaEMNDMVI22/dcAGhXCbmRlzBCl0VP1GkE6f1xsOjSANiQd1wABYK8COANgw/XtTf6ybdzHGnmGMfZExtmx6PM4YO8UY+xZj7J36Y/MACpxzcSbq9zXBGPug/vmnrl27ZuFwp4t8tdnTAwzomBRWLXqBidHHjCngNrsP44hEB6yfC/vqfGriLfJSXRlJgA/A0Jc4LVDeKjZwaIzCSYyNTiznbDvpj0JKCiPEPOqAKe2B+i+gc+PjxUg06JSHbEEemIkhxPzjhl+stbBTaw3VfwkyichYI8hOCHfvjpumAXPuHOCUBiwdi2AhHcN5EuIDcE6E/2cAVjjntwP4KrSOluA45/xOAL8I4L8wxl5p5wtzzj/JOb+Tc37ngQMHHDrc4JCvyD03IAFzB8zmCNJ0Yssl9l8BJrQR3UasgpWFFC4XJysUHacDlklEoHLY9ogbxlapYQQhj8JiNgHA3QBuM4wx3ZLDmy3IQRYUgOYRFg0z6oANoamoaCqqYRjdi2g4hAMzMd9YURieXBY7YOOK8EWH/vhcfw1YU1GNwmlc6k1NZzzuFiSg2XRQB0zDSgF2EYC5o3VUf8yAc57nnItciE8BeJ3pYxf1/54F8A0AJwHkAeQYY+IdtudrToLf/doP8bbf/ftJH8Yu8pX+HbCOBszaCb1sxHt03kSzScnx0Fa/U6y3kIlHeurqgM5JdJKZZaWGYtuEVeBU1Ek3o7rgC8wdMK9wayGhG00DNvzilLZpHTMOv/GV5/CZb5335Hs5SbVLq9qPxYw1M9bnLhbx7k8+6Wrhe+ZqBcBeV/p+aCL88QqwpWx/wX/OYZNtQwM2ZgcM0MamZ69VoKr+sRCZFFYKsKcA3KhvLUoA3g3gUfMTGGNLpn/eD+AF/fFZxlhM//sCgHsBfJ9rfdGvA/g5/XM+AOAr4/wgTtBqq3hxq+SbX4xGq42yrAzogOkjSKsasB4jyFwyip2a8+MqP6MFcfdfuhWbkJO0oijXWyNtQALOhv0Kak0FFVnBgZnRBPgA8BO3HMKH//GNeP3KnGPHNYxMIuLpFuQw0vGIZ1uQjz59Cf+///li4Fb+O536wTcgi9m4YY0yiP/rb36Ib529jnPX3Hs//8npTSxm4niF5Q6YFpPVtLjB3k2vEG4zTqecCA1Y0oEO2L03LGC70sTf/XD/SYq6GXrG0HVaHwLwOLTC6guc8+cZYx9njImtxg8zxp5njD0N4MMAHtAffzWAU/rjXwfwf3DOv69/7N8D+LeMsTPQNGG/59QPNSrzaQkq948vVr7a3wMM6HSyrI8gWwiHGOKmUYloVe+nfLpCrdVXgA90dBWT1IGNNYJ0wX5B+NGNugEJaHFa//atr3LdgNWME35LVpCV4VuQAJCORY1OtJuItIdCrYU/XZv4cMEW5Ya1DthSNjG0ANu4XsNXv38FgHuZty9dKeOJM3m8743HLS+odGKyRvvdHBb6LTa8nUo5qTUVRELMkffuT922hAMzMTz0xPr4BxZwLN1ic84fA/BY12MfM/39owA+2uPzvgngtj5f8yy0DUvfIPIW8xUZc32KHi8ZlAMJdET4VkeQwl3aLIDOGblhTSSkxDiHGxgKtSayAzpgM/EoFtLSxDYhOee6CH/0LUjA2RGkcTPQZxzuV2biEU86mU1FtVQwz8S86YCJtAcAeOiJc3j365c9WXxwAtEBG9YBPpSJoywrAy0rfv/JdeN1cOvG+qEn1hGLhPCLdx2z/DnGe7Sh9D2/90MI/gdFHgmPQ6d+5npTHVuAL5AiIfzS3cfxO197CS9fq+CVB9KOfN0gQk74JkTe4rWKPOSZ3mC44PfbghQjSMs+YO09J6r9GMhdqA/ugAFanMikRpCyoqLZVg0fK7u4MYIcdjPgV7QOmEcifKsjSA86YELX+YZXzOGlKxU8+XLe9e/pFBU9rHyQDQVgyhft0wWrygo+/9QG3vAKbeRddKEDVqg18eXTm/iZk0cwa+OmfRyd5rk+IdxmcnoHzKmuX73VHtsDzMwv3n0MUjiER7657tjXDCJUgJlYMDpg/hClb+sXvX5jn3g0hBCz4wO2V1fkdKs6COxUmz1jiMysTNCKwgjiHlmELzpgzo8g+43D/cq4YmerWNWApWLeFGBi0/f9b1zBfErCpwM07rE6glwcUoD9yemLKDcU/JsffxUAOOoML/jcdzbQaKl44N4VW583zk2S6MwPEvw7LcJvtNqOdcAAzUbk7Xcs4Yvf3UTRJ5KfSUAFmAlxccn7pQM2ZOzDGENKitiyodjTAXO4Ve132ipHqaEMFOED2qr0lZJsebzrJKJwGlWE74YB6TWjAxawAiweRa3ZhtJ2V+NoZwvSi6UAcUN1KBPHL959DH/9gys4H5DVf6sjSGHG2suKQlU5Hn7iHG4/msVdq3OYiUUc7/IrbRWfeXIdb3zFPG5ezNj63E4HzP7vwrntKhgDluf6jyDj0TDi0ZBjN9b1prMFGAD88r2rqDXb+ONTG8OfPKVQAWYil5QQYp3CZ9LkKzIS0fCetHszyVjYlgasu62fMzpg+6MAE0VJbsgI0sgsm4BhYGmMIG5A01gkomFHxd75ShNJafDvoh8RY1y3ix4rPmCAVlR4YUMh3s+5ZBS/9IbjCDOGR74ZDEsKyzYURgdsrxnr35/ZxsvXqnjw3hUwxnTDaWfP6//z+1dwqdjAgza7X8B4MVnr+SoOZxNDLSFyCclRGwonR5AAcOuRLF6/MouHv7mOtk+cB7yGCjAT4RDDXErCtk9GkIM8wAQpyfpIo5e7tFmEvx8QP+fskA7YygRDuUWROOoIEtCdth0V4fc3BPYzRqfB5TGkZRuKWAT1lvsdOSPtIRHFoUwcP337Ev741EYgTGArDQWMDbc8iEfDmE1Ge3qBPfzEORyYieGnbzsMoOMM7yQPPXEOy3MJ/ONXH7L9uZ1N5VEKsJolvzFhMeQE9VYbCQs3GHZ58N5VbO7U8dcvXHH8awcBKsC6mE/FfDOCvFaRh4qeU7GI9TDuhrLHXVq0qvfLHF6chLMWO2CTEOKLiJLsiCJ8QM+ac1SEP/xmwI/MuKCH64Umwrc2ggSsW8eMSnfawwP3rKAsK/jSdzdd/b5OUJb3bmv3YzGb2BPIffZaBV9/8Rree/cxSHpR7HQ24nMXi3hqfQcfeONKX0PnQSSlMMIhNtLvpWZBMTz0O5eMouiQybbTGjDBT9xyCIez8X1rSUEFWBcLM5Ihfp80+UoTC0NEz0kpbCuMu1dbfzYpYccnY1e3KVjsgKVjERyYiU3EiqI8pghf+9yIo0XH9oBQeD/jxkZoN5xzNBXVuNgPwsiDlN294SnqRr7Cl+rksVmcWM7h4W+u+8Zouh/CLscKi5nYng7YI99chxQO4b13HzceyyaiKDoos3joiXUkpTB+/s7l4U/uAWMMM/GI7d/LnWoTxbq1zEmt6HTKhqLtSAxRN5FwCO974wqePJvHC5dLjn99v0MFWBfzqZh/NGAWxj6pWMRSGHdb5ag12z0DbrMJ59vzfsXQxljQV63Op3A+PwENmF44jaoBE5/raAes2jRsWoKEW7FMZmTdzdzKCFJ0oN0eBe7UmntuMh68dwXntqv425f87UA+yNerm8UuM9ZSo4UvfncTb79jaVdqg5MdsGtlGX/29CX83OuO9s2TtcIoJsFWLCgEuaRzOb/1VtuRGKJevOeuZcSjITy8D7tgVIB1MZ+WfGFDwTm3NPZJSmHULIwzRJHW68SWc0Gg6lfEHeGwDhigOeJPIjS21GghGmaWLuj9cNIBXlU5rleDOYL0QoRvpwATSzBum7EWaq09iyY/ddsSDmVi+PQT51z93uNS6aFV7cdSNo58tQlZ0c6Bf3xqE9VmGw/es7rredo4ruVI9+8Pv30BzbaKD9yzMtbXySQihtzAKqIjbyX0O5eUUKg1HYmZc2sECWjH+TMnj+JP1y7iuk+aH15BBVgXC+kYKrJiZF9NilJdgaLyoRqwtMUOmJED2ePENpt0blvG7xRrTTBmzeJhZSGFa2XZc+Fyqd5CJh4dy7ncyQzEQr2FtsppBNkHcfGPWbhAicLC7d+pQo+802hYcyD/+x9u48zVsqvffxzKtkaQ2ibk1ZKMtsrxyDfXcefxWdx2NLvrebmkFjM37nuiqaj4g2+fx5tuOjC2g3smHrUtwl/friLEgGMDLCgEuUQUisotG3UPwg0bCjMP3LMCWVHxue9ccO17+BEqwLowvMAmXIlvVzUd2rCxT9KiD5g44fdyl3ZyW8bv7NRayCaiCFkQzopQbq91YKWGMtb4EdA7YA1nQtbzAfUAA4C0FAFj7o4gmz4cQRbqrZ5j9l/UhekP+9iBvCorlj3whBXF5WIDf/ODq7hwvYYH713d8zzxWhTGFKU/9uxlXCvLPb+HXWZG0Gmey9dwZDZhSW8ouvzjTjc459oWpAsaMMFNizO494Z5fObJ82i5vCHsJ6gA68KcBzlJOs7jwzRgYVSbytAL7SB36VxSQrHuTKva72gxRNYKCcMLzOMxpNYBG89vayYeRavNHQlZ33YgiHtShEIM6Zj9UY8d7IwgjQ6YyyPInWqzZ9zWfDqGd9xxGF/67kVHRelOYkcDtmQUYHU89MQ5HM7G8ZOv2WsLIQynx7nR5JzjoSfO4RUHUvjRGxZG/jqCzAibyuvbVUv6L6Cz6T3udKPZVqFyuKYBEzx4zyq2Sg381XNbrn4fP0EFWBei4zRpHdi2xa5DKhYB5xh6oR3kLp1LaBdrJ1rVfqdQa1oWzq5MqANWbrTG74CNYfTYTb4azBxIgZN6uF7ILVGAWbehcLMDJtIe+gXOP3jvKuqtNv7olD/HPdoWpLXf/0N6AfZ3L23jmy/n8b43rhibn2aciFz73oUCnt4s4sF7Vix10IeRSdj7veScY327askDDDB3wMb73a/r14Vhvmzj8pabD+L4fBIP+Vyj6CRUgHUhtg4nHchtdeyT0t8Uw07oHXfpvSc2p1rVQaBQGx7ELUhIYSxm4jjnsRt+qWF9BNMPJ7f/hoXC+x238yA7GjALInzJ/aUA8f+83+/5LYczuHt1Do9887zvHMhVlaPSVJCOWbvYz8QiSElh/MnpTcSjIbznrt62EOK1GMfv8KEnzmEmHsHPvvboyF/DTCYeRdVGTFa+2kRZVix3wJwy2a7remg3NWCA1q3+wBtXtEJ3o+Dq9/ILVIB1Me+bDpgmFp8bMi4T0TDD4ojEyKOnDYXDwa1+ZqeHOHkQKwvJCY0gx+2AOSc+z1dkMGZtc9SPZOL+GUGKkaibHTBxwR0Ut/XgvSu4WKjjq9/3lwN5rdUG573PU71gjGExGwfnwM+cPNL3vS0eH9Xv8HKxjr98bgvvfv1yTx3tKNjd0LUSwm3GCOQe8yZMdMDc1IAJfu7Oo0hJYV9rFJ0kWMFuHpCUIkhEwyNrwP7gW+dx25Es7ljOjXUc+aqM2aTUs51uJmXRWbs8IF9tlFb13/zgCupNFT99+5Llz/EDxR7r+YNYmU95fpEqOTGCFA7wDhQe29Um5pLSSI7ffiCTiGLjuntdzE4BZu0ClYqFXdWAFYy80/4F81tvWcSRXAL/+2Mv4C+fu9z3eUkpjI+87dVj+V3ZwbhRtDiCBDQh/svXqnjgnv7C+GxivGLks9+6AM453v/GlZE+vxedOCIFs0MMt4FOKocVCwrAlPM75kKZ6IC5rQEDtNfk5+9cxme/fR4ffdvNOKhvuU4r1AHrwXxaGmkLUlU5/uOfPe9I9Z6vNI2NzEGk9Fa91Q5YqsddTOdOyfrP/Ltf+yH+01983/Lz/UCrraIsK8aJyQrLc0nkq03PbEmaiopGS3VEhA84M4LcLsuBHT8Cmu7RVR8w/XfDqm9bOhZBxYJ1zKiYcyD7EQ4x/K8/+SqEQwxPbxR6/jm1voPPfWcDT5zZdu1Yu6noCQFWO2AA8NO3HcYD96zgpsWZvs8Jhxgy8cjIXf7vrF/HyWOzWLZg/2AVIybLYpd6PV9FOMRwdDZh6flSJISUFB67A9bwaAQp+MA9K1BUjj/4tj81ik5CHbAezKdjI8UR5atNtNrckfxAq9l7YgQ5bKRRkVtIRMM9O2odrYD1N+p6voZivYUrpQYOBeQuReg/xEaUFUQRfL3axOGctRPfOBgxRI6J8Me/0Gsu+MEU4AMeiPD1DljcYlhxOh51twNWG94BA4CfOXkUP3Oyv56pIiu49Tce93QEX9E7+d2ZtYP4xbuPWXqeMCYdhXxFHljgjYIhE7D4u7mer2F5NoHokKmImZwDCQD1pvb77cUIEtBGrG++6SD+8Nvn8a/f/ErLneUgQh2wHhwY0Q1fhMKed+CEtV0dHsQNdEaKwwK5B7lLi45Q0eIbVeSRAcDpCwVLn+MHCl0BxVYQhYdX+aCiYBpbA+aoCN/a76JfySSiKMuKa4JzUYBJYevCcXc1YINF+FZJxyJYSHubhzpIqzous2P4HearTceNiI33qNUO2HbV8vhR4EQGplcifDMP3ruC7UoTf/50//H4NEAFWA+0PEj7F1wRCrtTa439S79dlocGcQOd1eBhgdzlhtL3rlK0qq2enMzxPKc3dix9jh+wGsRtxuulDFEwjbsFGY+GIUVCDonwrY3D/UrGZfd5O1uQgD6CdLED1kl7GF+3tbqQxLqHW8BiBCm2RZ0km5RGGse12ioKtZbjXWCjS23BjFVYUFjdgBTMpqKObUF6oQET/MgNC7jhYBoPffPcVPtTUgHWA5EHaTc3bKtYN/4+ToZgU1FRaiiW3vAdEf5wG4pBd5U5G3FE4o54NhnFWgA7YHZE+N53wJwZQQJi9Dbehb7RaqMsK4EM4hbYHfXYpeMDZnUE6X4HLJuIOrI0sTKf8jQPtTwgMm1cZkfMvBWbk07rIO1sKl+ryKg221iZt6dByyVGKzrNNDzcghQwxvDAPSt47mIJp84H5ybfLlSA9WA+HYOictvdgy19BAmMZ9553XjDWynA9A6YlRHkAF1FNmH95CTyyN522xKevVi07GMzaXbG6YB5FE0lCqZxR5CAyIMc7+Rr53fRr9gd9dil2ba3BZmOjf//ZRD9YohGwes81MqAbe1xySWiI4nwhSek0zchRkyWhW6o6ELaHUHmksEcQQLAz772CDLxyFQbs1IB1gPxRtu2OXa6XGxgIR0DYxhLiG/VBR8ApHAIkRAbugU5LOB2NhW1fKck8sjuWplDrdnGS1cqlj5v0gjdWtZGB2xcWxK7dDpg41+AZuLRsUX4xu/iFIwgx+0G9kN0wKzk8wFacVFttl0brfQK4h4V4TnllQ7M2NZ2owBLSig1Wra1gB0jYmdvQoyYLAvnXbseYIJcUjuvj/O7NqkCLClF8J67juHx56/gYqE+/BMCCBVgPRBiS7sX3a1iA8fmEjicTYy1OSS6LVbuuBhjSErhoT5gwzpguYT1bRmhRTh5LAcAWAuIa/FOrYlwiNnasAI6I2kvMLYgneiAxa2d3Achfu6FmQB3wBw0pe2FrLQRDTPLI790PIK26kxOZy8KNr3uBnFcH3l5tQlZkRXEIiHLxawdcskoOLc/ijaiuFy4CbGaB3kuX0UkxHDE5ib2bFJCW+WGD+QoCCNWqyN2J3nfG4+Dc47PPHne8+/tBVSA9WDUsdNWqYGlbAKrC6mx7hiNGCKLWzepWGSoBmzQFiRgvVVtziM7NpfEXErC6QvBmNEXatpohjF72pj5dMyzaKpSXUE4xBzJXXMigkd0wBYc3gDzEic3QnshK6qtVXlxI1SW3TmenVrTsdQCr/NQK/L4MVz9EK+JXVG6Wx0wQORBWhlBVnFsLjnUmLsbw4C2OvrvWqPVRjwaciT/0i5HZ5P4iVsW8bnvXDAKwWmCCrAeCOG1nQ4Y5xxbxQYWs3GsLCRxbrs6ctvXzggS0AqwQTYUnHM94HZwAWalVW3OI2OM4Y6j2cB0wAq1lq3xo2BUW5JRKDVamIlHbBeJvXBChJ93SYDsJXYjX+wiK21b3QFRYLi1CVnURfhOkIpFcHAm5lke6rBO/ThkR4zm2a40IYVDY5sj90KLybLQARvBggIwpZzYMNnupt5qez5+NPPgvSso1lv48umLEzsGt6ACrAezySgYA67ZuOiWGgpqzTYWM3GszKdQaiije85UmohFQpZPRCkpPFAkKysqFJUP7IBZbVV3axFOHpvFmWsVV8OOnaJQH60zMKotySg4kQMpcEKEn6/IiEdDjnTkJoV4H7k2gmyptgowcTxuCNtF2oOTuZ0rCynvRpANxRX9F2COXLPbAdOSIJy4KepG64AN/r3knON8vmbbggIYzWS7m3pzsgXYXatzuGUpg4en0JKCCrAeRMIhzCYlWx2wLd0DbDEbN4qTUYX425WmLua39oZPSpGBInxxoh+kfbLaqu7OIzuxnAPnwDMbRUvHOkl2qqNthwkNmBdv/lJDcUSAD2gdMFlRx4pR0jzArP8u+pFIOKSLnd3qgKmI2bhAGQWYCx2wopED6Vx24+r8eJIKO5Rd7ICJ977dTch81VoqyShk4tGhndkrJRn1VhurC/ZjkHIjFp1maq22pxYU3TDG8OC9K3jpSgXffDk/seNwAyrA+jCfsjd2EhYUS9m4UZyMetLKV+1l72kasP4XWSvu0lZb1d15ZCJ0fC0AhqzFemuk7TDDlsSlC7gZRztg8fFHb9vVZqA9wAQzFkc9o2B3BJkyNGDO/z6N4nU3jJWFFPLVpidd7krDPQ2YkXlrswDbrsiOu+ALrPxe2g3hNjPqz2ym0ZxsAQYA/+SOw5hPSVNnSUEFWB+0QG47HTBtTfZQJo7l2SRCbPTNIbvO46lYGFULHbB0rP9J2eobdX17dx5ZNhHFKw+kAhFJpK3n278wGbYkHowhyw3FwRHk+Nt/WhB3cAX4AjfzIGVFtbW1JwqMYYszo2AEcTs4ghSdFy+6YG5qwDJxTVpifwTpYgcsEUVFVgaafotou5FGkCN2/cxMWgMGaC78v3j3Mfz1D646EvXnF6gA68N8OmarAyZiiA5l4pAiIRyZTYw8grSbvZeUBnfAyoa3Tv83Uc7ihtB6fq8Y9MTyLNY2Cr6ezzcVFdVme6R8vI4tiftCfCHCdwIntv/yVXkqOmCZhIsdMB9pwIwOmEMifKDTeRnH29AqwxI7xiEUYprhtI33A+cc2xXZtTD6TDwCzgd3Q8/lq5DCIRy2aUEBaOP3mVhkrDiieqvtaQxRP37pDccRZgwPf3N90ofiGFSA9eFAOmYrfuZKSTNhFXfCK/OjCVc559i2qTlIx8IWNWDDO2DFASenfnlkJ4/lkK82sbnjX7M8MVrNjtAZWJgRxrzud8BK9ZYjMUSAKWtuxBEk51y/+5+ODpi7W5A2NGAOjIb7MUrawzCOz2nv9/N59zchNQ2Yc8VjN7NJyZYgvdpsQ1ZU14yIrcRkrW9XcWw+OXK0VC4VHXheH8akRfiCQ5k4fvr2JfzxqU1XkyS8hAqwPsynJJQaCpqKNbPEy8UGFrOdC9XqQgrnt2u2u0JlWfuednyXNBF+u28bWwTcDvQB008EOwNE+P3yyE7oOrDv+dgPTHQGxuuAuVuAKW2tS+ecBkz7OqOerEp1BYrKA+2CL3DCE60fzba9DlgsEoYUDrnSARsl7WEYCSmMpWzc9RGkrLTRVFSkB3Tqx8VO5BrQec+71wEbLhNY3x5tA1KQS0hjifAbExbhm3nw3lVUZAVf+u7mpA/FEagA64O467eqA9sqNrCY6bSIV+ZTKMuKbTPXjvO4PQ0YoG2r9KKijycHaStEq3qQCL9fHtnNizOIR0O+9gPrjGbsFxPClsRuNJVdREfEsS1I4+56tAu90Ly5dfHxEi0VwL0ooljU3qk0HY+4sgUp0h6c9qzyIpS7auE8NS5aILf1Qny74q4P3jCPOlXlmuzDZgi3mVwyOp4NhQ80YIITyzmcWM7hkSfPD9TNBQUqwPpguOFbvOhqLvhx49+jZqjZdcEHOltVtT531OJEP0xblB1ycuqXRxYJh3D7kZyvhfg7hjjZfmfAsCVxWYRvFGAOdcDE/+9ROz95ly8+XjITj6LcaFk6ab90pYwzV63nm9p1wge0mya3NGDZEdIehrEyZrqHFTrb2u6NIHNJyZYp6bZXHbA+I8KtUgOyoo60ASnIJaWxR5B+0IAJHrx3Bee2q/jGS1cnfShjQwVYHzqB3MMvuvVmG4VaC4umAmxU4arQUZm/1jBSkr5V1ccNvyK3EAmxoWOS2eTgVvWgPLITx3L4/qUSZMWfcRHFMdfz7dqSjIIolJwS4SeiYURCbGQR/ig3A34lk4hA5Ri4LSz48OdO4z/+2fOWv7ZdGwoAWMzE8fylouOLK07mQJpZXUhip9ayFFc2KiKayc0OWC4ZtRXL4/ZNSGcE2fv3ctQQbjO5RHQsEX6jpfpmBAkAP3XbEnLJKB5/7sqkD2VsLJ01GGP3McZeZIydYYx9pMfHH2CMXWOMrel//rn++AnG2JOMsecZY88wxv6p6XMeZoydM33OCcd+Kgews/kmPMAWM52i6ehsAuEQsy3EX9soICmF8coDacufI1zK+621C3fpYXfFw1rVg/LITizn0GyreOFy2fJxe8m44mQvArlFoeSUCJ8xNpb2ybj7tzEO9ysdPdzgAqzcaOHFK2VcK1vvdmodMHsF2M+/bhkvXangSYeNJQv1pqMbkAKhQXJzDGm1Uz8OuYSEsqyg1bam7RU3IXOuifD1LnWfmyTxeo/TAZtNaiL8UUZ2SltFs636ZgQJANFwCDceTLs+EveCoWcNxlgYwCcAvA3ALQDewxi7pcdT/4hzfkL/8yn9sRqA93POXwPgPgD/hTGWM33Or5s+Z22cH8RpFmasa8Au6x5g5hFkNBzC8mzC0E1Z5fSFHdx+NGtr40WMIPsVYFbdpYe1qgflkZ08lgMA3wZzF+otRMOjh1zP29yKHQVRKDk1gtS+1ujaJ6F/mXNwo25SWPVEe3azCM7t+SZpGjB7v1f3nziMuZSEhxxeqd+pthzdgBSMKqmwg+hOuqoBSw3f9jaTrzYxE4/YHjFbZVhM1vp2FbFICEsZ6xORbrJJCZyPJkVo6EtofirAAN1lwKN0Bjexctt2F4AznPOznPMmgM8DeIeVL845f4lz/kP975cAXAVwYNSD9ZKUFEYsErLU9bhS6sQQmVlZSNkaQTZabXz/cgknlmftHavQgPUbQVp0lx7Uqh6WR7aUTeBQJuZbIX6h1kQ2MXqem11bklEQhZJTInzta0VH3oLMV2XMJqM9O55Bo6O1GVyMntZ/f63qhDjnI40g49EwfvGuY/jaC1dwwUF7h2J9tMD5YSzPJcGYu15gZQuJHeOStWlM6qYHGNCJyerXmT23XcPx+SRCI1pQAJ3N71HMWOv6NSXuoxEkoF1br5ZlV8yMvcTKWeMIgA3Tvzf1x7p5lz5m/CJjbLn7g4yxuwBIAF42Pfxb+uf8DmOs5285Y+yDjLFTjLFT165ds3C4zsAYw0I6hmsWLrqXi30KMN0LzKrO4/uXS2i1udFNskpKf3P0E/VadZce1Kq2kkd2cnnWt0L8Qq01kgWFwK4tySgYHTAHR0ha1MloJ6lp8QADTAsJQzof4ve30bKWoamoHCqH7QIMAN73Rs1Y8pEn121/bj8KteZIm77DiEfDOJxNuBrK3UnscFMDZi8bMV9xP4prJh7p+3upbUCOPn4EzIHc9iUU4j3gtw6Y0ZEN+BjSqVvbPwOwwjm/HcBXATxi/iBjbAnAZwA8yDkXV7CPArgZwOsBzAH4972+MOf8k5zzOznndx444G3zzKruZ6vYQCYeQVLafeJYXUih1mxb1pOIk/9J3VfLKkmjA9b7QmvVXXpQq9pKHtmJYzlcuF5z3S9rFHZGjCESiELkuk1bETuUGgoYA9KSgx2wMSJ47EZi+RkrI0jOOdY2CoiGtW6DlY6BrBfko4yoDmXi+KnblvCFpzYc2YgcJ+3BCisLSVfHPsYWpMs2FID1blC+6l4OpCAT763TbKscF/K1sQT4gKnoHOE8UPdpASaKUrsSH79hpQC7CMDc0TqqP2bAOc9zzsVV91MAXic+xhjLAPgLAP9Pzvm3TJ9zmWvIAB6CNur0FfMpa9YDW8UGlrJ7NwPtbkKubRRwOBvHQZvzfnHB7hdHZFUDNujktG4hj0wYsj69WRj6vbxG2w4bvZiYt7EVOyqlegvpWGSscUM3/U7uVtiuujt+8ZKMhQ7Y5k4d2xUZr1+ZA2CtYyDrFyg7WZBmHrh3BWVZwZ98b3xjSTE2dWMLEtC9wLatd/TtUpG1G5BRdZpWEN1Bq92gbRdzIAWZRG+d5uViHc32eBYUgDkP0v7NoxhBuvn/ZBRWRD7pPuiAPQXgRsbYKmNMAvBuAI+an6B3uAT3A3hBf1wC8GUAv885/2Kvz2GaKOedAJ4b8WdwDat5kFulBg71sI1YnbfXJj19YQcnj9nTfwEwVoQHbUFa0oCJAqzHRWrdQh7Z7UezCDH4cgxZqLXG2g4TYwi7xrp2KDVajgrwgf4ndytsl6cjBxLQfMCAwVuQQr/45psOArDbARutAHvtsVncsZzDw0+sj20saZgNu7Q0sbqQQqmhjGXqOYhyQ7tRdNrDzEzOhghfaavYqbk/hu93k2QYX485gpw1xq72/78JXbGffMAALf3l4EzMk3xSNxl61uCcKwA+BOBxaIXVFzjnzzPGPs4Yu19/2od1q4mnAXwYwAP6478A4McAPNDDbuKzjLFnATwLYAHAf3Lqh3KKBb0AG3bHd7nY6LmlcjgXRzTMcM5Cm3S7ImNzp250kewgRUKQwqEBPmCK4RU2iEGB3FbyyJJSBDctZnwpxC/Um5gdY5wmxhDbNuwJ7FKqK47qvwDt5F5vtS2v3QuaiopSQ5kaDZgUCSERDQ/sBq5tFBCLhHD3K7QOmJWOgdAE2nXCN/PL967g7HYVf/vD8TSuhTG97oZhWFG4dNGryApmXBw/AsBMLIJwiFkqRnZqLXAO129C+lnFCJuFcUeQmYSW5DFKAWZowHzWAQO8MQd2G0u/7ZzzxwA81vXYx0x//yg0TVf35/0BgD/o8zXfYutIJ8BCWkKzraIsK307E622iu2K3NM4NRIOYXnOmm5iTei/bArwBak+gdxtlaPWbFvSgIkOUS+zRat5ZCeWc/jzZy5BVbmjo7RxaLTaaLRUYwNqFIxkBBfd8LUOmLMXIFHQlRuKLS8joXWbBhd8wbBuoLCAEWNXK5qZcTRggrfduoTfmnkBDz2xbnTfRsGNIG4zYhR2Pl/F647b79QPw6pWdRwYY5aNScV73X0NWO8tyPXtKhLRMA5lxvv+WjSVvQxMgV81YIA2YfrrHwTbjDX4++UuYiWO6GpZBuf9nevFJuQwTm/sIBJiuPVIdqRjTUqRnkJeO5tFs306YHbyyE4ey6HcUHB223qUi9t0grhHvzClYxHLtiSjUm443wGzuv3XzfYUueALZgbo4ZqKiuculXBiOdf3fdALkfww6ggS0Lpz73vDcfzdS9dsRSB1I26cxrnRGMSxuSRCzD0vsIqsGJY6bpJNRi0V10Yur+tbkNqiTPekZX27iuPzSUdGsjmLP3M3QgPmxwJsZSGF7UpzZJsdP0AF2ACMsdMA4fVWcXB0kCjAhuk71jYKuHlpZuRZeyoWRq2HCF/owqxowDJ9PHLs5JGJDU4/6cCcECcLWxI3A7lL9ZbjLuCdqBN7JymhdZsWDRigm9L2eR1euFxCU1Fx8tgs4tEQpEjIUuyOEx0wAHjP3ccghUN4ZAxjVqMD5tLmqhQJ4chsAucc9C0zIzRgbjMsck1g3IS4rQEzYrJ2n7/POWBBIcglpZG0e6IDFpf8VyoIS6Qgb0L671X1EZ0O2KACTPvYUp8CbHUhiUZLxdUB2qG2yvH0RhEnbRqwmknFIj1z7jodsOHFh9aqjuw5OdnJI3vlgTRmYhHD0NIP7FSd0cbMp90N5HZHhG/NgLSbvEcXHy/JJKJ9XwehWzyxnANjDLNJa2MquTW+BgzQ9Kb3nziML31vc+Tg5EJdy3xNuajXcdOBvCJbWxYal1wiakkPte1RB6xXILfSVrFxvTb2BqQgl4iiOEU+YIDJZSDAm5BUgA1AaEEGdT2MGKJM7+1AK1YUL1+roCIrIwnwBSkp0tMJ36679GxK2tOqtpNHFgox3LGcMzRtfqAoOmBjGlS6GcitqhwV2QURvsias9sBczmEeBJk4v1TAdY2Cjg4EzNupHIJyeIW5PgjSMGD966g1mzjC09tDH9yDwq1JnLJ0dMerLCqC5/dsKKoeNQByyWt/b/NV2REdP2Um/TyqLtUaKDV5gONr+0wOyTntx91n25BAsDxOffjsdyGCrABCNHyoIvuVrGBeDTUNz5mxYIVhShWTowowAc0n5ZeNhR23aU1geruN6rdPLITyzm8eKXc1xjWa8TPI3LgRkWzJXGnA1aWFXAO50X4hv2CfQ2YFAm5vpXmJZlE/1QAzQImZxQvuaS1LolTI0gAeM3hLO5ancMjT66jPYIlheZ1526xsDKfQllWXLFj0RI73D1+QPy/tSDCrzQxl5JcXybqFZN1zoLvoh1yFseu3dRbbUTDDFEfxpElpDCWsnEqwKaVaDiEXDI6cOx0uaSZsPa76zycS0AKhwb+kpze2EE2ETV8w0ah7wjSprt0LintaVXbzSM7eSyHtsrx7GbR0vPdxljPH7cDlpawbcGWZBTE+MH5DthoI8jtShMLKXe7KV6T6SN23qk2sZ6v7cpg1UTL3ojwzfzyvSvY3Knjay/Y3+7aqTVdc8EXuBXKLTrAbm9BAlo3qNpsD40Vy1dlT0bw4ubdfJNkR/ZhhWwiilJDgWLTjqbeavuy+yVYmU/RCHKaGTZ2ulJsYHFAZygcYjg2nxw4gjx9oYA7lnNj3Wn1E+FXZO1NbfXEluvRqrabRyZGqX7xAyvUmpAiIcTH1OkcSMcMWxKnEaNip8cdKSmMEBtFhO/NxcdLZuJRKCo3hMUCs/5LMGtxTOWUBkzw468+hCO5BB564pztzy3UWsi6kANpxm66h1Vq+v8TLzquWSOaZ3CBve1BDiTQMQk2v0fPbVeRksI4MOPMe1AU5nZzYRutti/1X4Kge4FRATaE+XRs4Bbk5WKj7wakYJAVRVVW8NKV8lj6L0DTgPWyoSjb7IB1bwiNkkc2n45heS7hm01IEcQ9bjfHii3JqBhB3A53ABhjxpq7HfIeRLB4jaGH6+oGnt4oIMS0JAdBVh9BDut2OjmCBDTvwPe/8Ti+dfY6XrhcsvW5xbr7I8ijswmEQ8zxCBjRqffChiLXZ9u7m7xHUVydmKzO7+V6vorj8ynHOtCDTLYHUW+2fWnCKlhdSGKn1rK0sexHqAAbwkJa6luAqSrHldLwAmx1IYnz+VpPK4pnNotQ+egGrIKkFIGsqHtazCIf0moB1t2qvlQYLY/s5PLs2B2wUqPVN17JDju15tjjR6BjS+KGDsytEaT2Nftrn/qRr7gfQuw1/fRwaxsFvOrQzK6L/2xSM2Hu7pZ1I0aQo2ZB9uLdrz+GRDRsuwvmxQgyGg5heTbh+Oq/3U79OFiN5vEqjH6mxxbkeQdCuM3kbIaQC+p+74DZjPvzG1SADWE+FesrOM1Xm1BU3teCQrCykIKsqLhcauz5mDH+OJob6zhTMe1NUuu6YFTkFpJSeGCEkJnuVrWVEO5evPZYDlulBs5cLdv6PAHnHO/9H9/Gr3/x6ZE+30zBoc5AJ5DbjQ6YOyNI8TXtdMA459iuejN+8ZJe22aqyrHWI4NVdEmGbY41x8yC7EU2GcU7Tx7BV9YuWY6QEmkPbuVAmllZSDk+ghSdei9GkOJcMKgbVGsqqDXbnozhu2OyOhYUzmxAAp0OmF0hfr2l+loDZmgSqQCbTubTmhak14lwq6gVVIeGbAcaodw9TlqnL+xgdSE1tnmiuHvv7hhpm0XWT2rdb9R13XTR7t3Y2+84rBtLnrf1eYInz+bx7MUiLhf3Fq120dbzxy9sxDjCDS+wTgfM+QuQZr9gvQNWkRU0FdWT8YuX9Br1nMtXUWoohoGwwOoFS1ZUhBgQcXhT7rXHcpAVFRd36pae73YOpBkhqXByGcXY1vbCByzZP3JN4LUNizkma3OnDkXljm1AAp0ba7sdsEbT3x2w5bkkGHMvn9RtqAAbgrgI7fToghkeYBY6YMDeXxLOOU5vFMbWfwGaDQXQGTkK7LpLd+4OtTfqqHlkC+kY/skdoxtLPvTEOgD0XCywi6YBG/9EKr7Gdtn5DphdrZ4dtBGk9f8H21PoAQb07oD1s4CxOrKRFRWxSNjxbdFVmyaTBYe87qywMp9ErdnGNQeD6e1ua49DzoIIX8hOvOoCZ+JRlPUxrFMh3GbE74XdOKJaSzGuLX4kHg3jcDYRWCE+FWBDWBgwdrqijxSHacAWM3HEInutKC4VG7hWlh0pwMSJq9t7y+5qtzg5CfPScfLIhLHkH5+yZyx5IV/D1164AsbQc7HADpxzFOotZB3oDEiRELKJwbYko1JqtJCSwoi44LdjV4Q/jS74QO9czNMbO5iJRXDDgfSu51rVCcmttmMbkGZWbNo9iLQHtzVggDubkGWbfoXjkJLCiIbZwPGy0QHzSAc5E+90wMT/c6dc8MXXD7ERRpDNNuI+LsAAYGUh6Vo8lttQATaE+QFjp8vFBiIhhoUhb9JQiPXchBR33+MK8AFNhA/sLVjsukuLE7g4oZ/LV0e+E7v1SBZ3rczh4W/aM5Z85Ml1hBnDj7/60NhmrvWW5vfjRAcM0ApyV7Yg6y1XBPiArgGzMYI0OmAeCJC9pJOL2Xkt1jYKuH05u8cCxopOCBAdMOdPo/MpCTOxiOUCTNwwOXGjMQxxPjjv4EWv6mEBxhhDdkjSgTjfLzhkAzGMTKITFL++XcVMLOLo+y8UYshajGAy02ipvh5BAu7GY7kNFWBDEG+CXpuQW8UGDmXilvy7jvfwAlvb2IEUCeHmxczYx2mI8OVuEb7NEaSpVS3EoMfH0CI8aNNYsior+MJTG3jbbUt4xYHUnoBau3RMWJ25MA2zJRkVN3IgBZmEZlFi1YTRuPhMWQcsHg1DioSMC1292cYLl8s9M1iz+u/LsPG5GEE6DWNME7tbLHKMtAcPRPhHcglEQsxRA0wvbSgA7UZzUDfI65sQ86LMubyWAen0WHs2Kdm3ofD5FiSg3RAU662eMiG/QwXYEIwOWI+uhxUPMMHqQgob1+u7OkGnLxRw6+GMIyvshgh/zBGkuVXtRB7ZW2+xZyz5pe9toiwrePDeFaSlCJqKankTrBfihOPUdthCWnIlhqVUV1wR4AOdzo/Vca74XZ+bsg4YIC502uvw3KUi2irvKQGIR8NIRMNDT+qy0nalAwZoN21W7+y9FOFHwiEcm7N+bFaoyApikZCjdh6DGBY1la80kY5FPNsANFvFCNmH02STUdt6XL/7gAGdDf0gOuJTATaETDwCKRzqqwEb5IJvZmUhhWZbxaWCJtxvtVU8e7G4Z/19VFKS2ILc2wGzs9ptblU7kUcWCYfwPovGkqrK8fAT67hjOYfXHptFUujaxhDiFx2+MM2n3MmDdLcDJvyvrBZgMrKJqGcXQy8xLyQMy2DV4oiGacBUVzRggHbTtrlTGxqZA3TSHrzqVjhtRVGWFUOj5wW5Id2g7Yrs6RKK6IA1FRWbO856gAnsdsA4576PIgLs6yX9xPSdYR2GMYb5tLTnoss5t9UB6zaM+8HlMmRFdUSADwBJMYI0dcA455oGzOaJTZycnMoje/frlxGPhvCwvtnYj7/94TWc3a7il+9dAaCJZYG9XT07OD2amU9L2OljSzIO5YbimgZMXNis3v1uT6ELvsC8kHB6YwfLc4m+o1YrAcZujSAB7ZyhcmBjZ/gYslBrIZcYP+3BKivzKZzP1xyzorCrVR2XXGJwNyhflT3VQIqYrJeulKFy50K4zeRsasBEyoPfR5DH5pIIMSrAppb5HmOnUl1BvdUeakEh6A6xXdvYAQDHCrBeHTBZUaGo3LauIqe3qp3KI8slJfzsa4/iT9cu4vqAkc5DT6zj4EwMb7t1CQA6HbAxCjBjPd+pDtgAW5JxKDVarnUAMj2y5gaxXZGHLpYElUy8M+pZu1DYFcDdjZULlpsjSDt39jsOed1ZZXUhiXqrjSslZ7rBXgVxC7TM2/7vYS2Ky7v3gJAfPLNZBODsBqQgZzHfVFDX9bcJlzq8TiFFQjgymwjkJqS/X1mf0GvstGXRgkJwKBNDIhrGOT3C4/RGAQvpGI7OJhw5xnCIIR4N7SpWRnWXziW0k5OTeWQP3rMCWVHxue9c6PnxM1cr+LuXruGX3nDcGH2l9a5eZYwRpDjhZB3qLh1wwQ2fc65tQboowgf2ZiD2I1+d3g5YJhFFud7ClVIDl4qNPQasZmZTFkaQLm1BAiYvMAsFmJb24N3/M6etKOwuC41LLimh0VLR6BM15VUQt0C895/ZLABw1gNMkEtGUZEVy917EcPldw0YENxNSCrALDCflvZccIUJq1UNGGNME9XqI0jt7jvn6MigO5B7VHfpWf1OaX17dAuKbm48NIMfuWEBn3nyfM8TwCPfXIcUDuEX7z5mPCasNWpjeIEVak0komHHdAyDbElGpdpsQ+XuuOAD9jtgeY/1L14iLDlOD9F/AdCtCoaMIFuqa1q52WQUmXjEUsxKodZ0bNPXCk5n8Hk+ghxgtKuqHNc9CuIWCPnBM5tFZOIRV/zc7LrhiwLM7xowQCtY17edTWfwAirALLCgWw+Y/+eKGCKrHTCg80tSrLVwdrvqiP+XmWQsjJrJtqHjrWPvzZxNRpGvNLG5U3c0j+zBe1ewVWrgr57b2vV4sd7Cl763iftPHN510jPGqmNYUezUnMmBFAhdiJNeYEYMkcsifCtmrEpbxU6tNXVB3AIhwl/bKCAaZrhlqb8FzKy+KTfopN5su6cBY4xhdSFlyW/LqbQHqxzOJSCF95pLj4rXHbDZAW74hXoLKvfWB0/EZL14pYxVFywoACDbZbI9jM4I0v8F2Mp8CmVZcWVD3U2oALPAfEqCrKi7CoGtUgOMAQdnrBdgKwspXLhew3cvXAeAgeOPUUhJkV1ZkKPG28wmJdRbbcfzyN5800GszCf3WFJ84akN1JptPKiL7wXC26w739IOhZqzoxnRAXPSC0z8f3JNhB+LgDFrW5DX9Y7PtAVxCzLxKJqKim+dzeOWw9mBd/e5pCaMHmTfIbfc04AB1rYNRdqDlxqwcIjhWA9vw1HxXAMmwtare29KtieQBCHe+22Vu6L/Ajo/s9UOWCNAI8hujXVQoALMAkYIs+miu1VsYD4VszV+WJ1PQVE5/vyZy2AMuO1o1tHjTMUiuzYGxYXDrrjbfCJ3UosQCjF84J4VfO9CAU9vFABoJ5xHnlzHXatzeM3h3a9HP28zOzg9msnEI4iGmaMaMDEadEuEHwoxpCVreZCiszdtJqwC0Wl4ZrMw9AYoZyGOSFbcs6EAtDv7S4U6ZKV/F1ikPXipAQPQM91jVLQRpHcFZHfkmplOAeblFmTnve/GBiTQ6foNimAyY2jAAtABE75pQQvlpgLMAvM9hNeXiw3LG5ACcWfzV89t4VUHZzDj8MgpKYV3bUFW9HBXux0w84nc6buxn3vdUaRjETz8zXUAwNdeuILNnToevGdlz3NFCOw4PmCFeguzKedeZ8aY415gbo8gAT3qxIIIfxJ3/14iOg0qH76BbKVj4KYNBaDdAKkc2LjefwzppQmrmdWFJM7na1BtxIz1QlbaaLZVj33ARNTU3v+3k7gJMb/33RDgA2bdm70RZBA0YMtzSYRDzNF4LC+gAswC/TpgdvRfAAw9Va3Zdsx+wkw6Ftm1BTlqvIe48DidRwZofjc/97qj+PNnLuFqqYGHnjiHI7kE3nrLoT3PTUpOdMBayCac/Rl62ZKMg+hMuTWCBPSwXxsdsGkW4QuGaTBnU/11QgI3bSgA87Zh/wuLsFPwIojbzMpCCrKi4rK+ET4qlRGlEuMwKGzdCKP3UAMmYrIAdywogMGLB70I0hZkNBzC0dlE4NzwqQCzgLgYmS+6WzZc8AUH0jHDXHTQ9tWoJKXIrg5YecQRpDg5uZFHBgAP3LMCReX42Feex7fOXsf733gckfDeX8VwiCERDY+sAeOco1BrOn5hWkg73QHTNWAudgC0DtjwE6/ogE2tD5i+aTqXknBsbvCCiaET6nPBaqscrTZ3twM2P1zbUjSsVrwtmsWxnR9z7CPOWV7lQAJAPKrFHvUqrvPVJkLMm1xNM+LmYNWlEWQ6FkEkxAbeUJgRHbBkAAowIJhWFFSAWWDO2HzTLk61poJivWW7AyYCdoHhd9+jkIqFd3WLqrKCSIjZvkMXd0pu3YmtLKTwlpsO4q+e30IiGsa7X3+s73O1n2m0EWS1qS0SOD2a6WVLMg6iMHJ6JG0mE49aEuHnq01EQsw1S4xJIy5yVixgDJ1Qn5GNiAhyUwOWTUYxm4wOvLM30h4cHLVbwejOjdl1KI8olRgHxpi25dpThN/EXCqGUMibVAFBJqHZT2Rd6mQyxnQD2unTgAHBtKKYzrOsw8QiYczEI8ZFV1hQ2NWAAZ1fkhsPzjh6jIB2B2nWS4kYIrtdLFGwrLoQCCt48N5V/PUPruJnX3tk4AlH+5lG64AJt/qcw52BhXQM+apmS2Lltf2lT30bT7y83ffjnGt3mW5mL2YSETy9KUNV+cALi/AA8yrSxmvE75oVCUB2SAdMCOPdHEECwPEhd/ZG2oPHHbDFTByxyPhWFGIE6aUGDNBer54dsIo8kS3gXCLqmGF0P7ScX4sdsAD5gAHAynwS1WYb1yqyLXeCSUIFmEUO6F5ggMkF3+YIEgB+7cdfhV+4cxlhF+6uUlIYzbaKpqKZQ5ZH9NaZiUfxf7/3tXj9ypzjxyi494Z5/J/vuh3/+NUHBz4vKUVGdsLv2Ds4+2s+n9JctGvN9tCxSbHewj+c2caPveoATgzYer15gB+VE/zojQv4k+9dxN+f2cY/etWBvs/LV5pTuwEJaLYx/+WfnsCbbxr8ewdoEScpKdxXMyOy8twcQQLaTdu3z+b7fnxSIvxQSDOXHqRPs4JhGO1hBwxA326Q10Hcgv/w9ltcuS6YOTgTx1WL8VGNZhuMuX+D4RSd6K4aFWDThhbIvbsDZncECQA3HEzjhoNpR49NYDjHNxVIEWksd+mfum3JyUPbA2MMv/D65aHPS0nhkbMgxTjW6fV2sxfYsAJMRIt88EdfgR+5ccHR47DDT922hN/6ix/g4SfODSzAtqveZuBNgneePGL5uYMCueWWKMDcvUCtzKfw5dMX0Wi1e3YjCrUm4tHQRDoVK/MpnB23AzZiYse45JJRrPcoHvPVJu6YzXl6LABw8lj/XFKnWMrG8e1z1y09t95qIxENB6YbbvYCu2vVveaBkwSjtPUB86mYET9zeYwCzE3Shm+W1jHy2l3aDZKxyMgaMGO7yuETey9bkn6cvlAAY8Dty856vtklFgnjl95wDF9/8RrOXqv0fd52WcaCh9tffieX7J8HaYwgXQ4rFtvT/Vbsd2otz8ePgtWFFC7ka2iPYUUxambtuOQSUs9Abi2IezrfA4eycVwtNyxZh4gCLCgcySUQCbFAbUJSAWYRcwfsSqmBbCJqdJz8QrLLOd5rd2k3SMdG34IsuzTaEBuCVjYh1zYKuOFA2lWPL6u89+7jkMIhPKJ7sHXDOUe+Or05kKMwm+x9kQY6I0ipxwavkwwL5S44HLdlh5WFFJptFZcK9ZG/xsQ6YHrYulm03Wi1UZGVqR3DL2XjaLW5JRudelMNjP4LACLhEI7NJQO1CUkFmEXm0zFcrzXRVjkuF+1bUHiBkZ0oCjCPA27dICmNLsJ3y19oYWavLUkvOOdY2yi44vk2CgdmYnj7HUv44nc3e3qC1ZptNFrq1I8g7ZBNRg2bh24MDZjLFylD29Lnzr5Qa06uAHMglLsqKwgx77ftcgkJTUU1xOZA5z09rVFc4rolZDSDaLTagfAAM2MlustPUAFmkYW0BM6B69XmSCasXmA4x5tGkF5vFjlNShrdhsJIAnD4Nei2JenHhes1XK82PdF2WOXBe1ZRbbbxhac29nzMMGGlEaTBrJURpMsasEw8ivmUhPP9CrC6t0HcZpzI4Cs3FKRi9re1x2W2hzFpx4R1Om9ClrIJAMDl4vCOZdBGkIB2Q3A+XwuMFYWlMwdj7D7G2IuMsTOMsY/0+PgDjLFrjLE1/c8/N33sA4yxH+p/PmB6/HWMsWf1r/lfmc+VfuINma/KI8UQeYGRnWgeQQa8A5aKaQHjo7yhKg0FjAFJh08i3bYk/VjT8y790gEDtPzRO4/P4vefPL9Ht7OtaxwXZqbz4jMKuYQmwu+lmelsQbp/Hzvozn6SI8hDmRgS0fBYm5AVWfFc/wWY44g67+NJ5EB6yaGs9t6+YiG9oN4MYAG2kES91cYVi5uek2bomYMxFgbwCQBvA3ALgPcwxm7p8dQ/4pyf0P98Sv/cOQC/AeBuAHcB+A3GmGgH/DcAvwLgRv3PfeP+MG4iWtKXiw3kqzIO+XEEaQqvbqsctWbb04BbN0jFIlBUjmZbtf25FbmNtBRxxVBxwWRL0o/TFwpIRMN41SF3tl5H5cF7V3Hheg1/84Orux43MvCm9O5/FHLJKFTe0ROa6WxBun+R0ly+9xY5Iu3B6yBuAWOaFcU4I0jhV+g1HaPdTgdse8rD6BdSMURCzFgkG0S91UY8aCPI+cF6Sb9h5dbtLgBnOOdnOedNAJ8H8A6LX/8nAXyVc36dc74D4KsA7mOMLQHIcM6/xbXWxu8DeKf9w/cOoYt54XIJnI9mwuo2IuaoKrcnJmx1mnECuStyy7Wffz7VWcrox+mNAm4/mu0ZszRJfvI1h7CUjeOhJ87tejw/5Xf/o5AzMgP3/r/2agsS0IKvt0oNIx5GYKQ9uGzgOQhhLj0qk+rU9wrknvYs1FCI4VAmbl0D5sHvtpOsDtFL+g0rr+4RAGbByKb+WDfvYow9wxj7ImNMGDz1+9wj+t+HfU0wxj7IGDvFGDt17do1C4frDqID9vzFEgD/WVAAnQ5YramYzA2DdQfTjbmrZxc3T+xaIHf/DpistPHCpZIrmZ/jEgmH8L43Hsc3X87jB1sl43HR0ZsjDZhBL52QwOsRJLD3wiLSHialAQO0Y9vYqUEZoUsNaN3F9AS2hI1AbpMbfr4iIxEN+27D3UkWs3HDTHwQQdSAHc4lIIXHT2fwCqfOHH8GYIVzfju0LtcjDn1dcM4/yTm/k3N+54ED/Q0k3SYTjyISYnj+UhGAPwsw8WapyG3TBmDAR5DGZqf9DljZxdGGFsjdvwP2/KUSmm0VJ5f9I8A3857XH0M8GsLDT6wbj21XmpiJRQK1eu42vXRCAq+c8AHTtmHXhaWoLwi4lR9ohdX5FFptjkuF4Rf1XlQarYlowETszy4RfrVpbDlPK4tZax2wejN4W5DhEMPyXGKqRpAXAZgty4/qjxlwzvOcc9EO+BSA1w353Iv63/t+Tb8RCjHMpSSs62aIS5nEhI9oL6EQQ1IKoyYrrm0Aeo3hbea7DljHlqQXaxcKANwJXXeC2ZSEnzl5BF8+fdHoouSr02tAOSqGTqjHJqTc8m4E2S/4WhSGk+yAHdczY0c1wKzKbaQm0KmPR8NIRMO7xsvbFXlqNyAFS5k4LhcbQxeb6n2SF/zO6kKqr2mx37By5ngKwI2MsVXGmATg3QAeNT9B13QJ7gfwgv73xwH8BGNsVhff/wSAxznnlwGUGGNv0Lcf3w/gK2P+LK4jdGCJaNjxfEGnSOnO8SI/MehbkOL4R9KAueiDJmxJ+pl0nt4oYCkb9+WyhuCBe1YhKyo+99QFACKIe7ovPnYR2qqdHp5vXo4g07EIFtKxPR2wSeVAmhnXikK7UZrM8eeS0S4biubUeoAJFrNx1FttlOqDb2rrzbahwQ0SK/MprOerltz+J83QMwfnXAHwIWjF1AsAvsA5f54x9nHG2P360z7MGHueMfY0gA8DeED/3OsAfhNaEfcUgI/rjwHAv4LWLTsD4GUAf+nYT+US4o25mI37Nh8rJWnO8WIEGXQfMHECqIxgxupqByzVyYPsxdrGjm+7X4KbFmdw7w3z+MyT59Fqq/vi4mMXY0zVqwPmkRO+YHUhuWcTUnRvJinCPzATQ0oKjzT2UVU+0cSObGJ3IPd+6IAJ+cwgHVirrUJReeA0YIDWLZYV1ZLObdJYOnNwzh/jnL+Kc/5Kzvlv6Y99jHP+qP73j3LOX8M5v4Nz/mbO+Q9Mn/tpzvkN+p+HTI+f4pzfqn/ND/EAOKeJ1WQ/uuALklJEF+HrI8iAd8BSpoBxu7h5Yhejul46sO2KjI3rdV/5f/XjgXtWcbnYwOPPb+kxRNN98bFLJBzCTDzSU4TfVFRIkZBnN2Mr86k9Yz5xXJPUgGlWFKmRNs+EtGASGjBAG90WdRG+qnJc3wdjeLHBP8iMVaQDBHUECYxnDuwVwdoxnTDCIdyPFhSCdCyCqtw2Am6nRwNmbwTJOXfV4HHBCOTe2wHr6L/8KcA385abD+LYXBK/9w/ncL3apCDuHmhjqt42FF6MHwUrCylcK8u7usE7tRaSUtiTRYBBjGpFMWm7nFyy0wErNVpQVD71NyGHLMQRNfTzbdBE+EB/vaQfoQLMBuKNecjHBVgyFkbVZEORCvg6dbrL3d8qtWYbnLt3YjeSEXp0wNY2CgiHGG49nHXleztJOMTwgXtWcPpCASrH1F98RkEL5O49gvSy8Ol1Z1+oNycqwBesLCSxsVNHy6YVhVt5rVbJJSWji9gxYZ386+kmB2fiYGzwCFJ0wII4glzKxBGLBMOKggowG4jWtJ87YCkpYmjAklIYYRdc4L0kHgmDMdgO5DYKUJdO7NmEZkvSywtsbaOAmxdnAnP3+PN3HjVMfKd9/DIK2UTvPEi5pXrbAesRfF2otQyd2iRZmU+hrXJs7gzPGDRTliddgGndTc65YUQ8rS74AikSwkI6NrADFuQCLBTS0hnGicfyimC3RzzGEOH7WgMWRq3ZRrUZ/BxIQLfWiNoP5C67fGctbEm6O2CqyvH0RgHvOHnYle/rBpl4FD/3uqN45MnzUy9AHoXZpIQL1/eezGWl7YkFhWBlQbN7MK/YF2pNzKYmX4CZu3Pi71aoTFgqMZuMQlE5qs028tXpdsE3s6hbUfRDJC4ELYpIsDKfwj+c2cbP/t9PDHzeb7/rdtx4aMajo9pL8K/QHnLnyhze/fpl3P2K+UkfSl9SsQgqsuKqCanXiEBuO4gOmJtboPM98iBfvlZBWVZwwqcGrP34l2+6AfVWG7cf9f/Y1Gu6rQoEXo8gk1IEhzKxXduGhXoLS9nJexIaupvtKt5s4/POXqsAAI7kJvMz5BJasbVTbXaCuPfBTchiNo6NHjcVgiB3wADgPXcdM36GQUzazWA6rtAekYlH8X+86/ZJH8ZAUjGtA1ZuuCdA9xrhbWaHqux+EsBCWjJ0I4LTugA/CBuQZhazcfyfP3fHpA/Dl+SSEkqNFtoq3zXS1wowb1UcWij37hHkJD3ABPMpCTOxiO1NyNMbBRzKxCYm6xCvXbHewnalCcY68VPTzFI2ju+cu973442AF2Bvvvkg3nzzwUkfxlBIAzZlJKUI2vo69bR0wIS7vx3cHkECeiB3lwbs9EYBmXgEr7AxhiH8TS4RBedAqUsHJre83YIE9G1DvchRVY5CremLAowxhpWFlJEUYpW1jQJOLOcm1okQSQc7tSbyFRmzSQkRj3zdJsliNo5ivdXX3qfe1JYpgqJjDSrT/5u2zxAFx5VSYyo0YIDogPlzBNmtAVvbKOCO5RxCAV9+IDoIjVW3EF9WVMQ87hCsLKSwXWmi3GihLCtQ+WRjiMwcn0/a2jzLV2Scz9cmatdiDlvPV5qG1dC0szjEiiLoI8igQAXYlCGc47crsmsbgF6jufvbG0FWGu4b0S6kY6g128ZdZFVW8OJWKRD+X4R1DJ1QlxfYpEaQALC+XUNRmLD6YAsS0Lpzmzs1NBVrVhRPbxYATHZcnzUKsKZuRLxPCrAhbvhBNmINElSATRmi6FL55NylnSY5RgfMzSK02w3/2YtFqBw4GTD9FzEYQydU6+6AeT+CFJuQ5/JVoyDM+aQDtjKfgsqBjR1rY8i1CwWEGHDbkcktfojiWnTApt2CQiAWN/p1wIJsxBokqACbMswFx7RowNJSxHYYd1lWIEVCkFy8QApbErG+LgT4d1ABNlWYdUJmmh5vQQLA8bmO3YMYifpFNL5iMwLm9EYBNy1mJtqplyIhpKQwCvUWtivyvinAxAiynxWF0QHz+AZjv0Gv7pSRMt2xuLkB6CXJWNi+DYUHW6BGIHdZE+KvbexgZT6JuX2iI9kvmHVCZmQ9C9JLElIYS9m4VoAZHTB/vM9XTVYUw1BVbgjwJ00uKeFqWUapoewbDVhCCiObiOJKnxFkrdmGFA7ti4WESUKv7pSRlKavA5aStBGknbz2qotB3AJjBFmVwTnH6Qv+uKAQzjITj4Ix7MmDnMQWJNAJ5RYFoV9GkLPJKDJxa1YUZ7erKDcUX4zrc8koXr6q+ZHtpyiupWx/M9ZGq03jRw+gAmzKMIvOp0cDFobKtY6DVSqy+0kARges0sTlYgNXyzIJ8KeQcIj1jCPStiAnUIDpwddiJOoXET5jTA/lHq4BO31hBwBw8ljO5aMaTi4ZxdltUYD5o5j1gkOZeP8tyGabNiA9gAqwKSMZ67xppmULUhRSFRtjyHLD/QIsIYWRksLIV5pY2ygACJ4BK2GNXCK6K5Cbc+65E75gdSGJnVoLF/I1zMQiiPpoTLSykLI0glzbKGAmFsErD6Q9OKrB5JISGi3t5m7ag7jNDOqA1akD5gn+eecSjpAyjyCnpAATY1U7QnwvOmAAsDATQ74q4/SFHUiREF69lHH9exLek01Ku0aQzbZ2wZ7UCBLQipisT/RfgpX5FC4V64aTej9OX/CPX17O1EHcLyJ8QLOiyFflnrYh9VabLCg8gAqwKSMeDUGc09w0IfUSsVhgx4qi4oEGDNDd8PUO2K2HM56LsglvmO3KgxTj8EkUYELsfna76hsTVsHqQgqcY3DOYLONF6+UfdMtNr+G+0kDtpiJg3PganlvF6zRaiMxgfH6foNe4SmDMWZ0waalAyZGqXY2ISsejCAB7YS9VWrg2YvFwAVwE9bJJaIo1DsdMFkfWXnthA8Ay3NJiOQev2xACgwrigGRRM9eLKKtct8UYOI1jOmWFPsFw4y1xxiy3qQRpBdQATaFCB3Y1GxBxkQHzOYI0oOffyEt4czVChotFSd8ICgm3CGXlFComjtg2u/iJDpg8WgYh3UjTb9sQApW5jWj2EFeYEKA75f3i3gNF9KxiWVSTgLDjLWHFUW9RSJ8L6ACbAqZtg5YRwNmrQPWVFTIiurJFqjYhATIAX+aySWjKMsKWrr2a5IjSKAzhsz5ZANSkEtKyCWjODfAimJto4DluYRv9FbiNdxPG5DAkA4YacA8gQqwKSQViyAaZhO7ODiNKCStdsDEqNKbEaS4e5ZwdDbh+vcjJoPQCZV0KwpjBDmBLUigE0nkFxd8MyvzqYEdsLWNAk76aFwvwtb3iwmrIBOPIBEN99yEbJANhSdMxxWa2EVSCiMVi0xNO10EjFvVgAm7inTc/YuTEO2eWJ6dmteb2IvQCQkrCmMLckJCZbEJmfXZCBKA7gXWuwDbKjZwudjwjf4LALJ6HuR+EuADml54KRvvP4IkDZjrUAE2haRikakZPwImEb7FLchyQ3TA3D+BCN8gPxhKEu4hdEJFXYgvtyanAQM6BZjfRpCAsKJo9LSiWNvwl/4L6BTXfhmJeslitrcZK2nAvIEKsCnkja+Yxz961YFJH4ZjxCIhhEPMsg+Y0QHzIAvzpkMzuOnQDH781Ydc/17E5BCFzo4uxJ+0BuzEsRxuXpzBHcvZiXz/QYjx6Pkem5CnLxQghUN4zWH/+OXNJiXctTqHu1fnJn0onrPYww1fVTkaLZU0YB4wPW0SwuBXfuwVkz4ER2GMISmFLTvhV2TtIumJD1g6hsf/zY+5/n2IySI0YCKOqFOATeYitZCO4a9+zZ+/d+ZQ7psWZ3Z97PRGAa8+nJnY69aLcIjhC//LGyd9GBNhMRvHlVIDqsoNU1zxu00jSPehDhgRCFJSBDWLI8iK3imbpjEsMVmE47xww5+kDYXf6XiB7daBKW0Vz24WaVvYRyxl41BUju2qbDxW10fHNIJ0Hzp7EIEgGQtb3oKs6BqwaUkCICZPJh5BOMQMN/xJb0H6mUw8ivmUtEeI/+KVMuqtNuklfcShzF4rCnGjSwWY+1ABRgSCdCxiYwuyZXwOQTgBYwzZRBQ7RgdssluQfqdXKDcF1vsPYcZqtqIQyxM0gnQfOnsQgSApha2L8BsKGOvYVxCEE2hxREIDRiPIQazMp/aMIE9fKGAuJeHYXHJCR0V0I8xYr5isKOpNXQNGHTDXobMHEQhSUsS6DYWsIC1Njw8a4Q9yyahJA0YjyEGszCdxpSTv0m2ubRRwYjlH70sfMZ+SEA2zXR2wOnXAPIMKMCIQpGIR1GxowKYlB5PwD7mktEcDJlEHrCdCiC+sKIr1Fs5crZAA32eEQgwHZ3ZbUYgCjGwo3IfOHkQgSMWs21BUmwrpvwjH0TpgnRFkNMwQDlE3pxfCikII8Z/ZLADwlwErobHUZcZab9IWpFdQAUYEgqQUsRzGXaYOGOECuYRkjCCbikrjxwGIDpgI5V67UAAA3H40N6EjIvpxqCuOiET43kEFGBEIUrEIaq02VJUPfW5Fpg4Y4TyzySiqzTaaigpZUUmAP4B0LIKFdMzogK1tFHDDwTSyPoxO2u8sZeK4XKyDc+3cSj5g3kFnECIQpKQwOO+cHAZRaSjkAUY4jsgMLNSbkJU2FWBDWF1IYn27Bs45TusCfMJ/LGbjaLRUFPUNXxpBegedQYhAkLQRyF2RFaQkKsAIZzECuWstyIpKAvwhrMyncC5fxcb1Oq5Xm2TA6lOEF5gYQxoifIl+v93G0ivMGLuPMfYiY+wMY+wjA573LsYYZ4zdqf/7vYyxNdMflTF2Qv/YN/SvKT520JGfiJhK0jHtbsyKFxhtQRJuIDpgO7UW5BZpwIaxspDCtbKMfzizDYAMWP3KYjYGoGPG2mi1EWKAFKYCzG2GXqUYY2EAnwDwVgCbAJ5ijD3KOf9+1/NmAPwqgG+LxzjnnwXwWf3jtwH4U875munT3ss5PzXuD0FMP0m9ozVsE5JzjkpTwQxpwAiHMQK5a/oIklzwByI2If907SIS0TBuOjQz5DOISbAoOmB6AVZvtpGIhsmvzQOsnEHuAnCGc36Wc94E8HkA7+jxvN8E8NsAGj0+BgDv0T+XIGwjRorDvMBqzTY4B3XACMcRAvKCPoIkDdhgVua1Auw7567jtqNZRKij4ksOzsTAmKkAa7VpA9IjrLwjjgDYMP17U3/MgDH2WgDLnPO/GPB1/imAz3U99pA+fvwPrE+5zRj7IGPsFGPs1LVr1ywcLjGNJPUR5DANmOiQpWO0bUU4y2xK74DVm3oBRhepQawsdCKHyIDVv0TDISykY7sKMDJh9Yaxb0kYYyEA/xnAvxvwnLsB1Djnz5kefi/n/DYAP6r/eV+vz+Wcf5Jzfifn/M4DBw6Me7hEQBG2EsMCucsNvQCjDhjhMCkpjEiIaRow2oIcSlKK4FBG0xeRAN/fLGXjuFzqaMBoA9IbrJxBLgJYNv37qP6YYAbArQC+wRhbB/AGAI8KIb7Ou9HV/eKcX9T/Wwbwh9BGnQTRExGsPUyELzpgpAEjnIYxZsQRyS2VNGAWOK6PIU8sz074SIhBLGbi2CrWAWgyjiSNID3ByhnkKQA3MsZWGWMStGLqUfFBznmRc77AOV/hnK8A+BaA+4W4Xu+Q/QJM+i/GWIQxtqD/PQrg7QDM3TGC2IXQgA0dQeodsBQVYIQLiEBuGkFa48RyDjccTGMxG5/0oRADWDTFEdWbNIL0iqFXKc65whj7EIDHAYQBfJpz/jxj7OMATnHOHx38FfBjADY452dNj8UAPK4XX2EAXwPwP0b6CYh9gSiohonwK7JmJkhO+IQb5BJaHmSTRPiW+PWfvAm/9uM3TvowiCEsZuMoNRRUZQWNVtvQOxLuYukqxTl/DMBjXY99rM9z39T1729AG0uaH6sCeJ2N4yT2OVIkhGiYDbWhqOgjSnLCJ9wgl5SwuVMjDZhFouEQorT96HuW9A7lVqmBequNw9QB8wR6ZxCBwUogd6VBHTDCPXLJKIp13YaCLlLElHAooxVgV4paAUYifG+gqxQRGNKxCKpDR5CkASPcYzYZxU6tiVabUweMmBpEHNHlYgP1poo4ifA9ga5SRGBISuHhNhSyglgkRDl9hCvkkhIaLRUARbUQ08NipjOCJBsK76AzCBEYklY6YA2Fxo+Ea4g8SABkQ0FMDQkpjFwyisvFOo0gPYTOIERgSMfCwzVgMgVxE+6RS3S2w8iGgpgmFjNxbFyvo61yiiLyCCrAiMCQlCLDtyCpA0a4yKy5A0ZjbmKKWMzGcW67CgDkA+YRdAYhAkNKClvwAaMCjHCPLI0giSllKRvH5k4NAGgE6RF0BiECQzIWQc1CGDd5gBFuMZukESQxnRzKxKFy7e8JiUoDL6BXmQgM6ZiFESR1wAgXydEIkphSlkxxUdQB8wY6gxCBISmF0WipaIvbtB5UGiTCJ9wjEQ0bFifUASOmiUXdCwwgDZhXUAFGBAYRyD1oDFmWFTJhJVyDMYZcQuuCkQaMmCaEFxhAHTCvoDMIERiGBXI3FRVNRcUMFWCEiwgdGI0giWli0TSCTEp0DvUCOoMQgSEV0+7K+unAhEs+acAINxGbkDSCJKaJTDyCpO7/RSJ8b6BXmQgM4q6sJvfugInCLB2P9vw4QTiBMYKkDhgxRTDGjDEkacC8gc4gRGAQHbBqHw1YuUEdMMJ9xAiS8kaJaUOMIUkD5g10BiECgxDh9wvkFh0w8gEj3CSXpA4YMZ0YBRhFEXkCnUGIwNDpgPUbQbYAUAeMcJeDmTgiIUZCZWLqODaXhBQJIU76Rk+gMwgRGIwtyD4dMDGCJBsKwk3e/fplvPZYjroExNTxyz+yijffdBChEJv0oewLqANGBAbRcei3BUkjSMILUrEITh6bnfRhEITjZOJR3LGcm/Rh7BuoACMCg1iR7ucDRjYUBEEQRFCgAowIDNFwCFIk1HcLstJQwFinUCMIgiAIv0IFGBEo0rFIXx+wsh7EzRjpFwiCIAh/QwUYESiSUri/DUVDoRgigiAIIhBQAUYEipQU6T+CpCBugiAIIiBQAUYEilQs3FeEX5EVpGkDkiAIgggAVIARgSIViwy0oaANSIIgCCIIUAFGBIqkFO4fxt1QyAOMIAiCCARUgBGBIhUbrAGjDhhBEAQRBKgAIwJFSooM3IJMx6IeHxFBEARB2IcKMCJQJGPhnmHcqspRaZIInyAIgggGVIARgSItRdBUVLTa6q7Ha602OAfSMXLBJwiCIPwPFWBEoEjqGq9uIX6lIXIgaQRJEARB+B8qwIhAkdJzHruF+MKagkaQBEEQRBCgAowIFEYHrE8BRlFEBEEQRBCgAowIFELjVe03gqQOGEEQBBEAqAAjAkVS0gqsbiuKitwCAPIBIwiCIAKBpQKMMXYfY+xFxtgZxthHBjzvXYwxzhi7U//3CmOszhhb0//8d9NzX8cYe1b/mv+VMcbG/3GIaSclCrAuK4qyIcKnAowgCILwP0OvVoyxMIBPAHgrgE0ATzHGHuWcf7/reTMAfhXAt7u+xMuc8xM9vvR/A/Ar+vMfA3AfgL+0+wMQ+4uUPoLspwGjAowgCIIIAlY6YHcBOMM5P8s5bwL4PIB39HjebwL4bQCNYV+QMbYEIMM5/xbnnAP4fQDvtHzUxL4lpRdY3YHcYiSZogKMIAiCCABWCrAjADZM/97UHzNgjL0WwDLn/C96fP4qY+w0Y+xvGWM/avqam4O+pulrf5AxdooxduratWsWDpeYZpK6DUW3D1hZVhCLhCBFSNZIEARB+J+x2wWMsRCA/wzggR4fvgzgGOc8zxh7HYA/ZYy9xs7X55x/EsAnAeDOO+/kYx4uEXAMEX73CLKhYIY2IAmCIIiAYOWKdRHAsunfR/XHBDMAbgXwDV1HvwjgUcbY/ZzzUwBkAOCcf5cx9jKAV+mff3TA1ySInoRDDIlouMcWpEL6L4IgCCIwWJnXPAXgRsbYKmNMAvBuAI+KD3LOi5zzBc75Cud8BcC3ANzPOT/FGDugi/jBGHsFgBsBnOWcXwZQYoy9Qd9+fD+Arzj7oxHTSqpHIHelQUHcBEEQRHAYesXinCuMsQ8BeBxAGMCnOefPM8Y+DuAU5/zRAZ/+YwA+zhhrAVAB/AvO+XX9Y/8KwMMAEtC2H2kDkrBEKhZBrasDVpYVw6KCIAiCIPyOpSsW5/wxaFYR5sc+1ue5bzL9/UsAvtTneaegjS4JwhZJKYJKDyf8w7n4hI6IIAiCIOxBK2NE4EhJ4T0+YNUmacAIgiCI4EAFGBE4krEIacAIgiCIQEMFGBE40rFwTw1YOhad0BERBEEQhD2oACMCR1KK7LKhkJU2mopKPmAEQRBEYKACjAgcKWm3DUVVF+STBowgCIIIClSAEYEjFYvsEuFXGpQDSRAEQQQLKsCIwJGKRdBqc8iK1vkSwdzUASMIgiCCAhVgRODoDuQWBRhpwAiCIIigQAUYETjEqFEEclfkFgDqgBEEQRDBgQowInCIyCEhvi/rGjDyASMIgiCCAhVgROBIxrQRZKcDpo8gqQNGEARBBAQqwIjAITpghgaMtiAJgiCIgEEFGBE4Uj06YIx1xPkEQRAE4XeoACMCR0cD1inA0rEIGGOTPCyCIAiCsAwVYETg6GjAOiNI0n8RBEEQQYIKMCJwCLuJmrkDRhuQBEEQRICgAowIHPFIGIztHUESBEEQRFCgAowIHKEQQzLaCeQuNxSk49EJHxVBEARBWIcKMCKQmAO5tQ4YbUASBEEQwYEKMCKQpGIRVEw+YDSCJAiCIIIEFWBEIElKYUOEX5UVpGM0giQIgiCCAxVgRCBJxSKoNhWoKkelSVuQBEEQRLCgAowIJCkpjKrcRq3VBueUA0kQBEEECyrAiECS1DtgIgeSOmAEQRBEkKACjAgkKSmMmtxGRW5p/6YOGEEQBBEgqAAjAonQgJX1DhiNIAmCIIggQQUYEUhSUgRVWUFFphEkQRAEETyoACMCSTIWhsqBfKUJAOQDRhAEQQQKKsCIQCIKriulxq5/EwRBEEQQoAKMCCRJSSu4tvQCbIZGkARBEESAoAKMCCQpSct+vFqStX9TB4wgCIIIEFSAEYEkZRpBxiIhRMP0q0wQBEEEB7pqEYEkFdM6YFfKDRo/EgRBEIGDCjAikAgN2JWSTAJ8giAIInBQAUYEElF0NRWVPMAIgiCIwGGpAGOM3ccYe5ExdoYx9pEBz3sXY4wzxu7U//1Wxth3GWPP6v99i+m539C/5pr+5+D4Pw6xX0jqInyALCgIgiCI4DH0ysUYCwP4BIC3AtgE8BRj7FHO+fe7njcD4FcBfNv08DaAf8I5v8QYuxXA4wCOmD7+Xs75qTF/BmIfYt56TMeiEzwSgiAIgrCPlQ7YXQDOcM7Pcs6bAD4P4B09nvebAH4bQEM8wDk/zTm/pP/zeQAJxlhszGMmCMQiIYSY9vd0LDz4yQRBEAThM6wUYEcAbJj+vYndXSwwxl4LYJlz/hcDvs67AHyPcy6bHntIHz/+B8YY6/VJjLEPMsZOMcZOXbt2zcLhEvsBxpjRBSMNGEEQBBE0xhbhM8ZCAP4zgH834DmvgdYd+19MD7+Xc34bgB/V/7yv1+dyzj/JOb+Tc37ngQMHxj1cYopI6ZuQNIIkCIIggoaVAuwigGXTv4/qjwlmANwK4BuMsXUAbwDwqEmIfxTAlwG8n3P+svgkzvlF/b9lAH8IbdRJEJZJ6qNH8gEjCIIggoaVAuwpADcyxlYZYxKAdwN4VHyQc17knC9wzlc45ysAvgXgfs75KcZYDsBfAPgI5/wJ8TmMsQhjbEH/exTA2wE859QPRewPxPYjbUESBEEQQWNoAcY5VwB8CNoG4wsAvsA5f54x9nHG2P1DPv1DAG4A8LEuu4kYgMcZY88AWIPWUfsfY/wcxD5EWFFQAUYQBEEEDUtXLs75YwAe63rsY32e+ybT3/8TgP/U58u+ztohEkRvDA0YjSAJgiCIgEFO+ERgSdEIkiAIgggoVIARgUUEclMBRhAEQQQNKsCIwJKkESRBEAQRUKgAIwKLGEHOUAeMIAiCCBhUgBGBZTETR1IKI5MgI1aCIAgiWFDrgAgsP3/nUbzppgOIRykLkiAIgggW1AEjAks0HMLhXGLSh0EQBEEQtqECjCAIgiAIwmOoACMIgiAIgvAYKsAIgiAIgiA8hgowgiAIgiAIj6ECjCAIgiAIwmOoACMIgiAIgvAYKsAIgiAIgiA8hgowgiAIgiAIj6ECjCAIgiAIwmOoACMIgiAIgvAYKsAIgiAIgiA8hgowgiAIgiAIj6ECjCAIgiAIwmOoACMIgiAIgvAYKsAIgiAIgiA8hnHOJ30MlmGMlQG8OOnjmBIWAGxP+iCmCHo9nYNeS+eg19I56LV0jv30Wh7nnB/o9YGI10cyJi9yzu+c9EFMA4yxU/RaOge9ns5Br6Vz0GvpHPRaOge9lho0giQIgiAIgvAYKsAIgiAIgiA8JmgF2CcnfQBTBL2WzkKvp3PQa+kc9Fo6B72WzkGvJQImwicIgiAIgpgGgtYBIwiCIAiCCDxUgBEEQRAEQXhMYAowxth9jLEXGWNnGGMfmfTxBAnG2KcZY1cZY8+ZHptjjH2VMfZD/b+zkzzGoMAYW2aMfZ0x9n3G2POMsV/VH6fX0yaMsThj7DuMsaf11/I/6o+vMsa+rb/X/4gxJk36WIMCYyzMGDvNGPtz/d/0Wo4IY2ydMfYsY2yNMXZKf4ze5yPAGMsxxr7IGPsBY+wFxtgb6bUMSAHGGAsD+ASAtwG4BcB7GGO3TPaoAsXDAO7reuwjAP6ac34jgL/W/00MRwHw7zjntwB4A4B/rf8u0utpHxnAWzjndwA4AeA+xtgbAPw2gN/hnN8AYAfAP5vcIQaOXwXwgunf9FqOx5s55ydMnlX0Ph+N3wXwV5zzmwHcAe13dN+/loEowADcBeAM5/ws57wJ4PMA3jHhYwoMnPO/A3C96+F3AHhE//sjAN7p5TEFFc75Zc759/S/l6GdSI6AXk/bcI2K/s+o/ocDeAuAL+qP02tpEcbYUQA/DeBT+r8Z6LV0Gnqf24QxlgXwYwB+DwA4503OeQH0WgamADsCYMP07039MWJ0DnHOL+t/3wJwaJIHE0QYYysATgL4Nuj1HAl9ZLYG4CqArwJ4GUCBc67oT6H3unX+C4D/DYCq/3se9FqOAwfwPxlj32WMfVB/jN7n9lkFcA3AQ/p4/FOMsRTotQxMAUa4CNe8SMiPxAaMsTSALwH4Nc55yfwxej2twzlvc85PADgKrdN982SPKJgwxt4O4Crn/LuTPpYp4kc456+FJn3514yxHzN/kN7nlokAeC2A/8Y5Pwmgiq5x4359LYNSgF0EsGz691H9MWJ0rjDGlgBA/+/VCR9PYGCMRaEVX5/lnP+J/jC9nmOgjyS+DuCNAHKMMZFTS+91a9wL4H7G2Do0icZboOlu6LUcEc75Rf2/VwF8GdoNAr3P7bMJYJNz/m3931+EVpDt+9cyKAXYUwBu1Dd6JADvBvDohI8p6DwK4AP63z8A4CsTPJbAoOtqfg/AC5zz/2z6EL2eNmGMHWCM5fS/JwC8FZqm7usAfk5/Gr2WFuCcf5RzfpRzvgLt/Pg3nPP3gl7LkWCMpRhjM+LvAH4CwHOg97ltOOdbADYYYzfpD/1jAN8HvZbBccJnjP0UNI1DGMCnOee/NdkjCg6Msc8BeBOABQBXAPwGgD8F8AUAxwCcB/ALnPNuoT7RBWPsRwD8PYBn0dHa/D+g6cDo9bQBY+x2aOLbMLSbwS9wzj/OGHsFtC7OHIDTAH6Jcy5P7kiDBWPsTQD+V8752+m1HA39dfuy/s8IgD/knP8WY2we9D63DWPsBLTlEAnAWQAPQn/PYx+/loEpwAiCIAiCIKaFoIwgCYIgCIIgpgYqwAiCIAiCIDyGCjCCIAiCIAiPoQKMIAiCIAjCY6gAIwiCIAiC8BgqwAiCIAiCIDyGCjCCIAiCIAiP+f8DKN0RJPxfROEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(k_vs_score[1:],index=range(3,X.shape[1],1)).plot(figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GLQVL39etxA7",
    "w1XbpuI2txBD",
    "uVhYASlKtxBE",
    "kA8xUq80txBG",
    "WvunB2T2txBH",
    "yaZKt1aQtxBH",
    "o0FDRw9otxBI",
    "4Ps-TQJZtxBK",
    "Hvi7sE4mtxBK",
    "EnI0cgNDtxBL",
    "O2JRt_catxBL",
    "0t2vvLQstxBM",
    "WFxO_oNltxBN",
    "MR3swdq4txBO",
    "C6yWLR4StxBO",
    "BQF6Nd4NtxBW",
    "oqvY9hq6txBW",
    "O_VKfbbptxBX",
    "Q2aQq_0ZtxBY",
    "mmSDP734txBZ",
    "EVKPJo8KtxBZ",
    "gHYaLzzAtxBa",
    "u4_fMM9otxBa",
    "UMDvNtcitxBb",
    "TAmsdvUwtxBd",
    "mR1zw3eJtxBe",
    "F4t54GmWtxBf",
    "I-i7Chs1txBg",
    "DVLZJzx-txBh",
    "jSZ3ULpJtxBi",
    "c329l7BptxBj",
    "csFs7BZWtxBl",
    "NpEryjovtxBl",
    "UXo3Ahr0txBp",
    "aX2TRyThtxBr",
    "aIHcMoYXtxBt",
    "0bP1g5m0txBu",
    "7qGStQbAtxBw",
    "kI0uCb6ttxBz",
    "YvVsjbrptxB4",
    "AUrsC36KtxB-",
    "Gji2KE9ntxCB",
    "VIn0WCHTtxCC",
    "fZ134YHCtxCD",
    "d9p5fXTGtxCE",
    "MIeCms0NtxCF"
   ],
   "name": " Experimentos_+_EDA_(5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
